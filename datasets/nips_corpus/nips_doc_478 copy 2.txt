I I 
Incrementally Learning Time-varying Half-planes 
Anthony Kuh* 
Dept. of Electrical Engineering 
University of Hawaii at Manoa 
Honolulu, HI 96822 
Thomas Petsche* 
Siemens Corporate Research 
755 College Road East 
Princeton, NJ 08540 
Ronald L. Rivest* 
Laboratory for Computer Science 
M_IT 
Cambridge, MA 02139 
Abstract 
We present a distribution-free model for incremental learning when concepts vary 
with time. Concepts are caused to change by an adversary while an incremental 
learning algorithm attempts to track the changing concepts by minimizing the 
error between the current target concept and the hypothesis. For a single half- 
plane and the intersection of two half-planes, we show that the average mistake 
rate depends on the maximum rate at which an adversary can modify the concept. 
These theoretical predictions are verified with simulations of several learning 
algorithms including back propagation. 
1 INTRODUCTION 
The goal of our research is to better understand the problem of learning when concepts are 
allowed to change over time. For a dichotomy, concept drift means that the classification 
function changes over time. We want to extend the theoretical analyses of learning to 
include time-varying concepts; to explore the behavior of current learning algorithms in the 
face of concept drift; and to devise tracking algorithms to better handle concept drift. In this 
paper, we briefly describe our theoretical model and then present the results of simulations 
*kuh@ wiliki.eng.hawaii.edu *petscheleaming.siemens.com *rivest@theory. lcs.mit.edu 
920 
Incrementally Learning Time-varying Half-planes 921 
in which several tracking algorithms, including an on-line version of back-propagation, are 
applied to time-varying half-spaces. 
For many interesting real world applications, the concept to be learned or estimated is not 
static, i.e., it can change over time. For example, a speaker's voice may change due to 
fatigue, illness, stress or background noise (Galletti and Abbott, 1989), as can handwriting. 
The output of a sensor may drift as the components age or as the temperature changes. In 
control applications, the behavior of a plant may change over time and require incremental 
modifications to the model. 
Haussler, et al. (1987) and Littlestone (1989) have derived bounds on the number of mistakes 
an on-line learning algorithm will make while leaming any concept in a given concept class. 
'However, in that and most other learning theory research, the concept is assumed to be fixed. 
Helmbold and Long (1991) consider the problem of concept drift, but their results apply to 
memory-based tracking algorithms while ours apply to incremental algorithms. In addition, 
we consider different types of adversaries and use different methods of analysis. 
2 DEFINITIONS 
We use much the same notation as most learning theory, but we augment many symbols 
with a subscript to denote time. As usual, X is the instance space and xt is an instance drawn 
at time t according to afixed, a. rbitrary distribution Px. The function ct: X --+ {0, 1 } is the 
active concept at time t, that is, at time t any instance is labeled according to c t. The label 
of the instance is at -' Ct(Xt). Each active concept ci is a member of the concept class C. A 
sequence of active concepts is denoted c. At any time t, the tracker uses an algorithm 12 to 
generate a hypothesis t of the active concept. 
We use a symmetric distance function to measure the difference between two concepts: 
cl(c,c') = ?x[x: c(x) c'(x)]. 
As we alluded to in the introduction, we distinguish between two types of tracking al- 
gorithms. A memory-based tracker stores the most recent m examples and chooses a 
hypothesis based on those stored examples. Helmbold and Long (1991), for example, 
use an algorithm that chooses as the hypothesis the concept that minimizes the number 
of disagreements between t(xt) and ct(xt). An incremental tracker uses only the previous 
hypothesis and the most recent examples to form the new hypothesis. In what follows, we 
focus on incremental trackers. 
The task for a tracking algorithm is, at each iteration t, to form a good estimate t of the 
active concept ct using the sequence of previous examples. Here good means that the 
probability of a disagreement between the label predicted by the tracker and the actual label 
is small. In the time-invariant case, this would mean that the tracker would incrementally 
improve its hypothesis as it collects more examples. In the time-varying case, however, we 
introduce an adversary whose task is to change the active concept at each iteration. 
Given the existence of a tracker and an adversary, each iteration of the tracking problem 
consists of five steps: (1) the adversary chooses the active concept ct; (2) the tracker is 
given an unlabeled instance, xt, chosen randomly according to Px; (3) the tracker predicts 
a label using the current hypothesis: t - t-(xt); (4) the tracker is given the correct label 
at '= Ct(Xt); (5) the tracker forms a new hypothesis: t = 12(t-, (xt, at)). 
922 Kuh, Petsche, and Rivest 
It is clear that an unrestricted adversary can always choose a concept sequence (a sequence 
of active concepts) that the tracker can not track. Therefore, it is necessary to restrict 
the changes that the adversary can induce. In this paper, we require that two subsequent 
concepts differ by no more than 'y, that is, d(c t, ct-) < 'y for all t. We define the restricted 
concept sequence space Cy = {� � ct  C, d(ct, Ct+l) _< 'Y}. In the following, we are 
concerned with two types of adversaries: a benign adversary which causes changes that are 
independent of the hypothesis; and a greedy adversary which always chooses a change that 
will maximize d(ct, ct-1) constrained by the upper-bound. 
Since we have restricted the adversary, it seems only fair to restrict the tracker too. We 
require that a tracking algorithm be: deterministic, i.e., that the process generating the 
hypotheses be deterministic; prudent, i.e., that the label predicted for an instance be a 
deterministic function of the current hypothesis: t = t-l(Xt); and conservative, i.e., that 
the hypothesis is modified only when an example is mislabeled. The restriction that a tracker 
be conservative rules out algorithms which attempt to predict the adversary's movements 
and is the most restrictive of the three. On the other hand, when the tracker does update its 
hypothesis, there are no restrictions on d(t, t-). 
To measure performance, we focus on the mistake rate of the tracker. A mistake occurs 
when the tracker mislabels an instance, i.e., whenever t_l(Xt)  Ct(Xt). For convenience, 
we define a mistake indicator function, M(xt, ct, t-1) which is 1 if t_l(Xt)  Ct(Xt) and 0 
otherwise. Note that if a mistake occurs, it occurs before the hypothesis is updated 
a conservative tracker is always a step behind the adversary. We are interested in the 
1 t 
asymptotic mistake rate,/a -- lim inft- 7 Y'4=0 M(xt, ct, ct-1). 
Following Helmbold and Long (1991), we say that an algorithm (/a, 'y)-tracks a sequence 
space � if, for all c 6 �y and all drift rates .yt not greater than ?, the mistake rate/a t is at 
most 
We are interested in bounding the asymptotic mistake rate of a tracking algorithm based 
on the concept class and the adversary. To derive a lower bound on the mistake rate, we 
hypothesize the existence of a perfect conservative tracker, i.e., one that is always able to 
guess the correct concept each time it makes a mistake. We say that such a tracker has 
complete side information (CSI). No conservative tracker can do better than one with CSI. 
Thus, the mistake rate for a tracker with CSI is a lower bound on the mistake rate achievable 
by any conservative tracker. 
To upper bound the mistake rate, it is necessary that we hypothesize a particular tracking 
algorithm when no side information (NSI) is available, that is, when the tracker only knows 
it mislabeled an instance and nothing else. In our analysis, we study a simple tracking 
algorithm which modifies the previous hypothesis just enough to correct the mistake. 
3 ANALYSIS 
We consider two concept classes in this paper, half-planes and the intersection of two half- 
planes which can be defined by lines in the plane that pass through the origin. We call these 
classes HS2 and IHS2. In this section, we present our analysis for H$2. 
Without loss of generality, since the lines pass through the origin, we take the instance 
space to.be the circumference of the unit circle. A half-plane in NS 2 is defined by a vector 
w such that for an instance x, c(x) = 1 if wx > 0 and c(x) = 0 otherwise. Without loss of 
Incrementally Learning Time-varying Half-planes 923 
(a) 
(b) 
Figure' 1: Markov chain for the greedy adversary and (a) CSI and (b) COVER trackers. 
generality, as we will show later, we assume that the instances are chosen uniformly. 
To begin, we assume a greedy adversary as follows: Every time the tracker guesses the 
correct target concept (that is, t-t = ct-), the greedy adversary randomly chooses a 
vector r orthogonal to w and at every iteration, the adversary rotates w by zy radians in the 
direction defined by r. We have shown that a greedy adversary maximizes the asymptotic 
mistake rate for a conservative tracker but do not present the proof here. 
To lower bound the achievable error rate, we assume a conservative tracker with complete 
side information so that the hypothesis is unchanged if no mistake occurs and is updated to 
the correct concept otherwise. The state of this system is fully described by d(c t, t) and, 
for 'y = 1/K for some integer K, is modeled by the Markov chain shown in figure 1 a. In 
each state si (labeled i in the figure), d(ct, t) = iT. The asymptotic mistake rate is equal to 
the probability of state 0 which is lower bounded by 
l(y) = 2y/= 
Since/(T) depends only on 'y which, in tur
