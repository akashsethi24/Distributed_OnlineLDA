Synaptic Transmission: An 
Information-Theoretic Perspective 
Amit Manwani and Christof Koch 
Computation and Neural Systems Program 
California Institute of Technology 
Pasadena, CA 91125 
email: quixoteklab.caltech. edu 
kochklab. caltech. edu 
Abstract 
Here we analyze synaptic transmission from an information-theoretic 
perspective. We derive closed-form expressions for the lower-bounds on 
the capacity of a simple model of a cortical synapse under two explicit 
coding paradigms. Under the signal estimation paradigm, we assume 
the signal to be encoded in the mean firing rate of a Poisson neuron. The 
performance of an optimal linear estimator of the signal then provides 
a lower bound on the capacity for signal estimation. Under the signal 
detection paradigm, the presence or absence of the signal has to be de- 
tected. Performance of the optimal spike detector allows us to compute 
a lower bound on the capacity for signal detection. We find that single 
synapses (for empirically measured parameter values) transmit informa- 
tion poorly but significant improvement can be achieved with a small 
amount of redundancy. 
1 Introduction 
Tools from estimation and information theory have recently been applied by researchers 
(Bialek et. al, 1991) to quantify how well neurons transmit information about their random 
inputs in their spike outputs. In these approaches, the neuron is treated like a black-box, 
characterized empirically by a set of input-output records. This ignores the specific nature 
of neuronal processing in terms of its known biophysical properties. However, a systematic 
study of processing at various stages in a biophysically faithful model of a single neuron 
should be able to identify the role of each stage in information transfer in terms of the pa- 
meters relating to the neuron's dendritic structure, its spiking mechanism, etc. Employing 
this reductionist approach, we focus on a important component of neural processing, the 
synapse, and analyze a simple model of a cortical synapse under two different representa- 
'tional paradigms. Under the signal estimation paradigm, we assume that the input signal 
202 A. Manwani and C. Koch 
is linearly encoded in the mean firing rate of a Poisson neuron and the mean-square error 
in the reconstruction of the signal from the post-synaptic voltage quantifies system per- 
formance. From the performance of the optimal linear estimator of the signal, a lower 
bound on the capacity for signal estimation can be computed. Under the signal detection 
paradigm, we assme that information is encoded in an all-or-none format and the error in 
deciding whether or not a presynaptic spike occurred by observing the post-synaptic voltage 
quantifies system performance. This is similar to the conventional absent/present(Yes-No) 
decision paradigm used in psychophysics. Performance of the optimal spike detector in 
this case allows us to compute a lower bound on the capacity for signal detection. 
01' 0 J 
Poisson ] ' ' ' ] J n(t) Estimator 
ke   etease J Optimal 
Encoding _  
Stimulus I / Spike � , ,  Estimate 
-J k(t) J.Train / JNo,se 
<' ' J/'P(a)J J J  / J I re(t) 
Spike / Optreal Dision 
No Spike Dettor Spike / 
 Ske 
Encodina SvnaDtic Channel Deco{!ina 
Figure 1: Schematic block diagram for the signal detection and estimation tasks. The 
synapse is modeled as a binary channel followed by a filter h(t) = a t e:cp(-t/ts). where 
a is a random variable with probability density, P(a) = c (cm)k-e:cp(-cm)/(k - 1)!. 
The binary channel, (inset, eo = Pr[spontaneous release], q = Pr [release failure]) models 
probabilistic vesicle release and h(t) models the variable epsp size observed for cortical 
synapses. n(t) denotes additive post-synaptic voltage noise and is assumed to be Gaussian 
and white over a bandwidth Bn. Performance of the optimal linear estimator (Wiener 
Filter) and the optimal spike detector (Matched Filter) quantify synaptic efficacy for signal 
estimation and detection respectively. 
2 The Synaptic Channel 
Synaptic transmission in cortical neurons is known to be highly random though the role of 
this variability in neural computation and coding is still unclear. In central synapses, each 
synaptic bouton contains only a single active release zone, as opposed to the hundreds or 
thousands found at the much more reliable neuromuscularjunction. Thus, in response to an 
action potential in the presynaptic terminal at most one vesicle is released (Korn and Faber, 
1991). Moreover, the probability of vesicle release p is known to be generally low (0.1 
to 0.4) from in vitro studies in some vertebrate and invertebrate systems (Stevens, 1994). 
This unreliability is further compounded by the trial-to-trial variability in the amplitude of 
the post-synaptic response to a vesicular release (Bekkers et. al, 1990). In some cases, the 
variance in the size of EPSP is as large as the mean. The empirically measured distribution 
of amplitudes is usually skewed to the right (possibly biased due the inability of measuring 
very small events) and can be modeled by a Gamma distribution. 
In light of the above, we model the synapse as a binary channel cascaded by a random am- 
plitude filter (Fig. 1). The binary channel accounts for the probabilistic vesicle release. eo 
Synaptic Transmission: An Information-Theoretic Perspective 203 
and q denote the probabilities of spontaneous vesicle release and failure respectively. We 
follow the binary channel convention used in digital communications (q = l-p), whereas, 
p is more commonly used in neurobiology. The filter h(t) is chosen to correspond to the 
epsp profile of a fast AMPA-like synapse. The amplitude of the filter a is modeled as ran- 
dom variable with density P(a), mean it, and standard deviation a,. The CV (standard 
deviation/mean) of the distribution is denoted by UV,. We also assume that additive Gaus- 
sian voltage noise n(t) at the post-synaptic site further corrupts the epsp response. n(t) is 
2 and a bandwidth Bn corresponding to the membrane 
assumed to white with variance o- n 
time constant r. One can define an effective signal-to-noise ratio, SNiri = E,/No, given 
by the ratio of the energy in the epsp pulse, Eh -- fc h2 (t) dt to the noise power spectral 
2/B. The performance of the synapse depends on the SNiri and not on 
density, No = a N 
the absolute values of Eh or a,. In the above model, by regarding synaptic parameters as 
constants, we have tacitly ignored history dependent effects like paired-pulse facilitation, 
vesicle depletion, calcium buffering, etc, which endow the synapse with the nature of a 
sophisticated nonlinear fiker (Markram and Tsodyks, 1997). 
a) 
Effective Continuous 
Estimation Chanl 
b) x=0 
No Spike 
Spike 
X=I 
Y=O 
////No Spike 
///  Spike 
  �:1 
Effective Binary 
Detection Chanl 
Figure 2: (a) Effective chan- 
nel model for signal estima- 
tion. re(t), ff(t), it(t) denote 
the stimulus, the best linear es- 
timate, and the reconstruction 
noise respectively. (b) Effective 
channel model for signal detec- 
tion. X and Y denote the bi- 
nary variables corresponding to 
the input and the decision re- 
spectively. Pf and Pm are the 
effective error probabilities. 
3 Signal Estimation 
Let us assume that the spike train of the presynaptic neuron can be modeled as a doubly 
stochastic Poisson process with a rate (t) = k(t) � re(t) given as a convolution between 
the stimulus re(t) and a filter k(t). The stimulus is drown from a probability distribution 
which we assume to be Gaussian. k(t) = ezp(-t/r) is a low-pass filter which models 
the phenomenological relationship between a neuron's firing rate and its input current. r 
is chosen to correspond to the membrane time constant. The exact form of k(t) is not 
cmcial and the above form is assumed primarily for analytical tractability. The objective is 
to find the optimal estimator of re(t) from the post-synaptic voltage v (t), where optimality 
is in a least-mean square sense. The optimal mean-square estimator is, in general, non- 
linear and reduces to a linear filter only when all the signals and noises are Gaussian. 
However, instead of making this assumption, we restrict ourselves to the analysis of the 
optimal linear estimator, (t) = g(t) � v(t), i.e. the filter g(t) which minimizes the 
mean-square error E = ((re(t) - (t)) 2) where (.) denotes an ensemble average. The 
overall estimation system shown in Fig. 1 can be characterized by an effective continuous 
channel (Fig. 2a) where it(t) = a(t) - re(t) denotes the effective reconstruction noise. 
System performance can be quantified by E, the lower E, the better the synapse at signal 
transmission. The expression for the optimal filter (enerfilter) in the frequency domain is 
g(w) = S.v(-w)/Sv(w) where S.(w) is the cross-spectral density (Fourier transform 
of the cross-correlation P) of re(t) and s(t) and S. (co) is the power spectral density of 
v(t). The minimummean-square erroris givenby, E = a2- fs I S,(w) I 2/S(w) dw. 
The set $ = {co [ S(w)  0} is called the support of S(w). 
204 A. Manwani and C. Koch 
Another measure of system performance is the mutual information rate I(m; v) between 
re(t) and v(t), defined as the rate of information transmitted by v(t) about s(t). By the 
Data Processing inequality (Cover 1991), I(m, v) > I(m, a). A lower bound of I(m, 
1 log 2 [ s.. (,,)] d (units 
and thus of I(m; v) is given by the simple expression fib =  fs s () 
of bits/sec). The lower bound is achieved when (t) is Gaussian and is independent of 
re(t). Since the spike train s(t) =  (t - ti) is a Poisson_process with rate k(t) � re(t), 
its power spectrum is given by the expression, Sss(w) = ,X+ [ K(w) 12 S,m(CO) where 
 is the mean firing rate. We assume that the mean (/m) and variance (a2) of re(t) are 
chosen such that the probability that )(t) < 0 is negligible 1 The vesicle release proce
