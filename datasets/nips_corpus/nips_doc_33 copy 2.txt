301 
ENCODING GEOMETRIC INVARIANCES IN 
HIGHER-ORDER NEURAL NETWORKS 
C.L. Giles 
Air Force Office of Scientific Research, Bolling AFB, DC 20332 
R.D. Griffin 
Naval Research Laboratory, Washington, DC 20375-5000 
T. Maxwell 
Sachs-Freeman Associates, Landover, MD 20785 
ABSTRACT 
We describe a method of constructing higher-order neural 
networks that respond invariantly under geometric transformations on 
the input space. By requiring each unit to satisfy a set of 
constraints on the interconnection weights, a particular structure is 
imposed on the network. A network built using such an architecture 
maintains its invariant performance independent of the values the 
weights assume, of the learning rules used, and of the form of the 
nonlinearities in the network. The invariance exhibited by a first- 
order network is usually of a trivial sort, e.g., responding only to 
the average input in the case of translation invariance, whereas 
higher-order networks can perform useful functions and still exhibit 
the invariance. We derive the weight constraints for translation, 
rotation, scale, and several combinations of these transformations, 
and report results of simulation studies. 
INTRODUCTION 
A persistent difficulty for pattern recognition systems is the 
requirement that patterns or objects be recognized independent of 
irrelevant parameters or distortions such as orientation (position, 
rotation, aspect), scale or size, background or context, doppler 
shift, time of occurrence, or signal duration. The remarkable 
performance of humans and other animals on this problem in the visual 
and auditory realms is often taken for granted, until one tries to 
build a machine with similar performance. Though many methods have 
been developed for dealing with these problems, we have classified 
them into two categories: 1) preprocessing or transformation 
(inherent) approaches, and 2) case-specific or brute force 
(learned) approaches. Common transformation techniques include: 
Fourier, Hough, and related transforms; moments; and Fourier 
descriptors of the input signal. In these approaches the signal is 
usually transformed so that the subsequent processing ignores 
arbitrary parameters such as scale, translation, etc. In addition, 
these techniques are usually computationally expensive and are 
sensitive to noise in the input signal. The brute force approach 
is exemplified by training a device, such as a perceptron, to 
classify a pattern independent of it's position by presenting the 
American Institute of Physics 1988 
302 
training pattern at all possible positions. MADALINE machines 2 have 
been shown to perform well using such techniques. Often, this type 
of invariance is pattern specific, does not easily generalize to 
other patterns, and depends on the type of learning algorithm 
employed. Furthermore, a great deal of time and energy is spent on 
learning the invariance, rather than on learning the signal. We 
describe a method that has the advantage of inherent invariance but 
uses a higher-order neural network approach that must learn only the 
desired signal. Higher-order units have been shown to have unique 
computational strengths and are quite amenable to the encoding of a 
priori knowledge. 3'7 
MATHEMATICAL DEVELOPMENT 
Our approach is similar to the group invariance approach, 8,10 
although we make no appeal to group theory to obtain our results. We 
begin by selecting a transformation on the input space, then require 
the output of the unit to be invariant to the transformation. The 
resulting equations yield constraints on the interconnection weights, 
and thus imply a particular form or structure 'for the network 
architecture. 
For the i-th unit Yi of order M defined on a discrete input 
space, let the output be given by 
Yi[WiM(x),p(x)] = f( wi � +  wil(xl) p(x 1) 
+ wi2(Xl,X2) p(xl) P(X2) + ... 
+ ... wiM(xl,..XM) p(xl)..p(x M) ), 
(1) 
where p(x) is the input pattern or signal function (sometimes called 
a pixel) evaluated at position vector x, wim(xl,...Xm) is the weight 
of order m connecting the outputs of units at Xl, x2,..x m to the i- 
th unit, i.e., it correlates m values, f(u) is some threshold or 
sigmoid output function, and the summations extend over the input 
space. wiM(x) represents the entire set of weights associated with 
the i-th unit. These units are equivalent to the sigma-pi units a 
defined by Rumelhart, Hinton, and Williams. 7 Systems built from 
these units suffer from a combinatorial explosion of terms, hence are 
more complicated to build and train. To reduce the severity of this 
problem, one can limit the range of the interconnection weights or 
the number of orders, or impose various other constraints. We find 
that, in addition to the advantages of inherent invariance, imposing 
an invariance constraint on Eq. (1) reduces the number of allowed 
aThe sigma-pi neural networks are multi-layer networks with 
higher-order terms in any layer. As such, most of the neural 
networks described here can be considered as a special case of the 
sigma-pi units. However, the sigma-pi units as originally formulated 
did not have invariant weight terms, though it is quite simple to 
incorporate such invariances in these units. 
303 
weights, thus simplifying the architecture and shortening the 
training time. 
We now define what we mean by invariance. The output of a unit 
is invariant with respect to the transformation T on the input 
pattern if 9 
T[Yi(WiM,p(x))] = Y(WiM,T[p(x)]) = y(wiM,p(x)) 
(2) 
An example of the class of invariant response defined by Eq. (2) 
would be invariant detection of an object in the receptive field of a 
panning or zooming camera. An example of a different class would be 
invariant detection of an object that is moving within the field of a 
fixed camera. One can think of this latter case as consisting of a 
fixed field of noise plus a moving field that contains only the 
object of interest. If the detection system does not respond to the 
fixed field, then this latter case is included in Eq. (2). 
To illustrate our method we derive the weight constraints for 
one-dimensional translation invariance. We will first switch to a 
continuous formulation, however, for reasons of simplicity and 
generality, and because it is easier to grasp the physical 
significance of the results, although any numerical simulation 
requires a discrete formulation and has significant implications for 
the implementation of our results. Instead of an index i, we now 
keep track of our units with the continuous variable u. With these 
changes Eq. (2) now becomes 
y[u;WM(x),p(x)] = f( w � + Idxl wl(u;xl) p(x 1) + ... 
+ f..fdxl..dxM(-;Xl,..xM> P(Xl)..p(xM) ), 
The limits on the integrals are defined by the problem and are 
crucial in what follows. Let T be a translation of the input pattern 
by -x0, so that 
T[p(x)] = p(x+x0) 
(4) 
where x 0 is the translation of the input pattern. Then, from eq (2), 
Ty[u;wM(x) ,p(x)] = y[u;ll(x),p(x+x0)] = y[u;WM(x) ,p(x)] (5) 
Since p(x) is arbitrary we must impose term-by-term equality in the 
argument of the threshold function; i.e., 
fdx 1 wl(u;xl) p(xl) = f dx 1 wl(u;Xl) p(xl+xO) , (5a) 
f f dxl dx2 w2(-;x1,x2) p(xl+O) p(x2+o), 
etc. 
304 
Making the substitutions x 1. x 1-xO, x 2 .x 2-xO, etc, we find that 
fdx I wl(u;Xl) P(Xl) - fdx 1 wl(u;Xl-X0) p(xl) , (6a) 
etc. 
Note that the limits of the integrals on the right hand side must be 
adjusted to satisfy the change-of-variables. If the limits on the 
integrals are infinite or if one imposes some sort of periodic 
boundary condition, the limits of the integrals on both sides of the 
equation can be set equal. We will assume in the remainder of this 
paper that these conditions can be met; normally this means the 
limits of the integrals extend to infinity. (In an implementation, 
it is usually impractical or even impossible to satisfy these 
requirements, but our simulation results indicate that these networks 
perform satisfactorily even though the regions of integration are not 
identical. This question must be addressed for each class of 
transformation; it is an integral part of the implementation design.) 
Since the functions p(x) are arbitrary and the regions of integration 
are the same, the weight functions must be equal. This imposes a 
constraint on the functional form of the weight functions or, in the 
discrete implementation, limits the allowed connections and thus the 
number of weights. In the case of translation invariance, the 
constraint on the functional form of the weight functions requires 
that 
w 1 (U;Xl) -- wl(u;xl-x0), 
w2(U;Xl,X2) - w2(U;Xl-X0,x2-x0), 
etc. 
(7a) 
(7b) 
These equations imply that the first order weight is independent of 
input position, and depends only on the output position u. The 
second order weight is a function only of vector differences, 10 i.e., 
wl(xi) m w!(, (Sa) 
w2(U;Xl,X 2) - w2(u;x].-x2). (85) 
For a discrete implementation with N input units (pixels) fully 
connected to an output unit, this requirement reduces the number of 
second-order weights from order N 2 to order N, i.e., only weights for 
differences of indexes are needed rather than all unique pair 
combinations. Of course, this advantage is multiplied as the number 
of fully-connected output units increases. 
FURTHER EXAMPLES 
We have applied these techniques to several other 
transformations of interest. For the case of transformation of scale 
305 
define the scale operator S such that 
Sp(x) = anp(ax) 
(9) 
where a is the scale factor, and x is a vector of dimension n. The 
factor a n is used for normalization purposes, so that a given figure 
always contains the same energy regardless of its scale. 
Application of the same procedure to this transformation leads to the 
following constraints on the weights: 
(tgx/a) = (tgxi) , 
w2(u;xL/a,x2/a) = w2(u;xi,x2), 
w 3(u;xl/a,x2/a,x3/a ) = w3(u;Xl,X2,X3), etc. 
(10a) 
(10b) 
(10c) 
Consider a two-di
