Combining Classifiers Using 
Correspondence Analysis 
Christopher J. Metz 
Dept. of Information and Computer Science 
University of California, Irvine, CA 92697-3425 U.S.A. 
cmerz@ics.uci.edu 
Category: Algorithms and Architectures. 
Abstract 
Several effective methods for improving the performance of a sin- 
gle learning algorithm have been developed recently. The general 
approach is to create a set of learned models by repeatedly apply- 
ing the algorithm to different versions of the training data, and 
then combine the learned models' predictions according to a pre- 
scribed voting scheme. Little work has been done in combining the 
predictions of a collection of models generated by many learning 
algorithms having different representation and/or search strategies. 
This paper describes a method which uses the strategies of stack- 
ing and correspondence analysis to model the relationship between 
the learning examples and the way in which they are classified by 
a collection of learned models. A nearest neighbor method is then 
applied within the resulting representation to classify previously 
unseen examples. The new algorithm consistently performs as well 
or better than other combining techniques on a suite of data sets. 
1 Introduction 
Combining the predictions of a set of learned models  to improve classification 
and regression estimates has been an area of much research in machine learn- 
ing and neural networks [Wolpert, 1992, Metz and Pazzani, 1997, Pertone, 1994, 
Breiman, 1996, Meir, 1995]. The challenge of this problem is to decide which models 
to rely on for prediction and how much weight to give each. The goal of combining 
learned models is to obtain a more accurate prediction than can be obtained from 
any single source alone. 
A learned model may be anything from a decision/regression tree to a neural network. 
592 C. J. Merz 
Recently, several effective methods have been developed for improving the perfor- 
mance of a single learning algorithm by combining multiple learned models gener- 
ated using the algorithm. Some examples include bagging [Breiman, 1996], boosting 
[Freund, 1995], and error correcting output codes [Kong and Dietterich, 1995]. The 
general approach is to use a particular learning algorithm and a model genera- 
tion technique to create a set of learned models and then combine their predic- 
tions according to a prescribed voting scheme. The models are typically generated 
by varying the training data using resampling techniques such as bootstrapping 
[Efron and Tibshirani, 1993] or data partitioning [Meir, 1995]. Though these meth- 
ods are effective, they are limited to a single learning algorithm by either their 
model generation technique or their method of combining. 
Little work has been done in combining the predictions of a collection of models 
generated by many learning algorithms each having different representation and/or 
search strategies. Existing approaches typically place more emphasis on the model 
generation phase rather than the combining phase [Opitz and Shavlik, 1996]. As a 
result, the combining method is rather limited. The focus of this work is to present 
a more elaborate combining scheme, called SCANN, capable of handling any set 
of learned models, and evaluate it on some real-world data sets. A more detailed 
analytical and empirical study of the SCANN algorithm is presented in [Merz, 1997]. 
This paper describes a combining method applicable to model sets that are homoge- 
neous or heterogeneous in their representation and/or search techniques. Section 2 
describes the problem and explains some of the caveats of solving it. The SCANN 
algorithm (Section 3), uses the strategies of stacking [Wolpert, 1992] and correspon- 
dence analysis [Greenacre, 1984] to model the relationship between the learning ex- 
amples and the way in which they are classified by a collection of learned models. A 
nearest neighbor method is then applied to the resulting representation to classify 
previously unseen examples. 
In an empirical evaluation on a suite of data sets (Section 4), the naive approach of 
taking the plurality vote (PV) frequently exceeds the performance of the constituent 
learners. SCANN, in turn, matches or exceeds the performance of PV and several 
other stacking-based approaches. The analysis reveals that SCANN is not sensitive 
to having many poor constituent learned models, and it is not prone to overfit by 
reacting to insignificant fluctuations in the predictions of the learned models. 
2 Problem Definition and Motivation 
The problem of generating a set of learned models is defined as follows. Suppose 
two sets of data are given: a learning set/2 - {(xi, yi), i = 1,..., I} and a test set 
7- = {(xt, yt), t - 1,..., T}. xi is a vector of input values which are either nominal 
or numeric values, and yi  {�,..., �c} where C is the number of classes. Now 
suppose/2 is used to build aset of N functions, . -- {f (x)}, each element of which 
approximates f(x), the underlying function. 
The goal here is to combine the predictions of the members of . so as to find 
the best approximation of f(x). Previous work [Perrone, 1994] has indicated that 
the ideal conditions for combining occur when the errors of the learned models are 
uncorrelated. The approaches taken thus far attempt to generate learned models 
which make uncorrelated errors by using the same algorithm and presenting different 
samples of the training data [Breiman, 1996, Meir, 1995], or by adjusting the search 
heuristic slightly [Opitz and Shavlik, 1996, All and Pazzani, 1996]. 
No single learning algorithm has the right bias for a broad selection of problems. 
Combining Classifiers Using Correspondence Analysis 593 
Therefore, another way to achieve diversity in the errors of the learned models 
generated is to use completely different learning algorithms which vary in their 
method of search and/or representation. The intuition is that the learned models 
generated would be more likely to make errors in different ways. Though it is not 
a requirement of the combining method described in the next section, the group of 
learning algorithms used to generate . will be heterogeneous in their search and/or 
representation methods (i.e., neural networks, decision lists, Bayesian classifiers, 
decision trees with and without pruning, etc.). In spite of efforts to diversify the 
errors committed, it is still likely that some of the errors will be correlated because 
the learning algorithms have the same goal of approximating f, and they may use 
similar search strategies and representations. A robust combining method must 
take this into consideration. 
Approach 
The approach taken consists of three major components: Stacking, Correspondence 
Analysis, and Nearest Neighbor (SCANN). Sections 3.1-3.3 give a detailed descrip- 
tion of each component, and section 3.4 explains how they are integrated to form 
the SCANN algorithm. 
3.1 Stacking 
Once a diverse set of models has been generated, the issue of how to combine them 
arises. Wolpert [Wolpert, 1992] provided a general framework for doing so called 
stacked 9eneralization or stackin9. The goal of stacking is to combine the members 
of : based on information learned about their particular biases with respect to C 2. 
The basic premise of stacking is that this problem can be cast as another induction 
problem where the input space is the (approximated) outputs of the learned models, 
and the output space is the same as before, i.e., 
The approximated outputs of each learned model, represented as j, (xi), are gener- 
ated using the following in-sample/out-of-sample approach: 
1. Divide the Co data up into V partitions. 
2. For each partition, v, 
� Train each algorithm on all but partition v to get {jv }. 
� Test each learned model in {j-v} on partition v. 
� Pair the predictions on each example in partition v (i.e., the new input 
space) with the corresponding output, and append the new examples 
to Cs 
3. Return 
3.2 Correspondence Analysis 
Correspondence Analysis (CA) [Greenacre, 1984] is a method for geometrically ex- 
ploring the relationship between the rows and columns of a matrix whose entries 
are categorical. The goal here is to explore the relationship between the training 
2Henceforth � will be referred to as �0 for clarity. 
594 C. J. Metz 
Table 1: Correspondence Analysis calculations. 
Stage Symbol Definition Description 
I N (I x J) indicator matrix Records votes of learned models. 
n y]/=  J 
-]j= hid Grand total of table N. 
r ri = hi+In Row masses. 
c cj = n+j/n Column masses. 
P (1 In) N Correspondence matrix. 
De (J x J) diagonal matrix Masses c on diagonal. 
Dr (I x I) diagonal matrix Masses r on diagonal. 
A Dr-/2(P- rcT)D� -/2 Standardized residuals. 
2 A UI'V T SVD of A. 
3 F Dr-1/ur Principal coordinates of rows. 
G De- /VF Principal coordinates of columns. 
examples and how they are classified by the learned models. To do this, the predic- 
tion matrix, M, is explored where mi, = ](xi) (1 _< i _< I, and 1 _< n _< N). It is 
also important to see how the predictions for the training examples relate to their 
true class labels, so the class labels are appended to form M', an (I x J) matrix 
(where J = N + 1). For proper application of correspondence analysis, M' must be 
converted to an (I x (J. C)) indicator matrix, N, where ni,(j.J+c) is a one exactly 
when rnij = Cc, and zero otherwise. 
The calculations of CA may be broken down into three stages (see Table 1). Stage 
one consists of some preprocessing calculations performed on N which lead to the 
standardized residual matrix, A. In the second stage, a singular value decomposition 
(SVD) is performed on A to redefine it in terms of three matrices: U(xK), F(KxK), 
and V(Kx0,), where K = min(I- 1, J- 1). These matrices are used in the third 
stage to determine F(xK) and G(JxK), the coordinates of the rows and columns 
of N, respective
