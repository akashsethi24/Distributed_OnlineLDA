568 
DYNAMICS OF ANALOG NEURAL 
NETWORKS WITH TIME DELAY 
C.M. Marcus and R.M. Westervelt 
Division of Applied Sciences and Department of Physics 
Harvard University, Cambridge Massachusetts 02138 
ABSTRACT 
A time delay in the response of the neurons in a network can 
induce sustained oscillation and chaos. We present a stability 
criterion based on local stability analysis to prevent sustained 
oscillation in symmetric delay networks, and show an 
example of chaotic dynamics in a non-symmetric delay 
network. 
I. INTRODUCTION 
Understanding how time delay affects the dynamics of neural networks is important for 
two reasons: First, some degree of time delay is intrinsic to any physically realized 
network, both in biological neural systems and in electronic artificial neural networks. 
As we will show, it is not obvious what constitutes a small (i.e. ignorable) delay 
which will not qualitatively change the network dynamics. For some network 
configurations, delay much smaller than the intrinsic relaxation time of the network can 
induce collective oscillatory behavior not predicted by mathematical models which ignore 
delay. These oscillations may or may not be desirable; in either case, one should 
understand when and how new dynamics can appear. The second reason to study time 
delay is for its intentional use in parallel computation. The dynamics of neural networks 
which always converge to fixed points are now fairly well understood. Several neural 
network models have appeared recently which use time delay to produce dynamic 
computation such as associative recall of sequences [Kleinfeld, 1986; Sompolinsky and 
Kanter, 1986]. It has also been suggested that time delay produces an effective noise in 
the network dynamics which can yield improved recall of memories IConwell, 1987] 
Finally, to the extent that neural networks research is inspired by biological systems, the 
known presence of time delays in a many real neural systems suggests their usefulness 
in parallel computation. 
In this paper we will show how time delay in an analog neural network can produce 
sustained oscillation and chaos. In section 2 we consider the case of a symmetrically 
connected network. It is known [Cohen and Grossberg, i983; Hopfield, 1984] that in the 
absence of time delay a symmetric network will always converge to a fixed point 
attractor. We show that adding a fixed delay to the response of each neuron will produce 
sustained oscillation when the magnitude of the delay exceeds a critical value, which 
depends on the neuron gain and the network connection topology. We then analyze the 
Dynamics of Analog Neural Networks with Time Delay 569 
all-inhibitory and symmetric ring topologies as examples. In section 3, we discuss 
chaotic dynamics in asymmetric neural networks, and give an example of a small (N=3) 
network which shows delay-induced chaos. The analytical results presented here are 
supported by numerical simulations and experiments performed on a small electronic 
neural network with controllable time. A detailed derivation of the stability results for 
the symmetric network is given in [Marcus and Westervelt, 1989], and the electronic 
circuit used is described in described [Marcus and Westervelt, 1988]. 
II. STABILITY OF SYMMETRIC NETWORKS WITH DELAY 
The dynamical system we consider describes an electronic circuit of N saturable 
amplifiers (neurons) coupled by a resistive interconnection matrix. The neurons do not 
respond to an input voltage u i instantaneously, but produce an output after a delay, 
which we take to be the same for all neurons. The neuron input voltages evolve 
according to the following equations: 
N 
fii(t) = -ui(t) + E Jijf(uj(t-)). (1) 
j=l 
The transfer function for each neuron is taken to be an identical sigmoidal function f(u) 
with a maximum slope df/du --- [5 at u = 0. The unit of time in these equations has been 
scaled to the characteristic network relaxation time, thus  can be thought of as the ratio 
of delay time to relaxation time. The symmetric interconnection matrix J:: describes the 
conductance between neurons i and j is normalized to satisfy I;iIJiil = 1 for all i. This 
normalization assumes that each neuron sees the same conductadce'at its input [Marcus 
and Westervelt, 1989]. The initial conditions for this system are a set of N continuous 
functions defined on the interval -' < t < 0. We take each initial function to be constant 
over that interval, though possibly different for different i. We find numerically that the 
results do not depend on the form of the initial functions. 
Linear Stability Analysis at Low Gain 
Studying the stability of the fixed point at the origin (ui -- 0 for all i) is useful for 
understanding the source of delay-induced sustained oscillation and will lead to a low-gain 
stability criterion for symmetric networks. It is important to realize however, that for 
the system (1) with a sigmoidal nonlinearity, if the origin is stable then it is the unique 
attractor, which makes for rather uninteresting dynamics. Thus the origin will almost 
certainly be unstable in any useful configuration. Linear stability analysis about the 
origin will show that at x = 0, as the gain [5 is increased, the origin always loses 
stability by a type of bifurcation which only produces other fixed points, but for x > 0 
an alternative type of bifurcation of the origin can occur which produces the sustained 
oscillatory modes. The stability criterion derived insures that this alternate bifurcation - 
a Hopf bifurcation - does not occur. 
The natural coordinate system for the linearized version of (1) is the set of N 
eigenvectors of the connection matrix Jij, defined as xi(t), i= 1,..N. In terms of the xi(t), 
570 Marcus and Westervelt 
the linearized system can be written 
5ti(t ) = _ xi(t ) + 
[X i xi(t- ') (2) 
where l] is the neuron gain and k i (i=l,..N) are the eigenvalues of Jij' In general, these 
eigenvalues have both real and imaginary parts; for Jij = J'i the ; are purely real. 
Assuming exponential time evolution of the form xi(t ) --'Jxi(0)eit , where s i is a 
complex characteristic exponent, yields a set of N transcendental characteristic equations: 
(s i + 1)eSi ' =I]k i. The condition for stability of the origin, Re(si) < 0 for all i, and the 
characteristic equations can be used to specify a stability region in the complex plane of 
eigenvalues, as illustrated in Fig. (la). When all eigenvalues of Jij are within the 
stability region, the origin is stable. For ' = 0, the stability region is defined by 
Re(k) < l/l], giving a half-plane stability condition familiar from ordinary differential 
equations. For ' > 0, we define the border of the stability region A(0) at an angle 0 
from the Re(k) axis as the radial distance from the point k = 0 to the fh'st point (i.e. 
smallest value of A(0)) which satisfies the characteristic equation for purely imaginary 
characteristic exponent sj -- io)j. The delay-dependent value of A(0) is given by 
1 40)2 
^(0) = + 1 ; co = -tan - 0) (3) 
where to is in the range (0-rd2) so)x $ 0, modulo 2. 
(a) (b) 
Re(), ) 
':::::....x = 1 ...:? 1/[ 
lOO 
1 
O.Ol 
o. 1 1 lO 
Figure 1. (a) Regions of Stability in the Complex Plane of Eigenvalues k of the 
Connection Matrix Jij' for x = 0,1,,. (b) Where Stability Region Crosses the Real-k 
Axis in the Negative Half Plane. 
Notice that for nonzero delay the stability region closes on the Re(k) axis in the negative 
half-plane. It is therefore possible for negative real eigenvalues to induce an instability 
of the origin. Specifically, if the minimum eigenvalue of the symmetric matrix J:: is 
lj 
more negative than -A(0 = :z) then the origin is unstable. We define this back door 
to the stability region along the real axis as A > 0, dropping the argument 0 = :z. A is 
inversely proportional to the gain [5 and depends on delay as shown in Fig. (lb). For 
large and small delay, A can be approximated as an explicit function of delay and gain: 
Dynamics of Analog Neural Networks with Time Delay 571 
{ (1/[5) /2x x< < 1 (4a) 
A _= 1/2 
(1, + > >1 
In the infinite-delay limit, the delay-differential system (1) is equivalent to an iterated 
map or parallel-update network of the form ui(t+l ) = ï¿½ J.. f(u.(t)) where t is discrete 
., .j j .. a 
iteration index. In this limit, the stability region is crcular, corresponmng to the fixed 
point stability condition for the iterated map system. 
Consider the stability of the origin in a symmetrically connected delay system (1) as the 
neuron gain [5 is increased from zero to a large value. A bifurcation of the origin will 
occur when the maximum eigenvalue 'max > 0 of J becomes larger than 1/[5 or when 
the minimum eigenvalue 'min < 0 becomes more r$gative than -A = -[5-1(02+1)1/2, 
where 0 = -tan(0x), [2 < o < g]. Which bifurcation occurs first depends on the 
delay and the eigenvalues of Ji:' The bifurcation at 'max = [ 5-1 is a pitchfork (as it is 
for x = 0) corresponding to a aracteristic exponent s i crossing into the positive real 
half plane along the real axis. This bifurcation creates a pair of fixed points along the 
eigenvector x i associated with that eigenvalue. These fixed points constitute a single 
memory state of the network. The bifurcation at 'min = - A corresponds to a Hopf 
bifurcation [Marsden and McCracken, 1976], where a pair of characteristic exponents pass 
into the real half plane with imaginary components +0 where 0 = -tan(0x), [g/2 < 0 
< g]. This bifurcation, not present at x = 0, creates an oscillatory attractor along the 
eigenvector associated with 'min' 
A simple stability criterion can be constructed by requiring that the most negative 
eigenvalue of the (symmetric) connection matrix not be more negative than -A. Because 
A is always larger than its small-delay limit rd(2[5), the criterion can be stated as a 
limit on the size on the delay (in units of the network 
