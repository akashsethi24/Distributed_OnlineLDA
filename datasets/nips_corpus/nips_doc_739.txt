Probabilistic Anomaly Detection in 
Dynamic Systems 
Padhralc Smyth 
Jet Propulsion Laboratory 238-420 
California Institute of Technology 
4800 Oak Grove Drive 
Pasadena, CA 91109 
Abstract 
This paper describes probabilistic methods for novelty detection 
when using pattern recognition methods for fault monitoring of 
dynamic systems. The problem of novelty detection is particular- 
ly acute when prior knowledge and training data only allow one 
to construct an incomplete classification model. Allowance must 
be made in model design so that the classifier will be robust to 
data generated by classes not included in the training phase. For 
diagnosis applications one practical approach is to construct both 
an input density model and a discriminative class model. Using 
Bayes' rule and prior estimates of the relative likelihood of data 
of known and unknown origin the resulting classification equations 
are straightforward. The paper describes the application of this 
method in the context of hidden Markov models for online fault 
monitoring of large ground antennas for spacecraft tracking, with 
particular application to the detection of transient behaviour of 
unknown origin. 
I PROBLEM BACKGROUND 
Conventional control-theoretic models for fault detection typically rely on an accu- 
rate model of the plant being monitored (Patton, Frank, and Clark, 1989). However, 
in practice it common that no such model exists for complex non-linear systems. 
The large ground antennas used by JPL's Deep Space Network (DSN) to track 
825 
826 Smyth 
Deep Space Communlcaons Unk 
Jet Propulsion Laboak)ry 
GCF Ground Communcations 
Facility, low-error rate link 
Figure 1' Block diagram of typical Deep Space Network downlink 
planetary spacecraft fall into this category. Quite detailed analytical models exist 
for the electromechanical pointing systems. However, these models are primarily 
used for determining gross system characteristics such as resonant frequencies; they 
are known to be a poor fit for fault detection purposes. 
We have previously described the application of adaptive pattern recognition meth- 
ods to the problem of online health monitoring of DSN antennas (Smyth and Mell- 
strom, 1992; Smyth, in press). Rapid detection and identification of failures in the 
electromechanical antenna pointing systems is highly desirable in order to minimize 
antenna downtime and thus minimise telemetry data loss when communicating with 
remote spacecraft (see Figure 1). Fault detection based on manual monitoring of 
the various antenna sensors is neither reliable or cost-effective. 
The pattern-recognition monitoring system operates as follows. Sensor data such as 
motor current, position encoder, tachometer voltages, and so forth are synchronous- 
ly sampled at 50Hz by a data acquisition system. The data are blocked off into 
disjoint windows (200 samples are used in practice) and various features (such as 
estimated autoregressive coefficients) are extracted; let the feature vector be 0_. 
The features are fed into a classification model (every 4 seconds) which in turn pro- 
vides posterior probability estimates of the m possible states of the system given the 
estimated features from that window, P(i ]_0). 0./1 corresponds to normal conditions, 
the other aq's, i _< i _< m, correspond to known fault conditions. 
Finally, since the system has memory in the sense that it is more likely to remain 
in the current state than to change states, the posterior probabilities need to be 
correlated over time. This is achieved by a standard first-order hidden Markov 
Probabilistic Anomaly Detection in Dynamic Systems 827 
model (HMM) which models the temporal state dependence. The hidden aspect 
of the model reflects the fact that while the features are directly observable, the 
underlying system states are not, i.e., they are in effect hidden. Hence, the purpose 
of the HMM is to provide a model from which the most likely sequence of system 
states can be inferred given the observed sequence of feature data. 
The classifier portion of the model is trained using simulated hardware faults. The 
feed-forward neural network has been the model of choice for this application be- 
cause of its discrimination ability, its posterior probability estimation properties 
(Richard and Lippmann, 1992; Miller, Goodman and Smyth, 1993) and its rel- 
atively simple implementation in software. It should be noted that unlike typical 
speech recognition HMM applications, the transition probabilities are not estimated 
from data but are designed into the system based on prior knowledge of the sys- 
tem mean time between failure (MTBF) and other specific knowledge of the system 
configuration (Smyth, in press). 
2 LIMITATIONS OF THE DISCRIMINATIVE MODEL 
The model described above assumes that there are m known mutually exclusive and 
exhaustive states (or classes) of the system, Wl,..., win. The mutually exclusive 
assumption is reasonable in many applications where multiple simultaneous failures 
are highly unlikely. However, the exhaustive assumption is somewhat impractical. 
In particular, for fault detection in a complex system such as a large antenna, there 
are thousands of possible fault conditions which might occur. The probability of 
occurrence of any single condition is very small, but nonetheless there is a significant 
probability that at least one of these conditions will occur over some finite time. 
While the common faults can be directly modelled it is not practical to assign model 
states to all the other minor faults which might occur. 
As discussed in (Smyth and Mellstrom, 1992; Smyth 1994) a discriminative model 
directly models p(wi10_), the posterior probabilities of the classes given the feature 
data, and assumes that the classes Wl,..., wm are exhaustive. On the other hand, a 
generarive model directly models the probability density function of the input data 
conditioned on each class, p(0_laq), and then indirectly determines posterior class 
probabilities by application of Bayes' rule. Examples of generative classifiers include 
parametric models such as Gaussian classifiers and memory-based methods such as 
kernel density estimators. Generative models are by nature well suited to novelty 
detection whereas discriminative models have no built-in mechanism for detecting 
data which are different to that on which the model was trained. However, there 
is a trade-off; because generative models typically are doing more modelling than 
just searching for a decision boundary, they can be less efficient (than discriminant 
methods) in their use of the data. For example, generative models typically scale 
poorly with input dimensionality for fixed training sample size. 
3 HYBRID MODELS 
A relatively simple and practical approach to the novelty detection problem is to 
use both a generative and discriminative classifier (an idea originally suggested to 
the author by R. P. Lippmann). An extra ra + lth state is added to the model to 
828 Smyth 
cover all other possible states not accounted for by the known m states. In this 
framework, the posterior estimates of the discriminative classifier are conditioned 
on the event that the data come from one of the m known classes. 
Let the symbol w{1,...,m} denote the event that the true system state is one of the 
known states, let 03rn+l be the unknown state, and let p(OZrn+l[0_) be the posterior 
probability that the system is in an unknown state given the data. Hence, one can 
estimate the posterior probability of individual known states as 
IS(wil_O) - pa(wilO, w{1,...,m}) x (1 - 
i <_ i _< m (1) 
where p,(wi[O_, 0./{1,...,rn}) is the posterior probability estimate of state i as provided 
by a discriminative model, i.e., given that the system is in one of the known states. 
The calculation of p(Wrn+l]0_) can be obtained via the usual application of Bayes' 
rule ifp(_010Zrn+l), p(OZm+l), and p(_010{1 .... ,m}) are known: 
P(Olwm+ l )P(COm+ l ) 
p(wm+llO)- p(_Olwm+1)p(wm+1 ) q- p(_OIw{1,...,m}) -] 
(2) 
Specifying the prior density p(O_lw,+l), the distribution of the features conditioned 
on the occurrence of the unknown state, can be problematic. In practice we have 
used non-informative Bayesian priors for p(O_lw,n+l ) over a bounded space of feature 
values (details are available in a technical report (Smyth and Mellstrom, 1993)), 
although the choosing of a prior density for data of unknown origin is basically 
ill-posed. The stronger the constraints which can be placed on the features the 
narrower the resulting prior density and the better the ability of the overall model 
to detect novelty. If we only have very weak prior information, this will translate 
into a weaker criterion for accepting points which belong to the unknown category. 
The term p(com+l) (in Equation (2)) must be chosen based on the designer's prior 
belief of how often the system will be in an unknown state -- a practical choice is 
that the system is at least as likely to be in an unknown failure state as any of the 
known failure states. 
The p(0lOZ{1,...,m }) term in Equation (2) is provided directly by the generative mod- 
el. Typically this can be a mixture of Gaussian component densities or a kernel 
density estimate over all of the training data (ignoring class labels). In practice, 
for simplicity of implementation we use a simple Gaussian mixture model. Further- 
more, because of the afore-mentioned scaling problem with input dimensions, only 
a subset of relatively significant input features are used in the mixture model. A 
less heuristic approach to this aspect of the problem (with which we have not yet 
experimented) would be to use a method such as projection pursuit to project the 
data into a lower dimensional subspace and perform the input density estimation in 
this space. The main point is that the generative model need not necessarily work 
in the full dimensional space of the i
