Bayesian model of surface perception 
William T. Freeman 
MERL, Mitsubishi Electric Res. Lab. 
201 Broadway 
Cambridge, MA 02139 
freemanmerl. corn 
Paul A. Viola 
Artificial Intelligence Lab 
Massachusetts Institute of Technology 
Cambridge, MA 02139 
riolanai. mir. edu 
Abstract 
Image intensity variations can result from several different object 
surface effects, including shading from 3-dimensional relief of the 
object, or paint on the surface itself. An essential problem in vision, 
which people solve naturally, is to attribute the proper physical 
cause, e.g. surface relief or paint, to an observed image. We ad- 
dressed this problem with an approach combining psychophysical 
and Bayesian computational methods. 
We assessed human performance on a set of test images, and found 
that people made fairly consistent judgements of surface properties. 
Our computational model assigned simple prior probabilities to 
different relief or paint explanations for an image, and solved for 
the most probable interpretation in a Bayesian framework. The 
ratings of the test images by our algorithm compared surprisingly 
well with the mean ratings of our subjects. 
I Introduction 
When people study a picture, they can judge whether it depicts a shaded, 3- 
dimensional surface, or simply a fiat surface with markings or paint on it. The 
two images shown in Figure I illustrate this distinction [1]. To many observers 
Figure la appears to be a raised plateau lit from the left. Figure lb is simply a 
re-arrangement of the local features of la, yet it does not give an impression of 
shape or depth. There is no simple correct answer for this problem; either of these 
images could be explained as marks on paper, or as illuminated shapes. Neverthe- 
less people tend to make particular judgements of shape or reflectance. We seek an 
algorithm to arrive at those same judgements. 
There are many reasons to study this problem. Disentangling shape and reflectance 
is a prototypical underdetermined vision problem, which biological vision systems 
routinely solve. Insights into this problem may apply to other vision problems 
788 W. T. Freeman and P. A. 14old 
as well. A machine that could interpret images as people do would have many 
applications, such as the interactive editing and manipulation of images. Finally, 
there is a large body of computer vision work on shape from shading-inferring 
the 3-dimensional shape of a shaded object [4]. Virtually every algorithm assumes 
that all image intensity changes are caused by shading; these algorithms fail for any 
image with reflectance changes. To bring this body of work into practical use, we 
need to be able to disambiguate shading from reflectance changes. 
There has been very little work on this problem. Sinha and Adelson [9] examined 
a world of painted polyhedra, and used consistancy constraints to identify regions 
of shape and reflectance changes. Their consistancy constraints involved specific 
assumptions which need not always hold and may be better described in a prob- 
abilistic framework. In addition, we seek a solution for more general, greyscale 
images. 
Our approach combines psychophysics and computational modeling. First we will 
review the physics of image formation and describe the under-constrained surface 
perception problem. We then describe an experiment to measure the interpretations 
of surface shading and reflectance among different individuals. We will see that the 
judgements are fairly consistent across individuals and can be averaged to define 
ground truth for a set of test images. Our approach to modeling the human 
judgements is Bayesian. We begin by formulating prior probabilities for shapes and 
reflectance images, in the spirit of recent work on the statistical modeling of images 
[5, 8, 11]. Using these priors, the algorithm then determines whether an image is 
more likely to have been generated by a 3D shape or as a pattern of reflectance. 
We compare our algorithm's performance to that of the human subjects. 
(a) (b) 
(c) (d) 
Figure 1: Images (a) and (b), designed by Adelson [1], are nearly the same 
everywhere, yet give different percepts of shading and reflectance. (a) looks like 
a plateau, lit from the left; (b) looks like marks on paper. Illustrating the under- 
constrained nature of perception, both images can be explained either by reflectance 
changes on paper (they are), or, under appropriate lighting conditions, by the 
shapes (c) and (d), respectively (vertical scale exaggerated). 
Bayesian Model of Surface Perception 789 
2 Physics of Imaging 
One simple model for the generation of an image from a three dimensional shape is 
the Lambertian model: 
I(x,y)=R(x,y) (i-a(x,y)), (1) 
where I(x, y) is an image indexed by pixel location, fi(x, y) is the surface normal at 
every point on the surface conveniently indexed by the pixel to which that surface 
patch projects, [ is a unit vector that points in the direction of the light source, 
and R(x, y) is the reflectance at every point on the surface . A patch of surface 
is brighter if the light shines onto it directly and darker if the light shines on it 
obliquely. A patch can also be dark simply because it is painted with a darker 
pigment. The shape of the object is probably more easily described as a depth map 
z(x, y) from which fi(x, y) is computed. 
The classical shape from shading task attempts to compute z from I given knowl- 
edge of  and assuming R is everywhere constant. Notice that the problem is ill- 
posed; while I(x, y) does constrain fi(x, y) it is not sufficient to uniquely determine 
the surface normal at each pixel. Some assumption about global properties of z is 
necessary to condition the problem. If R is allowed to vary, the problem becomes 
even more under-constrained. For example, R = I and fi(x, y) =  is a valid solution 
for every image. This is the all reflectance hypothesis, where the inferred surface 
is fiat and. all of the image variation is due to reflectance. Interestingly there is also 
^ 
an all shape solution for every image where R -- 1 and I(x, y) -- l-fi(x, y) (see 
Figure 1 for examples of such shapes). 
Since the relationship between z and I is non-linear, shape from shading cannot 
be solved directly and requires a time consuming search procedure. For our com- 
putational experiments we seek a rendering model for shapes which simplifies the 
mathematics, yet maintains the essential ambiguities of the problem. We use the ap- 
proximations of linear shading [6]. This involves two sets of approximations. First, 
that the rendered image I(x y) is some function, G(ï¿½z 0 
,  0, 0y), only of the surface 
slope at any point: 
I(x y) G( Oz Oz 
' )' (2) 
The second approximation is that the rendering function G itself is a linear function 
of the surface slopes, 
G(OZ Oz c9z k Oz (3) 
Ox' Oy )  k + k2x x+ 3 Oy. 
Under linear shading, finding a shape which explains a given image is a trivial 
integration along the direction of the assumed light source. Despite this simplicity, 
images rendered under linear shading appear fairly realistically shaded [6]. 
3 Psychophysics 
We used a survey to assess subjects' image judgements. We made a set of 60 test 
images, using Canvas and Photoshop programs to generate and manipulate the 
images. Our goal was to create a set of images with varying degrees of shadedness. 
We sought to assess to what extent each subject saw each image as created by 
Note: we assume orthographic projection, a distant light source, and no shadowing. 
790 W.. T. Freeman and P. A. V'wla 
shading changes or reflectance changes. Each of our 18 naive observers was given 
4 page survey showing the images in a different random order. 
To explain the problem of image interpretation quickly to naive subjects, we used 
a concrete story (Adelson's Theater Set Shop analogy [2] is a related didactic ex- 
ample). The survey instructions were as follows: 
Pretend that each of the following pictures is a photograph of work 
made by either a painter or a sculptor. 
The painter could use paint, markers, air brushes, computer, etc., 
to make any kind of mark on a flat canvas. The paint had no 
$-dimensionality,' everything was perfectly flat. 
The sculptor could make S-dimensional objects, but could make no 
markings on them. She could mold, sculpt, and scrape her sculp- 
tures, but could not draw or paint. All the objects were made out 
of a uniform plaster material and were made visible by lighting and 
shading effects. 
The subjects used a 5-point rating scale to indicate whether each image was made 
by the painter (P) or sculptor (S): S, S?, ?, P?, P. 
3.1 Survey Results 
We examined a non-parametric comparison of the image ratings, the rank order 
correlation (the linear correlation of image rankings in order of shapeness by each 
observer) [7]. Over all possible pairings of subjects, the rank order correlations 
ranged from 0.3 to 0.9, averaging 0.65. All of these correlations were statistically 
significant, most at the 0.0001 level. We concluded that for our set of test images, 
people do give a very similar set of interpretations of shading and reflectance. 
We assigned a numerical value to each of the 5 survey responses (S=2; S?=I; ?=0; 
P?=-i; P=-2) and found the average numerical shadedness score for each image. 
Figure 2 shows a histogram of the survey responses for each image, ordered in 
decreasing order of shadedness. The two images of Figure 1 had average scores of 1.7 
and -1.6, respectively, confirming the impressions of shading and reflectance. There 
was good consensus for the rankings of the most paint-like and most sculpture- 
like images; the middle images showed a higher score variance. The rankings by 
each individual showed a strong correlation with the rankings by the average of the 
remaining subjects, ranging from 0.6 to 0.9. Figure 4 shows the histogram of those 
correlations. The ordering of the images by t
