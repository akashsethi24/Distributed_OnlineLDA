Facial Memory is Kernel Density Estimation 
(Almost) 
Matthew N. Dailey Garrison W. Cottrell 
Department of Computer Science and Engineering 
U.C. San Diego 
La Jolla, CA 92093-0114 
{mdailey, gary}@cs. ucsd. edu 
Thomas A. Busey 
Department of Psychology 
Indiana University 
Bloomington, IN 47405 
busey@indiana. edu 
Abstract 
We compare the ability of three exemplar-based memory models, each 
using three different face stimulus representations, to account for the 
probability a human subject responded old in an old/new facial mem- 
ory experiment. The models are 1) the Generalized Context Model, 2) 
SimSample, a probabilistic sampling model, and 3) MMOM, a novel 
model related to kernel density estimation that explicitly encodes stim- 
ulus distinctiveness. The representations are 1) positions of stimuli in 
MDS face space, 2) projections of test faces onto the eigenfaces of 
the study set, and 3) a representation based on response to a grid of Gabor 
filter jets. Of the 9 model/representation combinations, only the distinc- 
tiveness model in MDS space predicts the observed morph familiarity 
inversion effect, in which the subjects' false alarm rate for morphs be- 
tween similar faces is higher than their hit rate for many of the studied 
faces. This evidence is consistent with the hypothesis that human mem- 
ory for faces is a kernel density estimation task, with the caveat that dis- 
tinctive faces require larger kernels than do typical faces. 
1 Background 
Studying the errors subjects make during face recognition memory tasks aids our under- 
standing of the mechanisms and representations underlying memory, face processing, and 
visual perception. One way of evoking such errors is by testing subjects' recognition of 
new faces created from studied faces that have been combined in some way (e.g. Solso and 
McCarthy, 1981; Reinitz, Lammers, and Cochran 1992). Busey and Tunnicliff (submit- 
ted) have recently examined the extent to which image-quality morphs between unfamiliar 
faces affect subjects' tendency to make recognition errors. 
Their experiments used facial images of bald males and morphs between these images (see 
Facial Memory Is Kernel Densicy Estimation (Almost) 25 
Figure 1: Three normalized morphs from the database. 
Figure 1) as stimuli. In one study, Busey (in press) had subjects rate the similarity of all 
pairs in a large set of faces and morphs, then performed a multidimensional scaling (MDS) 
of these similarity ratings to derive a 6-dimensional face space (Valentine and Endo, 
1992). In another study, Experiment 3 (Busey and Tunnicliff, submiued), 179 subjects 
studied 68 facial images, including 8 similar pairs and 8 dissimilarpairs, as determined in a 
pilot study. These pairs were included in order to study how morphs between similar faces 
and dissimilar faces evoke false alarms. We call the pair of images from which a morph are 
derived its parents;' and the morph itself as their child. In the experiment's test phase, 
the subjects were asked to make new/old judgments in response to 8 of the 16 morphs, 20 
completely new distractor faces, the 36 non-parent targets and one of the parents of each of 
the 8 morphs. The results were that, for many of the morph/parent pairs, subjects responded 
old to the unstudied morph more often than to its studied parent. However, this effect (a 
morph familiarity inversion) only occurred for the morphs with similar parents. It seems 
that the similar parents are so similar to their child morphs that they both contribute 
toward an old (false alarm) response to the morph. 
Researchers have proposed many models to account for data from explicit memory ex- 
periments. Although we have applied other types of models to Busey and Tunnicliff's 
data with largely negative results (Dailey et al., 1998), in this paper, we limit discussion 
to exemplar-based models, such as the Generalized Context Model (Nosofsky, 1986) and 
SAM (Gillund and Shiffrin, 1984). These models rely on the assumption that subjects 
explicitly store representations of each of the stimuli they study. Busey and Tunnicliff ap- 
plied several exemplar-based models to the Experiment 3 data, but none of these models 
have been able to fully account for the observed similar morph familiarity inversion with- 
out positing that the similar parents are explicitly blended in memory, producing prototypes 
near the morphs. 
We extend Busey and Tunnicliff's (submitted) work by applying two of their exemplar 
models to additional image-based face stimulus representations, and we propose a novel 
exemplar model that accounts for the similar morphs' familiarity inversion. The results are 
consistent with the hypothesis that facial memory is a kernel density estimation (Bishop, 
1995) task, except that distinctive exemplars require larger kernels. Also, on the basis of 
our model, we can predict that distinctiveness with respect to the study set is the critical 
factor influencing kernel size, as opposed to a context-free notion of distinctiveness. We 
can easily test this prediction empirically. 
2 Experimental Methods 
2.1 Face Stimuli and Normalization 
The original images were 104 digitized 560x662 grayscale images of bald men, with con- 
sistent lighting and background and fairly consistent position. The subjects varied in race 
and extent of facial hair. We automatically located the left and right eyes on each face using 
a simple template correlation technique then translated, rotated, scaled and cropped each 
image so the eyes were aligned in each image. We then scaled each image to 114x 143 to 
speed up image processing. Figure 1 shows three examples of the normalized morphs (the 
original images are copyrighted and cannot be published). 
26 M. N. Dailey, G. W. Cottrell and T. ,4. Busey 
2.2 Representations 
Positions in multidimensional face space Many researchers have used a multidimen- 
sional scaling approach to model various phenomena in face processing (e.g. Valentine and 
Endo, 1992). Busey (in press) had 343 subjects rate the similarity of pairs of faces in the 
test set and performed a multidimensional scaling on the similarity matrix for 100 of the 
faces (four non-parent target faces were dropped from this analysis). The process resulted 
in a 6-dimensional solution with r 2 -- 0.785 and a stress of 0.13. In the MDS modeling 
results described below, we used the 6-dimensional vector associated with each stimulus as 
its representation. 
Principal component projections Eigenfaces, or the eigenvectors of the covariance 
matrix for a set of face images, are a common basis for face representations (e.g. Turk and 
Pentland, 1991). We performed a principal components analysis on the 68 face images used 
in the study set for Busey and Tunnicliff's experiment to get the 67 non-zero eigenvectors 
of their covariance matrix. We then projected each of the 104 test set images onto the 30 
most significant eigenfaces to obtain a 30-dimensional vector representing each face. l 
Gabor filter responses von der Malsburg and colleagues have made effective use of 
banks of Gabor filters at various orientations and spatial frequencies in face recognition sys- 
tems. We used one form of their wavelet (Buhmann, Lades, and von der Malsburg, 1990) at 
five scales and 8 orientations in an 8x8 square grid over each normalized face image as the 
basis for a third face stimulus representation. However, since this representation resulted 
in a 2560-dimensional vector for each face stimulus, we performed a principal components 
analysis to reduce the dimensionality to 30, keeping this representation's dimensionality the 
same as the eigenface representation's. Thus we obtained a 30-dimensional vector based 
on Gabor filter responses to represent each test set face image. 
2.3 Models 
The Generalized Context Model (GCM) There are several different flavors to the GCM. 
We only consider a simple sum-similarity form that will lead directly to our distinctiveness- 
modulated density estimation model. Our version of GCM's predicted P(old), given a 
representation y of a test stimulus and representations x 6 X of the studied exemplars, is 
predy = a + t5 E e-ï¿½(dx'')2 
xX 
where a and/5 linearly convert the probe's summed similarity to a probability, X is the set 
of representations of the study set stimuli; c is used to widen or narrow the width of the 
similarity function, and dx,y is either [[x - yll, the Euclidean distance between x and y 
or the weighted Euclidean distance X/5'-t, wt, (xt, - yt,) 2 where the attentional weights 
wt, are constants that sum to 1. Intuitively, this model simply places a Gaussian-shaped 
function over each of the studied exemplars, and the predicted familiarity of a test probe is 
simply the summed height of each of these surfaces at the probe's location. 
Recall that two of our representations, PC projection space and Gabor filter space, are 
30-dimensional, whereas the other, MDS, is only 6-dimensional. Thus allowing adaptive 
weights for the MDS representation is reasonable, since the resulting model only uses 8 
parameters to fit 100 points, but it is clearly unreasonable to allow adaptive weights in 
PC and Gabor space, where the resulting models would be fitting 32 parameters to 100 
points. Thus, for all models, we report results in MDS space both with and without adaptive 
weights, but do not report adaptive weight results for models in PC and Gabor space. 
SimSample Busey and Tunnicliff (submitted) proposed SimSample in an attempt to rem- 
edy the GCM's poor predictions of the human data. It is related to both GCM, in that it 
We used 30 eigenfaces because with this number, our theoretical distinctiveness measure was 
best correlated with the same measure in MDS space. 
Facial Memory Is Kernel Density Estimation (AlmosO 27 
uses representations in MDS space, and SAM (Gillund and Shiffrin, 1984), in that it in- 
volves sampling exemplars. The
