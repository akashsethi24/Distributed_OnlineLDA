Recognizing Evoked Potentials in a Virtual 
Environment * 
Jessica D. Bayliss and Dana H. Ballard 
Department of Computer Science 
University of Rochester 
Rochester, NY 14627 
{ bayliss, dana}@ cs. rochester. edu 
Abstract 
Virtual reality (VR) provides immersive and controllable experimen- 
tal environments. It expands the bounds of possible evoked potential 
(EP) experiments by providing complex, dynamic environments in or- 
der to study cognition without sacrificing environmental control. VR 
also serves as a safe dynamic testbed for brain-computer interface (BCI) 
research. However, there has been some concern about detecting EP sig- 
nals in a complex VR environment. This paper shows that EPs exist at 
red, green, and yellow stop lights in a virtual driving environment. Ex- 
perimental results show the existence of the P3 EP at go and stop 
lights and the contingent negative variation (CNV) EP at slow down 
lights. In order to test the feasibility of on-line recognition in VR, we 
looked at recognizing the P3 EP at red stop lights and the absence of this 
signal at yellow slow down lights. Recognition results show that the P3 
may successfully be used to control the brakes of a VR car at stop lights. 
1 Introduction 
The controllability of VR makes it an excellent candidate for use in studying cognition. It 
expands the bounds of possible evoked potential (EP) experiments by providing complex, 
dynamic environments in order to study decision making in cognition without sacrificing 
environmental control. We have created a flexible system for real-time EEG collection and 
analysis from within virtual environments. 
The ability of our system to give quick feedback enables it to be used in brain-computer in- 
terface (BCI) research, which is aimed at helping individuals with severe motor deficits 
to become more independent. Recent BC! work has shown the feasibility of on-line 
averaging and biofeedback methods in order to choose characters or move a cursor on 
a computer screen with up to 95% accuracy while sitting still and concentrating on 
the screen [McFarland et al., 1993; Pfurtscheller et al., 1996; Vaughn et al., 1996; 
Farwell and Donchin, 1988]. Our focus is to dramatically extend the BC! by allowing 
evoked potentials to propel the user through alternate virtual environments. For example, a 
*This research was supported by NIH/PHS grantl-P41-RR09283. It was also facilitated in part 
by a National Physical Science Consortium Fellowship and by stipend support from NASA Goddard 
Space Flight Center. 
4 J.D. Bayliss and D. H. Ballard 
Figure 1' (Left) An individual demonstrates driving in the modified go cart. 
stoplight scene in the virtual environment 
(Right) A typical 
user could choose a virtual living room from a menu of rooms, navigate to the living room 
automatically in the head-mounted display, and then choose to turn on the stereo. 
As shown in [Farwell and Donchin, 1988], the P3 EP may be used for a brain-computer 
interface that picks characters on a computer monitor. Discovered by [Chapman and Brag- 
don, 1964; Sutton et al., 1965] and extensively studied (see [Polich, 1998] for a literature 
review), the P3 is a positive waveform occurring approximately 300-500 ms after an in- 
frequent task-relevant stimulus. We show that requiring subjects to stop or go at virtual 
traffic lights elicits this EP. The contingent negative variation (CNV), an EP that happens 
preceding an expected stimulus, occurs at slow down lights. 
In order to test the feasibility of on-line recognition in the noisy VR environment, we 
recognized the P3 EP at red stop lights and the lack of this signal at yellow slow down 
lights. Results using a robust Kalman filter for off-line recognition indicate that the car 
may be stopped reliably with an average accuracy of 84.5% while the on-line average for 
car halting is 83%. 
2 The Stoplight Experiments 
The first experiment we performed in the virtual driving environment shows that a P3 EP 
is obtained when subjects stop or go at a virtual light and that a CNV occurs when subjects 
see a slow down light. Since all subjects received the same light colors for the slow down, 
go, and stop conditions we then performed a second experiment with different light colors 
in order to disambiguate light color from the occurrence of the P3 and CNV. 
Previous P3 research has concentrated primarily on static environments such as the contin- 
uous performance task [Rosvold et al., 1956]. In the visual continuous performance task 
(VCPT), static images are flashed on a screen and the subject is told to press a button when 
a rare stimulus occurs or to count the number of occurrences of a rare stimulus. This makes 
the stimulus both rare and task relevant in order to evoke a P3. As an example, given red 
and yellow stoplight pictures, a P3 should occur if the red picture is less frequent than the 
yellow and subjects are told to press a mouse button only during the red light. We assumed 
a similar response would occur in a VR driving world if certain lights were infrequent and 
subjects were told to stop or go at them. This differs from the VCPT in two important 
ways: 
1. In the VCPT subjects sit passively and respond to stimuli. In the driving task, 
Recognizing Evoked Potentials in a lrtual Environment 5 
subjects control when the stimuli appear by where they drive in the virtual world. 
Since subjects are actively involved and fully immersed in the virtual world, they 
make more eye and head movements. The movement amount can be reduced by 
a particular experimental paradigm, but it can not be eliminated. 
The first difference makes the VR environment a more natural experimental enviroranent. 
The second difference means that subjects create more data artifacts with extra movement. 
We handled these artifacts by first manipulating the experimental environment to reduce 
movements where important stimulus events occurred. This meant that all stoplights were 
placed at the end of straight stretches of road in order to avoid the artifacts caused by turning 
a corner. For our on-line recognition, we then used the eye movement reduction technique 
described in [Semlitsch et aI., 1986] in order to subtract a combination of the remaining 
eye and head movement artifact. 
2.1 Experimental Setup 
All subjects used a modified go cart in order to control the virtual car (see Figure 1). The 
virtual reality interface is rendered on a Silicon Graphics Onyx machine wih 4 proces- 
sors and an Infinite Reality Graphics Engine. The environment is presented to the subject 
through a head-mounted display (HMD). Since scalp EEG recordings are measured in mi- 
crovolts, electrical signals may easily interfere during an experiment. We tested the effects 
of wearing a VR4 HMD containing an ISCAN eye tracker and discovered that the noise 
levels inside of the VR helmet were comparable to noise levels while watching a laptop 
screen [Bayliss and Ballard, 1998]. 
A trigger pulse containing information about the color of the light was sent to the EEG 
acquisition system whenever a light changed. While an epoch size from -100 ms to 1 sec 
was specified, the data was recorded continuously. Information about head position as well 
as gas, braking, and steering position were saved to an external file. Eight electrodes sites 
(FZ, CZ, CPZ, PZ, P3, P4, as well as 2 vertical EOG channels) were arranged on the heads 
of seven subjects with a linked mastoid reference. Electrode impedances were between 
2 and 5 kohms for all subjects. Subjects ranged in age from 19 to 52 and most had no 
previous experiences in a virtual environment. The EEG signal was amplified using Grass 
amplifiers with an analog bandwidth from 0.1 to 100 Hz. Signals were then digitized at a 
rate of 500 Hz and stored to a computer. 
2.2 Ordinary Traffic Light Color Experiment 
Five subjects were instructed to slow down on yellow lights, stop for red lights, and go for 
green lights. These are normal traffic light colors. Subjects were allowed to drive in the 
environment before the experiment to get used to driving in VR. 
In order to make slow down lights more frequent, all stoplights turned to the slow down 
color when subjects were further than 30 meters aways from them. When the subject 
drove closer than 30 meters the light then turned to either the go or stop color with equal 
probability. The rest of the light sequence followed normal stoplights with the stop light 
turning to the go light after 3 seconds and the go light not changing. 
We calculated the grand averages over red, green, and yellow light trials (see Figure 2a). 
Epochs affected by artifact were ignored in the averages in order to make sure that any 
existing movements were not causing a P3-1ike signal. Results show that a P3 EP occurs 
for both red and green lights. Back averaging from the green/red lights to the yellow light 
shows the existence of a CNV starting at approximately 2 seconds before the light changes 
to red or green. 
6 J.D. Bayliss and D. H. Ballard 
a) 
StopLight 
Go Light 
Slow Down Light 
-5 uv 
+10 uv 
b) 
-8 uv 
200ms I +12 uv 
Figure 2: a) Grand averages for the red stop, green go, and yellow slow down lights. b) Grand 
averages for the yellow stop, red go, and green slow down lights. All slow down lights have been 
back-averaged from the occurrence of the go/stop light in order to show the existence of a CNV. 
2.3 Alternative Traffic Light Colors 
The P3 is related to task relevance and should not be related to color, but color needed to 
be disambiguated as the source of the P3 in the experiment. We had two subjects slow 
down at green lights, stop at yellow lights, and go at red lights. In order to get used to this 
combination of colors, subjects were allowed to drive in the town before the experiment. 
The grand averages for each light color were calculated in the same manner as the averages 
above and are shown in Figure 2b. As expected
