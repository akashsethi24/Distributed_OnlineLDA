178 Lang and Hinton 
Dimensionality Reduction and Prior Knowledge 
E-set Recognition 
ill 
Kevin J. Lang  
Computer Science Dept. 
Carnegie Mellon University 
Pittsburgh, PA 15213 
USA 
Geoffrey E. Hinton 
Computer Science Dept. 
University of Toronto 
Toronto, Ontario M5S 1A4 
Canada 
ABSTRACT 
It is well known that when an automatic learning algorithm is applied 
to a fixed corpus of data, the size of the corpus places an upper bound 
on the number of degrees of freedom that the model can contain if 
it is to generalize well. Because the amount of hardware in a neural 
network typically increases with the dimensionality of its inputs, it 
can be challenging to build a high-performance network for classifying 
large input patterns. In this paper, several techniques for addressing this 
problem are discussed in the context of an isolated word recognition 
task. 
1 Introduction 
The domain for our research was a speech recognition task that requires distinctions to be 
learned between recordings of four highly confusable words: the names of the letters B, 
D, E, and V. The task was created at IBM's T. J. Watson Research Center, and is 
difficult because many speakers were included and also because the recordings were made 
under noisy office conditions using a remote microphone. One hundred male speakers 
said each of the 4 words twice, once for training and again for testing. The words were 
spoken in isolation, and the recordings averaged 1.1 seconds in length. The signal-to- 
noise ratio of the data set has been estimated to be about 15 decibels, as compared to 
1Now at NEC Research Institute, 4 Independence Way, Princeton, NJ 08540. 
Dimensionality Reduction and Prior Knowledge in E-Set Recognition 179 
50 decibels for typical lip-mike recordings (Brown, 1987). The key feature of the data 
set from our point of view is that each utterance contains a tiny information-laden event 
-- the release of the consonant which can easily be overpowered by meaningless 
variation in the strong E vowel and by background noise. 
Our first step in processing these recordings was to convert them into spectrograms using 
a standard DFT program. The spectrograms encoded the energy in 128 frequency bands 
(ranging up to 8 kHz) at 3 msec intervals, and so they contained an average of about 
45,000 energy values. Thus, a naive back-propagation network which devoted a separate 
weight to each of these input components would contain far too many weights to be 
properly constrained by the task's 400 training patterns. 
As described in the next section, we drastically reduced the dimensionality of our training 
patterns by decreasing their resolution in both frequency and time and also by using a 
segmentation algorithm to extract the most relevant portion of each pattern. However, our 
network still contained too many weights, and many of them were devoted to detecting 
spurious features. This situation motivated the experiments with our network's objective 
function and architecture that will be described in sections 3 and 4. 
2 Reducing the Dimensionality of the Input Patterns 
Because it would have been futile to feed our gigantic raw spectrograms into a back- 
propagation network, we first decreased the time resolution of our input format by a factor 
of 4 and the frequency resolution of the format by a factor 8. While our compression 
along the time axis preserved the linearity of the scale, we combined different numbers 
of raw freqencies into the various frequency bands to create a mel scale, which is linear 
up to 2 kHz and logarithmic above that, and thus provides more resolution in the more 
informative lower frequency bands. 
Next, a segmentation heuristic was used to locate the consonant in each training pattern 
so that the rest of the pattern could be discarded. On average, all but 1/7 of each 
recording was thrown away, but we would have liked to have discarded more. The 
useful information in a word from the E-set is concentrated in a roughly 50 msec region 
around the consonant release in the word, but current segmentation algorithms aren't 
good enough to accurately position a 50 msec window on that region. To prevent the 
loss of potentially useful information, we extracted a 150 msec window from around each 
consonant release. This safeguard meant that our networks contained about 3 times as 
many weights as would be required with an ideal segmentation. 
We were also concerned that segmentation errors during recognition could lower our 
final system's performance, so we adopted a simple segmentation-free testing method in 
which the trained network is scanned over the full-length version of each testing utterance. 
Figures 3(a) and 3(b) show the activation traces generated by two different networks when 
scanned over four sample utterances. To the right of each of the capital letters which 
identifies a particular sample word is a set of 4 wiggly lines that should be viewed as 
the output of a 4-channel chart recorder which is connected to the network's four output 
units. Our recognition rule for unsegmented utterances states that the output unit which 
180 Lang and Hinton 
B 
output unit weights 
- 8 kHz 
--- 2 kHz 
(a) (b) (c) (d) 
-1 kHz 
Figure 1: Output Unit Weights from Four Different 2-layer BDEV Networks: (a) base- 
lbe, (b) smoothed, (c) decayed, (d) TDNN 
generates the largest activation spike (and hence the highest peak in the chart recorder's 
traces) on a given utterance determines the network's classification of that utterance. 2 
To establish a performance baseline for the experiments that will be described in the next 
two sections, we trained the simple 2-layer network of figure 2(a) until it had learned to 
correctly identify 94 percent of our training segments. 3 
This network contains 4 output units (one for each word) but no hidden units. 4 The 
weights that this network used to recognize the words B and D are shown in figure 1 (a). 
While these weight patterns are quite noisy, people who know how to read spectrograms 
can see sensible feature detectors amidst the clutter. For example, both of the units appear 
to be stimulated by an energy burst near the 9th time frame. However, the units expect 
to see this energy at different frequencies because the tongue position is different in the 
consonants that the two units represent. 
Unfortunately, our baseline network's weights also contain many details that don't make 
2One can't reasonably expect a network that has been trained on pre-segmented patterns to function well 
when tested in this way, but our best network (a 3-layer TDN..') actually does perform better in this mode 
than when trained and tested on segments selected by a Viterbi alignment with an IBM hidden Markov model. 
Moreover, because the Viterbi alignment procedure is told the identity of the words in advance, it is probably 
more accurate than any method that could be used in a real recognition system. 
3This rather arbitra halting rule for the learning procedure was uniformly employed during the experiments 
of sections 2, 3 and 4. 
4Experiments performed with multi-layer networks support the same general conclusions as the results 
reported here. 
Dimensionality Reduction and Prior Knowledge in E-Set Recognition 181 
any sense to speech recognition experts. These spurious features are artifacts of our 
small, noisy training set, and are partially to blame for the very poor performance of 
the network; it achieved only 37 percent recognition accuracy when scanned across the 
unsegmented testing utterances. 
3 Limiting the Complexity of a Network using a Cost Function 
Our baseline network performed poorly because it had lots of free parameters with which 
it could model spurious features of the training set. However, we had already taken our 
brute force techniques for input dimensionality reduction (pre-segmenting the utterances 
and reducing the resolution of input forma0 about as far as possible while still retaining 
most of the useful information in the patterns. Therefore it was necessary to resort to 
a more subtle form of dimensionality reduction in which the back-propagation learning 
algorithm is allowed to create complicated weight patterns only to the extent that they 
actually reduce the network's error. 
This constraint is implemented by including a cost term for the network's complexity in 
its objective function. The particular cost function that should be used is induced by a 
particular definition of what constitutes a complicated weight pattern, and this definition 
should be chosen with care. For example, the rash of tiny details in figure l(a) originally 
led us to penalize weights that were different from their neighbors, thus encouraging the 
network to develop smooth, low-resolution weight patterns whenever possible. 
1�1 
c = IIll <wi- wj> 2 
� 
(1) 
To compute the total tax on non-smoothness, each weight wi was compared to all of its 
neighbors (which are indexed by the set Af/). When a weight differed from a neighbor, 
a penalty was assessed that was proportional to the square of their difference. The term 
IIll normalized for the fact that units at the edge of a receptive field have fewer 
neighbors than units in the middle. 
When a cost function is used, a tradeoff factor ) is typically used to control the relative 
importance of the error and cost components of the overall objective function O = E+.XC. 
The gradient of the overall objective function is then VO = VE + )VC. To compute 
K7C, we needed the derivative of our cost function with respect to each weight wi. This 
derivative is just the difference between the weight and the average of its neighbors: 
OC _ 1 
ow, - wi-   wj, so minimizing the combined objective function was equivalent 
to minimizing the network's error while simultaneously smoothing the weight patterns 
by decaying each weight towards the average of its neighbors. 
Figure l(b) shows the B and D weight p
