Direct Multi-Step Time Series 
Prediction Using TDO) 
Peter T. Kazlas 
Department of Electrical 
and Computer Engineering 
University of Colorado 
Boulder, CO 80309-0425 
pk&zl&s@coo&do. edu 
Andreas S. Weigend 
Department of Computer Science 
and Institute of Cognitive Science 
University of Colorado 
Boulder, CO 80309-0430 
ane&tc. color&o. eu * 
Abstract 
This paper explores the application of Temporal Difference (TD) learning 
(Sutton, 1988) to forecasting the behavior of dynamical systems with real- 
valued outputs (as opposed to game-like situations). The performance 
of TD learning in comparison to standard supervised learning depends 
on the amount of noise present in the data. In this paper, we use a 
deterministic chaotic time series from a low-noise laser. For the task of 
direct five-step ahead predictions, our experiments show that standard 
supervised learning is better than TD learning. The TD algorithm can be 
viewed as linking adjacent predictions. A similar effect can be obtained 
by sharing the internal representation in the network. We thus compare 
two architectures for both paradigms: the first architecture (separate 
hidden units) consists of individual networks for each of the five direct 
multi-step prediction tasks; the second (shared hidden units) has a 
single (larger) hidden layer that finds a representation from which all five 
predictions for the next five steps are generated. For this data set we do 
not find any significant difference between the two architectures. 
*http://www. cs.colorado.edu/~andreas/Home.htm1. 
This paper is avlab wi figus in colors as ftp://ftp.cs.colorado.edu/pu/ 
Time-Series/MyPapers/kazlas.weigend_nips7.ps.Z . 
722 Peter Kazlas, Andreas S. Weigend 
1 Introduction 
The Santa Fe Time Series Prediction and Analysis Competition (Weigend & Gershenfeld, 
1994) saw a relatively large number of different nonlinear techniques applied to the predic- 
tion of a few time series. One of the results was that some neural networks did very well (but 
incidentally some other neural networks also did very poorly). All neural networks were 
trained with standard supervised learning where the network is trained based on differences 
between the predicted and observed values of the series. The differences only concerned 
the architecture; a good example was the time delay neural network architecture, also called 
finite impulse response network. 
Standard supervised learning (SL), on the one hand, views time series prediction essentially 
as nonlinear regression; the fact that we are dealing with a time series is basically ignored. 
Temporal difference (TD) learning, on the other hand, takes a different approach: it adjusts 
the parameters based on differences between successive predictions in time (Sutton, 1988). 
TD learning has been shown to be very successful in the context of games such as backgam- 
mon (Tesauro, 1992). This paper investigates whether the TD paradigm can also be applied 
to the somewhat different task of time series prediction. 
This paper is organized as follows: after briefly reviewing TD learning, Section 2 focuses 
on the application of TD learning to multi-step prediction of time series, and contrasts it 
to supervised learning (see Figure 1). Section 3 then describes the architectures and cost 
function as well as the data set used in the experiments. Section 4 presents the results, and 
Section 5 summarizes the paper. 
2 TD learning for nonlinear, direct multi-step predictors 
The key idea behind TD learning is that errors (used for gradient descent) are based on 
predictions that are adjacent in time. This is in contrast to the traditional SL approach 
where the errors are based on the difference between the prediction and the observed value. 
The general expression for the TD weight update rule (linear case), TD(A), is given by 
(Sutton, 88) 
zxw = - (1) 
]=1 
where r] is the learning rate; .0t+ and .0t are two adjacent predictions of the equivalent 
target; A is the recency weight with 0 < A _< 1; and 7.0 is the gradient of the prediction 
at time k with respect to the weights of the network. 
In Equation (1), we use the present weights to calculate the predictions .0t and .0t+ and 
we use the past weights to calculate the past gradients. In our experiments, since .0t is 
an output of a nonlinear connectionist network, we form .0t by propagating it through a 
multilayer network with hidden units and we backpropagate weight changes by applying 
the chain rule to the gradient 7.0 with respect to the hidden layer activation function. 
Several variants of TD(A) exist: TD(0) only forms gradients based on the present pair of 
predictions (.0t, .0t +  ); TD(1) continually adds gradients with no weighting of recency; and 
in the general case, TD(A) weights the kth past gradient by a recency weight of A . As will 
be shown in the subsequent section, in our example, TD(A) tends to lead to the best results 
for A around 0.3 (the optimal value of A cannot be determined by first principles). 
Direct Multi-Step Time Series Prediction Using TD() 723 
In multi-step prediction, we directly predict the value of a time series n time steps into 
the future (yt+, denotes the observed value at t + n), given a set of m past values at 
time t denoted by the observation vector xt: (yt, Yt-1,...Yt-m-1). To cast the multi- 
step prediction problem into the TD framework, we first form an overlapping sequence of 
predictions as described by Sutton (1988): For an n-step ahead prediction problem, we 
n ..n- 1 ^1 
form n successive predictions of the same target yt+,: t, at+l, ... Yt+,-1 (.0t* is the 
prediction at time t for the time series 6 steps ahead). At each time step, we form two sets 
of predictions .0t* and .0t*. 1 based on the observation pair (xt, xt+). The corresponding 
weight update at time t involves the temporal difference of the these equivalent predictions: 
k'-I 
Equation (2) shows that the TD algorithm reduces to the SL algorithm for single-step 
predictions, since there is no temporal structure revealed in time (i.e. the actual value is 
available with the first observation pair (xt, xt+) at time t, and therefore +l = Yt+l). 
However, for a multi-step prediction problem, temporal structure exists in the revelation of 
the observation vectors. on-line, the 
To differentiate the two algorithms, Figure 1 depicts the backpropagation of errors using 
SL and TD learning algorithms. In SL, errors are generated by the squared difference 
between predicted and target values: network training simply tries to minimize the error 
function based on structural difference between the predicted (.0t , or simply .0) and target 
values (y), see (Figure l(a)). In (Figure l(b)), TD learning minimizes a different error 
function--the difference between successive predictions .0 (t) and .0- 1 (t + 1). Note, in 
the case of a noiseless time series, we do not expect to see a difference in performance 
between SL and TD learning, as the actual values of the time series are accurate descriptors 
of the system's output. In the case of a noisy time series, we conjecture that TD learning 
provides a better teaching signal than simply using the noisy observable. In this paper, we 
begin by comparing the performance of SL and TD learning on a low noise deterministic 
time series. 
A A A 
Yl Y2 Y3 Y4 Y5 Yl Yl Y2 Y3 94 
- yi(t) _ Yi(t) ,, ,. ., 
Y-m Y-1 YO Y-m Y-1 YO 
(a) Supervised Learning (b) Temporal Difference Learning 
Figure 1: Backpropagation for Supervised and Temporal Difference learning. 
724 Peter Kazlas, Andreas S. Weigend 
3 Architecture and Data 
The multi-step prediction problem we chose is to directly predict the next five values of a 
time series given the past five values. In comparing the two algorithms, we examine two 
architectures and compare their performance on a real-world dataset. 
Architecture. Two network architectures were chosen to compare the SL and TD algo- 
rithms in the multi-step prediction task. 
Separate hidden units. The first architecture consists of five separate prediction 
networks, each forming a single prediction `0i for the ith step-ahead prediction of 
the series. The five outputs correspond to the predictions `01 through ,05. Each 
network has five input units (corresponding to the past five values of the time 
series), 10 hidden units (arbitrarily chosen) and a single linear output for each 
task. 
Shared hidden units. The second architecture is a single network with five outputs 
corresponding to the five predictions (`01 .. ï¿½ .05). The network has the same five 
inputs, but has 20 tanh hidden units. 
Cost Function. We train on sum squared error, weighting all five predictions equally. In 
the supervised learning case, the predictions are compared to the actual values, while in the 
TD case, errors are calculated based on successive predictions: 
5 
./TD () '-- E',(0k_l(  1)- `0(1)) 2 (3) 
k_-I 
Search. In network training, we use batch updates, i.e., update weights after each pass 
through the training data. Network training continues until the error on the cross-validation 
set stagnates or begins to increase. For networks trained by TD learning, A, the recency 
weight, ranges from 0 _< A _< 0.5. 
Data. We use the laser data from the Santa Fe Competition. 1 The data are intensity 
measurements of a NH3 laser in a chaotic state, exhibiting Lorenz-like dynamics. We 
use the 1,000 competition data points for training, but also 1,000 further points for cross- 
validation of our model and 2,000 further points for testing. We depart from the competition 
rules in order to get higher statistical significance. 
4 Results 
Learning curves. We begin our analysis by plotting the squared error normalized by the 
variance for each of the five output units (`01 - `05) as a function of training time for both 
The data set and several predictions and characterizations are described in the vol- 
ume edi
