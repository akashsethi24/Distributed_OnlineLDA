Asymptotics of Gradient-based 
Neural Network Training Algorithms 
Sayandev Mukherjee 
saymukhee. cornell. edu 
School of Electrical Engineering 
Cornell University 
Ithaca, NY 14853 
Terrence L. Fine 
tlf ineee. cornell. edu 
School of Electrical Engineering 
Cornell University 
Ithaca, NY 14853 
Abstract 
We study the asymptotic properties of the sequence of iterates of 
weight-vector estimates obtained by training a multilayer feedfor- 
ward neural network with a basic gradient-descent method using 
a fixed learning constant and no batch-processing. In the one- 
dimensional case, an exact analysis establishes the existence of a 
limiting distribution that is not Gaussian in general. For the gen- 
eral case and small learning constant, a linearization approximation 
permits the application of results from the theory of random ma- 
trices to again establish the existence of a limiting distribution. 
We study the first few moments of this distribution to compare 
and contrast the results of our analysis with those of techniques of 
stochastic approximation. 
i INTRODUCTION 
The wide applicability of neural networks to problems in pattern classification and 
signal processing has been due to the development of efficient gradient-descent al- 
gorithms for the supervised training of multilayer feedforward neural networks with 
differentiable node functions. A basic version uses a fixed learning constant and up- 
dates all weights after each training input is presented (on-line mode) rather than 
after the entire training set has been presented (batch mode). The properties of 
this algorithm as exhibited by the sequence of iterates are not yet well-understood. 
There are at present two major approaches. 
336 Sayandev Mukherjee, Terrence L. Fine 
Stochastic approximation techniques (Bucklew,Kurtz,Sethares, 1993; Finnoff, 1993; 
Kuan,Hornik, 1991; White, 1989) study the limiting behavior of the stochastic pro- 
cess that is the piecewise-constant or piecewise-linear interpolation of the sequence 
of weight-vector iterates (assuming infinitely many i.i.d. training inputs) as the 
learning constant approaches zero. It can be shown (Bucklew,Kurtz,Sethares, 1993; 
Finnoff, 1993) that as the learning constant tends to zero, the fluctuation between 
the paths and their limit, suitably normalized, tends to a Gaussian diffusion process. 
Leen and Moody (1993) and Orr and Leen (1993) have considered the Markov 
process formed by the sequence of iterates (again, assuming infinitely many i.i.d. 
training inputs) for a fixed nonzero learning constant. This approach has the merit 
of dealing with the nonzero learning constant case and of linking the study of the 
training algorithm with the well-developed literature on Markov processes. 
In particular, it is possible to solve (Leen,Moody, 1993) for the asymptotic distribu- 
tion of the sequence of weight-vector iterates from the Chapman-Kolmogorov equa- 
tion after certain assumptions have been used to simplify it considerably. However, 
the assumptions are unrealistic: in particular, the assumption of detailed balance 
does not hold in more than one dimension. This approach also fails to establish the 
existence of a limiting distribution in the general case. 
This paper follows the nethod of considering the sequence of weight-vector iter- 
ates as a discrete-time continuous state-space Markov process, when the learning 
constant is fixed and nonzero. We shall first seek to establish the existence of an 
asymptotic distribution, and then examine this distribution through its first few 
moments. 
It can be proved (Mukherjee, 1994), using Foster's criteria (Tweedie, 1976) for the 
positive-recurrence of a Markov process, that when a single sigmoidal node with one 
parameter is trained using the iterative form of the basic gradient-descent training 
algorithm (without batch-processing), the sequence of iterates of the parameter has 
a limiting distribution which is in general non-Gaussian, thereby qualifying the oft- 
stated claims in the literature (see, for example, (Bucklew,Kurtz,Sethares, 1993; 
Finnoff, 1993; White, 1989)). However, this method proves to be intractable in the 
multiple parameter case. 
2 THE GENERAL CASE AND LINEARIZATION IN Wn 
The general version of this problem for a neural network V with scalar out- 
put involves training V with the i.i.d. training sequence {(X___n,Yn)} , loss function 
__ 1 
�(x_,y,w) [y- V(x,w)] 2 (x E ]Ra, y E ]R,w  ]R m) and the gradient-descent 
updating equation for the estimates of the weight vector given by 
Wn+ 1 ---- W n - iVw__�(x__,y,w)l(x+,y,+,w) 
'-- W n -- [Yn+l - rl(Wn,Xn+l)]Vw_rl(w__,x_)l___w,,.,x,,.+l. 
As is customary in this kind of analysis, the training set is assumed infinite, so that 
{Wn}n__o forms a homogeneous Markov process in discrete time. In our analysis, 
the training data is assumed to come from the model 
Y = v(w �, _x) + z, 
Asymptomatics of Gradient-Based Neural Network Training Algorithms 33 7 
where Z and X are independent, and Z has zero mean and variance a 2. Hence, 
the unrestricted Bayes estimator of Y given X, E(YIX ) = r/(w�,X), is in the class 
of neural network estimators, and w � is the goal of training. For convenience, we 
define ITV -- W- w �. 
Assuming that / is small and that after a while, successive iterates, with high 
probability, jitter about in a close neighborhood of the optimal value w �, we make 
the important assumption that 
, = ore k) () 
for some 0 < k < 1 (see Section 4) I Applying Taylor series expansions to r/ 
and V_r/and neglecting all terms Op(Ig l+2k) and higher, we obtain the following 
linearized form of the updating equation: 
/n+l -- An+lln + Bn+ 1 , 
where 
(2) 
(3) 
(4) 
do not depend on W. The matrices {(An+,Bn+l) } form an i.i.d. sequence, but 
An+l and B+ 1 are dependent for each n. Hence the linearized W again forms a 
homogeneous Markov process in discrete time. 
In what follows we analyze this process in the hope that its asymptotics agree with 
those of the original Markov process. 
3 EXISTENCE OF A LIMITING DISTRIBUTION 
Let A, B, G, J denote random matrices with the common distributions of the i.i.d. 
sequences {An}, {Bn}, {Gn}, and {Jn} respectively, and let T' IR m --. IR m be 
the random affine transformation 
 AwL+B_. 
The following result establishes the existence of a limiting distribution of W n. 
Lemma 1 (Berger Thm. V, p.162) Suppose 
',[log + IIAII + log + IIl[] < 
E log IIA,A,_... A I1 < 
where 
log + x - log x V O. 
Then the following conclusions hold: 
XI.e., (Ve > O)(3MJ(�n)P(-k[l__nl[ <_ M) > 1 -e. 
oo; (5) 
0 for some n (6) 
338 Sayandev Mukherjee, Terrence L. Fine 
Unique stationary distribution: There exists a unique random variable 
W  IR m, upto distribution, that is stationary with respect to T (i.e., 17V is 
independent of T, and TITV has the same distribution as 17V). 
2. Asymptotic stationarity: We have convergence in distribution: 
Our choice of norm is the operator norm for the matrix A, 
][A[[ = max 
where are the eigenvalues of X, and the Euclidean norm for the vector 
We first verify (5). From the inequality Vx  IR, log+x < x 2, it is easily seen 
that if r/is a feedforward net where all activation functions are twice-continuously 
differentiable in the weights, all hidden-layer activation functions are bounded and 
have bounded derivatives up to order 2, and if the training sequence (X, Y) is 
i.i.d. with finite fourth moments, then (5) holds for the Euclidean norm for B and 
the Frobenius norm for A, [IA][ 2 = n=l En=l ]Alii 2. Since 
m m 
(max IA(A)I) 2 _<  IA(A)I 2 _<   I&jl 2, (7) 
i= 
we see that (5) also holds for the operator norm of A. 
Assumption (6) forces the product A-.. A1 to tend to 0 mx m almost surely (Berger, 
1993, p.146) and therefore removes the dependence of the asymptotic distribution 
of {17Vn} on that of the initial value ITV 0. A sufficient condition for (6) is given by 
the following lemma. 
Lemma 2 Suppose lEG is positive definite (note that it is positive semidefinite by 
definition), and for all n, lEA n < cx>. Then (6) holds for suJ2ficiently small, positive 
l. 
Proof: By assumption, min A(lEG) = 5 > 0 for some 5. 
I n 
Let H =  i=i(Gi - ZiJi). By the Strong Law of Large Numbers applied to the 
i.i.d. random matrices (Gi - ZiJi), we have H -4 lEG a.s., so 
minA(Hn)-* minA(lEG) a.s. (8) 
Applying (7) to rain A(H,), it is easily shown that the same conditions on r/ and 
the training sequence that are sufficient for (5) also give SUPn 1E[min A(Hn)] 2 < 
which in turn implies that {min A(Hn)} are uniformly integrable. Together with (8), 
this implies (Love, 1977, p.165) that minA(Hn) --, minA(lEG) in L 1. Hence there 
Asymptomatics of Gradient-Based Neural Network Training Algorithms 339 
exists some (nonrandom) N, say, such that EIminA(HN ) -- minA(EG)l <_ 6/2. 
Since 
[]Emin (HN) -- min,X(EG)l _< El min(HN) - min (EG)  6/2, 
we therefore have 
E min (Gi- ZiJi)  min(EG)-6/2 =6-6/2 =6/2 > 0. (9) 
We shall prove that (6) holds for this N ( m) by showing that 
log IIANAN-x � � � Axil = log [IANAN-x ' Axil 0, 
For our choice of norm, we therefore want 1F, [log (max IA(AN... A1)I) 2] < 0. From 
Jensen's inequality, it is sufficient to have log lE[max IA(AN' A1)1] 2 < 0, or equiv- 
alently, 
E[maxIA(AN...A1)[] 2 < 1. (10) 
Now, since N is fixed, we can choose u small enough that 
N 
AN' A1 =[m - [1E(C_i - ZiJi) q- 
i:1 
N 
Hence, A(AN ... A1) = 1 - ;tA(Y],i:l(G/- Z/J/)) + Oe(it2), and N is fixed, so 
[A(AN... A1)] 2 - 1 - 2A (G/- &J) + 
giving 
mA(AN...A)I 2 g 1--2minA (G-ZJ) +Oe(2), 
EmIA(AN ...A)] 2 5 1 - NS + o(), (11) 
where we use (9) and the observation that the structure of the lt Oe( 2) term is 
such that its expectation (guaranteed finite by the hypothesis EA N < ) is O(2), 
or o(), and we also restrict  < 1/N5 so that 
1 - 2E rain A (G - ZiJi) > 0. 
From (11), it is clear that (10) holds for all sufficien
