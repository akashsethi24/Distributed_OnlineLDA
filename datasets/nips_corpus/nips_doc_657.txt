Diffusion Approximations for the 
Constant Learning Rate 
Backpropagation Algorithm and 
Resistence to Local Minima 
William Finnoff 
Siemens AG, Corporate Research and Development 
Otto-Hahn-Ring 6 
8000 Munich 83, Fed. Rep. Germany 
Abstract 
In this paper we discuss the asymptotic properties of the most com- 
monly used variant of the backpropagation algorithm in which net- 
work weights are trained by means of a local gradient descent on ex- 
amples drawn randomly from a fixed training set, and the learning 
rate  of the gradient updates is held constant (simple backpropa- 
gation). Using stochastic approximation results, we show that for 
 -+ 0 this training process approaches a batch training and pro- 
vide results on the rate of convergence. Further, we show that for 
small  one can approximate simple back propagation by the sum 
of a batch training process and a Gaussian diffusion which is the 
unique solution to a linear stochastic differential equation. Using 
this approximation we indicate the reasons why simple backprop- 
agation is less likely to get stuck in local minima than the batch 
training process and demonstrate this empirically on a number of 
examples. 
1 INTRODUCTION 
The original (simple) backpropagation algorithm, incorporating pattern for pattern 
learning and a constant learning rate ]  (0, oo), remains in spite of many real (and 
459 
460 Finnoff 
imagined) deficiencies the most widely used network training algorithm, and a vast 
body of literature documents its general applicability and robustness. In this paper 
we will draw on the highly developed literature of stochastic approximation the- 
ory to demonstrate several asymptotic properties of simple backpropagation. The 
close relationship between backpropagation and stochastic approximation methods 
has been long recognized, and various properties of the algorithm for the case of 
decreasing learning rate rln+ < r/,, n  N were shown for example by White 
[W,89a], [W,89b] and Darken and Moody [D,M,91]. ttornik and Kuan tit,K,91] 
used comparable results for the algorithm with constant learning rate to derive 
weak convergence results. 
In the first part of this paper we will show that simple backpropagation has the 
same asymptotic dynamics as batch training in the small learning rate limit. As 
such, anything that can be expected of batch training can also be expected in simple 
backpropagation as long as the learning rate of the algorithm is very small. In the 
special situation considered here (in contrast to that in [H,K,91]) we will also be 
able to provide a result on the speed of convergence. As such, anything that can be 
expected of batch training can also be expected in simple backpropagation as long 
as the learning rate of the algorithm is very small. In the next part of the paper, 
Gaussian approximations for the difference between the actual training process and 
the limit are derived. It is shown that this difference, (properly renormalized), con- 
verges to the solution of a linear stochastic differential equation. In the final section 
of the paper, we combine these results to provide an approximation for the simple 
backpropagation training process and use this to show why simple backpropagation 
will be less inclined to get stuck in local minima than batch training. This ability 
to avoid local minima is then demonstrated empirically on several examples. 
2 NOTATION 
Define the. parametric version of a single hidden layer network activation function 
with h inputs, m outputs and q hidden units 
f: R d x R h  R'n,(O,x)  (fx(O,x),...,fm(O,x)), 
by setting for a:  R h, � = (a:, ..., a:t, 1), 0 = (7:,/:) and u = 1, ..., m, 
where denotes the transpose of � and d = m(q + 1) + q(h + 1) denotes the 
number of weights in the network. Let ((Yk, Xk))=L...,' be a set of training exam- 
ples, consisting of targets (Y)=,...,, and inputs (X)k=L...O.. We then define the 
parametric error function 
I]Y- f(O,)11 
and for every 0, the cummulative gradient 
Diffusion Approximations for the Constant Learning Rate Backpropagation Algorithm 461 
1 k ou 
h(o) = - 
k=l 
, Xk, 0). 
3 APPROXIMATION WITH THE ODE 
We will be considering the asymptotic properties of network training processes 
induced by the starting value 00, the gradient (or direction) function -.- the 
learning rate r/and an infinite training sequence (Yn,Xn)nEN, where each (yn,xn) 
example is drawn at random from the set ((Y1, X1), ...,(YT, XT)). One defines the 
discrete parameter process 0 = 0 = (0n)nEZ+ of weight updates by setting 
0o for n = 0 
0v On_l) fornN 
o = o.- (y,.,z., 
and the corresponding continuous parameter process (0n/))[0,oo), by setting 
OU O,  
o(t) = o- (t - (n- 1).)7(v.,x., ._1) 
for t  [(n - 1)r/, nr/), n  N. The first question that we will investigate is that 
of the 'small learning rate limit' of the continuous parameter process 0 n i.e. the 
limiting properties of the family 0 nfor r/--+ 0. We show that the family of (stochas- 
tic) processes (0)n0 converges with probability one to a limit process , where  
denotes the solution to the cummulative gradient equation, 
a(t) = Oo + h(a())&. 
Here, for 00 = a = constant, this solution is deterministic. This result corresponds 
to a 'law of large numbers' for the weight update process, in which the small learning 
rate (in the limit) averages out the stochastic fluctuations. 
Central to any application of the stochastic approximation results is the derivation 
0v and h. That is the subject of 
of local Lipschitz and linear growth bounds for  
the following, 
Lemma(3.1) i) There exists a constant K > 0 so that 
sup (y, :, o) < K( + I1011) 
(,)  - 
and 
IIh(O)11 _< K(X + IIO11). 
ii) For every G > 0 there exists a constant L6 so that for any 0, '  [-G, G] a, 
462 Finnoff 
and 
0) < 
(,) (y, x, - - 
37 - 
lib(o) - h(O)ll <_ Lal10 - 011. 
Proof: The calculations on which this result are based are tedious but straightfor- 
ward, making repeated use of the fact that products and sums of locally Lipschitz 
continuous functions are themselves locally Lipschitz continuous. It is even possible 
to provide explicit values for the constants given above. 
Denoting with P (resp. E) the probability (resp. mathematical expectation) of the 
processes defined above, we can_present the results on the probability of deviations 
of the process 0 from the limit 0. 
Theorem(3.2) Let r, 5  (0, o). Then there exists a constant Br (which 
doesn't depend on r/) so that 
i) E (sup,<r liOn(s)- (s)l[ ') <_ Brrl. 
ii)P (sup,<r IlO(s) -(s)l I > 5) _< bB,.rl. 
Proof: The first part of the proof requires that one finds bounds for 0nt) and (t) 
for t 6 [0, r]. This is accomplished using the results of Lemma(3.1) and Gronwall's 
Lemma. This places r/independent bounds on Br. The remainder of the proof uses 
Theorem(9), �1.5, Part II of [Ben,Met,Pri,87]. The required conditions (A1), (A2) 
follow directly from our hypotheses, and (A3), (A4) from Lemma(3.1). Due to the 
boundedness of the variables (Yn, xn)nN and 00, condition (A5) is trivially fulfilled. 
It should be noted that the constant Br is usually dependent on r and may indeed 
increase exponentially (in r) unless it is possible to show that the training process 
remains in some bounded region for t --, oo. This is not necessarily due exclusively 
to the difference between the stochastic approximation and the discrete parameter 
cummulative gradient process, but also to the the error between the discrete (Euler 
approximation) and continuous parameter versions of (3.3). 
4 GAUSSIAN APPROXIMATIONS 
In this section we will give a Gaussian approximation for the difference between 
the training process 0 n and the limit . Although in the limit these coincide, for 
r/ > 0 the training process fluctuates away from the limit in a stochastic fashion. 
The following Gaussian approximation provides an estimate for the size and nature 
Diffusion Approximations for the Constant Learning Rate Backpropagation Algorithm 463 
of these fluctuations depending on the second order statistics (variance/covariance 
matrix) of the weight update process. Define for any t  [0, oo), 
o(t) - 
ovi, ,0), (resp. h i 
Further, for i = 1, ..., dwe denote with  [y, z (0)) the i-th coordinate 
vector of x, = 
-g(y, 0) (resp. h(O)). Then define for i,j 1,...,d, 0  R a 
= 7 \ oo . 
Thus, for any n  N, 0  R a, R(O) represents the covariance matrix of the random 
elements -q-g(y,, xn, 0). We can then define for the symmetric matrix R(0) a further 
R aXa valued matrix RS(O) with the property that R(0)= R�(O)(R(O)) T. 
The following result represents a central limit theorem for the training process. This 
permits a type of second order approximation of the fluctuations of the stochastic 
training process around its deterministic limit. 
Theorem(4.1): Under the assumptions given above, the distributions of the 
processes O r/> 0, converge weakly (in the sense of weak convergence of measures) 
for r/-- 0 to a uniquely defined measure �{0}, where 0 denotes the solution to the 
following stochastic differential equation 
t Oh -  jo  
= (O(s))O(s)as + 
where W denotes a standard d-dimensional Brownian motion (i.e. with covariance 
matrix equal to the identity matrix). 
Proof: The proof here uses Theorem(7), �4.4, Part II of [Ben,Met,Pri,87]. As 
noted in the proof of Theorem(3.2), under our hypotheses, the conditions (A1)- 
(.A5) are fulfilled. Define for i,j = 1,...,d, (y,z)  I m+t, 0  R d, wij(y,z,O) = 
p' (y, x, O)p 5 (y, r, O)-h i (O)hJ (0), and v = p. Under our hypotheses, h has continuous 
first and second order derivatives for all 0  R d and the function R = (Rff)ij=l,...,d 
as well as W = (wiY)i,i=x,...,d fulfill the remaining requirements of (AS) as follows: 
(A8)i) and (A8)ii) are trivial consequence of the definition of R and W. Finally, 
setting Pa = p4 = 0 and p = 1, (AS)iii) then can be derived directly from the 
definitions 
