I I 
Computing with Action Potentials 
John J. Hopfield* 
Carlos D. Brody 
Sam Roweis 
Abstract 
Most computational engineering based loosely on biology uses contin- 
uous variables to represent neural activity. Yet most neurons communi- 
cate with action potentials. The engineering view is equivalent to using 
a rate-code for representing information and for computing. An increas- 
ing number of examples are being discovered in which biology may not 
be using rate codes. Information can be represented using the timing of 
action potentials, and efficiently computed with in this representation. 
The analog match problem of odour identification is a simple problem 
which can be efficiently solved using action potential timing and an un- 
derlying rhythm. By using adapting units to effect a fundamental change 
of representation of a problem, we map the recognition of words (hav- 
ing uniform time-warp) in connected speech into the same analog match 
problem. We describe the architecture and preliminary results of such a 
recognition system. Using the fast events of biology in conjunction with 
an underlying rhythm is one way to overcome the limits of an event- 
driven view of computation. When the intrinsic hardware is much faster 
than the time scale of change of inputs, this approach can greatly increase 
the effective computation per unit time on a given quantity of hardware. 
1 Spike timing 
Most neurons communicate using action potentials- stereotyped pulses of activity that are 
propagated along axons without change of shape over long distances by active regenerative 
processes. They provide a pulse-coded way of sending information. Individual action 
potentials last about 2 ms. Typical active nerve cells generate 5-100 action potentials/sec. 
Most biologically inspired engineering of neural networks represent the activity of a nerve 
cell by a continuous variable which can be interpreted as the short-time average rate of 
generating action potentials. Most traditional discussions by neurobiologists concerning 
how information is represented and processed in the brain have similarly relied on using 
short term mean firing rate as the carrier of information and the basis for computation. 
But this is often an ineffective way to compute and represent information in neurobiology. 
*Dept. of Molecular Biology, Princeton University. j hopf J. eldalzson. princeton. edu 
Computation & Neural Systems, California Institute of Technology. 
Computing with Action Potentials 167 
To define short term mean firing rate with reasonable accuracy, it is necessary to either 
wait for several action potentials to arrive from a single neuron, or to average over many 
roughly equivalent cells. One of these necessitates slow processing; the other requires 
redundant wetware. 
Since action potentials are short events with sharp rise times, action potential timing is 
another way that information can be represented and computed with ([Hopfield, 1995]). 
Action potential timing seems to be the basis for some neural computations, such as the 
determination of a sharp response time to an ultrasonic pulse generated by the moustache 
bat. In this system, the bat generates a 10 ms pulse during which the frequency changes 
monotonically with time (a chirp). In the cochlea and cochlear nucleus, cells which 
are responsive to different frequencies will be sequentially driven, each producing zero 
or one action potentials during the time when the frequency is in their responsive band. 
These action potentials converge onto a target cell. However, while the times of initiation 
of the action potentials from the different frequency bands are different, the length and 
propagation speed of the various axons have been coordinated to result in all the action 
potentials arriving at the target cell at the same time, thus recognizing the chirped pulse 
as a whole, while discriminating against random sounds of the same overall duration. 
Taking this hint from biology, we next investigate the use of action potential timing to rep- 
resent information and compute with in one of the fundamental computational problems 
relevant to oilaction, noting why the elementary neural net engineering solution is poor, 
and showing why computing with action potentials lacks the deficiencies of the conven- 
tional elementary solution. 
2 Analog match 
The simplest computational problem of odors is merely to identify a known odor when a 
single odor dominates the olfactory scene. Most natural odors consist of mixtures of sev- 
eral molecular species. At some particular strength a complex odor b can be described by 
the concentrations N of its constitutive molecular of species i. If the stimulus intensity 
changes, each component increases (or decreases) by the same multiplicative factor. It is 
convenient to describe the stimulus as a product of two factors, an intensity ), and normal- 
ized components n as: 
 = EjN = n i 
b 
The n i are normalized, or relative concentrations of different molecules, and ), describes 
the overall odor intensity. Ideally, a given odor quality is described by the pattern of n , 
which does not change when the odor intensity ), changes. When a stimulus s described 
by a set {N } is presented, an ideal odor quality detector answers yes to the question is 
odor b pres6nt? if and only if for some value of),: 
v j (2) 
This general computation has been called analog match. 
The elementary neural net way to solve analog match and recognize a single odor in- 
dependent of intensity would b to use a single grandmother unit of the following type. 
The analog match problem ofolfaction is actually viewed through olfactory receptor cells. Stud- 
ies of vertebrate sensory cells have shown that each molecular species stimulates many different 
sensory cells, and each cell is excited by many different molecular species. The pattern of relative 
excitation across the population of sensory cell classes determines the odor quality in the generalist 
olfactory system. There are about 1000 broadly responsive cell types; thus, the olfactory systems of 
higher animals apparently solve an analog match problem of the type described by (2), except that 
the indices refer to cell types, and the actual dimension is no more than 1000. 
168 J. J. Hopfield, C. D. Brody andS. Roweis 
Call the unknown odor vector I, and the weight vector W. The input to the unit will then 
be I- W. IfW = -/ll-II and I is pre-normalized by dividing by the Euclidean magnitude 
IIIII, recognition can be identified by I. W > .95, or whatever threshold describes the 
degree of precision in identification which the task requires. 
This solution has four major weaknesses. 
1. Euclidean normalization is used; not a trivial calculation for real neural hardware. 
2. The size of input components Ik and their importance is confounded. If a weak 
component has particular importance, or a strong one is not reliable, there is no 
way to represent this. W describes only the size of the target odor components. 
3. There is no natural composition if the problem is to be broken into a hierarchy 
by breaking the inputs into several parts, solving independently, and feeding these 
results on to a higher level unit for a final recognition. This is best seen by analogy 
to vision. If I recognize in a picture grandmother's nose at one scale, her mouth 
at another, and her right eye at a third scale, then it is assuredly not grandmother. 
Separate normalization is a disaster for creating hierarchies. 
4. A substantial number of inputs may be missing or giving grossly wrong informa- 
tion. The dot-product-and-threshold solution cannot contend with this problem. 
For example, in olfaction, two of the common sources of noise are the adaptation 
of a subset of sensors due to previous strong odors, and receptors stuck on due 
to the retention of strongly bound molecules from previous odors. 
All four problems are removed when the information is encoded and computed with in an 
action potential representation, as illustrated below. 'The three channels of analog input 
Ia,Ib, Ic are illustrated on the left. They are converted to a spike timing representation by 
the position of action potentials with respect to a fiducial time T. The interval between 
T and the time of an action potential in a channel j is equal to log Ij. Each channel is 
connected to an output unit through a delay line of length Aj = log n}, where n b is the 
target vector to be identified. When the analog match criterion is satisfied, the pulses on 
all three channels will arrive at the target unit at the same time, driving it strongly. If all 
inputs are scaled by a, then the times of the action potentials will all be changed by log a. 
The three action potentials will arrive at the recognition unit simultaneously, but a a time 
shifted by log a. Thus a pattern can be recognized (or not) on the basis of its relative 
components. Scale information is retained in the time at which the recognition unit is 
driven. The system clearly composes, and difficulty (3) is surmounted. No normalization 
is required, eliminating difficulty (1). Each pathway has two parameters describing it, a 
delay (which contains the information about the pattern to be recognized) and a synaptic 
strength (which describes the weight of the action potential at the recognition unit). Scale 
and importance are separately represented. The central computational motif is very similar 
to that used in bat sonar, using relative timing to represent information and time delays to 
represent target patterns. 
a _ log 
b log 
c log 
Imin Imax 
0 0 
Delays set 
prototype pattern 
Weights set relative 
feature importance 
recognition unit sums 
EPSPs then thresholds 
Computing with Action Potentials 169 
This system also tolerates errors due to missing or grossly inaccurate information. The 
figure below illustrates this fact for the case of three
