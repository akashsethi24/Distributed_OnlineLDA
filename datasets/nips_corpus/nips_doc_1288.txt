Relative Loss Bounds for Multidimensional 
Regression Problems 
Jyrki Kivinen 
Department of Computer Science 
P.O. Box 26 (Teollisuuskatu 23) 
FIN-00014 University of Helsinki, Finland 
Manfred K. Warmuth 
Department of Computer Science 
University of California, Santa Cruz 
Santa Cruz, CA 95064, USA 
Abstract 
We study on-line generalized linear regression with multidimensional 
outputs, i.e., neural networks with multiple output nodes but no hidden 
nodes. We allow at the final layer transfer functions such as the soft- 
max function that need to consider the linear activations to all the output 
neurons. We use distance functions of a certain kind in two completely 
independent roles in deriving and analyzing on-line learning algorithms 
for such tasks. We use one distance function to define a matching loss 
function for the (possibly multidimensional) transfer function, which al- 
lows us to generalize earlier results from one-dimensional to multidimen- 
sional outputs. We use another distance function as a tool for measuring 
progress made by the on-line updates. This shows how previously stud- 
ied algorithms such as gradient descent and exponentiated gradient fit 
into a common framework. We evaluate the performance of the algo- 
rithms using relative loss bounds that compare the loss of the on-line 
algoritm to the best off-line predictor from the relevant model class, thus 
completely eliminating probabilistic assumptions about the data. 
1 INTRODUCTION 
In a regression problem, we have a sequence of n-dimensional real valued inputs at  1t. n, 
t = 1,... ,�, and for each input at a k-dimensional real-valued desired output h 
Our goal is to find a mapping that at least approximately models the dependency between 
at and tt- Here we consider the parametric case t = f(o; at) where the actual outputt 
corresponding to the input at is determined by a parameter vector w  1t. ' (e.g., weights 
in a neural network) through a given fixed model f (e.g., a neural network architecture). 
288 J. Kivinen and M. K. Warmuth 
Thus, we wish to obtain parameters o., such that, in some sense, f(o; zt)  Yt for all 
t. The most basic model f to consider is the linear one, which in the one-dimensional 
case k = 1 means that f(w; at) = o., � :rt for o., E R n. In the multidimensional case 
we actually have a whole matrix f  R nxn of parameters and f(f; :rt) = f:rt. The 
goodness of the fit is quantitatively measured in terms of a loss function; the square loss 
given by '-t,j (yt,j - .Ot,d)/2 is a popular choice. 
In generalized linear regression [MN89] we fix a transfer function b and apply it on top of a 
linear model. Thus, in the one-dimensional case we would have f (o.,; :rt) = 4(o.,.:rt). Here 
4 is usually a continuous increasing function from R to R, such as the logistic function 
that maps z to 1/(1 q- e-z). It is still possible to use the square loss, but this can lead to 
problems. In particular, when we apply the logistic transfer function and try to find a weight 
vector o., that minimizes the total square loss over � examples (at, Yt), we may have up to 
 local minima [AHW95, Bud93]. Hence, some other choice of loss function might be 
more convenient. In the one-dimensional case it can be shown that any continuous strictly 
increasing transfer function b has a specific matching loss function L such that, among 
other useful properties, '-t L(yt, qb(o � :et)) is always convex in o, so local minima are 
not a problem [AHW95]. For example, the matching loss function for the logistic transfer 
function is the relative entropy (a generalization of the logarithmic loss for continuous- 
valued outcomes). The square loss is the matching loss function for the identity transfer 
function (i.e., linear regression). 
The main theme of the present paper is the application of a particular kind of distance func- 
tions to analyzing learning algorithms in (possibly multidimensional) generalized linear 
regression problems. We consider a particular manner in which a mapping b: R '  R ' 
can be used to define a distance function Ab: R ' x R n -- R; the assumption we must 
make here is that b has a convex potential function. The matching loss function L men- 
tioned above for a transfer function  in the one-dimensional case is given in terms of 
the distance function A as L(qS(a), qb(&)) -' A(&,a). Here, as whenever we use the 
matching loss L (g, .0), we assume that t and .0 are in the range of qb, so we can write 
g = qb(a) and .0 = qb(a) for some a and 6. Notice that for k -- 1, any strictly increasing 
continuous function has a convex potential (i.e., integral) function. In the more interesting 
case k > 1, we can consider transfer functions such as the softmax function, which is com- 
monly used to transfer arbitrary vectors a  1t. n into probability vectors . (i.e., vectors 
such that .0i _ 0 for all i and 'i .0i -' 1). The matching loss function for the softmax func- 
tion defined analogously with the one-dimensional case tums out to be the relative entropy 
(or Kullback-Leibler divergence), which indeed is a commonly used measure of distance 
between probability vectors. For the identity transfer function, the matching loss function 
is the squared Euclidean distance. 
The first result we get from this observation connecting matching losses to a general notion 
of distance is that certain previous results on generalized linear regression with matching 
loss on one-dimensional outputs [HKW95] directly generalize to multidimensional out- 
puts. From a more general point of view, a much more interesting feature of these distance 
functions is how they allow us to view certain previously known learning algorithms, and 
introduce new ones, in a simple unified framework. To briefly explain this framework with- 
out unnecessary complications, we restrict the following discussion to the case k = 1, i.e., 
f(.,; :r) --- b(o � :r) 6 R with ., 6 R n . 
We consider on-line learning algorithms, by which we here mean an algorithm that pro- 
cesses the training examples one by one, the pair (at, yt) being processed at time t. Based 
Relative Loss Bounds for Multidimensional Regression Problems 289 
on the training examples the algorithm produces a whole sequence of weight vectors 
t -- 1,..., �. At each time t the old weight vector o.,t is updated into wt+z based on at and 
yt. The best-known such algorithm is on-line gradient descent. To see some alternatives, 
consider first a distance function AX/, defined on 1:1, n by some function X/': l:{,n -- 
(Thus, we assume that X/' has a convex potential.) We represent the update somewhat indi- 
rectly by introducing a new parameter vector 0t E 1 :{,n from which the actual weights 
are obtained by the mapping wt = X/'(0t). The new parameters are updated by 
0t+ = 0. - (Lo(u.. 
(1) 
where r/> 0 is a learning rate. We call this algorithm the general additive algorithm with 
parameterization function b. Notice that here 0 is updated by the gradient with respect 
to o.,, so this is not just a gradient descent with reparameterization [JW98]. However, we 
obtain the usual on-line gradient descent when b is the identity function. When b is 
the softmax function, we get the so-called exponentiated gradient (EG) algorithm [KW97, 
HKW951. 
The connection of the distance function Ab to the update (1) is two-fold. First, (1) can 
be motivated as an approximate solution to a minimization problem in which the distance 
Axl,(Ot, Ot+) is Used as a kind of penalty term to prevent too drastic an update based on 
a single example. Second, the distance function AX/, can be used as a potential function 
in analyzing the performance of the resulting algorithm. The same distance functions have 
been used previously for exactly the same purposes [KW97, HKW95] in important special 
cases (the gradient descent and EG algorithms) but without realizing the full generality of 
the method. 
It should be noted that the choice of the parameterization function xb is left completely 
free, as long as b has a convex potential function. (In contrast, the choice of the transfer 
function qb depends on what kind of a regression problem we wish to solve.) Earlier work 
suggests that the softmax parameterization function (i.e., the EG algorithm) is particularly 
suited for situations in which some sparse weight vector oJ gives a good match to the 
data [HKW95, KW97]. (Because softmax normalizes the weight vector and makes the 
components positive, a simple transformation of the input data is typically added to realize 
positive and negative weights with arbitrary norm.) 
In work parallel to this, the analogue of the general additive update (1) in the context of 
linear classification, i.e., with a threshold transfer function, has recently been developed 
and analyzed by Grove et al. [GLS97] with methods and results very similar to ours. Cesa- 
Bianchi [CB97] has used somewhat different methods to obtain bounds also in cases in 
which the loss function does not match the transfer function. Jagota and Warmuth [JW98] 
view (1) as an Euler discretization of a system of partial differential equations and investi- 
gate the performance of the algorithm as the discretization parameter approaches zero. 
The distance functions we use here have previously been applied in the context of expo- 
nential families by Amari lama85] and others. Here we only need some basic technical 
properties of the distance functions that can easily be derived from the definitions. For a 
discussion of our line of work in a statistical context see Azoury and Warmuth [AW97]. 
In Section 2 we review the definition of a matching loss function and give examples. Sec- 
tion 3 discusses the general additive algorithm in more detail. The actual relative on-line 
loss bounds we have for the general additive algorithm are explained in Section 4. 
290 J. Kivinen and M. K. Warmuth 
2 DISTANCE FUNCTIONS AND M
