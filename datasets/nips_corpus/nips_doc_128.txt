468 
LEARNING THE SOLUTION TO THE 
APERTURE PROBLEM FOR PATTERN 
MOTION WITH A HEBB RULE 
Martin I. Sereno 
Cognitive Science C-015 
University of California, San Diego 
La Jolla, CA 92093-0115 
ABSTRACT 
The primate visual system learns to recognize the true direction of 
pattern motion using local detectors only capable of detecting the 
component of motion perpendicular to the orientation of the 
moving edge. A multilayer feedforward network model similar to 
Linsker's model was presented with input patterns each consisting 
of randomly oriented contours moving in a particular direction. 
Input layer units are granted component direction and speed tuning 
curves similar to those recorded from neurons in primate visual 
area V1 that project to area MT. The network is trained on many 
such patterns until most weights saturate. A proportion of the 
units in the second layer solve the aperture problem (e.g., show the 
same direction-tuning curve peak to plaids as to gratings), 
resembling pattern-direction selective neurons, which first appear 
in area MT. 
INTRODUCTION 
Supervised learning schemes have been successfully used to learn a variety of input- 
output mappings. Explicit neuron-by-neuron error signals and the apparatus for 
propagating them across layers, however, are not realistic in a neurobiological 
context. On the other hand, there is ample evidence in real neural networks for 
conductances sensitive to correlation of pre- and post-synaptic activity, as well as 
multiple areas connected by topographic, somewhat divergent feedforward 
projections. The present project was to try to learn the solution to the aperture 
problem for pattern motion using a simple hebb rule and a layered feedforward 
network. 
Some of the connections responsible for the selectivity of cortical neurons to local 
stimulus features develop in the absence of pattered visual experience. For example, 
newborn cats and primates already have orientation-selective neurons in primary 
visual cortex (area 17 or V1), before they open their eyes. The prenatally generated 
orientation selectivity is sharpened by subsequent visual experience. Linsker (1986) 
Learning the Solution to the Aperture Problem 469 
has shown that feedforward networks with somewhat divergent, topographic 
interlayer connections, linear summation, and simple hebb rules develop units in 
terti_ary and higher layers that have parallel, elongated excitatory and inhibitory 
subfields when trained solely on random inputs to the first layer. 
By contrast, the development of the circuitry in secondary and tertirary visual 
cortical areas necessary for processing more complex, non-local features of visual 
arrays--e.g., orientation gradients, shape from shading, pattern translation, dilation, 
rotation--is probably much more dependent on patterned visual experience. Parietal 
direction noise 2-D rotation 
horizontal 
direction noise 
I 
3-D cylinder 
Figure 1. Motion field transitions 
visual cortical areas, for example, 
are almost totally unresponsive in 
dark-reared monkeys, despite the fact 
that these monkeys have a normal- 
appearing V1 (Hyvarinen, 1984). 
Behavioral indices suggest that 
development of some perceptual 
abilities may require months of 
experience. Human babies, for 
example, only evidence seeing the 
transition between randomly moving 
dots and circular 2-D motion at 6 
months, while the transition from 
horizontally moving dots with 
random x-axis velocities to dots 
with sinusoidally varying x-axis 
velocities (the latter gives the 
percept of a rotating 3-D cylinder) is 
only detected after 7 months (Spitz, 
Stiles-Davis, & Siegel, 1988) (see 
Fig. l). 
During the first 6 months of its life, 
a human baby typically makes 
approximately 30 million saccades, experiencing in the process many views which 
contain large moving fields and smaller moving objects. The importance of these 
millions of glances for the development of the ability to recognize complex visual 
objects has often been acknowledged. Brute visual experience may, however, be just 
as important in developing a solution to the simpler problem of detecting pattern 
motion using local cues. 
NETWORK ARCHITECTURE 
Moving visual stimuli are processed in several stages in the primate visual system. 
The first cortical stage is layer 4C-alpha of area V1, which receives its main 
ascending input from the magnocellular layers of the lateral geniculate nucleus. 
Layer 4C-alpha projects to layer 4B, which contains many tightly-tuned direction- 
selective neurons (Movshon et al., 1985). These neurons, however, respond to 
470 Sereno 
moving contours as if these contours were moving perpendicular their local 
orientation--i.e., they fare in proportion to the difference between the orthogonal 
component of motion and their best direction (for a bar). An orientation series run 
for a layer 4B neuron using a plaid (2 orthogonal moving gratings) thus results in 
two peaks in the direction tuning curve, displaced 45 degrees to either side of the 
peak for a single grating (Movshon et al., 1985). The aperture problem for pattern 
motion (see e.g., Horn & Schunck, 1981) thus exists for cells in area V1 of the 
adult (and presumably infan0 primate. 
Layer 4B neurons project topographically via direct and indirect pathways to area 
MT, a small extrasMate area specialized for processing moving stimuli. A subset 
Input 
Layer 
(=V1, layer 
Second \ 
Layer 
\, / 
Figure 2. Network Architecture 
of neurons in MT show a single peak in their direction tuning curves for a plaid that 
is lined up with the peak for a single grating--i.e., they fire in proportion to the 
difference between the true pattern direction and their best direction (for a bar). 
These neurons therefore solve the aperture problem presented to them by the local 
translational motion detectors in layer 4B of V1. The excitatory receptive fields of 
all MT neurons are much larger than those in V1 as a result of divergence in the V 1- 
MT projection as well as the smaller areal extent of MT compared to V 1. 
M.E. Sereno (1987) showed using a supervised learning rule that a linear, two layer 
network can satisfactorily solve the aperture problem characterized above. The 
present task was to see if unsupervised learning might suffice. A simple caraicature 
of the VI-to-MT projection was constructed. At each x-y location in the first 
layer of the network, there are a set of units tuned to a range of local directions and 
speeds. The input layer thus has four dimensions. The sample network illustrated 
above (Fig. 2) has 5 different directions and 3 speeds at each x-y location. Input 
units are granted tuning curves resembling those found for neurons in layer 4B of 
Learning the Solution to the Aperture Problem 471 
resp 
0 /I; 2/I; 
velocity component 
orthogonal to contour 
resp I 
0 
o 0.5 1 
speed component 
orthogonal to contour 
Figure 3. Excitatory Tuning 
Curves (1 st layer) 
area V1. The tuning curves are linear, with half-height overlap for both direction 
and speed (see Fig. 3--for 12 directions and 4 speeds), and direction and speed tuning 
interact linearly. Inhibition is either tuned or untuned (see Fig. 4), and scaled to 
balance excitation. Since direction tuning wraps around, there is a trough in the 
tuned inhibition condition. Speed tuning does not wrap around. The relative effect 
of direction and speed tuning in the output of first layer units is set by a parameter. 
As with Linsker, the probability that a unit in the first layer will connect with a 
unit in the second layer falls off as a gaussian centered on the retinotopically 
t untuned 
res ......... tuned 
0 /C 
velocity component 
orthogonal to contour 
I I I 
0 0.5 1 
speed component orthogonal 
to contour (no wrap-around) 
Figure 4. Tuned vs. Untuned Inhibition 
472 Sereno 
equivalent point in the second layer (see Fig. 2). New random numbers are drawn to 
generate the divergent gaussian projection pattern for each farst layer unit (i.e., all 
of the units at a single x-y location have different, overlapping projection 
patterns). There are no local connections within a layer. 
The network update rule is similar to that of Linsker except that there is no term 
like a decay of synaptic weights (/q) and no offset parameter for the correlations 
(k2). Also, all of the units in each layer are modeled explicifiy. The activation, 
for each unit is a linear weighted sum of its u inputs, scaled by x, and clipped to a 
maximum or minimum value: 
f E u i 
Weights are also clipped to maximum and minimum values. The change in each 
weight, Awij, is a simple fraction, 5, of the product of the pre- and post-synaptic 
values: 
ai. i = a ui v./ 
RESULTS 
The network is trained with a set of full field texture movements. Each stimulus 
consists of a set of randomly oriented contours--one at each x-y point--all moving 
in the same, randomly chosen pattern direction. A typical stimulus is drawn in 
figure 5 as the set of component motions visible to neurons in V1 (i.e., direction 
components perpendicular to the local contour); the local speed component varies as 
the cosine of the angle between the pattern direction and the perpendicular to the 
local contour. The single component motion at each point is run through the farst 
layer tuning curves. The response of the input layer to such a pattern is shown in 
Figure 6. Each rectangular box represents a single x-y location, containing 48 units 
Figure 5. Local Component Motions from a Training 
Stimulus (pattern direction is toward right) 
Learning the Solution to the Aperture Problem 473 
] ........ 0 ............ O0 .......... O0 ......... 
� . � , , , , ,0, , , , , , , , , , , , ,0. , , , .... 0o ....... , , , 
.0 ...... OD ............. [] ..... O0 ......... 
� . � .... oO ............. o � � � � � � � no � � � � � � � 
� . � � � � � ,0, � � � � � � � � � � � ,. � � � � � � � no � � � ,., � � � � 
.... , , , , , , , , .
