Utilizing Time: Asynchronous Binding 
Bradley C. Love 
Department of Psychology 
Northwestern University 
Evanston, IL 60208 
Abstract 
Historically, connectionist systems have not excelled at represent- 
ing and manipulating complex structures. How can a system com- 
posed of simple neuron-like computing elements encode complex 
relations? Recently, researchers have begun to appreciate that rep- 
resentations can extend in both time and space. Many researchers 
have proposed that the synchronous firing of units can encode com- 
plex representations. I identify the limitations of this approach 
and present an asynchronous model of binding that effectively rep- 
resents complex structures. The asynchronous model extends the 
synchronous approach. I argue that our cognitive architecture uti- 
lizes a similar mechanism. 
1 Introduction 
Simple connectionist models can fall prey to the binding problem. A binding 
problem occurs when two different events (or objects) are represented identically. 
For example, representing John hit Ted by activating the units JOHN, HIT, 
and TED would lead to a binding problem because the same pattern of activation 
would also be used to represent Ted hit John. The binding problem is ubiquitous 
and is a concern whenever internal representations are postulated. In addition 
to guarding against the binding problem, an effective binding mechanism must 
construct representations that assist processing. For instance, different states of the 
world must be represented in a manner that assists in discovering commonalities 
between disparate states, allowing for category formation and analogical processing. 
Interestingly, new connectionist binding mechanisms [5, 9, 12] utilize time in their 
operation. Pollack's Recursive Auto-Associative Memory (RAAM) model combines 
a standard fixed-width multi-layer network architecture with a stack and a simple 
controller, enabling RAAM to encode hierarchical representations over multiple pro- 
cessing steps. RAAM requires more time to encode representations as they become 
more complex, but its space requirements remain constant. The clearest example 
Utilizing Time: Asynchronous Binding 39 
of utilizing time are models that perform dynamic binding through synchronous 
firings of units [17, 5, 12]. Synchrony models explicitly use time to mark relations 
between units, distributing complex representations across multiple time steps. 
Most other models neglect the time aspect of representation. Even synchrony mod- 
els fail to fully utilize time (I will clarify this point in a later section). In this 
paper, a model is introduced (the asynchronous binding mechanism) that attempts 
to rectify this situation. The asynchronous approach is similar to the synchronous 
approach but is more effective in binding complex representations and exploiting 
time. 
2 Utilizing time and the brain 
Representational power can be greatly increased by taking advantage of the time 
dimension of representation. For instance, a telephone would need thousands of 
buttons to make a call if sequences of digits were not used. From the standpoint of 
a neuron, taking advantage of timing information increases processing capacity by 
more than a 100 fold [13]. While this suggests that the neural code might utilize 
both time and space resources, the neuroscience community has not yet arrived at a 
consensus. While it is known that the behavior of a postsynaptic neuron is affected 
by the location and arrival times of dendritic input [10], it is generally believed that 
only the rate of firing (a neuron's firing rate is akin to the activation level of a unit in 
a connectionist network) can code information, as opposed to the timing of spikes, 
since neurons are noisy devices [14]. However, findings that are taken as evidence 
for rate coding, like elevated firing rates in memory retention tasks [8], can often 
be reinterpreted as part of complex cortical events that extend through time [1]. In 
accord with this view, recent empirical findings suggests that the timing of spikes 
(e.g., firing patterns, intervals) are also part of the neural code [4, 16]. Contrary to 
the rate based view (which holds only that only the firing rate of a neuron encodes 
information), these studies suggest that the timing of spikes encodes information 
(e.g., when two neurons repeatedly spike together it signifies something different 
than when they fire out of phase, even if their firing rates are identical in both 
cases). 
Behavioral findings also appear consistent with the idea that time is used to con- 
struct complex representations. Behavioral research in illusory conjunction phe- 
nomena [15], and sentence processing performance [11] all suggest that bindings 
or relations are established through time, with bindings becoming more certain as 
processing proceeds. In summary, early in processing humans can gauge which 
representational elements are relevant while remaining uncertain about how these 
elements are interrelated. 
3 Dynamic binding through synchrony 
Given the demands placed on a representational system, a system that utilizes 
dynamic binding through synchrony would seem to be a good candidate mental 
architecture (though, as we will see, limitations arise when representing complex 
structures). A synchronous binding account of our mental architecture is consistent 
(at a general level) with behavioral findings, the intuition that complex represen- 
tations are distributed across time, and that neural temporal dynamics code infor- 
mation. Synchrony seems to offer the power to recombine a finite set of elements 
in a virtually unlimited number of ways (the defining characteristic of a discrete 
combinatorial system). 
40 B. C. Love 
While synchrony models seem appropriate for modeling certain behaviors, dynamic 
binding through synchrony does not seem to be an appropriate mechanism for 
establishing complex recursive bindings [2]. In a synchronous dynamic binding 
system, the distinction between a slot and a filler is lost, since bindings are not 
directional (i.e., which unit is a predicate and which unit is an argument is not clear). 
The slot and the filler simply share the same phase. In this sense, the mechanism is 
more akin to a grouping mechanism than to a binding mechanism. Grouping units 
together indicates that the units are a part of the same representation, but does 
not sort out the relations among the units as binding does. 
Synchrony runs into trouble when a unit has to act simultaneously as a slot and 
a filler. For instance, to represent embedded propositions with synchronous bind- 
ing, a controller needs to be added. For instance, a structure with embedding, like 
A-->B-->C, could be represented with synchronous firings if A and B fired syn- 
chronously and then B and C fired synchronously. Still, synchronous binding blurs 
the distinction between a slot and a filler, necessitating that A, B, and C be marked 
as slots or fillers to unambiguously represent the simple A->B->C structure. Notice 
that B must be marked as a slot when it fires synchronously with A, but must be 
marked as filler when it synchronously fires with C. When representing embedded 
structures, the synchronous approach becomes complicated (i.e., simple connections 
are not sufficient to modulate firing patterns) and rigid (i.e., parallelism and flexi- 
bility are lost when a unit has to be either a slot or a filler). Ideally, units would be 
able to act simultaneously as slots and fillers, instead of alternating between these 
two structural roles. 
4 The asynchronous approach 
While synchrony models utilize some timing information, other valuable timing in- 
formation is discarded as noise, making it difficult to represent multiple levels of 
structure. If A fired slightly before B, which fired slightly before C, asynchronous 
timing information (ordering information) would be available. This ordering in- 
formation allows for directional binding relations and alleviates the need to label 
units as slots or fillers. Notice that B can act simultaneously as a slot and a filler. 
Directional bindings can unambiguously represent complex structures. 
Phase locking and wave like patterns of firing need not occur during asynchronous 
binding. For instance, the firing pattern that encodes a structure like A-B-->C 
does not need to be orderly (i.e., starting with A and ending with C). To encode 
A-->B-->C, unit B's firing schedule must observably speed up (on average) after unit 
A fires, while C's must speed up after B fires. For example, if we only considered the 
time window immediately after a unit fires, a firing sequence of B, C, no unit fires, 
A, and then B would provide evidence for the structure A-->B-->C. Of course, if 
A, B, and C fire periodically with stochastic schedules that are influenced by other 
units' firings, spurious binding evidence will accrue (e.g., occasionally, C will fire 
and A will fire in the next time step). Luckily, these accidents will be less frequent 
than events that support the intended bindings. As binding evidence is accumulated 
over time, binding errors will become less likely. 
Interestingly, the asynchronous mechanism can also represent structures through an 
inhibitory process that mirrors the excitatory process described above. A-B->C 
could be represented asynchronously if A was less likely to fire after B fired and B 
was less likely to fire after C fired. An inhibitory (negative) connection from B to 
A is in some ways equivalent to an excitatory (positive) connection form A to B. 
Utilizing Time: Asynchronous Binding 41 
4.1 The mathematical expression of the model 
The previous discussion of the asynchronous approach can be formalized. Below is 
a description of an asynchronous model that I have implemented. 
4.1.1 The anatomy of a unit 
Individual units, when unaffected by other units, will fire periodically when active: 
if tlti  1, then 
