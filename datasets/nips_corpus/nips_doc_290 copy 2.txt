A Recurrent Neural Network Model of 
Velocity Storage in the Vestibulo-Ocular Reflex 
Thomas J. Anastasio 
Department of Otolaryngology 
University of Southern California 
School of Medicine 
Los Angeles, CA 90033 
Abstract 
A three-layered neural network model was used to explore the organization of 
the vestibulo-ocular reflex (VOR). The dynamic model was trained using 
recurrent back-propagation to produce compensatory, long duration eye muscle 
motoneuron outputs in response to short duration vestibular afferent head 
velocity inputs. The network learned to produce this response prolongation, 
known as velocity storage, by developing complex, lateral inhibitory interac- 
tions among the interneurons. These had the low baseline, long time constant, 
rectified and skewed responses that are characteristic of real VOR inter- 
neurons. The model suggests that all of these features are interrelated and 
result from lateral inhibition. 
1 SIGNAL PROCESSING IN THE VOR 
The VOR stabilizes the visual image by producing eye rotations that are nearly equal 
and opposite to head rotations (Wilson and Melvill Jones 1979). The VOR utilizes 
head rotational velocity signals, which originate in the semicircular canal receptors of 
the inner ear, to control contractions of the extraocular muscles. The reflex is coor- 
dinated by brainstem interneurons in the vestibular nuclei (VN), that relay signals from 
canal afferent sensory neurons to eye muscle motoneurons. 
32 
A Recurrent Neural Network Model of Velocity Storage 33 
The VN interneurons, however, do more than just relay signals. Among other func- 
tions, the VN neurons process the canal afferent signals, stretching out their time con- 
stants by about four times before transmitting this signal to the motoneurons. This time 
constant prolongation, which is one of the clearest examples of signal processing in 
motor neurophysiology, has been termed velocity storage (Raphan et al. 1979). The 
neural mechanisms underlying velocity storage, however, remain unidentified. 
The VOR is bilaterally symmetric (Wilson and Melvill Jones 1979). The semicircular 
canals operate in push-pull pairs, and the extraocular muscles are arranged in 
agonist/antagonist pairs. The VN are also arranged bilaterally and interact via in- 
hibitory commissural connections. The commissures are necessary for velocity storage, 
which is eliminated by cutting the commissures in monkeys (Blair and Gavin 1981). 
When the overall VOR fails to compensate for head rotations, the visual image is not 
stabilized but moves across the retina at a velocity that is equal to the amount of VOR 
error. This 'retinal slip' signal is transmitted back to the VN, and is known to modify 
VOR operation (Wilson and Melvill Jones 1979). Thus the VOR can be modeled 
beautifully as a three-layered neural network, complete with recurrent connections and 
error signal back-propagation at the VN level. By modeling the VOR as a neural net- 
work, insight can be gained into the global organization of this reflex. 
Figure 1: Architecture of the 
Horizontal VOR Neural Network 
Model. lhc and rhc, left and right 
horizontal canal afferents; lvn and 
rvn, left and right VN neurons; lr 
and mr, lateral and medial rectus 
motoneurons of the left eye. This 
and all subsequent figures are 
redrawn from Anastasio (1991), 
with permission. 
34 Anastasio 
2 ARCHITECTURE OF THE VOR NEURAL NETWORK MODEL 
The recurrent neural network model of the horizontal VOR is diagrammed in Fig. 1. 
The input units represent afferents from the left and right horizontal semicircular canals 
(lhc and rhc). These are the canals and afferents that respond to yaw head rotations (as 
in shaking the head 'no'). The output units represent moroneurons of the lateral and 
medial rectus muscles of the left eye (lr and mr). These are the moroneurons and 
muscles that move the eye in the yaw plane. The units in the hidden layer correspond 
to interneurons in the VN, on both the left and right sides of the brainstem (lvnl, lvn2, 
rvnl and rvn2). All units compute the weighted sum of their inputs and then pass this 
sum through the sigmoidal squashing function. 
To represent the VOR relay, input project to hidden units and hidden project to output 
units. Commissural connections are modeled as lateral interconnections between hidden 
units on opposite sides of the brainstem. The model is constrained to allow only those 
connections that have been experimentally well described in mammals. For example, 
canal afferents do not project directly to moroneurons in mammals, and so direct connec- 
tions from input to output units are not included in the model. 
Evidence to date suggests that plastic modification of synapses may occur at the VN 
level but not at the motoneurons. The weights of synapses from hidden to output units 
are therefore fixed. All fixed hidden-to-output weights have the same absolute value, 
and are arranged in a reciprocal pattern. Hidden units lvnl and lvn2 inhibit lr and ex- 
cite mr; the opposite pattern obtains for rvnl and rvn2. The connections to the hidden 
units, from input or contralateral hidden units, were initially randomized and then 
modified by the continually running, recurrent back-propagation algorithm of Williams 
and Zipser (1989). 
3 TRAINING AND ANALYZING THE VOR NETWORK MODEL 
The VOR neural network model was trained to produce compensatory motoneuron 
responses to two impulse head accelerations, one to the left and the other to the right, 
presented repeatedly in random order. The preset impulse responses of the canal af- 
ferents (input units) decay with a time constant of one network cycle or tick (Fig. 2, A 
and B, solid). The desired motoneuron (output unit) responses are equal and opposite 
in amplitude to the afferent responses, producing compensatory eye movements, but 
decay with a time constant four times longer, reflecting velocity storage (Fig. 2, A and 
B, dashed). Because of the three-layered architecture of the VOR, a delay of one net- 
work cycle is introduced between the input and output responses. 
After about 5000 training set presentations, the network learned to match actual and 
desired output responses quite closely (Fig. 2, C and D, solid and dashed, 
respectively). The input-to-hidden connections arranged themselves in a reciprocal pat- 
tern, each input unit exciting the ipsilateral hidden units and inhibiting the contralateral 
ones. This arrangement is also observed for the actual VOR (Wilson and Melvill Jones 
1979). The hidden-to-hidden (commissural) connections formed overlapping, lateral 
inhibitory feedback loops. These loops mediate velocity storage in the network. Their 
removal results in a loss of velocity storage (a decrease in output time constants from 
four to one tick), and also slightly increases output unit sensitivity (Fig. 2, C and D, 
dotted). These effects on VOR are also observed following commissurotomy in 
monkeys (Blair and Gavin 1981). 
A Recurrent Neural Network Model of Velocity Storage 35 
0.65 
ILl 
Z 
C) 0,55 
C,O o.5 
O.45 
0 
0,65 
LU 0.6 
Z 
0 0.55 
C,O 0.5 
0.45 
Z 0.4 
0.35 
0 
, ^1 
I I 
! 
10 20 30 40 50 60 
10 20 30 40 50 
NETWORK CYCLES 
o 
O.85 
0.6 
0.55 
0.5 
0.45 
0.4 
0.35 
0.65 
0.6 
0.55 
0.5 
0.45 
0.4 
0.35 
60 0 
B 
10 20 30 40 50 60 
D 
10 20 30 40 50 60 
NETWORK CYCLES 
Figure 2: Training the VOR Network Model. A and B, input unit responses (solid), 
desired output unit responses (dashed), and incorrect output responses of initially ran- 
domized network (dotted); lhc and lr in A, rhc and mr in B. C and D, desired output 
responses (dashed), actual output responses of trained network (solid), and output 
responses following removal of commissural connections (dotted); lr in C, mr in D. 
Although all the hidden units project equally strongly to the output units, the inhibitory 
connections between them, and their response patterns, are different. Hidden units lvnl 
and rvnl have developed strong mutual inhibition. Thus units lvnl and rvnl exert net 
positive feedback on themselves. Their responses appear as low-pass filtered versions 
of the input unit responses (Fig. 3, A, solid and dashed). In contrast, hidden units lvn2 
and rvn2 have almost zero mutual inhibition, and tend to pass the sharply peaked input 
responses unaltered (Fig. 3, B, solid and dashed). Thus the hidden units appear to 
form parallel integrated (lvnl and rvnl) and direct (lvn2 and rvn2) pathways to the out- 
puts. This parallel arrangement for velocity storage was originally suggested by 
Raphan and coworkers (1979). However, units lvn2 and rvn2 are coupled to units rvnl 
and lvnl, respectively, with moderately strong mutual inhibition. This coupling en- 
dows units lvn2 and rvn2 with longer overall decay times than they would have by 
themselves. This arrangement resembles the mechanism of feedback through a neural 
low-pass filter, suggested by Robinson (1981) to account for velocity storage. Thus, 
the network model gracefully combines the two mechanisms that have been identified 
for velocity storage, in what may be a more optimal configuration than either one 
alone. 
36 Anastasio 
LU o. 
Z o.s 
o 
O.. 0.4 
LU o. 
-- 0.2 
z 
:=) o. 
O' 
0 
0.$ 
LU o.? 
o 
O.. 
LU 0.4 
F- 0.3 
Z 
 o.e 
0.1 
0 
B 
60 0 10 20 30 40 50 60 
o. 
0.5  
0.4 
o. 
0.2 
  ] [ ] 0.1 
10 20 0 40 50 60 0 10 20 0 40 50 
NETWORK CYCLES NETWORK CYCLES 
Figure 3: Responses of Model VN Interneurons. Networks trained with (A and B) and 
without (C and D) velocity storage. A and C, rvnl, solid; lvnl, dashed. B and D, 
rvn2, solid; lvn2, dashed. rhc, dotted, all plots. 
Besides having longer time constants, the hidden units also have lower baseline firing 
rates and higher sensitivities than the input units (Fig. 3, A and B). The lower baseline 
forces the hidden units to operate closer to the bottom of the squashing function. This 
in turn causes the hidden units to have asymmetric responses, larger 
