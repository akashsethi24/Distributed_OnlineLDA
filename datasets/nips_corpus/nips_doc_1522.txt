Bayesian modeling of human concept learning 
Joshua B. Tenenbaum 
Department of Brain and Cognitive Sciences 
Massachusetts Institute of Technology, Cambridge, MA 02139 
j bt@psyche. mi t. edu 
Abstract 
I consider the problem of learning concepts from small numbers of pos- 
itive examples, a feat which humans perform routinely but which com- 
puters are rarely capable of. Bridging machine learning and cognitive 
science perspectives, I present both theoretical analysis and an empirical 
study with human subjects for the simple task of learning concepts corre- 
sponding to axis-aligned rectangles in a multidimensional feature space. 
Existing learning models, when applied to this task, cannot explain how 
subjects generalize from only a few examples of the concept. I propose 
a principled Bayesian model based on the assumption that the examples 
are a random sample from the concept to be learned. The model gives 
precise fits to human behavior on this simple task and provides qualitative 
insights into more complex, realistic cases of concept learning. 
1 Introduction 
The ability to learn concepts from examples is one of the core capacities of human cognition. 
From a computational point of view, human concept learning is remarkable for the fact that 
very successful generalizations are often produced after experience with only a small number 
of positive examples of a concept (Feldman, 1997). While negative examples are no doubt 
useful to human learners in refining the boundaries of concepts, they are not necessary 
in order to make reasonable generalizations of word meanings, perceptual categories, and 
other natural concepts. In contrast, most machine learning algorithms require examples of 
both positive and negative instances of a concept in order to generalize at all, and many 
examples of both kinds in order to generalize successfully (Mitchell, 1997). 
This paper attempts to close the gap between human and machine concept learning by 
developing a rigorous theory for concept learning from limited positive evidence and 
testing it against real behavioral data. I focus on a simple abstract task of interest to 
both cognitive science and machine learning: learning axis-parallel rectangles in m. We 
assume that each object :r in our world can be described by its values (:rl,..., :rm) on rn 
real-valued observable dimensions, and that each concept C to be learned corresponds to a 
conjunction of independent intervals (rnin(C') < c < rnac(C')) along each dimension 
60 . B. Tenenbaurn 
(a) 
(b) : 
(c) 
 + ++ 
Figure 1: (a) A rectangle concept C. (b-c) The size principle in Bayesian concept learning: 
of the many hypotheses consistent with the observed positive examples, the smallest rapidly 
become more likely (indicated by darker lines) as more examples are observed. 
i. For example, the objects might be people, the dimensions might be cholesterol level 
and insulin level, and the concept might be healthy levels. Suppose that healthy 
levels applies to any individual whose cholesterol and insulin levels are each greater than 
some minimum healthy level and less than some maximum healthy level. Then the concept 
healthy levels corresponds to a rectangle in the two-dimensional cholesterol/insulin space. 
The problem of generalization in this setting is to infer, given a set of positive (+) and 
negative (-) examples of a concept C, which other points belong inside the rectangle 
corresponding to C (Fig. 1 a.). This paper considers the question most relevant for cognitive 
modeling: how to generalize from just a few positive examples? 
In machine learning, the problem of learning rectangles is a common textbook example 
used to illustrate models of concept learning (Mitchell, 1997). It is also the focus of state- 
of-the-art theoretical work and applications (Dietterich et al., 1997). The rectangle learning 
task is not well known in cognitive psychology, but many studies have investigated human 
learning in similar tasks using simple concepts defined over two perceptually separable 
dimensions such as size and color (Shepard, 1987). Such impoverished tasks are worth 
our attention because they isolate the essential inductive challenge of concept learning in a 
form that is analytically tractable and amenable to empirical study in human subjects. 
This paper consists of two main contributions. I first present a new theoretical analysis 
of the rectangle learning problem based on Bayesian inference and contrast this model's 
predictions with standard learning frameworks (Section 2). I then describe an experiment 
with human subjects on the rectangle task and show that, of the models considered, the 
Bayesian approach provides by far the best description of how people actually generalize 
on this task when given only limited positive evidence (Section 3). These results suggest 
an explanation for some aspects of the ubiquotous human ability to learn concepts from just 
a few positive examples. 
2 Theoretical analysis 
Computational approaches to concept learning. Depending on how they model a con- 
cept, different approaches to concept learning differ in their ability to generalize meaning- 
fully from only limited positive evidence. Discriminative approaches embody no explicit 
model of a concept, but only a procedure for discriminating category members from mem- 
bers of mutually exclusive contrast categories. Most backprop-style neural networks and 
exemplar-based techniques (e.g. K-nearest neighbor classification) fall into this group, 
along with hybrid models like ALCOVE (Kruschke, 1992). These approaches are ruled out 
by definition; they cannot learn to discriminate positive and negative instances if they have 
seen only positive examples. Distributional approaches model a concept as a probability 
distribution over some feature space and classify new instances x as members of C if their 
Bayesian Modeling of Human Concept Learning 61 
estimated probability p(zlC) exceeds a threshold 0. This group includes novelty detec- 
tion techniques based on Bayesian nets (Jaakkola et al., 1996) and, loosely, autoencoder 
networks (Japkowicz et al., 1995). While p(zlC) can be estimated from only positive ex- 
amples, novelty detection also requires negative examples for principled generalization, in 
order to set an appropriate threshold 0 which may vary over many orders of magnitude for 
different concepts. For learning from positive evidence only, our best hope are algorithms 
that treat a new concept C as an unknown subset of the universe of objects and decide how 
to generalize C' by finding good subsets in a hypothesis space H of possible concepts. 
The Bayesian framework. For this task, the natural hypothesis space H corresponds to all 
rectangles in the plane. The central challenge in generalizing using the subset approach is 
that any small set of examples will typically be consistent with many hypotheses (Fig. lb). 
This problem is not unique to learning rectangles, but is a universal dilemna when trying to 
generalize concepts from only limited positive data. The Bayesian solution is to embed the 
hypothesis space in a probabilistic model of our observations, which allows us to weight 
different consistent hypotheses as more or less likely to be the true concept based on the 
particular examples observed. Specifically, we assume that the examples are generated by 
random sampling from the true concept. This leads to the size principle: smaller hypotheses 
become more likely than larger hypotheses (Fig. lb - darker rectangles are more likely), 
and they become exponentially more likely as the number of consistent examples increases 
(Fig. 1 c). The size principle is the key to understanding how we can learn concepts from 
only a few positive examples. 
Formal treatment. We observe n positive examples X '- {z(1),..., z �} of concept C 
and want to compute the generalization function p(t E C IX), i.e. the probability that some 
new object y belongs to C given the observations X. Let each rectangle hypothesis h be 
denoted by a quadruple (l, 12, s, s2), where li E [-0, 0] is the location of h's lower-left 
coruer and si E [0, o] is the size of h along dimension i. 
Our probabilistic model consists of a prior density p(h) and a likelihood function p(XIh) 
for each hypothesis h E H. The likelihood is determined by our assumption of randomly 
sampled positive examples. In the simplest case, each example in X is assumed to be 
independently sampled from a uniform density over the concept C. For n examples we 
then have: 
p(Xlh) - z/Ihl if �j,x (j)  h (1) 
- 0 otherwise, 
where Ihl denotes the size of h. For rectangle (1, 12, s, s2), Ihl is simply ss2. Note that 
because each hypothesis must distribute one unit mass of likelihood over its volume for each 
example (fh P(xlh)dh = 1), the probability density for smaller consistent hypotheses is 
greater than for larger hypotheses, and exponentially greater as a function of n. Figs. lb,c 
illustrate this size principle for scoring hypotheses (darker rectang!es are more likely). 
The appropriate choice of p(h) depends on our background knowledge. If we have no a 
priori reason to prefer any rectangle hypothesis over any other, we can choose the scale- 
and location-invariant uninformative prior, p(h) = p(ll, 12, sl, s2) = 1/(s, s2). In any 
realistic application, however, we will have some prior information. For example, we may 
know the expected size ri of rectangle concepts along dimension i in our domain, and then 
use the associated maximum entropy prior p(ll, 12, Sl, s2) = exp{--(Sl/rl + s2/o'2)}. 
The generalization function p(y  CI X) is computed by integrating the predictions of all 
hypotheses, weighted by their posterior probabilities p(h IX): 
p(y e CIX) = f p(y e CIh) p(hlX) dh, (2) 
EH 
where from Bayes' theorem p(hIX ) o p(XIh)p(h ) (normalized such that 
fheHP(hIX)dh = 1), and p(y  CI h) = 1 if y E h and 0 otherw
