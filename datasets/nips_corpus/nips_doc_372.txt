Speech Recognition 
Using Demi-Syllable Neural Prediction Model 
Ken-ichi Iso and Takao Watanabe 
C & C Information Technology Research Laboratories 
NEC Corporation 
4-1-1 Miyazaki, Miyamae-ku, Kawasaki 213, JAPAN 
Abstract 
The Neural Prediction Model is the speech recognition model based on 
pattern prediction by multilayer percepttons. Its effectiveness was con- 
firmed by the speaker-independent digit recognition experiments. This 
paper presents an improvement in the model and its application to large 
vocabulary speech recognition, based on subword units. The improvement 
involves an introduction of backward prediction, which further improves 
the prediction accuracy of the original model with only 'florward predic- 
tion. In application of the model to speaker-dependent large vocabulary 
speech recognition, the demi-syllable unit is used as a subword recognition 
unit. Experimental results indicated a 95.2% recognition accuracy for a 
5000 word test set and the effectiveness was confirmed for the proposed 
model improvement and the demi-syllable subword units. 
I INTRODUCTION 
The Neural Prediction Model (NPM) is the speech recognition model based on 
pattern prediction by multilayer percepttons (MLPs). Its effectiveness was con- 
firmed by the speaker-independent digit recognition experiments (Iso, 1989; Iso, 
1990; Levin, 1990). 
Advantages in the NPM approach are as follows. The underlying process of the 
speech production can be regarded as the nonlinear dynamical system. Therefore, 
it is expected that there is causal relation among the adjacent speech feature vectors. 
In the NPM, the causality is represented by the nonlinear prediction mapping F, 
at = F,,,(a,_), (1) 
where at is the speech feature vector at frame t, and subscript w represents map- 
ping parameters. This causality is not explicitly considered in the conventional 
227 
228 Iso and Watanabe 
speech recognition model, where the adjacent speech feature vectors are treated as 
independent variables. 
Another important model characteristic is its applicability to continuous speech 
recognition. Concatenating the recognition unit models, continuous speech recog- 
nition and model training from continuous speech can be implemented without the 
need for segmentation. 
This paper presents an improvement in the NPM and its application to large vocab- 
ulary speech recognition, based on subword units. It is an introduction of backward 
prediction, which further improves the prediction accuracy for the original model 
with only forward prediction. In Section 2, the improved predictor configuration, 
NPM recognition and training algorithms are described in detail. Section 3 presents 
the definition of demi-syllables used as subword recognition units. Experimental 
results obtained from speaker-dependent large vocabulary speech recognition are 
described in Section 4. 
2 NEURAL PREDICTION MODEL 
2.1 MODEL CONFIGURATION 
Figure 1 shows the MLP predictor architecture. It is given two groups of feature 
vectors as input. One is feature vectors for forward prediction. Another is feature 
vectors for backward prediction. The former includes the input speech feature 
vectors, at-Tr,..., at-, which have been implemented in the original formulation. 
The latter, at+, ..., at+,.,, are introduced in this paper to further improve the pre- 
diction accuracy over the original method, with only forward prediction. This, for 
example, is expected to improve the prediction accuracy for voiceless stop conso- 
nants, which are characterized by a period of closure interval, followed by a sudden 
release. The MLP output, , is used as a predicted feature vector for input speech 
Forward prediction Backward prediction 
I at I Output layer 
Figure 1: Multilayer perceptron predictor 
Speech Recognition Using Demi-Syllable Neural Prediction Model 229 
feature vector at. The difference between the input speech feature vector at and its 
prediction fit is the prediction error. Also, it can be regarded as an error function 
for the MLP training, based on the back-propagation technique. 
The NPM for a recognition class, such as a subword unit, is constructed as a state 
transition network, where each state has an MLP predictor described above (Figure 
2). This configuration is similar in form to the Hidden Markov Model (HMM), 
in which each state has a vector emission probability distribution (Rabiner, 1989). 
The concatenation of these subword NPMs enables continuous speech recognition. 
Figure 2: Neural Prediction Model 
2.2 RECOGNITION ALGORITHM 
This section presents the continuous speech recognition algorithm based on the 
NPM. The concatenation of subword NPMs, which is also the state transition net- 
work, is used as a reference model for the input speech. Figure 3 shows a diagram 
of the recognition algorithm. In the recognition, the input speech is divided into 
segments, whose number is equal to the total states in the concatenated NPMs 
(= N). Each state makes a prediction for the corresponding segment. The local 
prediction error, between the input speech at frame t and the n-th state, is given 
by 
where n means the consecutive number of the state in the concatenated NPM. The 
accumulation of local prediction errors defines the global distance between the input 
speech and the concatenated NPMs 
T 
O= min -dt(n,), (3) 
where nt denotes the state number used for prediction at frame t, and a sequence 
{hi, n2, ..., nt,..., nT} determines the segmentation of the input speech. The mini- 
mization means that the optimal segmentation, which gives a minimum accumulated 
prediction error, should be selected. This optimization problem can be solved by 
the use of dynamic-programming. As a result, the DP recursion formula is obtained 
gt(n) = dt(n) + min { gt-l(n) ) 
gt_i(n- 1) ' (4) 
At the end of Equation (4) recursive application, it is possible to obtain D = gT(N). 
Backtracking the result provides the input speech segmentation. 
230 Iso and Watanabe 
NPM I . T 
, ........................................................ ; I D = 
! I / i I , ,__Z t(nt) 
: qlt2 
, lla2a31;lp[it. at � � � aT 
' ....................................................... ' Speech 
Figure 3: Recognition algorithm based on DP 
In this algorithm, temporal distortion of the input speech is efficiently absorbed by 
DP based time-alignment between the input speech and an MLPs sequence. For 
simplicity, the reference model topology shown above is limited to a sequence of 
MLPs with no branches. It is obvious that the algorithm is applicable to more 
general topologies with branches. 
2.3 TRAINING ALGORITHM 
This section presents a training algorithm for estimating NPM parameters from con- 
tinuous utterances. The training goal is to find a set of MLP predictor parameters, 
which minimizes the accumulated prediction errors for training utterances. The ob- 
jective function for the minimization is defined as the average value for accumulated 
prediction errors for all training utterances 
M 
,b = M E D(m), (5) 
m--1 
where M is the number of training utterances and D(m) is the accumulated predic- 
tion error between the m-th training utterance and its concatenated NPM, whose 
expression is given by Equation (3). The optimization can be carried out by an 
iterative procedure, combining dynamic-programming (DP) and back-propagation 
(BP) techniques. The algorithm is given as follows: 
1. Initialize all MLP predictor parameters. 
2. Setm--1. 
Speech Recognition Using Demi-Syllable Neural Prediction Model 231 
e 
e 
Compute the accumulated prediction error D(m) by DP (Equation (4)) and 
determine the optimal segmentation {n }, using its backtracking. 
Correct parameters for each MLP predictor by BP, using the optimal segmenta- 
tion {nt), which determines the desired output at for the actual output (t) 
&t n* 
of the n-th MLP predictor. 
Increase m by 1. 
Repeat 3 - 5, while m _< M. 
Repeat 2 - 6, until convergence occurs. 
Convergence proof for this iterative procedure was given in (Iso, 1989; Iso, 1990). 
This can be intuitively understood by the fact that both DP and BP decrease the 
accumulated prediction error and that they are applied successively. 
3 Demi-Syllable Recognition Units 
In applying the model to large vocabulary speech recognition, the demi-syllable 
unit is used as a subword recognition unit (Yoshida, 1989). The demi-syllable is a 
half syllable unit, divided at the center of the syllable nucleus. It can treat contex- 
tual variations, caused by the co-articulation effect, with a moderate unit number. 
The units consist of consonant-vowel (CV) and vowel-consonant (VC) segments. 
Word models are made by concatenation of demi-syllable NPMs, as described in 
the transcription dictionary. Their segmentation boundaries are basically defined 
as a consonant start point and a vowel center point (Figure 4). Actually, they 
are automatically determined in the training algorithm, based on the minimum 
accumulated prediction error criterion (Section 2.3). 
ha aS * 
[hakata] 
ka aS * 
Figure 4: Demi-syllable unit boundary definition 
4 EXPERIMENTS 
4.1 SPEECH DATA AND MODEL CONFIGURATION 
In order to examine the validity of the proposed model, speaker-dependent Japanese 
isolated word recognition experiments were carried out. Phonetically balanced 250, 
500 and 750 word sets were selected from a Japanese word lexicon as training vo- 
cabularies. For word recognition experiments, a 250 word test set was prepared. All 
232 Iso and Watanabe 
the words in the test set were different from those in the training sets. A Japanese 
male speaker uttered these word sets in a quiet environment. The speech data was 
sampled at a 16 kHz sampling rate, and analyzed by a 10 msec frame period. As 
a feature vector for each time frame, 10 mel-scaled cepstral parameters, 10 mel- 
scaled delta cepstral parameters and a changing ratio parameter for amplitude were 
calculated from the FFT ba
