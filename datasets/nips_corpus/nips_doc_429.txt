Threshold Network Learning in the Presence of 
Equivalences 
John Shawe-Taylor 
Department of Computer Science 
Royal Holloway and Bedford New College 
University of London 
Egham, Surrey TW20 0EX, UK 
Abstract 
This paper applies the theory of Probably Approximately Correct (PAC) 
learning to multiple output feedforward threshold networks in which the 
weights conform to certain equivalences. It is shown that the sample size 
for reliable learning can be bounded above by a formula similar to that 
required for single output networks with no equivalences. The best previ- 
ously obtained bounds are improved for all cases. 
I INTRODUCTION 
This paper develops the results of Baum and I-Iaussler [3] bounding the sample sizes 
required for reliable generalisation of a single output feedforward threshold network. 
They prove their result using the theory of Probably Approximately Correct (PAC) 
learning introduced by Valiant [11]. They show that for 0 < e <_ 1/2, if a sample of 
size 
64W 64N 
m>_ m0 = --log-- 
is loaded into a feedforward network of linear threshold units with N nodes and W 
weights, so that a fraction 1- e/2 of the examples are correctly classified, then with 
confidence approaching certainty the network will correctly classify a fraction I - e 
of future examples drawn according to the same distribution. A similar bound was 
obtained for the case when the network correctly classified the whole sample. The 
results below will imply a significant improvement to both of these bounds. 
879 
880 Shawe-Taylor 
In many cases training can be simplified if known properties of a problem can 
be incorporated into the structure of a network before training begins. One such 
technique is described by Shawe-Taylor [9], though many similar techniques have 
been applied as for example in TDNN's [61. The effect of these restrictions is to 
constrain groups of weights to take the same value and learning algorithms are 
adapted to respect this constraint. 
In this paper we consider the effect of this restriction on the generalisation per- 
formance of the networks and in particular the sample sizes required to obtain a 
given level of generalisation. This extends the work described above by Baum and 
Haussler [3] by improving their bounds and also improving the results of Shawe- 
Taylor and Anthony [10], who consider generalisation of multiple-output threshold 
networks. The remarkable fact is that in all cases the formula obtained is the same, 
where we now understand the number of weights W to be the number of weight 
classes, but N is still the number of computational nodes. 
2 DEFINITIONS AND MAIN RESULTS 
2.1 SYMMETRY AND EQUIVALENCE NETWORKS 
We begin with a definition of threshold networks. To simplify the exposition it is 
convenient to incorporate the threshold value into the set of weights. This is done 
by creating a distinguished input that always has value 1 and is called the threshold 
input. The following is a formal notation for these systems. 
A network A/' = (C, 
set I of input nodes, 
threshold node. The 
with (no) x C C_ E. 
I, O, n0, E) is specified by a set C of computational nodes, a 
a subset O _C C of output nodes and a node n0 E I, called the 
connectivity is given by a set E C_ (C U I) x C of connections, 
With network Af we associate a weight function w from the set of connections to 
the real numbers. We say that the network Af is in state w. For input vector i 
with values in some subset of the set 7Z of real numbers, the network computes a 
function F. sf(w, i). 
An automorphism 7 of a network Af = (C, I, O, n0, E) is a bijection of the nodes of 
Af which fixes I setwise and {n0} U 0 pointwise, such that the induced action fixes 
E setwise. We say that an automorphism 7 preserves the weight assignment w if 
wji = w(j)(ti ) for alliE IUC, j  C. Let 7 be an automorphism of a network 
Af = (C, I, O, n0, E) and let i be an input to A/'. We denote by i t the input whose 
value on input / is that of i on input 7-xk. 
The following theorem is a natural generalisation of part of the Group Invariance 
Theorem of Minsky and Pappert [8] to multi-layer percepttons. 
Theorem 2.1 [9] Let 7 be a weight preserving automorphism of the network 
(C, I, O, no, E) in state w. Then for every input vector i 
i): it). 
Following this theorem it is natural to consider the concept of a symmetry net- 
work [9]. This is a pair (Af, r), where Af is a network and F a group of weight 
Threshold Network Learning in the Presence of Equivalences 881 
preserving automorphims of Af. We will also refer to the automorphisms as sym- 
metries. For a symmetry network (Af, F), we term the orbits of the connections E 
under the action of F the weight classes. 
Finally we introduce the concept of an equivalence network. This definition ab- 
stracts from the symmetry networks precisely those properties we require to obtain 
our results. The class of equivalence networks is, however, far larger than that 
of symmetry networks and includes many classes of networks studied by other re- 
searchers [6, 7]. 
Definition 2.2 An equivalence network is a threshold network in which an equiva- 
lence relation is defined on both weights and nodes. The two relations are required 
to be compatible in that weights in the same class are connected to nodes in the same 
class, while nodes in the same class have the same set of input weight connection 
types. The weights in an equivalence class are at all times required to remain equal. 
Note that every threshold network can be viewed as an equivalence network by 
taking the trivial equivalence relations. We now show that symmetry networks 
are indeed equivalence networks with the same weight classes and give a further 
technical lemma. For both lemmas proofs are omitted. 
Lemma 2.3 A symmetry network (Af, P) is an equivalence network, where the 
equivalence classes are the orbits of connections and nodes respectively. 
Lemma 2.4 Let A/' be an equivalence network and C be the set of classes of nodes. 
Then there is an indezing of the classes, Ci, i = 1,..., n, such that nodes in Ci do 
not have connections from nodes in Cj for j _) i. 
2.2 MAIN RESULTS 
We are now in a position to state our main results. Note that throughout this paper 
log means natural logarithm, while an explicit subscript is used for other bases. 
Theorem 2.5 Let A/' be an equivalence network with W weight classes and N com- 
putational nodes. If the network correctly computes a function on a set of m inputs 
drawn independently according to a fized probability distribution, where 
[ 
ra_ mo(6,)= 6(1- vf) log + 2Wlog 6 
then with probability at least 1 - l the error rate of the network will be less than e 
on inputs drawn according to the same distribution. 
Theorem 2.6 Let A/' be an equivalence network with W weight classes and N 
computational nodes. If the network correctly computes a function on a fraction 
1- (1- q,)e of ra inputs drawn independently according to a fized probability distri- 
bution, where 
m _ m0(e,$, 7) = q,2e(1 _ X/) 41os + 6Wlog 4Ne 
then with probability at least 1 - l the error rate of the network will be less than  
on inputs drawn according to the same distribution. 
882 
Shawe-Taylor 
3 THEORETICAL BACKGROUND 
3.1 DEFINITIONS AND PREVIOUS RESULTS 
In order to present results for binary outputs ({0, 1} functions) and larger ranges 
in a unified way we will consider throughout the task of learning the graph of a 
function. All the definitions reduce to the standard ones when the outputs are 
binary. 
We consider learning from examples as selecting a suitable function from a set H of 
hypotheses, being functions from a space X to set Y, which has at most countable 
size. At all times we consider an (unknown) target function 
c:X ,Y 
which we are attempting to learn. To this end the space X is required to be a 
probabihty space (X, Ig,/), with appropriate regularity conditions so that the sets 
considered are measurable [4]. In particular the hypotheses should be measurable 
when Y is given the discrete topology as should the error sets defined below. The 
space S: X x Y is equipped with a a-algebra Ig x 2 Y and measure v: v(/, c), 
defined by its value on sets of the form U x {y}: 
Using this measure the error of a hypothesis 
The introduction of v allows us to consider 
is defined to be 
Slh()  Y). 
samples being drawn from S, as they 
will automatically reflect the output value of the target. This approach freely 
generalises to stochastic concepts though we will restrict ourselves to target func- 
tions for the purposes of this paper. The error of a hypothesis h on a sample 
x = ((zx, yx),...,(z,,y,))  S  is defined to be 
We also define the VC dimension of a set of hypotheses by reference to the product 
space S. Consider a sample x = ((z,y),..., (z,,y,)) G S  and the function 
x*: H , {0, 1} , 
given by x*(h): 1 if and only if h(zi): y, for i = 1,..., m. We can now define 
the growth function Bq(rn) as 
BH(m): max I(x*(h)lh G H}l _< 2 . 
XS , 
The Vapnik-Chervonenkis dimension of a hypothesis space H is defined as 
VCdim(H) = { c; if BH(m): 2 , for all m; 
max{rnlB/(rn ) = 2}; otherwise. 
In the case of a threshold network A/', the set of functions obtainable using all 
possible weight assignments is termed the hypothesis space of Af and we will refer 
Threshold Network Learning in the Presence of Equivalences 883 
to it as A/'. For a threshold network A/', we also introduce the state growth function 
$xr(m). This is defined by first considering all computational nodes to be output 
nodes, and then counting different output sequences. 
Sxr(m) -- max I{(F,(w, it),Fg,(w,i.),...,F'(w, im))lw : E  7Z}l 
x=(i,...,i)ex ' 
where X = [0, 1] Ill and AP is obtained from Af by setting O = C. We clearly have 
that for all Af and m, Bxr(m) < Sxr(m). 
Theorem 3.1 [ï¿½] If a hypothesis space H has growth function BH(m) then for 
any e> 0 and k > m and 
1 
0<r<l 
the pro
