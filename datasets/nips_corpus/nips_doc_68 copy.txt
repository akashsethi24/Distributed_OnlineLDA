74O 
SPATIAL ORGANIZATION OF NEURAL NETWORKS: 
A PROBABILISTIC MODELING APPROACH 
A. Stafylopati s 
M. Dikaiakos 
D. Kontoravdi s 
National Technical University of Athens, Department of Electri- 
cal Engineering, Computer Science Division, 157 73 Zographos, 
Athens, Greece. 
ABSTRACT 
The aim of this paper is to explore the spatial organization of 
neural networks under Markovian assumptions, in what concerns the be- 
haviour of individual cells and the interconnection mechanism. Space- 
organizational properties of neural nets are very relevant in image 
modeling and pattern analysis, where spatial computations on stocha- 
stic two-dimensional image fields are involved. As a first approach 
we develop a random neural network model, based upon simple probabi- 
listic assumptions, whose organization is studied by means of dis- 
crete-event simulation. We then investigate the possibility of ap- 
proximating the random network's behaviour by using an analytical ap- 
proach originating from the theory of general product-form queueing 
networks. The neural network is described by an open network of no- 
des, in which customers moving from node to node represent stimula- 
tions and connections between nodes are expressed in terms of sui- 
tably selected routing probabilities. We obtain the solution of the 
model under different disciplines affecting the time spent by a sti- 
mulation at each node visited. Results concerning the distribution 
of excitation in the network as a function of network topology and 
external stimulation arrival pattern are compared with measures ob- 
tained from the simulation and validate the approach followed. 
INTRODUCTION 
Neural net models have been studied for many years in an attempt 
to achieve brain-like performance in computing systems. These models 
are composed of a large number of interconnected computational ele- 
ments and their structure reflects our present understanding of the 
organizing principles of biological nervous systems. In the begin- 
ing, neural nets, or other equivalent models, were rather intended 
to represent the logic arising in certain situations than to provide 
an accurate description in a realistic context. However, in the last 
decade or so the knowledge of what goes on in the brain has increased 
tremendously. New discoveries in natural systems, make it now rea- 
sonable to examine the possibilities of using modern technology in 
order to synthesige sys.ems that have some of the properties of real 
neural systems 8,9,10,1 
In the original neural net model developed in 1943 by McCulloch 
and Pitts 1,2 the network is made of many interacting components, 
known as the McCulloch-Pitts cells or formal neurons, which are 
simple logical units with two possible states changing state accord- 
American Institute of Physics 1988 
741 
ing to a threshold function of their inputs. Related automata moel. 
have been used later for gene control systems (genetic networks) , 
in which genes are represented as binary automata changing state ac- 
cording to boolean functions of their inputs. Boolean networks con- 
stitute a more general model, whose dynamical behaviour has been stu- 
died extensively. Due to the large number of elements, the exact 
structure of the connections and the functions of individual compo- 
nents are generally unknown and assumed to be distributed at random. 
Several studies on these random boolean networks 5,6 have shown that 
they exhibit a surprisingly stable behaviour in what concerns their 
temporal and spatial organization. However, very few formal analyti- 
cal results are available, since most studies concern statistical 
descriptions and computer simulations. 
The temporal and spatial organization of random boolean networks 
is of particular interest in the attempt of understanding the proper- 
ties of such syste.ms, and models originating from the theory of sto- 
chastic processes l seem to be very useful. Spatial properties of 
neural nets are most important in the field of image recognition 12. 
In the biological eye, a level-normalization computation is pe.rformed 
by the layer of horizontal cells, which are fed by the immediately 
preceding layer of hotoreceptors. The horizontal cells take the 
outputs of the receptors and average them spatial ly, this average 
being weighted on a nearest-neighbor basis. This procedure corres- 
ponds to a mechanism for determining the brightness level of pixels 
in an image field by using an array of processing elements. The 
principle of local computation is usually adopted in models used for 
representing and generating textured images. Among the stochastic 
models applied to analyzi the parameters of image fields, the ran- 
dom Markov field model /, seems to give a suitably structured re- 
presentation, which is mainly due to the application of the marko- 
vian property in space. This type of modeling constitutes a promi- 
sing alternative in the study of spatial organization phenomena in 
neural nets. 
The approach taken in this paper aims to investigate some as- 
pects of spatial organization under simple stochastic assumptions. 
In the next section we develop a model for random neural networks 
assuming boolean operation of individual cells. The behaviour of 
this model, obtained through simulation experiments, is then appro- 
ximated by using techniques from the theory of queueing networks. 
The approximation yields quite interesting results as illustrated by 
various examples. 
THE RANDOM NETWORK MODEL 
We define a random neural network as a set of elements or cells, 
each one of which can be in one of two different states: firing or 
quiet. Cells are interconnected to form an NxN grid, where each grid 
point is occupied by a cell. We shall consider only connections be- 
tween neighbors, so that each cell is connected to 4 among the other 
cells- two input and two output cells (the output of a cell is equal 
'to its internal state and it is sent to its output cells which use 
.it as one of their inputs). The network topology is thus specified 
742 
by its incidence matrix A of dimension MxM, where M=N 2. This matrix 
takes a simple form in the case of neighbor-connection considered 
here. We further assume a periodic structure of connections in what 
concerns inputs and outputs; we will be interested in the following 
two types of networks depending upon the period of reproduction for 
elementary square modules 5, as shown in Fig.l: 
- Propagative nets (Period 1) 
- Looping nets (Period 2) 
(a) 
(b) m  
Fig.1. (a) Propagative connections, (b) Looping connections 
At the edges of the grid, circular connections are established (mo- 
dulo N), so that the network can be viewed as supported by a torus. 
The operation of the network is non-autonomous: changes of sta- 
te are determined by both the interaction among cells and the influ- 
ence of external stimulations. We assume that stimulations arrive 
from the outside world according to a Poisson process with parameter 
A. Each arriving stimulation is associated with exactly one cell of 
the network; the cell concerned is determined by means of a given 
discrete probability distribution qi (l<_i<_M), considering an one-di- 
mensional labeling of the M cells. 
The operation of each individual cell is asynchronous and can be 
described in terms of the following rules: 
- A quiet cell moves to the firing state if it receives an arriving 
stimulation or if a boolean function of its inputs becomes true. 
- A firing cell moves to the quiet state if a boolean function of its 
inputs becomes false. 
- Changes of state imply a reaction delay of the cell concerned; the- 
se delays are independent identically distributed random variables 
following a negative exponential distribution with parameter V. 
According to these rules, the operation of a cell can be viewed as il- 
lustrated by Fig.2, where the horizontal axis represents time and th 
numbers 0,1,2 and 3 represent phases of an operation cycle. Phases 1 
and 3, as indicated in Fig.2, correspond to reaction delays. In this 
sense, the quiet and firing states, as defined in the beginingofthis 
section, represent the aggregates of phases 0,1 and 2,3 respectively. 
External stimulations affect the receiving cell only when itisinpha- 
se O; otherwise we consider that the stimulation is lost. In the sa- 
me way, we assume that changes of the value of the input boolean func- 
.ion do not affect the operation of the cell during phases I and 3. The 
conditions are checked onlyat the end of the respective reaction delay. 
743 
quiet 
s ta te 
firing state 
0 
Fig.2. Changes of state for individual cells 
The above defined model includes some features of the original 
McCulloch-Pitts cells 1,2 . In fact, itrepresents an asynchronous 
counterpart of the latter, in which boolean functions are considered 
instead of threshold functions. However, it can be shown that any 
McCulloch and Pitts' neural network can be implemented by a boolean 
network designed in an appropriate fashion 5. In what follows,wewill 
consider that the firing condition for each individual cell is de- 
termined by an or function of its inputs. 
Under the assumptions adopted, the evolution of the network in 
time can be described by a continuous-parameter Markov process. How- 
ever, the size of the state-space and the complexity of the system 
are such that no analytical solution is tractable. The spatial orga- 
nization of the network could be expressed in terms of the steady- 
state probability distribution for the Markov process. A more useful 
representation is provided by the marginal probability distributions 
for all cells in the network, or equivalently by the probability of 
being in the firing state for each cell. This measure expresses the 
level of excitation for each point in the grid. 
We have studied the behaviour of the above model by means of si- 
mulation experiments for various cases depending upon the n
