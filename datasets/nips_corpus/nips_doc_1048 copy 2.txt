Is Learning The -th Thing Any Easier Than 
Learning The First? 
Sebastian Thrun  
Computer Science Department 
Carnegie Mellon University 
Pittsburgh, PA 15213-3891 
World Wide Web: http://www.cs.cmu.edu/thrun 
Abstract 
This paper investigates learning in a lifelong context. Lifelong learning 
addresses situations in which a learner faces a whole stream of learn- 
ing tasks. Such scenarios provide the opportunity to transfer knowledge 
across multiple learning tasks, in order to generalize more accurately from 
less training data. In this paper, several different approaches to lifelong 
learning are described, and applied in an object recognition domain. It 
is shown that across the board, lifelong learning approaches generalize 
consistently more accurately from less training data, by their ability to 
transfer knowledge across learning tasks. 
1 Introduction 
Supervised learning is concerned with approximating an unknown function based on exam- 
ples. Virtually all current approaches to supervised learning assume that one is given a set 
of input-output examples, denoted by X, which characterize an unknown function, denoted 
by f. The target function f is drawn from a class of functions, F, and the learner is given a 
space of hypotheses, denoted by H, and an order (preference/prior) with which it considers 
them during learning. For example, H might be the space of functions represented by an 
artificial neural network with different weight vectors. 
While this formulation establishes a rigid framework for research in machine learning, it 
dismisses important aspects that are essential for human learning. Psychological studies 
have shown that humans often employ more than just the training data for generalization. 
They are often able to generalize correctly even from a single training example [2, 10]. One 
of the key aspects of the learning problem faced by humans, which differs from the vast 
majority of problems studied in the field of neural network learning, is the fact that humans 
encounter a whole stream of learning problems over their entire lifetime. When faced with 
a new thing to learn, humans can usually exploit an enormous amount of training data and 
also affiliated with: Institut fiir Informatik III, Universitfit Bonn, R6merstr. 164, Germany 
Is Learning the n-th Thing Any Easier Than Learning the First? 641 
experiences that stem from other, related learning tasks. For example, when learning to drive 
a car, years of learning experience with basic motor skills, typical traffic patterns, logical 
reasoning, language and much more precede and influence this learning task. The transfer of 
knowledge across learning tasks seems to play an essential role for generalizing accurately, 
particularly when training data is scarce. 
A framework for the study of the transfer of knowledge is the lifelong learning framework. 
In this framework, it is assumed that a learner faces a whole collection of learning problems 
over its entire lifetime. Such a scenario opens the opportunity for synergy. When facing its 
n-th learning task, a learner can re-use knowledge gathered in its previous n - 1 learning 
tasks to boost the generalization accuracy. 
In this paper we will be interested in the most simple version of the lifelong learning problem, 
in which the learner faces a family of concept learning tasks. More specifically, the functions 
to be learned over the lifetime of the learner, denoted by f, f2, f,. � � C F, are all of the type 
f: I > {0, 1} and sampled from F. Each function f C {f, f2, f,...} is an indicator 
function that defines a particular concept: a pattern z  I is member of this concept if 
and only if f(z) = 1. When learning the n-th indicator function, f,, the training set X 
contains examples of the type {x, f, ()) (which may be distorted by noise). In addition to 
the training set, the learner is also given n - 1 sets of examples of other concept functions, 
denoted by Xk (k - 1,..., n - 1). Each Xk contains training examples that characterize 
f. Since this additional data is desired to support learning f,, X is called a support set 
for the training set X. 
An example of the above is the recognition of faces [5, 7]. When learning to recognize the 
n-th person, say fBob, the learner is given a set of positive and negative example of face 
images of this person. In lifelong learning, it may also exploit training information stemming 
from other persons, such as f  {fRich, fMike, fDave, � � -}. The support sets usually cannot be 
used directly as training patterns when learning a new concept, since they describe different 
concepts (hence have different class labels). However, certain features (like the shape of the 
eyes) are more important than others (like the facial expression, or the location of the face 
within the image). Once the invariances of the domain are learned, they can be transferred 
to new learning tasks (new people) and hence improve generalization. 
To illustrate the potential importance of related learning tasks in lifelong learning, this 
paper does not present just one particular approach to the transfer of knowledge. Instead, 
it describes several, all of which extend conventional memory-based or neural network 
algorithms. These approaches are compared with more traditional learning algorithms, i.e., 
those that do not transfer knowledge. The goal of this research is to demonstrate that, 
independent of a particular learning approach, more complex functions can be learned from 
less training data if learning is embedded into a lifelong context. 
2 Memory-Based Learning Approaches 
Memory-based algorithms memorize all training examples explicitly and interpolate them 
at query-time. We will first sketch two simple, well-known approaches to memory-based 
learning, then propose extensions that take the support sets into account. 
2.1 Nearest Neighbor and Shepard's Method 
Probably the most widely used memory-based learning algorithm is K-nearest neighbor 
(KNN) [ 15]. Suppose � is a query pattern, for which we would like to know the output y. 
KNN searches the set of training examples X for those K examples {zi, Yi/  X whose 
input patterns i are nearest to z (according to some distance metric, e.g., the Euclidian 
distance). It then returns the mean output value k  yi of these nearest neighbors. 
Another commonly used method, which is due to Shepard [ 13], averages the output values 
642 S. THRUN 
of all training examples but weights each example according to the inverse distance to the 
querypointx. ( ) ( 
Yi ' E 1 
(x,,y,)x (x,,y,)x 
Here s > 0 is a small constant that prevents division by zero. Plain memory-based learning 
uses exclusively the training set X for learning. There is no obvious way to incorporate the 
support sets, since they carry the wrong class labels. 
2.2 Learning A New Representation 
The first modification of memory-based learning proposed in this paper employs the support 
sets to learn a new representation of the data. More specifically, the support sets are employed 
to learn a function, denoted by #: ! > I', which maps input patterns in ! to a new space, 
I'. This new space F forms the input space for a memory-based algorithm. 
Obviously, the key property of a good data representations is that multiple examples of a 
single concept should have a similar representation, whereas the representation of an example 
and a counterexample of a concept should be more different. This property can directly be 
transformed into an energy function for g: 
k= (,=)xk (,,,=)xk 
) ] IIg(x)-g(x')11) (2) 
(x',y'=O) X 
Adjusting # to minimize E forces the distance between pairs of examples of the same 
concept to be small, and the distance between an example and a counterexample of a concept 
to be large. In our implementation, # is realized by a neural network and trained using the 
Back-Propagation algorithm [ 12]. 
Notice that the new representation, g, is obtained through the support sets. Assuming that 
the learned representation is appropriate for new learning tasks, standard memory-based 
learning can be applied using this new representation when learning the n-th concept. 
2.3 Learning A Distance Function 
An alternative way for exploiting support sets to improve memory-based learning is to learn 
a distance function [3, 9]. This approach learns a function d: I x I > [0, 1] which accepts 
two input patterns, say z and z , and outputs whether z and z  are members of the same 
concept, regardless what the concept is. Training examples for d are 
((x,x'),l) if y:y=l 
((x, x'), 0)if(y=lAy':O)or(y=OAy':l). 
They are derived from pairs of examples (x, y), {x , y') C Xk taken from a single support 
set Xt, (k - 1,..., n - 1). In our implementation, d is an artificial neural network trained 
with Back-Propagation. Notice that the training examples for d lack information concerning 
the concept for which they were originally derived. Hence, all support sets can be used to 
train d. After training, d can be interpreted as the probability that two patterns x, x'  I are 
examples of the same concept. 
Once trained, d can be used as a generalized distance function for a memory-based approach. 
Suppose one is given a training set X and a query point z  I. Then, for each positive 
example (x', y' = 1)  X, d(x, x') can be interpreted as the probability that x is a member 
of the target concept. Votes from multiple positive examples (z, 1), (z2, 1),... G X are 
combined using Bayes' rule, yielding 
(3) 
erob(f(x)=) := l- II 
(z',y'=l)6X 
Is Learning the n-th Thing Any Easier Than Learning the First? 643 
Notice that d is not a distance metric. It generalizes the notion of a distance metric, because 
the triangle inequality needs not hold, and because an example of the target concept z  can 
provide evidence that z is not a member of that concept (if d(z, z t) < 0.5). 
3 Neural Network Approaches 
To make our comparison mor
