240 
TEMPORAL REPRESENTATIONS IN A 
CONNECTIONIST SPEECH SYSTEM 
Erich J. Smythe 
207 Greenmanville Ave, #6 
Mystic, CT 06355 
ABSTRACT 
SYREN is a connectionist model that uses temporal information 
in a speech signal for syllable recognition. It classifies the rates 
and directions of formant center transitions, and uses an adaptive 
method to associate transition events with each syllable. The 
system uses explicit spatial temporal representations through de- 
lay lines. SYREN uses implicit parametric temporal representa- 
tions in formant transition classification through node activation 
onset, decay, and transition delays in sub-networks analogous to 
visual motion detector cells. SYREN recognizes 79% of six repe- 
titions of 24 consonant-vowel syllables when tested on unseen 
data, and recognizes 100% of its training syllables. 
INTRODUCTION 
Living organisms exist in a dynamic environment. Problem solving systems, both 
natural and synthetic, must relate and interpret events that occur over time. 
Although connectionist models are based on metaphors from the brain, few have 
been designed to capture temporal and sequential information common to even 
the most primitive nervous systems. Yet some of the most popular areas of appli- 
cation of these models, including speech recognition, vision, and motor control, 
require some form of temporal processing. 
The variation in a speech signal contains considerable information. Changes in 
format location or other acoustic parameters (Delattre, et al., 1955; Pols and 
Schouten, 1982) can determine the identity of constituents of speech, even when 
segmentation information is obscure. Speech recognition systems have shown 
good results when they incorporate some temporal information (Waible, et al., 
1988, Anderson, et al., 1988). Successful speech systems must incorporate tem- 
poral processing. 
Natural organisms have sensory organs that are continuously updated and can do 
only limited buffering of input stimuli. Synthetic implementations can buffer their 
input, transforming time into space. Often the size and complexity of the input 
representations place limits on the amount of input that can be buffered, espe- 
cially when data is coming from hundreds or thousands of sensors, and other 
methods must be found to integrate temporal information. 
Temporal Representations in a Connectionist Speech System 241 
This paper describes SYREN (SYllable REcognition Network), a connectionist 
network that incorporates various temporal representations for consonant-vowel 
(CV) syllable recognition by the classification of formant center transitions. Input 
is presented sequentially, one time slice at a time. The network is described, 
including the temporal processing used in formant transition classification, learn- 
ing, and syllable recognition. The results of syllable recognition experiments are 
discussed in the final section. 
TEMPORAL REPRESENTATIONS 
Various types of temporal representations may be used to incorporate time in 
connectionist models. They range from explicit spatial representations where 
time is converted into space, to implicit parametric representations where time is 
incorporated using network computational parameters. Spatiotemporal represen- 
tations are a middle ground combining the two extremes. The categories repre- 
sent a continuum rather than absolute distinctions. Several of these types are 
found in SYREN. 
EXPLICIT SPATIAL REPRESENTATIONS 
In a purely spatial representation temporal information is preserved by spreading 
time steps over space through the network topology. These representations in- 
clude input buffers, delay lines, and recurrent networks. 
Fixed input buffers allow interaction between time slices of input. Parts of the 
network are copied to represent states at particular time slices. Other methods 
use sliding input buffers in the form of a queue. Tapped delay lines and delay 
filters are means of spreading network node activations over time. Composed of 
chains of network nodes or delay functions, they can preserve the sequential 
structure of information. A value on a connection from a delay line represents 
events that have occurred in the past. Delay lines and filters have been used in 
speech recognition systems by Waible, et al. (1988), and Tank and Hopfield 
(1987). 
Recurrent networks are similar to delay lines in that information is preserved by 
propagating activation through the network. They can store information indefi- 
nitely or generate potentially infinite sequences of behaviors through feedback 
cycles, whereas delay lines without cycles are limited by their fixed length. Re- 
current networks pose problems for learning, although researchers are working on 
recurrent back propagation networks (Jordan, 1988). 
Spatial representations are good for explicitly preserving sequences of events, and 
can simplify the learning of temporal patterns. Resource constraints place a limit 
on the size of fixed length buffers and delay lines, however. Input data from 
thousands of sensors place limits on the length of time represented in the buffer, 
and may not be able to retain information long enough to be of use. Fixed input 
buffers may introduce edge effects. Interaction is lost between the edges of the 
buffer and data from preceding and succeeding buffers unless the input is prop- 
erly segmented. Long delay lines may be computationally expensive as well. 
242 Smythe 
SPATIOTEMPORAL REPRESENTATIONS 
Implicit parametric methods represent time in connectionist models by the behav- 
ior of network nodes. State information stored in individual nodes allows more 
complex activation functions and the accumulation of statistical information. 
This method may be used to regulate the flow of activation in the network, pro- 
vide a trace of previous activation, and learn from data separated in time. 
Adjusting the parameters of functions such as the interactive activation equation 
of McClelland and Rumelhart (1982) can control the strength of input, affecting 
the rate that activation reaches saturation. This leads to pulse trains used in 
synchronization. Variations in decay parameters control the duration of an acti- 
vation trace. 
State and statistical information is useful in learning. Eligibility traces from classi- 
cal conditioning models provide decaying memory of past connection activation. 
Temporally weighted averages may be used for weight computations. 
Spatiotemporal representations combine implicit parametric representations with 
explicit spatial representations. These include the regulation of propagation time 
and pulse trains through parameter adjustment. Gating behavior that controls the 
flow of activation through a network is another spatiotemporal method. 
SYREN DESCRIPTION 
SYREN is a connectionist model that incorporates temporal processing in isolated 
syllable recognition using formant center transitions. Formant center tracts are 
presented in 5 ms time slices. Input nodes are updated once per time slice. The 
network classifies the rates and directions of form ant transitions. Transition data 
are used by an adaptive network to associate transition patterns with syllables. A 
recognition network uses output of the adaptive network to identify a syllable. 
Complete details of the system may be found in Smythe (1988). 
DATA CORPUS 
Input data consist of formant centers from five repetitions of twenty-four conso- 
nant-vowel syllables (the stop consonants/b, d, g/paired with the vowels/ii, ey, 
ih, eh, ae, ah, ou, uu/), and an averaged set of each of the five repetitions from 
work performed by Kewley Port (1982). Each repetition is presented as a binary 
matrix with a row representing frequency in 20 Hz units, and a column represent- 
ing time in 5 ms slices. The matrix is given to the input units one column at a 
time. A '1' in a cell of a matrix represents a formant center at a particular 
frequency during a particular time slice. 
FORMANT TRANSITION CLASSIFICATION 
In the first stage of processing SYREN determines the rate and direction of for- 
mant center transitions. Formant transition detectors are subnetworks designed 
to respond to transitions of one of six rates in either rising or falling directions, 
Temporal Representations in a Connectionist Speech System 243 
and also to steady-state events. The method used is motivated by a mechanism 
for visual motion detection in the retina that combines interactions between sub- 
units of a dendritic tree and shunting, veto inhibition (Koch et al, 1982). For- 
mant motion is analogous to visual motion, and formant transitions are treated as 
a one dimensional case of visual motion. 
S-Node 
Preferred 
Transition 
Input Branch Nodes 
Nodes Nodes Distal Proximal 
Figure 1. Formant transition detector subnetwork and its preferred 
descending transition type. The vertical axis is frequency (one row for 
each input unit) and the horizontal axis is time in 5 ms slices. 
A detector subnetwork for a slow transition is shown in figure 1, along with its 
preferred transition. Branch nodes are analogous to dendritic subunits, and serve 
as activation transmission lines. Their activation is computed by the equation: 
at+l t netS(1 a) 
i = ai(1 - O) + - 
Where a is the activation of unit i at time t, net is the weighted input, t is an 
update cycle (there are 7 updates per time slice), and 0 is a decay constant. 
Input to a branch node drives the activation to a maximum value, the rate of 
which is determined by the strength of the input. In the absence of input the 
activation decays to 0. 
For the preferred direction, input nodes are activated for two time slices (10 ms) 
in order from top to bottom. An input node causes the activation of the most 
distal branch node to rise to a maximum value. This in turn causes the next node 
to activate, slightly delayed with respect to the first, and so on for the rest of the 
branch. This results in a 
