Structural Risk Minimization for 
Nonparametric Time Series Prediction 
Ron Meir* 
Department of Electrical Engineering 
Technion, Haifa 32000, Israel 
rmeirdumbo. technion. ac. il 
Abstract 
The problem of time series prediction is studied within the uniform con- 
vergence framework of Vapnik and Chervonenkis. The dependence in- 
herent in the temporal structure is incorporated into the analysis, thereby 
generalizing the available theory for memoryless processes. Finite sam- 
ple bounds are calculated in terms of covering numbers of the approxi- 
mating class, and the tradeoff between approximation and estimation is 
discussed. A complexity regularization approach is outlined, based on 
Vapnik's method of Structural Risk Minimization, and shown to be ap- 
plicable in the context of mixing stochastic processes. 
1 Time Series Prediction and Mixing Processes 
A great deal of effort has been expended in recent years on the problem of deriving robust 
distribution-free error bounds for learning, mainly in the context of memoryless processes 
(e.g. [9]). On the other hand, an extensive amount of work has been devoted by statisticians 
and econometricinns to the study of parametric (often linear) models of time series, where 
the dependence inherent in the sample, precludes straightforward application of many of 
the standard results form the theory of memoryless processes. In this work we propose 
an extension of the framework pioneered by Vapnik and Chervonenkis to the problem of 
time series prediction. Some of the more elementary proofs are sketched, while the main 
technical results will be proved in detail in the full version of the paper. 
Consider a stationary stochastic process  = {-.- , X_l, Xo, X1, � �. }, where Xi is a ran- 
dom variable defined over a compact domain in R and such that [Xi[ _< B with probability 
1, for some positive constant B. The problem of one-step prediction, in the mean square 
sense, can then be phrased as that of finding a function f(-) of the infinite past, such that 
E IXo - f(X_-)l 2 is minimal, where we use the notation X] = (Xi,Xi_l,... ,Xj), 
� This work was supported in pan by the a grant from the Israel Science Foundation 
Structural Risk Minimization fo r Nonparametric 7rne Series Prediction 309 
j ) i. It is well known that the optimal predictor in this case is given by the conditional 
mean, E[XolX_-]. While this solution, in principle, settles the issue of optimal predic- 
tion, it does not settle the issue of actually computing the optimal predictor. First of all, 
note that to compute the conditional mean, the probabilistic law generating the stochastic 
process  must be known. Furthermore, the requirement of knowing the full past, X, 
is of course rather stringent. In this work we consider the more practical situation, where 
a finite sub-sequence X = (X, X2,. � � , XN) is observed, and an optimal prediction is 
needed, conditioned on this data. Moreover, for each finite sample size N we allow the 
predictors to be based only on a finite lag vector of size d. Ultimately, in order to achieve 
full generality one may let d --+ ec when N --+ ec in order to obtain the optimal predictor. 
We first consider the problem of selecting an empirical estimator from a class of functions 
Y'a,, ' R a  R, where n is a complexity index of the class (for example, the number 
of computational nodes in a feedforward neural network with a single hidden layer), and 
{fl -< B for f E Y'a,,. Consider then an empirical predictor fa,,,N 
(xi_a), i > N, 
for Xi based on the finite data set X N and depending on the d-dimensional lag vector 
Xi_ a, where fa,n,v E .T',n. It is possible to split the error incurred by this predictor into 
three terms, each possessing a rather intuitive meaning. It is the competition between these 
terms which determines the optimal solution, for a fixed amount of data. First, define the 
loss of a functional predictor f � R a  R as L(f) E Xi i- 2, . 
= - f(Xi_a) ] and let 
be the optimal function in .ct,n minimizing this loss. Furthermore, denote the optimal lag 
d predictor by f, and its associated loss by L. We are then able to split the loss of the 
empirical predictor fd,n,N into three basic components, 
(l) 
where Ld,n,N --' L(fa,n,N). The third term, L}, is related to the error incurred in using a fi- 
nite memory model (of lag size d) to predict a process with potentially infinite memory. We 
do not at present have any useful upper bounds for this term, which is related to the rate of 
convergence in the martingale convergence theorem, which to the best of our knowledge is 
unknown for the type of mixing processes we study in this work. The second term in (1), is 
related to the so-called approximation error, given by E[ f i-  , { ,'i--1'12 
(Xi- a)-Jct,,  i-a to which 
it can be immediately related through the inequality I[al p - Ib[P[ < pla- bl{ max(a, b)I p- . 
This term measures the excess error incurred by selecting a function f from a class of lim- 
ited complexity a,n, while the optimal lag d predictor f may be arbitrarily complex. Of 
course, in order to bound this term we will have to make some regularity assumptions about 
the latter function. Finally, the first term in (1) re, presents the so called estimation error, 
and is the only term which depends on the data X  . Similarly to the problem of regression 
for i.i.d. data, we expect that the approximation and estimation terms lead to conflicting 
demands on the choice of the the complexity, n, of the functional class .Ta,,. Clearly, in 
order to minimize the approximation error the complexity should be made as large as pos- 
sible. However, doing this will cause the estimation error to increase, because of the larger 
freedom in choosing a specific function in a,n to fit the data. However, in the case of time 
series there is an additional complication resulting from the fact that the misspecification 
error L is minimized by choosing d to be as large as possible, while this has the effect 
of increasing both the approximation as well as the estimation errors. We thus expect that 
some optimal values of d and n exist for each sample size N. 
Up to this point we have not specified how to select the empirical estimator fa,,,N. In this 
work we follow the ideas of Vapnik [8], which have been studied extensively in the con- 
text of i.i.d observations, and restrict our selection to that hypothesis which minimizes the 
f Xi_  2 
empiricalerror, givenby Lv(f)= 1 Y=a+ IXi- ( i-a)[ For this function it is 
N--d ' 
easy to establish (see for example [8]) that (L&n,N -L},,) < 2 sup/ey., I L(f)- Lv (f)l. 
The main distinction from the i.i.d case, of course, is that random variables appearing in 
310 R. Meir 
the empirical error, L:v(f), are no longer independent. It is clear at this point that some 
assumptions are needed regarding the stochastic process , in order that a law of large 
numbers may be established. In any event, it is obvious that the standard approach of using 
randomization and symmetrization as in the i.i.d case [3] will not work here. To circum- 
vent this problem, two approaches have been proposed. The first makes use of the so-called 
method of sieves together with extensions of the Bernstein inequality to dependent data [6]. 
The second approach, to be pursued here, is based on mapping the problem onto one char- 
acterized by an i.i.d process [10], and the utilization of the standard results for the latter 
case. 
In order to have some control of the estimation error discussed above, we will restrict our- 
selves in this work to the class of so-called mixing processes. These are processes for which 
the 'future' depends only weakly on the 'past', in a sense that will now be made precise. 
Following the definitions and notation of Yu [10], which will be utilized in the sequel, let 
at = a(X) and (r+ m: a(X+m), be the sigma-algebras of events generated by the ran- 
dom variables X = (X, X2,... , Xt) and Xt m - (Xt+m, Xt+m+,. . . ), respectively. 
We then define m, the coefficient of absolute regularity, as 
m -- supt> Esup {IP(Bla,) - P(B)I � B E �;+m}, where the expectation is taken 
with respect to at = a(X). A stochastic process is said to be -mixing if 3m  0 as 
m  oc. We note that there exist many other definitions of mixing (see [2] for details). 
The motivation for using the -mixing coefficient is that it is the weakest form of mixing 
for which uniform laws of large numbers can be established. In this work we consider two 
type of processes for which this coefficient decays to zero, namely algebraically decaying 
processes for which m < m -', , r > 0, and exponentially mixing processes for which 
m < / exp{ -bm'}, , b,  > 0. Note that for Markov processes mixing implies expo- 
nential mixing, so that at least in this case, there is no loss of generality in assuming that 
the process is exponentially mixing. Note also that the usual i.i.d process may be obtained 
from either the exponentially or algebraically mixing process, by taking the limit   oc 
or r  ec, respectively. 
In this section we follow the approach taken by Yu [10] in deriving uniform laws of large 
numbers for mixing processes, extending her mainly asymptotic results to finite sample 
behavior, and somewhat broadening the class of processes considered by her. The basic 
idea in [10], as in many related approaches, involves the construction of an independent- 
block sequence, which is shown to be 'close' to the original process in a well-defined 
probabilistic sense. We briefly recapitulate the construction, slightly modifying the nota- 
tion in [10] to fit in with the present paper. Divide the sequence X into 2uv blocks, 
each of size aN; we assume for simplicity that N = 2]tNaN. The blocks are then num- 
bered according to their order in the block-sequence. For 1 < j < /v define H i -- 
{i' 2(j - 1)aN + 1 _< i _< (2j - 1)aN} an
