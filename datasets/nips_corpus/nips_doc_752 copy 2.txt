Asynchronous Dynamics of Continuous 
Time Neural Networks 
Xin Wang 
Computer Science Department 
University of California at Los Angeles 
Los Angeles, CA 90024 
Qingnan Li 
Department of Mathematics 
University of Southern California 
Los Angeles, CA 90089-1113 
Edward K. Blum 
Department of Mathematics 
University of Southern California 
Los Angeles, CA 90089-1113 
ABSTRACT 
Motivated by mathematical modeling, analog implementation and 
distributed simulation of neural networks, we present a definition of 
asynchronous dynamics of general CT dynamical systems defined 
by ordinary differential equations, based on notions of local times 
and communication times. We provide some preliminary results 
on globally asymptotical convergence of asynchronous dynamics 
for contractive and monotone CT dynamical systems. When ap- 
plying the results to neural networks, we obtain some conditions 
that ensure additive-type neural networks to be asynchronizable. 
1 INTRODUCTION 
Neural networks are massively distributed computing systems. A major issue in par- 
allel and distributed computation is synchronization versus asynchronization (Bert- 
sekas and Tsitsiklis, 1989). To fix our idea, we consider a much studied additive-type 
model (Cohen and Grossberg, 1983; Hopfield, 1984; Hirsch, 1989) of a continuous- 
time (CT) neural network of n neurons, whose dynamics is governed by 
ki(t) = -aixi(t) + E wiJ�'J(ljxj � + Ii, i = 1,2, ...,n, (1) 
j=l 
493 
494 Wang, Li, and Blum 
with neuron states zi(t) at time t, constant decay rates ai, external inputs h, gains 
/d, neuron activation functions a i and synaptic connection weights wij. Simu- 
lation and implementation of idealized models of neural networks such as (1) on 
centralized computers not only limit the size of networks, but more importantly 
preclude exploiting the inherent massive parallelism in network computations. A 
truly faithful analog implementation or simulation of neural networks defined by 
(1) over a distributed network requires that neurons follow a global clock t, com- 
municate timed states xj(t ) to all others instantaneously and synchronize global 
dynamics precisely all the time (e.g., the same x I (t) should be used in evolution of 
all xi(t) at time t). Clearly, hardware and software realities make it very hard and 
sometimes impossible to fulfill these requirements; any mechanism used to enforce 
such synchronization may have an important effect on performance of the net- 
work. Moreover, absolutely insisting on synchronization contradicts the biological 
manifestation of inherent asynchrony caused by delays in nerve signal propagation, 
variability of neuron parameters such as refractory periods and adaptive neuron 
gains. On the other hand, introduction of asynchrony may change network dynam- 
ics, for example, from convergent to oscillatory. Therefore, validity of asynchronous 
dynamics of neural networks must be assessed in order to ensure desirable dynamics 
in a distributed environment. 
Motivated by the above issues, we study asynchronous dynamics of general CT dy- 
namical systems with neural networks in particular. Asynchronous dynamics has 
been thoroughly studied in the context of iterative maps or discrete-time (DT) dy- 
namical systems; see, e.g., (Bertsekas and Tsitsiklis, 1989) and references therein. 
Among other results are that P-contractive maps on It n (Baudet, 1978) and contin- 
uous maps on partially ordered sets (Wang and Parker, 1992) are asynchronizable, 
i.e., any asynchronous iterations of these maps will converge to the fixed points 
under synchronous (or parallel) iterations. The synchronization issue has also been 
addressed in the context of neural networks. In fact, the celebrated DT Hopfield 
model (Hopfield, 1982) adopts a special kind of asynchronous dynamics: only one 
randomly chosen neuron is allowed to update its state at each iterative step. The 
issue is also studied in (Barhen and Gulati, 1989) for CT neural networks. The 
approach there is, however, to convert the additive model (1) into a DT version 
through the Euler discretization and then to apply the existing result for contrac- 
tive mappings in (Baudet, 1978) to ensure the discretized system to be asynchro- 
nizable. Overall, studies for asynchronous dynamics of CT dynamical systems are 
still lacking; there are even no reasonable definitions for what it means, at least to 
our knowledge. 
In this paper, we continue our studies on relationships between CT and DT dy- 
namical systems and neural networks (Wang and Blum, 1992; Wang, Blum and Li, 
1993) and concentrate on their asynchronous dynamics. We first extend a concept 
of asynchronous dynamics of DT systems to CT systems, by identifying the distinc- 
tion between synchronous and asynchronous dynamics as (i) presence or absence of 
a common global clock used to synchronize the dynamics of the different neurons 
and (ii) exclusion or inclusion of delay times in communication between neurons, 
and present some preliminary results for asynchronous dynamics of contractive and 
monotone CT systems. 
Asynchronous Dynamics of Continuous Time Neural Networks 495 
2 MATHEMATICAL FORMULATION 
To be general, we consider a CT dynamical system defined by an n-dimensional 
system of ordinary differential equations, 
ki(t) = fi(ah(t),...,xn(t)), i= 1,2,...,n, 
(2) 
where fi: R n '--* R are continuously differentiable and x(t)  R n for all t in R+ (the 
set of all nonnegative real numbers). In contrast to the asynchronous dynamics 
given below, dynamics of this system will be called synchronous. An asynchronous 
scheme consists of two families of functions ci : R+  R+ and rj : R+  R+, 
i, j = 1, ..., n, satisfying the following constraints: for any t _> 0, 
(i) Initiation: ci(t) >_ 0 and rj(t) _> 0; 
(ii) Non-starvation: ci's are differentiable and ki(t) > 0; 
(iii) Liveness: limt_.. ci(t) = cx> and limt_...� rj(t) 
(iv) Accessibility: rj(t) _< cj(t). 
Given an asynchronous scheme ({ci}, {rj}), the associated asynchronous dynamics 
of the system (2) is the solution of the following parametrized system: 
i(Ci()) --' 
We shall call this system an asynchronized system of the original one (2). 
The functions ci(t) should be viewed as respective local times (or clocks) of com- 
ponents i, as compared to the global time (or clock) t. As each component i 
evolves its state according to its local time ci(t), no shared global time t is needed 
explicitly; t only occurs implicitly. The functions rj(t) should be considered as time 
instants at which corresponding values xj of components j are used by component 
i; hence the differences (cj(t)- rj(t)) _> 0 can be interprated as delay times in 
communication between the components j and i. Constraint (i) reflects the fact 
that we are interested in the system dynamics after some global time instance, say 
0; constraint (ii) states that the functions ci are monotone increasing and hence the 
local times evolve only forward; constraint (iii) characterizes the liveness property 
of the components and communication channels between components; and, finally, 
constraint (iv) precludes the possibility that component i accesses states xj ahead 
of the local times cj(t) of components j which have not yet been generated. 
Notice that, under the assumption on monotonicity of ci (t), the inverses c- x (t) exist 
and the asynchronized system (3) can be transformed into 
9,(t) = a,(t) 9}(t), ..., 
(4) 
by letting yi(t) = xi(ci(t)) and .0j (t) = xj(rj(t)) = yj(cj-X(rj(t)) for i,j = 1,2,..., n. 
The vector form of (4) can be given by 
t = C'F[] (5) 
496 Wang, Li, and Blum 
w_here y(t) = [yx (t), ..., yn(t)] T, C' = diag(dc (t)/dt, ..., dcn(t)/dt), F = [f, ..., fn] T 
Y = [] and 
., 
r[?] = f2((t),(t),...,}(t)) . 
Notice that the complication in the way F applies to  simply means that every 
component i will use possibly different global states [.O(t),.O}(t), ...,-i 
y.(t)]. This 
peculiarity makes the equation (5) fit into none of the categories of general functional 
differential equations (Hale, 1977). However, if rj(t) for i : 1,...,n are equal, 
all the components will use a same global state .0 = [.O(t),.O(t),...,(t)l and 
the asynchronized system (5) assumes a form of retarded functional differential 
equations, 
= (6) 
We shall call this case uniformly-delayed, which will be a main consideration in the 
next section where we discuss asynchronizable systems. 
The system (5) includes some special cases. In a no communication delay situation, 
rj(t) = cj(t) for alii and the system (5) reduces to : C'F(y). This includes the 
simplest case where the local times ci(t) are taken as constant-time scalings cit of 
the global time t; specially, when all ci(t) = t the system goes back to the original 
one (2). If, on the other hand, all the local times are identical to the global time t 
and the communication times take the form of vj(t) = t - 0(t) one obtains a most 
general delayed system 
i(t) -- fi(Yl(t --O(t)),y2(t -- 0}(/)), ...,yn(t- O/n(/))), 
(7) 
where the state yj(t) of component j may have different delay times O(t) for dif- 
ferent other components i. 
Finally, we should point out that the above definitions of asynchronous schemes and 
dynamics are analogues of their counterparts for DT dynamical systems (Bertsekas 
and Tsitsiklis, 1989; Blum, 1990). Usually, an asynchronous scheme for a DT 
system defined by a map f � X -4 X, where X = Xx x X2 x � .. x X,, consists of a 
family {T i C_Nli: 1, ...,n} of subsets of discrete times (N) at which components 
i update their states and a family {vj � N -4 Nli = 1, 2, ..., n} of communication 
times. Asynchronous dynamics (or chaotic iteration, relaxation) is then given by 
;ri(l q- 1) -- { fi(Xl(T())'''X(Tni())) if t � T  
xi(t) otherwise. 
Notice that the sets T i can be interpreted as local times of components i. In fact, 
one can define local time functions ci ' N -4 N as ci(O) = 0 and ci(t 
