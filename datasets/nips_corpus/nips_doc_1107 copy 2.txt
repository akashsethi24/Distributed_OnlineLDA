Recursive Estimation of Dynamic 
Modular RBF Networks 
Visakan Kadirkamanathan 
Automatic Control & Systems Eng. Dept. 
University of Sheffield, Sheffield S1 4DU, UK 
visakan@acse.sheffield.ac.uk 
Maha Kadirkamanathan 
Dragon Systems UK 
Cheltenham GL52 4RW, UK 
maha@dragon.co.uk 
Abstract 
In this paper, recursive estimation algorithms for dynamic modular 
networks are developed. The models are ba.sed on Gaussian RBF 
networks and the gating network is considered in two stages: At 
first, it is simply a time-varying scalar and in the second, it is 
based on the state, as in the mixture of local experts scheme. The 
resulting algorithm uses Kalman filter estimation for the model 
estimation and the gating probability estimation. Both, 'hard' and 
'soft' competition based estimation schemes are developed where in 
the former, the most probable network is adapted and in the latter 
all networks are adapted by appropriate weighting of the data. 
I INTRODUCTION 
The problem of learning multiple modes in a complex nonlinear system is increas- 
ingly being studied by various researchers [2, 3, 4, 5, 6]. The use of a mixture of 
local experts [5, 6], and a conditional mixture density network [3] have been devel- 
oped to model various modes of a system. The development has mainly been on 
model estimation from a given set of block data, with the model likelihood depen- 
dent on the input to the networks. A recursive algorithm for this static case is the 
approximate iterative procedure based on the block estimation schemes [6]. 
In this paper, we consider dynamic systems - developing a recursive algorithm is 
difficult since mode transitions have to be detected on-line whereas in the block 
scheme, search procedures allow optimal detection. Block estimation schemes for 
general architectures have been described in [2, 4]. However, unlike in those schemes, 
the algorithm developed here uses relationships based on Bayes law and Kalman 
filters and attempts to describe the dynamic system explicitly. The modelling is 
carried out by radial basis function (RBF) networks for their property that by pre- 
selecting the centres and widths, the problem can be reduced to a linear estimation. 
240 V. KADIRKAMANATHAN, M. KADIRKAMANATHAN 
2 DYNAMIC MODULAR RBF NETWORK 
The dynamic modular RBF network consists of a number of models (or experts) 
to represent each nonlinear mode in a dynamical system. The models are based 
on the RBF networks with Gaussian function, where the RBF centre and width 
parameters are chosen a priori and the unknown parameters are only the linear 
coefficients w. The functional form of the RBF network can be expressed as, 
K 
f(x; p) - E wg(x) - w rg 
(1) 
k-'l 
where w = [...,w,...]T C K is the linear weight vector and g = 
[..., g(x),...]C R are the radial basis functions, where, 
g(x) - exp {-0.5r-2ll x - mll 2 } (2) 
m  ]M are the RBF centres or means and r the width. The RBF networks 
are used for their property that having chosen appropriate RBF centre and width 
parameters m, r, only the linear weights w need to be estimated for which fast, 
efficient and optimal algorithms exist. 
Each model has an associated probability score of being the current underlying 
model for the given observation. In the first stage of the development, this prob- 
ability is not determined from parametrised gating network as in the mixture of 
local experts [5] and the mixture density network [3], but is determined on-line as it 
varies with time. In dynamic systems, time information must be taken into account 
whereas the mixture of local experts use only the state information which is not 
sufficient in general, unless the states contain the necessary information. In the 
second stage, the probability is extended to represent both the time and state infor- 
mation explicitly using the expressions from the mixture of local experts. Recently, 
time and state information have been combined in developing models for dynamic 
systems such as the mixture of controllers [4] and the Input - Output HMM [2]. 
However, the scheme developed here is more explicit and is not as general as the 
above schemes and is recurslye as opposed to block estimation. 
3 RECURSIVE ESTIMATION 
The problem of recursive estimation with RBF networks have been studied previ- 
ously [7, 8] and the algorithms developed here is a continuation of that process. Let 
the set of input - output observations from which the model is to be estimated be, 
= 
where, ZN includes all observations upto the Nth data and z, is the nth data, 
- [ (4) 
The underlying system generating the observations are assumed to be multi-modal 
(with known H modes), with each observation satisfying the nonlinear relation, 
y ---- fn(x) + r/ (5) 
where r/is the noise with unknown distribution and fn ('): M H  is the unknown 
underlying nonlinear function for the hth mode which generated the observation. 
Under assumptions of zero mean Gaussian noise and that the model can approxi- 
mate the underlying function arbitrarily closely, the probability distribution, 
p(zlwn,A// = A//A, Z_x) = (2w)-R0  exp -R ' [Yn - fn(xn;wn)l  (6) 
Recursive Estimation of Dynamic Modular RBF Networks 241 
is Gaussian. This is the likelihood of the observation z for the model .Ma, which 
in our case is the GRBF network, given model parameters w and that the nth 
observation was generated by .Ma. R0 is the variance of the noise r/. In general 
however, the model generating the nth observation is unknown and the likelihood 
of the nth observation is expanded to include 7 the indicator variable, as in [6], 
H 
p(z,%lW,A, Z-x)- II 
h=l 
[p(zlwh,M  = Mh, 2_x)p(  - 
(7) 
The Bayes law relation (8) applies to each model. Hence, the only modification 
in the Kalman filter algorithm is that the noise variance for each model is set to 
Ro/7 and the resulting equations can be found in [7]. It increases the apparent 
uncertainty in the measurement output according to how likely the model is to be 
the true underlying mode, by increasing the noise variance term of the Kalman filter 
algorithm. Note that the term p(Ad ' = Aria Ix,, 2 '-) is a time-varying scalar and 
does not influence the parameter estimation process. 
The evidence term can also be determined directly kom the Kalman filter, 
p(zl,z_): (2)-nk  ep -Sn l,k (l) 
a is the prediction error and R is the innovation variance with, 
where the % 
en = Yn -- Wn-lgn 
a - pa (13) 
This is also the likelihood of the n ta observation given the model  and the past 
observations 2n_. The above equation shows that the evidence term used in 
Bayesian model selection [9] is computed recursively, but for the specific priors 
P0. Ondine Bayesian model selection can be carried out by choosing many different 
priors, effectively sampling the prior space, to determine the best model to fit the 
given data, as discussed in [7]. 
Bayes law can be applied to the on-line or recursive parameter estimation, 
p(WlZ=,j ) = P(zIW,A, Z=-x)p(WlZ=-x,A4) 
p(z=lZ=-x, A4) (8) 
and the above equation is applied recursively for n -- 1,...,N. The term 
p(zn]Zn-x,) is the evidence. If the underlying system is unimodal, this will 
result in the optimal Kalman estimator and if we assign the prior probability dis- 
tribution for the model parameters p(wn to be Gaussian with mean w0 and 
covariance matrix (positive definite) P0 xK, which combines the likelihood 
and the prior to give the posterior probability distribution which at time n is given 
by p(wn]Zn,n) which is also Gaussian, 
p(walz,a) (2)- P[-} { 1 } 
= exp (w a a,T a-  
- - w  (w  - w) 
In the multimodal case also, the estimation for the individual model parameters 
decouple naturally with the only modification being that the likelihood used for the 
parameter estimation is now based on weighted data and given by, 
p(lw,',z_) = (2)-(0,)- p -0 , y - 
(10) 
242 V. KADIRKAMANATHAN, M. KADIRKAMANATHAN 
4 RECURSIVE MODEL SELECTION 
Bayes law can be invoked to perform recursive or on-line model selection and this 
has been used in the derivation of the multiple model algorithm [1]. The multiple 
model algorithm has been used for the recurslye identification of dynamical nonlin- 
ear systems [7]. Applying Bayes law gives the following relation: 
p(Anlz) = 
(14) 
which can be computed recursively for n - 1,..., N. p(z[Mh, Z_x) is the likeli- 
hood given in (11) and p(A4 h [Zn) is the posterior probability of model A4 n being the 
underlying model for the nth data given the observations Zn. The term p(zn 
is the normalising term given by, 
H 
h--1 
(15) 
The initial prior probabilities for models are assigned to be equal to 1/H. The 
equations (11), (14) combined with the Kalman filter estimation equations is known 
as the multiple model algorithm [1]. 
Amongst all the networks that are attempting to identify the underlying system, 
the identified model is the one with the highest posterior probability p(n[Z,) at 
each time n, ie., 
AA ' -- arg .axp(A/[h [2;,) (16) 
and hence can vary from time to time. This is preferred over the averaging of all the 
H models as the likelihood is multimodal and hence modal estimates are sought. 
Predictions are based on this most probable model. 
Since the system is dynamical, if the underlying model for the dynamics is known, 
it can be used to predict the estimates at the next time instant based on the current 
estimates, prior to observing the next data. Here, a first order Markov assumption 
is made for the mode transitions. Given that at the time instant n- i the given 
mode is j, it is predicted that the probability of the mode at time instant n being 
h is the transition probability Pnj. With H modes, Pnj = 1. The predicted 
probability of the mode being h at time n therefore is given by, 
H 
= Pnyp(.Ay IZ,-x) 
j=l 
(17) 
This can be viewed as the prediction stage of the model selection algorithm. The 
predict
