On the Effect of Analog Noise in 
Discrete-Time Analog Computations 
Wolfgang Maass 
Institute for Theoretical Computer Science 
Technische Universitt Graz* 
Pekka Orponen 
Department of Mathematics 
University of Jyv'kyl/ t 
Abstract 
We introduce a model for noise-robust analog computations with 
disirete time that is flexible enough to cover the most important 
concrete cases, such as computations in noisy analog neural nets 
and networks of noisy spiking neurons. We show that the presence 
of arbitrarily small amounts of analog noise reduces the power of 
analog computational models to that of finite automata, and we 
also prove a new type of upper bound for the VC-dimension of 
computational models with analog noise. 
1 Introduction 
Analog noise is a serious issue in practical analog computation. However there exists 
no formal model for reliable computations by noisy analog systems which allows us 
to address this issue in an adequate manner. The investigation of noise-tolerant 
digital computations in the presence of stochastic failures of gates or wires had been 
initiated by [von Neumann, 1956]. We refer to [Cowan, 1966] and [Pippenger, 1989] 
for a small sample of the mimerous results that have been achieved in this direction. 
In all these articles one considers computations which produce a correct output not 
 (for some parameter p  (0, ]). 
with perfect reliability, but with probability >_  +p  
The same framework (with stochastic failures of gates or wires) has been applied 
to analog neural nets in [Siegelmann, 1994]. 
The abovementioned approaches are insufficient for the investigation of noise in 
analog computations, because in analog computations one has to be concerned not 
only with occasianal total failures of gates or wires, but also with imprecision, i.e. 
with omripresent smaller (and occasionally larger) perturbations of analog outputs 
* Klosterwiesgasse 32/2, A-8010 Graz, Austria. E-mail: maassigi.tu-graz.ac.at. 
 P. O. Box 35, FIN-40351 Jyv'gkyli, Finland. E-mail: orponenmath.jyu.fi. Part of 
this work was done while this author was at the University of Helsinki, and during visits 
to the Technische Universitt Graz and the University of Chile in Santiago. 
On the Effect of Analog Noise in Discrete-Time Analog Computations 219 
of internal computational units. These perturbations may for example be given 
by Gaussian distributions. Therefore we introduce and investigate in this article 
a notion of noise-robust computation by noisy analog systems where we assume 
that the values of intermediate analog values are moved according to some quite 
arbitrary probability distribution. We consider - as in the traditional framework for 
noisy digital computations - arbitrary computations whose output is correct with 
1 (for E (0, 1 ) 
some given probability _>  + p p 3] ï¿½ We will restrict our attention to 
analog computation with digital output. Since we impose no restriction (such as 
continuity) on the type of operations that can be performed by computational units 
in an analog computational system, an output unit of such system can convert an 
analog value into a binary output via thresholding. 
Our model and our Theorem 3.1 are somewhat related to the analysis of probabilistic 
finite automata in [Rabin, 1963]. However there the finiteness of the state space 
simplifies the setup considerably. [Casey, 1996] addresses the special case of analog 
computations on recurrent neural nets (for those types of analog noise that can 
move an internal state at most over a distance e) whose digital output is perfectly 
reliable (i.e. p = 1/2 in the preceding notation). 1 
The restriction to perfect reliability in [Casey, 1996] has immediate consequences 
for the types of analog noise processes that can be considered, and for the types of 
mathematical arguments that are needed for their investigation. In a computational 
model with perfect reliability of the output it cannot happen that an intermediate 
state s occurs at some step t both in a computation for an input _x that leads to 
output 0 , and at step t in a computation for the same input x__ that leads to 
output 1 . Hence an analysis of perfectly reliable computations can focus on par- 
titions of intermediate states s according to the computations and the computation 
steps where they may occur. 
Apparently many important concrete cases of noisy analog computations require a 
different type of analysis. Consider for example the special case of a sigmoidal neural 
net (with thresholding at the output), where for each input the output of an internal 
noisy sigmoidal gate is distributed according to some Gaussian distribution (perhaps 
restricted to the range of all possible output values which this sigmoidal gate can 
actually produce). In this case an intermediate state s of the computational system 
is a vector of values which have been produced by these Gaussian distributions. 
Obviously each such intermediate state s can occur at any fixed step t in any 
computation (in particular in computations with different network output for the 
same network input). Hence perfect reliability of the network output is unattainable 
in this case. For an investigation of the actual computational power of a sigmoidal 
neural net with Gaussian noise one has to drop the requirement of perfect reliability 
of the output, and one has to analyze how probable it is that a particular network 
output is given, and how probable it is that a certain intermediate state is assumed. 
Hence one has to analyze for each network input and each step t the different 
There are relatively few examples for nontrivial computations on common digital or 
analog computational models that can ahieve perfect reliability of the output in spite of 
noisy internal components. Most constructions of noise-robust computational models rely 
on the replication of noisy computational units (see [von Neumann, 1956], [Cowan, 1966]). 
The idea of this method is that the average of the outputs of k identical noisy computational 
units (with stochastically independent noise processes) is with high probability close to the 
expected value of their output, if k is sufficiently large. However for any value of k there 
exists in general a small but nonzero probability that this average deviates strongly from 
its expected value. In addition, if one ssumes that the computational unit that produces 
the output of the computations is also noisy, one cannot expect that the reliability of the 
output of the computation is larger than the reliability of this last computational unit. 
Consequently there exist many methods for reducing the error-probability of the output 
to a small value, but these methods cannot ahieve error probability 0 at the output. 
220 W. Maass and P Orponen 
probability distributions over intermediate states s that are induced by computations 
of the noisy analog computational system. In fact, one may view the set of these 
probability distributions over intermediate states s as a generalized set of states of 
a noisy analog computational system. In general the mathematical structure of this 
generalized set of states is substantially more complex than that of the original 
set of intermediate states s . We have introduced in [Maass, Orponen, 1996] some 
basic methods for analyzing this generalized set of states, and the proofs of the 
main results in this article rely on this analysis. 
The preceding remarks may illustrate that if one drops the assumption of perfect 
reliability of the output, it becomes more difficult to prove upper bounds for the 
power of noisy analog computations. We prove such upper bounds even for the case 
of stochastic dependencies among noises for different internal units, and for the case 
of nonlinear dependencies of the noise on the current internal state. Our results also 
cover noisy computations in hybrid analog/digital computational models, such as for 
example a neural net combined with a binary register, or a network of noisy spiking 
neurons where a neuron may temporarily assume the discrete state not-firing. 
Obviously it becomes quite difficult to analyze the computational effect of such 
complex (but practically occuring) types of noise without a rigorous mathematical 
framework. We introduce in section 2 a mathematical framework that is general 
enough to subsume all these cases. The traditional case of noisy digital computations 
is captured as a special case of our definition. 
One goal of our investigation of the effect of analog noise is to find out which features 
of analog noise have the most detrimental effect on the computational power of an 
analog computational system. This turns out to be a nontrivial question? As a 
first step towards characterizing those aspects and parameters of analog noise that 
have a strong impact on the computational power of a noisy analog system, the 
proof of Theorem 3.1 (see [Maass, Orponen, 1996]) provides an explicit bound on 
the number of states of any finite automaton that can be implemented by an analog 
computational system with a given type of analog noise. It is quite surprising to 
see on which specific parameters of the analog noise the bound depends. Similarly 
the proofs of Theorem 3.4 and Theorem 3.5 provide explicit (although very large) 
upper bounds for the VC-dimension of noisy analog neural nets with batch input, 
which depend on specific parameters of the analog noise. 
2 Preliminaries: Definitions and Examples 
An analog discrete-time computational system (briefly: computational system) M 
is defined in a general way as a 5-tuple (f,pO, F, I, s), where f, the set of states, 
is a bounded subset of R a, pO  f is a distinguished initial state, F _C f is the 
set of accepting states,  is the input domain, and s: f x  -+ f is the transition 
function. To avoid unnecessary pathologies, we impose the conditions that f and 
F are Bore
