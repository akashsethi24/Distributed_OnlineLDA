22 
LEARNING ON A GENERAL NETWORK 
Amir F. Atiya 
Department of Electrical Engineering 
California Institute of Technology 
Ca 91125 
Abstract 
This paper generalizes the backpropagation method to a general network containing feed- 
back connections. The network model considered consists of interconnected groups of neurons, 
where each group could be fully interconnected (it could have feedback connections, with pos- 
sibly asymmetric weights), but no loops between the groups are allowed. A stochastic descent 
algorithm is applied, under a certain inequality constraint on each intra-group weight matrix 
which ensures for the network to possess a unique equilibrium state for every input. 
Introduction 
It has been shown in the last few years that large networks of interconnected neuron-like 
elements re quite suitable for performing a variety of computational and pattern recognition 
tasks. One of the well-known neural network models is the backpropagation model [1]-[4]. It 
is an elegant way for teaching a layered feedforward network by a set of given input/output 
examples. Neural network models having feedback connections, on the other hand, have lso 
been devised (for example the Hopfield network [5]), and are shown to be quite successful in 
performing some computational tasks. It is important, though, to have a method for learning 
by examples for a feedback network, since this is a general way of design, and thus one can 
avoid using an ad hoc design method for each different computational task. The existence 
of feedback is expected to improve the computational abilities of a given network. This is 
because in feedback networks the state iterates until a stable state is reached. Thus processing 
is performed on several steps or recursions. This, in general allows more processing abilities 
than the single step feedforward case (note also the fact that a feedforward network is 
a special case of a feedback network). Therefore, in this work we consider the problem of 
developing a general learning algorithm for feedback networks. 
In developing a learning algorithm for feedback networks, one has to pay attention to the 
following (see Fig. I for an example of a configuration of a feedback network). The state of 
the network evolves in time until it goes to equilibrium, or possibly other types of behavior 
such as periodic or chaotic motion could occur. However, we are interested in having a steady 
and and fixed output for every input applied to the network. Therefore, we have the following 
two important requirements for the network. Beginning in any initial condition, the state 
should ultimately go to equilibrium. The other requirement is that we have to have a unique 
American Institute of Physics 1988 
23 
equilibrium state. It is in fact that equilibrium state that determines the final output. The 
objective of the learning algorithm is to adjust the parameters (weights) of the network in small 
steps, so as to move the unique equilibrium state in a way that will result finally in an output 
as close as possible to the required one (for each given input). The existence of more than one 
equilibrium state for a given input causes the following problems. In some iterations one might 
be updating the weights so as to move one of the equilibrium states in a sought direction, while 
in other iterations (especially with different input examples) a different equilibrium state is 
moved. Another important point is that when implementing the network (after the completion 
of learning), for a fixed input there can be more than one possible output. Independently, other 
work appeared recently on training a feedback network [6],[7],[8]. Learning algorithms were 
developed, but solving the problem of ensuring a unique equilibrium was not considered, This 
problem is addressed in this paper and an appropriate network and a learning algorithm are 
proposed. 
outputs 
Fig. 1 
A recurrent network 
The Feedback Network 
Consider a group of n neurons which could be fully inter-connected (see Fig. ! for an 
example). The weight matrix W can be asymmetric (as opposed to the Hopfield network). 
The inputs are also weighted before entering into the network (let V be the weight matrix). 
Let x and y be the input and output vectors respectively. In our model y is governed by the 
following set of differential equations, proposed by Hopfield [5]: 
du 
 d--[ = Wf(u) - u + Vx, y = f(u) (1) 
24 
where f(u) = (f(ux),...,f(ur)) T, W denotes the transpose operator, f is a bounded and 
differentiable function, and r is a positive constant. 
For a given input, we would like the network after a short transient period to give a steady 
and fixed output, no matter what the initial network state was. This means that beginning 
any initial condition, the state is to be attracted towards a unique equilibrium. This leads to 
looking for a condition on the matrix W. 
Theorem: A network (not necessarily symmetric) satisfying 
2 1/max(?)2, 
i j 
exhibits no other behavior except going to a unique equilibrium for a given input. 
Proof: Let u(t) and u2(t) be two solutions of (1). Let 
J(t) = Ilu(t) - u2(t)ll 2 
where [I II is the [wo-norm. Differentiating J with respect to time, one obtains 
dJ(t) _ 2(u(t)-u2(t))r(du(t) du2(t)  
dt dt  1' 
Using (1) , the expression becomes 
dJ(t) 2 2 
dt - r []ul(t) -u2(t))[12 + ;(u(t) -u2(t))W[f(u(t)) - f(u2(t))]. 
Using Schwarz's Inequality, we obtain 
2 
dJ(t) < _211u(t ) _ u(t)ll  + _11u (t)_ u(t)11. iiW[f(u (t)) _ f(u2(t))] ii. 
dt - r r 
Again, by Schwarz's Inequality, 
w/ [f(u (t)) - f(u(t))] <_ Ilwgll - Ilf(u(t)) - f(u2(t))11 , i = 1,...,n 
where wi denotes the i th row of W. Using the mean value theorem, we get 
[If(u (t)) - f(u2(t)) II < (maxlf'l)llu (t) - u2(t)l I. (3) 
Using (2),(3), and the expression for J(t), we get 
dJ(t) <-aJ(t) (4) 
dt - 
where 
2 2 (maxl f,i)/- jwj.. 
T T i 
(2) 
25 
By hypothesis of the Theorem, a is strictly positive. Multiplying both sides of (4) by exp(at), 
the inequality 
d 0 
- 
results, from which we obtain 
J(t) _< J(0)e 
From that and from the fact that J is non-negative, it follows that J(t) goes to zero as t 
Therefore, any two solutions corresponding to any two initial conditions ultimately approach 
each other. To show that this asymptotic solution is in fact an equilibrium, one simply takes 
u2(t): u(t + T), where T is a constant, and applies the above argument (that J(t) - 0 as 
t --* c), and hence u (t + T) -- u (t) as t --* cw for any T, and this completes the proof. 
For example, if the function f is of the following widely used sigmoid-shaped form, 
1 
f (u) - 1 + e- 
then the sum of the square of the weights should be less than 16. Note that for any function 
f, scaling does not have an effect on the overall results. We have to work in our updating 
scheme subject to the constraint given in the Theorem. In many cases where a large network 
is necessary, this constraint might be too restrictive. Therefore we propose a general network, 
which is explained in the next Section. 
The General Network 
We propose the following network (for an example refer to Fig. 2). The neurons are 
partitioned into several groups. Within each group there are no restrictions on the connections 
and therefore the group could be fully interconnected (i.e. it could have feedback connections). 
The groups are connected to each other, but in a way that there are no loops. The inputs to 
the whole network can be connected to the inputs of any of the groups (each input can have 
several connections to several groups). The outputs of the whole network are taken to be the 
outputs (or part of the outputs) of a certain group, say group f. The constraint given in the 
Theorem is applied on each intra-group weight matrix separately. Let (qa, s,), a = 1, ..., N be 
the input/output vector pairs of the function to be implemented. We would like to minimize 
the sum of the square error, given by 
N 
a----1 
where 
M 
---- --$i) , 
i----1 
and �f is the output vector of group f upon giving input q, and M is the dimension of vector 
s a. The learning process is performed by feeding the input examples q sequentially to the 
network, each time updatg the weights in an attempt to minimize the eor. 
26 
inputa outputs 
Fig. 2 
An example of a general network 
(each group represents a recurrent network) 
Now, consider a single group l. Let W t be the intra-group weight matrix of group l, V 'q 
be the matrix of weights between the outputs of group r and the inputs of group l, and yt be 
I rl 
the output vector of group l. Let the respective elements be wo. , vO. , and Yi- Furthermore, 
let nt be the number of neurons of group l. Assume that the time constant  is sufficiently 
small so s to allow the network to settle quickly to the equilibrium state, which is given by 
the solution of the equation 
yt= f(Wtyt + E VtYr)' (5) 
rAl 
where At is the set of the indices of the groups whose outputs are connected to the inputs of 
group l. We would like each iteration to update the weight matrices W t and V rt so as to move 
the equilibrium in a direction to decrease the error. We need therefore to know the change in 
the error produced by a small change in the weight matrices. Let Oe 
3-Wr, and o�v-r, denote the 
Oe Oe Oea, 
matrices whose (i,j) th element are -,, and respectively. Let 3-fy be the column vector 
whose i th element is . We obtain the following relations: 
aea 
av,,t 
-1 3�a t T 
 = [,_ (w') T] y,(y ) , 
-1 aCa r T 
- ['- (w')q y,(y ) , 
wheee A t is the diagonal matrix whose ita diagonal element is 1/f'( k t t ,q ,- 
for a derivation refer to Appends). The vector  sociaed with group I can be obtaed 
in erms of the vectors  jeBt where Bt is the se of he indices of the groups whose puts 
e connected to the outputs of group l..We get (refer to Appends} 
 = (v')[a -(wq] - 
., aye' () 
The matrix A t - (Wt? ' for an
