The 
Statistical Mechanics of 
k-Satisfaction 
Scott Kirkpatrick* 
Racah Institute for Physics and 
Center for Neural Computation 
Hebrew University 
Jerusalem, 91904 Israel 
kirk@fiz.huji.ac.il 
G6za GySrgyl 
Institute for Theoretical Physics 
EStvSs University 
1-1088 Puskin u. 5-7 
Budapest, Hungary 
gyorgyi@ludens.elte.hu, 
Naftali Tishby and Lidror Troyansky 
Institute of Computer Science and Center for Neural Computation 
The Hebrew University of Jerusalem 
91904 Jerusalem, Israel 
{fishby, lidrort) @cs.huji.ac.il 
Abstract 
The satisfiability of random CNF formulae with precisely k vari- 
ables per clause (k-SAT) is a popular testbed for the performance 
of search algorithms. Formulae have M clauses from N variables, 
randomly negated, keeping the ratio a - M/N fixed. For k - 2, 
this model has been proven to have a sharp threshold at a - 1 
between formulae which are almost aways satisfiable and formulae 
which are almost never satisfiable as N -- oc. Computer experi- 
ments for k - 2, 3, 4, 5 and 6, (carried out in collaboration with 
B. Selman of ATT Bell Labs.). show similar threshold behavior for 
each value of k. Finite-size scaling, a theory of the critical point 
phenomena used in statistical physics, is shown to characterize the 
size dependence near the threshold. Annealed and replica-based 
mean field theories give a good account of the results. 
*Permanent address: IBM TJ Watson Research Center, Yorktown Heights, NY 10598 
USA. (kirk@watson.ibm.com) Portions of this work were done while visiting the Salk 
Institute, with support from the McDonnell-Pew Foundation. 
439 
440 Kirkpatrick, GyOrgyi, Tishby, and Troyansky 
1 Large-scale computation without a length scale 
It is increasingly possible to model the natural world on a computer. Condensed 
matter physics has strategies to manage the complexities of such calculations, usu- 
ally depending on a characteristic length. For example, molecules or atoms with 
finite ranged in[eracfions can be broken down into weakly interac[ing smaller parts. 
We may also use symmetry to identify natural modes of the system as a whole. 
Even in the most difficult case, continuous phase transitions correlated over a wide 
range of scales, the renormalization group provides a way of collapsing the problem 
down to its relevant parts by providing a generator of behavior on all scales in 
terms of the critical point itself. 
But length scales are not much help in organizing another sort of large calculation. 
Examples include large rule-based expert systems that model the particulars of 
complex industrial processes. Digital Equipment, for example, has used a network 
of three or more expert systems (originally called R1/XCON) to check computer 
orders for completeness and internal consistency, to schedule production and ship- 
ping, and to aid a salesman to anticipate customers' needs. This very detailed set 
of tasks in 1979 required 2 programmers and 250 rules to deal with 100 parts. In 
the ten years described by Barker (1989), it grew 100X, employing 60 programmers 
and nearly 20,000 rules to deal with 30,000 part numbers. 100X in ten years is only 
moderate growth, and it would be valuable to understand how technical, social, and 
business factors have constrained it. 
Many important commercial and scientific problems without length scales are ready 
for attack by computer modelling or automatic classification, and lie within a few 
decades of XCON's size. Retail industries routinely track 105 - 106 distinct items 
kept in stock. Banks, credit card companies, and specialized information providers 
are building models of what 108 Americans have bought and might want to buy 
next. In biology, human metabolism is currently described in terms of > 1000 
substances coupled through > 10,000 reactions, and the data is doubling yearly. 
Similarly, amino acid sequences are known for > 60,000 proteins. 
A deeper understanding of the computational cost of these problems of order 106ï¿½2 
is needed to see which are practical and how they can be simplified. We study 
an idealization of XCON-style resolution search, and find obvious collective effects 
which may be at the heart of its computational complexity. 
2 Threshold Phenomena and Random k-SAT 
Properties of randomly generated combinatorial structures often exhibit sharp 
threshold phenomena analogous to the phase transitions studied in condensed mat- 
ter physics. Recently, thresholds have been observed in randomly generated Boolean 
formulae. Mitchell et al. (1992) consider the k-satisfiability problem (k-SAT). An 
instance of k-SAT is a Boolean formula in conjunctive normal form (CNF), i.e., 
a conjunction (logical AND) of disjunctions or clauses (logical ORs), where each 
disjunction contains exactly k literals. A literal is a Boolean variable or, with equal 
probability, its negation. The task is to determine whether there is an assignment 
to the variables such that all clauses evaluate to true. Here, we will use N to denote 
the number of variables and M for the number of clauses in a formula. 
The Statistical Mechanics of k-Satisfaction 441 
For randomly generated 2-SAT instances, it has been shown analytically that for 
large N, when the ratio rt = M/N is less than 1 the instances are almost all 
satisfiable, whereas for ratios larger than 1, almost all instances are unsatisfiable 
(Chvtal and Reed 1992; Goerdt 1992). For k _> 3, a rigorous analysis has proven 
to be elusive. Experimental evidence, however, strongly suggests a threshold with 
a m 4.3 for 3SAT (Mitchell et al. 1992; Crawford and Auton 1993; Larrabee 1993). 
One of the main reasons for studying randomly generated 3CNF formulae is for their 
use in the empirical evaluation of combinatorial search algorithms. 3CNF formulae 
are good candidates for the evaluation of such algorithms because determining their 
satisfiability is an NP-complete problem. This also holds for larger values of k. For 
k = 1 or 2, the satisfiability problem can be solved efficiently (Aspvall et al. 1979). 
Despite the worst-case complexity, simple heuristic methods can usually determine 
the satisfiability of random formulae. However, computationally challenging test 
instances are found by generating formulae at or near the threshold (Mitchell et al. 
1992). Cheeseman (1991) has made a similar observation of increased computational 
cost for heuristic search at a boundary between two distinct phases or behaviors of 
a combinatorial model. 
We will provide a precise characterization of the N-dependence of the threshold 
phenomena for k-SAT with k ranging from 2 to 6. We will employ finite size scaling, 
a method from statistical physics in which direct observation of the width of the 
threshold, or critical region of a transition is used to characterize the universal 
behavior of quantities across the entire critical region, extending the analysis to 
combinatorial problems in which N characterizes the size of the model observed. 
For discussion of the applicability of finite-size scaling to systems without a metric, 
see Kirkpatrick and Selman (1993). 
Thresholds for 2SAT, 3SAT. 4SAT, 5SAT, and 6SAT 
o. 6 ..' 
0.4 i / 
0.2 
o ' ' ';! ; 
o J'-' ..'?;' ,,1, ..:... , 
10 20 30 
M/N 
6O 
Fig. 1: Fraction of unsatisfiable formulae for 2-, 3- 4-, 5- and 6-SAT. 
442 Kirkpatrick, Gy6rgyi, Tishby, and Troyansky 
3 Experimental data 
We have generated extensive data on the satisfiability of randomly generated k- 
CNF formulae with k ranging from 2 to 6. Fig. I shows the fraction of random 
k-SAT formulae that is unsatisfiable as a function of the ratio, (. For example, 
the left-most curve in Fig. I shows the fraction of formulae that is unsatisfiable for 
random 2CNF formulae with 50 variables over a range of values of (. 
Each data point was generated using 10000 randomly generated formulae, giving 
1% accuracy. We used a highly optimized implementation of the Davis-Putnam 
procedure (Crawford and Auton 1993). The procedure works best on formulae with 
smaller k. Data was obtained for k = 2 on samples with N _ 500, for k: 3 with 
N _ 100, and for k: 5 with N _ 40, all at comparable computing cost. 
Fig. 1 (for N ranging from 10 to 50) shows a threshold for each value of k. Except 
for the case k = 2, the curves cross at a single point and sharpen up with increasing 
N. For k = 2, the intersections between the curves for the largest values of N seem 
to be converging to a single point as well, although the curves for smaller N deviate. 
The point where 50% of the formulae are unsatisfiable is thought to be where the 
computationally hardest problems are found (Mitchell e! al. 1992; Cheeseman e! al. 
1991). The 50% point lies consistently to the right of the scale-invariant point (the 
point where the curves cross each other), and shifts with N. 
There is a simple explanation for the rapid shift of the thresholds to the right 
with increasing k. The probability that a given clause is satisfied by a random 
input configuration is (2 } - 1)/2 } - (1 -2 -}) _ 7}. If we treat the clauses as 
independent, the probability that all clauses are satisfied is 7 M = 7 v. We define 
the entropy, $, per input as 1/N times the log2 of the expected number of satisfying 
configurations, 2N3/ ' . S -- 1 + alog2(7}) --- 1 - Ot/Otann, and the vanishing of the 
entropy gives an estimate of the threshold, identical to the upper bound derived 
by several workers (see Franco (1983) and citations in Chvhtal (1992))' aa,m = 
-(log2(1 - 2-})) -  (/n2)2 }. This is called an annealed estimate for ac, because 
it ignores the interactions between clauses, just as annealed theories of materials 
(see Mdzard 1986) average over many details of the disorder. We have marked aa,,,, 
with an arrow for each k in the figures, and tabulate it in Table 1. 
4 Results of Finite-Size Scaling Analysis 
From Fig. 1, it is clear that the threshold sharpens up for larger values of N. 
Both t
