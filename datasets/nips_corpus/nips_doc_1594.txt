A Neurodynamical Approach to Visual Attention 
Gustavo Deco 
Siemens AG 
Corporate Technology 
Neural Computation, ZT IK 4 
Otto-Hahn-Ring 6 
81739 Munich, Germany 
Gustavo. Decomchp.siemens.de 
Josef Zihl 
Institute of Psychology 
Neuropsychology 
Ludwig-Maximilians-University Munich 
Leopoldstr. 13 
80802 Munich, Germany 
Abstract 
The psychophysical evidence for selective attention originates mainly 
from visual search experiments. In this work, we formulate a hierarchi- 
cal system of interconnected modules consisting in populations of neu- 
rons for modeling the underlying mechanisms involved in selective 
visual attention. We demonstrate that our neural system for visual 
search works across the visual field in parallel but due to the different 
intrinsic dynamics can show the two experimentally observed modes of 
visual attention, namely: the serial and the parallel search mode. In 
other words, neither explicit model of a focus of attention nor saliencies 
maps are used. The focus of attention appears as an emergent property 
of the dynamic behavior of the system. The neural population dynamics 
are handled in the framework of the mean-field approximation. Conse- 
quently, the whole process can be expressed as a system of coupled dif- 
ferential equations. 
1 Introduction 
Traditional theories of human vision considers two functionally distinct stages of visual 
processing [1]. The first stage, termed the preattentive stage, implies an unlimited- 
capacity system capable of processing the information contained in the entire visual field 
in parallel. The second stage is termed the attentive or focal stage, and is characterized by 
the serial processing of visual information corresponding to local spatial regions. This 
stage of processing is typically associated with a limited-capacity system which allocates 
its resources to a single particular location in visual space. The designed psychophysical 
experiments for testing this hypothesis consist of visual search tasks. In a visual search 
test the subject have to look at the display containing a frame filled with randomly 
positioned items in order to seek for an a priori defined target item. All other items in a 
frame which are not the target are called distractors. The number of items in a frame is 
called the frame size. The relevant variable to be measured is the reaction time as a 
function of the frame size. In this context, the Feature Integration Theory, assumes that the 
two stage processes operate sequentially [1]. The first early preattentive stage runs in 
parallel over the complete visual field extracting single primitive features without 
A Neurodynamical Approach to sual Attention II 
integrating them. The second attentive stage has been likened to a spotlight. This metaphor 
alludes that attention is focally allocated to a local region of the visual field where stimuli 
are processed in more detail and passed to higher level of processing, while, in the other 
regions not illuminated by the attentional spotlight, no further processing occurs. 
Computational models formulated in the framework of feature integration theory require 
the existence of a saliency or priority map for registering the potentially interesting areas 
of the retinal input, and a gating mechanism for reducing the amount of incoming visual 
information, so that limited computational resources in the system are not overloaded. The 
priority map serves to represent topographically the relevance of different parts of the 
visual field, in order to have a mechanism for guiding the attentional focus on salient 
regions of the retinal input. The focused area will be gated, such that only the information 
within will be passed further to yet higher levels, concerned with object recognition and 
action. The disparity between these two stages of attentional visual processing originated 
a vivid experimental disputation. Duncan and Humphreys [2] have postulated a hypothesis 
that integrates both attentional modes (parallel and serial) as an instantiates of a common 
principle. This principle sustains in both schemes that a selection is made. In the serial 
focal scheme, the selection acts on in the space dimension, while in the parallel spread 
scheme the selection concentrates in feature dimensions, e.g. color. On the other hand, 
Duncan's attentional theory [3] proposed that after a first parallel search a competition is 
initiated, which ends up by accepting only one object namely the target. Recently, several 
electrophysiological experiments have been performed which seems to support this 
hypothesis [4]. Chelazzi et al. [4] measured IT (inferotemporal) neurons in monkeys 
observing a display containing a target object (that the monkey has seen previously) and a 
distractor. They report a short period during which the neuron's response is enhanced. 
After this period the activity level of the neuron remains high if the target is the neuron's 
effective stimulus, and decay otherwise. The challenging question is therefore: is really 
the linear increasing reaction time observed in some visual search tests due to a serial 
mechanism? or is there only parallel processing followed by a dynamical time consuming 
latency? In other words, are really priority maps and spotlight paradigm required? or can a 
neurodynamical approach explain the observed psychophysical experiments?. 
Furthermore, it should be clarified if the feature dimension search is achieved 
independently in each feature dimension or is done after integrating the involved feature 
dimensions. We study in this paper these questions from a computational perspective. We 
formulate a neurodynamical model consisting in interconnected populations of biological 
neurons specially designed for visual search tasks. We demonstrate that it is plausible to 
build a neural system for visual search, which works across the visual field in parallel but 
due to the different intrinsic dynamics can show the two experimentally observed modes 
of visual attention, namely: the serial focal and the parallel spread over the space mode. In 
other words, neither explicit serial focal search nor saliency maps should be assumed. The 
focus of attention is not .included in the system but just results after convergence of the 
dynamical behavior of the neural networks. The dynamics of the system can be interpreted 
as an intrinsic dynamical routing for binding features if top-down information is available. 
Our neurodynamical computational model requires independent competition mechanism 
along each feature dimension for explaining the experimental data, implying the necessity 
of the independent character of the search in separated and not integrated feature 
dimensions. The neural population dynamics are handled in the framework of the mean- 
field approximation yielding a system of coupled differential equations. 
2 Neurodynamical model 
We extend with the present model the approach of Usher and Niebur [5], which is based 
on the experimental data of Chelazzi et al. [4], for explaining the results of visual search 
experiments. The hierarchical architecture of our system is shown in Figure 1. The input 
retina is given as a matrix of visual items. The location of each item at the retina is 
12 G. Deco and J. Zihl 
specified by two indices ij meaning the position at the row i and the column j. The 
dimension of this matrix is SxS, i.e. the frame size is also SxS. The information is 
processed at each spatial location in parallel. Different feature maps extract for the item at 
each position the local values of the features. In the present work we hypothesize that 
selective attention is guided by an independent mechanism which corresponds to the 
independent search of each feature. Let us assume that each visual item can be defined by 
K features. Each feature k can adopt L(k) values, for example the feature color can have 
the values red or green (in this case L(color)--2). For each feature map k exist L(k) 
layers of neurons for characterizing the presence of each feature value. 
st r 
Spiking -- 
Neuron 
Figure 1: Hierarchical architecture of spiking neural modules for visual selective 
attention. Solid arrows denote excitatory connections and dotted arrows denote 
inhibitory connections 
A cell assembly consisting in a population of full connected excitatory integrate-and-fire 
spiking neurons (pyramidal cells) is allocated in each layer and for each item location for 
encoding the presence of a specific feature value (e.g. color red) at the corresponding 
position. This corresponds to a sparse distributed representation. The feature maps are 
topographically ordered, i.e. the receptive fields of the neurons belonging to the cell 
assembly ij at one of these maps are sensible to the location ij at the retinal input. We 
further assume that the cell assemblies in layers corresponding to a feature dimension are 
mutually inhibitory. Inhibition is modeled, according to the constraint imposed by Dale's 
principle, by a different pool of inhibitory neurons. Each feature dimension has therefore 
an independent pool of inhibitory neurons. This accounts for the neurophysiological fact 
that the response of V4 neurons sensible to a specific feature value is enhanced and the 
activity of the other neurons sensible to other feature values are suppressed. A high level 
map consisting also in a topographically ordered excitatory cell assemblies is introduced 
for integration of the different feature dimension at each item location, i.e. for binding the 
features of each item. These cell assemblies are also mutually inhibited through a common 
A Neurodynamical Approach to Visual Attention 13 
pool of inhibitory neurons. This layer corresponds to the modeling of IT neurons, which 
show location specific enhancement of activity by suppression of the responses of the cell 
assemblies associated to other locations. This fact would yield a dynam
