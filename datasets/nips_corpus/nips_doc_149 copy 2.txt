459 
A BIFURCATION THEORY APPROACH TO THE 
PROGRAMMING OF PERIODIC ATTRACTORS IN 
NETWORK MODELS OF OLFACTORY CORTEX 
Bill Baird 
Department of Biophysics 
U.C. Berkeley 
ABSTRACT 
A new learning algorithm for the storage of static 
and periodic attractors in biologically inspired 
recurrent analog neural networks is introduced. 
For a network of n nodes, n stati, c or n/2 periodic 
attractors may be stored. The aigorithm ailows 
programming of the network vector fieid indepen- 
dent of the patterns to be stored. Stability of 
patterns, basin geometry, and rates of convergence 
may be controlled. For orthonormal patterns, the 
legming operation reduces to a kind of periodic 
outer product ruie that allows iocal, additive, 
commutative, incremental learning. Standing or 
traveiing wave cycles may be stored to mimic the 
kind of osciilating spatial patterns that appear 
in the neural activity of the olfactory bulb and 
prepyriform cortex during inspiration and suffice, 
in the buib, to predict the pattern recognition 
behavior of rabbits in ciassical conditioning ex- 
periments. These attractors arise, during simuIat- 
ed inspiration, through a muItipIe Hopf bifurca- 
tion, which can act as a criticaI decision point 
for their selection by a very smaIi input pattern. 
INTRODUCTION 
This approach allows the construction of biological models and 
the expioration of engineering or cognitive networks that 
empioy the type of dynamics found in the brain. Patterns of 40 
to 80 hz osciiiation have been observed in the iarge scaie ac- 
tivity of the oifactory bulb and cortex(Freeman and Baird 86) 
and even visuai neocortex(Freeman 87,Grey and Singer 88), and 
found to predict the oifactory and visual pattern recognition 
responses of a trained animai. Here we use anaiytic methods of 
bifurcation theory to design aigorithms for determining synap- 
tic weights in recurrent network architectures, iike those 
460 Baird 
found in olfactory cortex, for associative memory storage of 
these kinds of dynamic patterns. 
The projection algorithm n introduced here employs higher 
order correlations, and is the most analytically transparent 
of the algorithms to come from the bifurcation theory ap- 
proach(Baird 88). Alternative numerical algorithms employing 
unused capacity or hidden units instead of higher order corr- 
elations are discussed in (Baird 89). All of these methods 
provide solutions to the problem of storing exact analog at- 
tractors, static or dynamic, in recurrent neural networks, and 
allow programming of the ambient vector field independent of 
the patterns to be stored. The stability of cycles or equi- 
libria, geometry of basins of attraction, rates of convergence 
to attractors, and the location in parameter space of primary 
and secondary bifurcations can be programmed in a prototype 
vector field - the normal form. 
To store cycles by the projection algorithm, we start with the 
amplitude equations of a polar coordinate normal form, with 
coupling coefficients chosen to give stable fixed points on 
the axes, and transform to Cartesian coordinates. The axes of 
this system of nonlinear ordinary differential equations are 
then linearly transformed into desired spatial or spario-tem- 
poral patterns by projecting the system into network coordina- 
tes - the standard basis - using the desired vectors as colum- 
ns of the transformation matrix. This method of network syn- 
thesis is roughly the inverse of the usual procedure in bifur- 
cation theory for analysis of a given physical system. 
Proper choice of normal form couplings will ensure that the 
axis attractors are the only attractors in the system - there 
are no nspurious attractors . If symmetric normal form coef- 
ficients are chosen, then the normal form becomes a gradient 
vector field. It is exactly the gradient of an explicit poten- 
tial function which is therefore a strict Liapunov function 
for the system. Identical normal form coefficients make the 
normal form vector field equivariant under permutation of the 
axes, which forces identical scale and rotation invariant 
basins of attraction bounded by hyperplanes. Very complex 
periodic attractors may be established by a kind of Fourier 
synthesis as linear combinations of the simple cycles chosen 
for a subset of the axes, when those are programmed to be 
unstable, and a single 'mixed mode in the interior of that 
subspace is made stable. Proofs and details on vectorfield 
programming appear in (Baird 89). 
In the general case, the network resulting from the projection 
A Bifurcation Theory Approach to Programming 461 
algorithm has fourth order correlations, but the use of restr- 
ictions on the detail of vector field programming and the 
types of patterns to be stored result in network architectures 
requiring only second order correlations. For biological mod- 
eling, where possibly the patterns to be stored ore sparse and 
nearly orthogonal, the learning rule for periodic patterns 
becomes o periodic outer product rule which is local, add- 
itive, commutative, and incremental. It reduces to the usual 
Hebb-like rule for static attractors. 
CYCLES 
The observed physiological activity may be idealized mathe- 
maticalIy as a ycie, r xj e i(oj +wt) , j=l,2,...,n. Such o 
cycie is o periodic attractor if zt is stobie. The gioboi 
ompiitude r is just o scoiing factor for the pattern x , and 
the giobol phase w in e iwt is o periodic scaling that scales x 
by o factor between + I at frequency w os t varies. 
The same vector s or pattern of relative amplitudes can 
appear in space os o standing wave, like that seen in the 
bulb, if the relative phase 0st of each compartment (component) 
is the same, 0si+ 1 = s i, or os o traveling wave, like that seen 
in the prepyriform cortex, if the relative phase components of 
9 s form o gradient in space, si+ 1 = 1/a s i. The troveIing wave 
will sweep out the amplitude pattern s in time, but the 
root-mean-square amplitude measured in on experiment will be 
x s regardless of the phase pattern For on arbitrary 
the same _ , . 
phase vector these simple single frequency cycles con make 
very complicated looking spario-temporal patterns. From the 
mathematical point of view, the relative phase pattern 9 is o 
degree of freedom in the kind patterns that con be stored. 
Patterns of uniform amplitude  which differed only in the 
phase locking pattern 9 could be stored os well. 
To store the kind of patterns seen in bulb, the ompIitude 
vector  is assumed to be parsed into equai numbers of excita- 
tory and inhibitory components, where each ciass of component 
has identical phase, but there is o phase difference of 80 - 
g0 degrees between the ciosses. The traveling wove in the 
prepyriform cortex is modeied by introducing on odditionoi 
phase godient into both excitotory and inhibitory ciosses. 
PROJECTION ALGORITHM 
The central result of this paper is most compactly stated as 
the following: 
462 Baird 
THEOREM 
Any set S, s = 1,2, ...,n/2 , of cycles r s xjS ei(ejs+ t) of 
linearly independent vectors of relative component amplitudes 
s ( R n and phases 9 s ( S n, with frequencies w s ( R and global 
amplitudes r s  R, may be established in the vector field of 
the analo fourth order network: 
x i : -  x i + Ej Tij xj + Ejk i Tijki xj x k x i + b i (t) 
by some variant of the projection operation : 
= p-1 
Tij Emn Pim ]rnn nj ' 
= p-1 p-1 
Tijkl Emn Pim Amn mj P-lnk nl ' 
where the n x n matrix P contains the real and imaginary com- 
ponents [s cos s , s sin s] of the complex eigenvectors 
x s e ies as columns, J is an n x n matrix of complex conjugate 
eigenvalues in diagonal blocks, Amn is an n x n matrix of 2x2 
blocks of repeated coefficients of the normal form equations, 
and the input b i (t) is a delta function in time that establ- 
ishes an initial condition. The vector field of the dynamics 
of the global amplitudes r s and phases s is then given exactly 
by the normal form equations : 
2 
r s = u s r s - r s Ej asj rj 
s ' ws + Ej bsj rj 2 
In particular, for ask > 0 , and ass/aks < I , for all s and k, 
the cycles s = 1,2,...,n/2 ore stable, and have amplitudes 
r s = (us/ass) 1/2, where u s = I -  
Note that there is o multiple Hopf bifurcation of codimension 
n/2 at  = 1. Since there ore no approximations here, however, 
the theorem is not restricted to the neighborhood of this 
bifurcotion, and can be discussed without further reference to 
bifurcotion theoryï¿½ The normal form equations for drS/dt and 
dS/dt determine how r s and s for pattern s evolve in time in 
interaction with all the other patterns of the set S. This 
could be thought of os the process of phase locking of the 
pattern that finally emergesï¿½ The unusual power of this al- 
gorithm lies in the ability to precisely specify these non- 
linear interactions. In general, determination of the modes of 
the linearized system alone (Li and Hopfield 89) is insuf- 
ficient to say what the attractors of the nonlinear system 
will be. 
A Bifurcation Theory Approach to Programming 463 
PROOF 
The proof of the theorem is instructive since it is a constru- 
ctive proof, and we con use it to explain the learning algori- 
thm. We proceed by showing first that there ore always fixed 
points on the axes of these amplitude equations, whose stabil- 
ity is given by the coefficients of the nonlinear terms. /hen 
the network above is constructed from these equations by two 
coordinate transformations. /he first is from polar to Car- 
tesian coordinates, and the second is o linear transformation 
from these canonical mode coordinates into the standard 
basis e 1, e 2, ..., e N, or network coordinates. /his second 
transformation constitutes the learning algorithm, because 
it trofdrms the simple fixed points of the amplitude equa- 
tions into the specific spario-temporal memory patterns desi- 
red for the network. 
Amplitude Fixed Points 
Because the ampli
