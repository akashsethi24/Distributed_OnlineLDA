On the Computational Power of Noisy 
Spiking Neurons 
Wolfgang Maass 
Institute for Theoretical Computer Science, Technische Universitaet Graz 
Klosterwiesgasse 32/2, A-S010 Graz, Austria, e-maih maass@igi.tu-graz.ac.at 
Abstract 
It has remained unknown whether one can in principle carry out 
reliable digital computations with networks of biologically realistic 
models for neurons. This article presents rigorous constructions 
for simulating in real-time arbitrary given boolean circuits and fi- 
nite automata with arbitrarily high reliability by networks of noisy 
spiking neurons. 
In addition we show that with the help of shunting inhibition 
even networks of very unreliable spiking neurons can simulate in 
real-time any McCulloch-Pitts neuron (or threshold gate), and 
therefore any multilayer perceptron (or threshold circuit) in a 
reliable manner. These constructions provide a possible explana- 
tion for the fact that biological neural systems can carry out quite 
complex computations witlfin 100 msec. 
It turns out that the assumption that these constructions require 
about the shape of the EPSP's and the behaviour of the noise are 
surprisingly weak. 
I Introduction 
We consider networks that consist of a finite set V of neurons, a set E C V x V of 
synapses, a weight Wu,v _> 0 and a response function eu,v : R + - R for each synapse 
212 W. MAASS 
(u, v  E (where R + := (x  R' x _ 0)), and a threshold function Ov � R + - R + 
for each neuron v  V. 
If Fu _ R + is the set of firing times of a neuron u, then the potential at the trigger 
zone of neuron v at time t is given by Pv(t) :=   wu,v' 
u'(u,v)E sFu:s<t 
eu,v(t- s). The threshold function �v(t -t ) quantifies the reluctance of v to 
fire again at time t, if its last previous firing was at time t . We assume that 
Or(0)  (0, c), �,(x) = c for x  (0,�ef] (for some constant ',ef  0, the 
absolute refractory period), and sup(�v(x) ' x _ -) ( c for any -  'rei. 
In a deterministic model for a spiking neuron (Maass, 1995a, 1996) one can assume 
that a neuron v fires exactly at those time points t when Pv (t) reaches (from below) 
the value �v(t - t). We consider in this article a biologically more realistic model, 
where as in (Gerstner, van Hemmen, 1994) the size of the difference Pv(t)-�v(t-t ) 
just governs the probability that neuron v fires. The choice of the exact firing times 
is left up to some unknown stochastic processes, and it may for example occur that 
v does not fire in a time interval I during which Pv(t)-�v(t-t )  0, or that v fires 
spontaneously at a time t when P(t)-�v(t-t )  O. We assume that (apart from 
their communication via potential changes) the stochastic processes for different 
neurons v are independent. It turns out that the assumptions that one has to make 
about this stochastic firing mechanism in order to prove our results are surprisingly 
weak. We assume that there exist two arbitrary functions L,/ � R x R + - [0, 1] so 
that L(A, ) provides a lower bound (and U(A, ) provides an upper bound) for the 
probability that neuron v fires during a time interval I of length  with the property 
that Pv(t)-�v(t-t') _ A (respectively Pv(t)-�v(t-t') _ A) for all t  I up to the 
next firing of v (t  denotes the last firing time of v before I). We just assume about 
these functions L and U that they are non-decreasing in each of their two arguments 
(for any fixed value of the other argument), that lira /(A, �) = 0 for any fixed 
  0, and that lira L(A,f)  0 for any fixed f_ R/6 (where Ris the assumed 
length of the rising segment of an EPSP, see below). The neurons are allowed to 
be arbitrarily noisy in the sense that the difference lim L(A,)- lira /(A,) 
can be arbitrarily small. Hence our constructions also apply to neurons that exhibit 
persistent firing failures, and they also allow for synapses that fail with a rather high 
probability. Furthermore a detailed analysis of our constructions shows that we can 
relax the somewhat dubious assumption that the noise-distributions for different 
neurons are independent. Thus we are also able to deal with systematic noise in 
the distribution of firing times of neurons in a pool (e.g. caused by changes in the 
biochemical environment that simultaneously affect many neurons in a pool). 
It turns out that it suces to assume only the following rather weak properties of 
the other functions involved in our modeh 
1) Each response fimction eu,t, ' R + - R is either excitatory or inhibitory 
(and for the sake of biological realism one may assume that each neuron u induces 
only one type of response). All excitatory response functions eu,, (x) have the value 
On the Computational Power of Noisy Spiking Neurons 213 
0 for x  [0, Au,v), and the value eE(x - Au,v) for x _> Au,o, where Au,v _> 0 is 
the delay for this synapse between neurons u and v, and e E is the common shape 
of all excitatory response functions (EPSP's). Corresponding assumptions are 
made about the inhibitory response functions (IPSP's), whose common shape is 
described by some function e t: R + - {x  R � x _< 0). 
2) e  is continuous, ee(0) = 0, eZ(x) = 0 for all sufficiently large x, and there 
exists some parameter R > 0 such that e e is non-decreasing in [0, R], and some 
parameter p > 0 such that ee(x q- R/6) _> p q- eZ(x) for all x E [0,2R/3]. 
3) -e t satisfies the same conditions as e e. 
4) There exists a source BN- of negative background noise, that contributes 
to the potential Pv(t) of each neuron v an additive term that deviates for an arbi- 
trarily long time interval by an arbitrarily small percentage from its average value 
w _< 0 (which we can choose). One can delete this assumption if one assumes that 
the firing threshold of neurons can be shifted by some other mechanism. 
In section 3 we will assume in addition the availability of a corresponding positive 
background noise BN + with average value wv + >_ 0. 
In a biological neuron v one can interpret BN- and BN + as the combined effect 
of a continuous bombardment with a very large number of IPSP's (EPSP's) from 
randomly firing neurons that arrive at remote synapses on the dendritic tree of v. 
We assume that we can choose the values of delays Au,v and weights wu,v, Wv +, w. 
We refer to all assumptions specified in this section as our weak assumptions 
about noisy spiking neurons. It is easy to see that the most frequently studied 
concrete model for noisy spiking neurons, the spike response model (Gerstner and 
van Hemmen, 1994) satisfies these weak assumptions, and is hence a special case. 
However not even for the more concrete spike response model (or any other model 
for noisy spiking neurons) there exist any rigorous results about computations in 
these models. In fact, one may view this article as being the first that provides 
results about the computational complexity of neural networks for a neuron model 
that is acceptable to many neurobiologistis as being reasonably realistic. 
In this article we only address the problem of reliable digital computing with noisy 
spiking neurons. For details of the proofs we refer to the forthcoming journal-version 
of this extended abstract. For results about analog computations with noisy spiking 
neurons we refer to Maass, 1995b. 
2 
Simulation of Boolean Circuits and Finite Automata with 
Noisy Spiking Neurons 
Theorem 1: For any deterministic finite automaton D one can construct a net- 
work N(D) consisting of any type of noisy spiking neurons that satisfy our weak 
assumptions, so that N(D) can simulate computations of D of any given length 
with arbitrarily high probability of correctness. 
214 W. MAASS 
Idea of the proof: Since the behaviour of a single noisy spiking neuron is completely 
unreliable, we use instead pools A, B,... of neurons as the basic building blocks in 
our construction, where all neurons v in the same pool receive approximately the 
same input potential Pv(t). The intricacies of our stochastic neuron model allow 
us only to employ a weak coding of bits, where a 1 is represented by a pool A 
during a time interval I, if at least p � IAI neurons in A fire (at least once) during I 
(where p > 0 is a suitable constant), and 0 is represented if at most po. [A[ firings 
of neurons occur in A during I, where Po with 0 < p0 < pl is another constant (that 
can be chosen arbitrarily small in our construction). 
The described coding scheme is weak since it provides no useful upper bound (e.g. 
1.5.p. ]AI) on the number of neurons that fire during I if A represents a 1 (nor on 
the number of firings of a single neuron in A). It also does not impose constraints 
on the exact timing of firings in A within I. However a 0 can be represented more 
precisely in our model, by choosing p0 sufficiently small. 
The proof of Theorem 1 shows that this weak coding of bits suffices for reliable 
digital computations. The idea of these simulations is to introduce artificial nega- 
tions into the computation, which allow us to exploit that 0 has a more precise 
representation than 1. It is apparently impossible to simulate an AND-gate in a 
straightforward fashion for a weak coding of bits, but one can simulate a NOR-gate 
in a reliable manner. I 
Corollary 2: Any boolean function can be computed by a sufficiently large network 
of noisy spiking neurons (that satisfy our weak assumptions) with arbitrarily high 
probability of correctness. 
3 
Fast Simulation of Threshold Circuits via Shunting 
Inhibition 
For biologically realistic parameters, each computation step in the previously con- 
structed network takes around 25 msec (see point b) in section 4). However it 
is well-known that biological neural systems can carry out complex computations 
within just 100 msec (Churchland, Sejnowski, 1992). A closer inspection of the pre- 
ceding construction shows, that one can simulate with the same speed also OR- an
