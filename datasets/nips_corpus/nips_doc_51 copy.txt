524 
BASINS OF ATTRACTION FOR 
ELECTRONIC NEURAL NETWORKS 
C. M. Marcus 
R. M. Westervelt 
Division of Applied Sciences and Department of Physics 
Harvard University, Cambridge, MA 02138 
ABSTRACT 
We have studied the basins of attraction for fixed point and 
oscillatory attractors in an electronic analog neural network. Basin 
measurement circuitry periodically opens the network feedback loop, 
loads raster-scanned initial conditions and examines the resulting 
attractor. Plotting the basins for fixed points (memories), we show 
that overloading an associative memory network leads to irregular 
basin shapes. The network also includes analog time delay circuitry, 
and we have shown that delay in symmetric networks can introduce 
basins for oscillatory attractors. Conditions leading to oscillation 
are related to the presence of frustration; reducing frustration by 
diluting the connections can stabilize a delay network. 
(1) - INTRODUCTION 
The dynamical system formed from an interconnected network of 
nonlinear neuron-like elements can perform useful parallel 
computation 1-5. Recent progress in controlling the dynamics has 
focussed on algorithms for encoding the location of fixed points 1,4 
and on the stability of the flow to fixed points 3,5-8 An equally 
important aspect of the dynamics is the structure.of the basins of 
attraction, which describe the location of all points in initial 
condition space which flow to a particular attractor 10,22 
In a useful associative memory, an initial state should lead 
reliably to the closest memory. This requirement suggests that a 
well-behaved basin of attraction should evenly surround its attractor 
and have a smooth and regular shape. One dimensional basin maps 
plotting pull in probability against Hamming distance from an 
attractor do not reveal the shape of the basin in the high 
dimensional space of initial states 9,19 Recently, a numerical study 
of a Hopfield network with discrete time and two-state neurons showed 
rough and irregular basin shapes in a two dimensional Hamming space, 
suggesting that the high dimensional basin has a complicated 
structure 10. It is not known how the basin shapes change with the 
size of the network and the connection rule. 
We have investigated the basins of attraction in a network with 
continuous state dynamics by building an electronic neural network 
with eight variable gain sigmoid neurons and a three level (+,0,-) 
interconnection matrix. We have also built circuitry that can map 
out the basins of attraction in two dimensional slices of initial 
state space (Fig.l). The network and the basin measurements are 
described in section 2. 
American Institute of Physics 1988 
525 
In section 3, we show that the network operates well as an 
associative memory and can retrieve up to four memories (eight fixed 
points) without developing spurious attractors, but that for storage 
of three or more memories, the basin shapes become irregular. 
In section 4, we consider the effects of time delay. Real network 
components cannot switch infinitely fast or propagate signals 
instantaneously, so that delay is an intrinsic part of any hardware 
implementation of a neural network. We have included a controllable 
CCD (charge coupled device) analog time delay in each neuron to 
investigate how time delay affects the dynamics of a neural network. 
We find that networks with symmetric interconnection matrices, which 
are guaranteed to converge to fixed points for no delay, show 
collective sustained oscillations when time delay is present. By 
discovering which configurations are maximally unstable to 
oscillation, and looking at how these configurations appear in 
networks, we are able to show that by diluting the interconnection 
matrix, one can reduce or eliminate the oscillations in neural 
networks with time delay. 
(2) - NETWORK AND BASIN MEASUREMENT 
A block diagram of the network and basin measurement circuit is 
shown in fig.1. 
sigmoid amplifiers 
with delay 
digital 
comparator 
and 
oscillation 
detector 
storage 
outputs 
t 
'[desired 
jmemory 
initial 
-- run/load switches 
Fiq.1 Block diagram 
of the network and 
basin measurement 
system. 
The main feedback loop consists of non-linear amplifiers 
(neurons, see fig.2) with capacitive inputs and a resistor matrix 
allowing interconnection strengths of -l/R, 0, +i/R (R = 100 k). In 
all basin measurements, the input capacitance was 10 nF, giving a 
time constant of 1 ms. A charge coupled device (CCD) analog time 
delay 11 was built into each neuron, providing an adjustable delay per 
neuron over a range 0.4 - 8 ms. 
526 
Fig.2 Electronic neuron. 
Non-linear gain provided 
by feedback diodes. 
Inset: Nonlinear 
behavior at several 
different values of 
gain. 
Analog switches allow the feedback path to be periodically 
disconnected and each neuron input charged to an initial voltage. The 
network is then reconnected and settles to the attractor associated 
with that set of initial conditions. Two of the initial voltages are 
raster scanned (on a time scale that is long compared to the load/run 
switching time) with function generators that are also connected to 
the X and Y axes of a storage scope. The beam of the scope is 
activated when the network settles into a desired attractor, 
producing an image of the basin for that attractor in a two- 
dimensional slice of initial condition space. The attractor of 
interest can be one of the 2 8 fixed points or an oscillatory 
attractor. 
A simple example of this technique is the case of three neurons 
with symmetric non-inverting connection shown in fig.3. 
... / ,,',,,',:{{,,SASlN HTrl F i g. $ Basin of 
'.i].'..' ..,--....,.BASINFOR attraction for three 
neurons with sym- 
metric non-inverting 
 ,, .,, ',,, ,, ,,, ., ;,,', ;/ ,,',,__, ,,, ,,, ..,. ;,,iL.. -1.0V coupling. Slices are 
in the plane of 
initial voltages on 
'/'/;;<', ,,',; ;[t ,,--0.1V neurons 1 and 2. The 
,, i',',,b..,',;',.//', , 6';, *;..'.;< , v3 c, two fixed points are 
_ ''. 9%.':,%10V_ _/_ . . i7. ' all neurons saturated 
positive or all 
negative. The data 
-1V are photographs of 
 Vl __ I.UV I' -'-' the screen. 
-' V 1V scope 
(3) BASINS FOR FIXED POINTS - ASSOCIATIVE MEMORY 
Two dimensional slices of the eight dimensional initial condition 
space (for the full network) reveal important qualitative features 
about the high dimensional basins. Fig. 4 shows a typical slice for 
a network programmed with three memories according to a clipped Hebb 
rulel, 12. 
527 
Tij = 1/R Sqn(=l, m i  j); Tii = 0 (1) 
where  is an N-component memory vector of l's and -l's, and m is 
the number of memories. The memories were chosen to be orthogonal 
MEMORIES: 
1 , 1, 1, 1,-1 ,-1,-1,-1 
1 ,-1,1 ,-1,1 ,-1,1 ,-1 
1, 1 ,-1 ,-1,1 ,1 ,-1,-1 
Fig. 4 A slice of initial condition space shows the basins of 
attraction for five of the six fixed points for three memories 
in eight-neuron Hopfield net. Learning rule was clipped Hebb 
(Eq.1). Neuron gain = 15. 
Because the Hebb rule (eq.1) makes  and - stable attractors, a 
three-memory network will have six fixed point attractors. In fig.4, 
the basins for five of these attractors are visible, each produced 
with a different rastering pattern to make it distinctive. Several 
characteristic features should be noted: 
-- All initial conditions lead to one of the memories (or 
inverses), no spurious attractors were seen for three or four 
memories. This is interesting in light of the well documented 
emergence of spurious attractors at m/N -15% in larger networks with 
discrete time 2'18 
-- The basins have smooth and continuous edges. 
-- The shapes of the basins as seen in this slice are irregular. 
Ideally, a slice with attractors at each of the corners should have 
rectangular basins, one basin in each quadrant of the slice and the 
location of the lines dividing quadrants determined by the initial 
conditions on the other neurons (the unseen dimensions). With three 
or more memories the actual basins do not resemble this ideal form. 
(4) TIME DELAY, FRUSTRATION AND SUSTAINED OSCILLATION 
Arguments defining conditions which guarantee convergence to 
fixed points 3'$'6 (based, for example, on the construction of a 
Liapunov function) generally assume instantaneous communication 
between elements of the network. In any hardware implementation, 
these assumptions break down due to the finite switching speed of 
amplifiers and the charging time of long interconnect lines. 13 It is 
the ratio of delay/RC which is important for stability, so keeping 
this ratio small limits how fast a neural network chip can be 
designed to run. Time delay is also relevant to biological neural 
nets where propagation and response times are comparable. 14'15 
528 
Our particular interest in this section is how time delay can 
lead to sustained oscillation in networks which are known to be 
stable when there is no delay. We therefore restrict our attention 
to networks with symmetric interconnection matrices (Tij = Tji). 
An obvious ingredient in producing oscillations in a delay 
network is feedback, or stated another way, a graph representing the 
connections in a network must contain loops. 
The simplest oscillatory structure made of delay elements is the 
ring oscillator (fig.5a). Though not a symmetric configuration, the 
ring oscillator illustrates an important point: the ring will 
oscillate only when there is negative feedback at dc - that is, when 
the product of'interconnection around the loop is negative. Positive 
feedback at dc (loop product of connections > 0) will lead to 
saturation. 
Observing various symmetric configurations (e.g. fig.5b) in the 
delayed-neuron network, we find that a negative product of 
connections around a loop is also a necessary condition for sustained 
oscillation in symmetric circuits. An important difference between 
the ring (fig.5a) and th
