160 
SCALING AND GENERALIZATION IN 
NEURAL NETWORKS: A CASE STUDY 
Subutai Ahmad 
Center for Complex Systems Research 
University of Illinois at Urbana-Champaign 
508 S. 6th St., Champaign, IL 61820 
Gerald Tesauro 
IBM Watson Research Center 
PO Box 704 
Yorktown Heights, NY 10598 
ABSTRACT 
The issues of scaling and generalization have emerged as key issues in 
current studies of supervised learning from examples in neural networks. 
Questions such as how many training patterns and training cycles are 
needed for a problem of a given size and difficulty, how to represent the 
int!nt, and how to choose useful training exemplars, are of considerable 
theoretical and practical importance. Several intuitive rules of thumb 
have been obtained from empirical studies, but as ye there are few rig- 
orous results. In this paper we summarize a study of generalization in 
the simplest possible case-perceptron networks learning linearly separa- 
ble functions. The task chosen was the majority function (i.e. return 
a 1 if a majority of the input units are on), a predicate with a num- 
ber of useful properties. We find that many aspects of.generaiization 
in multilayer networks learning large, difficult tasks are reproduced in 
this simple domain, in which concrete numerical results and even some 
analytic understanding can be achieved. 
1 INTRODUCTION 
In recent years there has been a tremendous growth in the study of machines which 
learn. One class of learning systems which has been fairly popular is neural net- 
works. Originally motivated by the study of the nervous system in biological organ- 
isms and as an abstract model of computation, they have since been applied to a 
wide variety of real-world problems (for examples see [Sejnowski and Rosenberg, 87] 
and [Tesauro and Sejnowski, 88]). Although the results have been encouraging, 
there is actually little understanding of the extensibility of the formalism. In par- 
ticular, little is known of the resources required when dealing with large problems 
(i.e. scaling), and the abilities of networks to respond to novel situations (i.e. gen- 
eralization). 
The objective of this paper is to gain some insight into the relationships between 
three fundamental quantities under a variety of situations. In particular we are in- 
terested in the relationships between the size of the network, the number of training 
Scaling and Generalization in Neural Networks 1 61 
instances, and the generalization that the network performs, with an emphasis on 
the effects of the input representation and the particular patterns present in the 
training set. 
As a first step to a detailed understanding, we summarize a stud of scaling and 
generalization in the simplest possible case. Using feed forward networks, the type of 
networks most common in the literature, we examine the majority function (return 
a 1 if a majority of the inputs are on), a boolean predicate with a number of useful 
features. By using a combination of computer simulations and analysis in the limited 
domain of the majority function, we obtain some concrete numerical results which 
provide insight into the process of generalization and which will hopefully lead to a 
better understanding of learning in neural networks in general.* 
2 THE MAJORITY FUNCTION 
The function we have chosen to study is the majority function, a simple predicate 
whose output is a 1 if and only if more than half of the input units are on. This 
function has a number of useful properties which facilitate a study of this type. 
The function has a natural appeal and can occur in several different contexts in the 
real-world. The problem is linearly separable (i.e. of predicate order 1 [Minsky and 
Papeft, 69]). A version of the perceptton convergence theorem applies, so we are 
guaranteed that a network with one layer of weights can learn the function. Finally, 
when there are an odd number of input units, exactly half of the possible inputs 
results in an output of 1. This property tends to minimize any negative effects that 
may result from having too many positive or negative training examples. 
3 METHODOLOGY 
The class of networks used are feed forward n elworks [Rumelhart and McClelland, 86], 
a general category of networks that include perceptrons and the multi-layered net- 
works most often used in current research. Since majority is a boolean function 
of predicate order 1, we use a network with no hidden units. The output function 
used was a sigmoid with a bias. The basic procedure consisted of three steps. First 
the network was initialized to some random starting weights. Next it was trained 
using back propagation on a set of training patterns. Finally, the performance of 
the network was tested on a set of random test patterns. This performance figure 
was used as the estimate of the network's generalization. Since there is a large 
amount of randomness in the procedure, most of our data are averages over several 
simulations. 
0. The material contained in this paper is a condensation of portions of the first author's 
M.S. thesis [Ahmad, 88]. 
162 Abroad and Tesauro 
f 
.,50 
0.42 
0.33 
0.25 
0.17 
0.08 
0.00 
0 70 140 210 280 350 420 
Figure 1: The average failure rate as a function of S. d = 25 
Notation. In the following discussion, we denote S to be the number of training 
patterns, d the number of input units, and c the number of cycles through the train- 
ing set. Let f be the failure rate (the fraction of misclassified training instances), 
and r be the set of training patterns. 
4 RANDOM TRAINING PATTERNS 
We first examine the failure rate as a function of S and d. Figure 1 shows the 
graph of the average failure rate as a function of S, for a fixed input size d = 25. 
Not surprisingly we find that the failure rate decreases fairly monotonically with S. 
Our simulations show that in fact, for majority there is a well defined relationship 
between the failure rate and S. Figure 2 shows this for a network with 25 input 
units. The figure indicates that In f is proportional to S implying that the failure 
rate decreases exponentially with S, i.e., f = ae -s. lift can be thought of as a 
characteristic training set size, corresponding to a failure rate of c/e. 
Obtaining the exact scaling relationship of 1/9 was somewhat tricky. Plotting fi on 
a log-log plot against d showed it to be close to a straight line, indicating that 1// 
increases ~ d  for some constant a. Extracting the exponent by measuring the slope 
of the log-log graph turned out to be very error prone, since the data only ranged 
over one order of magnitude. An alternate method for obtaining the exponent is 
to look for a particular exponent a by setting S = cd . Since a linear scaling 
relationship is theoretically plausible, we measured the failure rate of the network 
Scaling and Generalization in Neural Networks 163 
In f 
0.G00 
-1.000 
-2. 000 
-3. 000 
-4. 000 
-S.000 
-6.000 
t ' I I i I. q 
0.0 70.0 140.0 210.0 280.0 3S0.0 420.0 
Figure 2: In f as a function of S. d = 25. The slope was  -0.01 
at S = ad for various values of a. As Figure 3 shows, the failure rate remains more 
or less constant for fixed values of a, indicating a linear scaling relationship with d. 
Thus O(d) training patterns should be required to learn majority to a fixed level of 
performance. Note that if we require perfect learning, then the failure rate has to 
be _< 1/(2 d- S) ~ 1/2 d. By substituting this for f in the above formula and solving 
for S, we get that ()(dln2 + lna) patterns are required. The extra factor of d 
suggests that O(d 2) would be required to learn majority perfectly. We will show in 
Section 6.1 that this is actually an overestimate. 
5 
THE INPUT REPR, ESENTATION 
So far in our simulations we have used the representation commonly used for boolean 
predicates. Whenever an input feature has been true, we clamped the corresponding 
input unit to a I, and when it has been off we have clamped it to a 0. There is no 
reason, however, why some other representation couldn't have been used. Notice 
that in back propagation the weight change is proportional to the incoming input 
signal, hence the weight from a particular input unit to the output unit is changed 
only when the pattern is misclassified and the input unit is non-zero. The weight 
remains unchanged when the input unit is 0. If the 0,1 representation were changed 
to a ~1,+1 representation each weight will be changed more often, hence the network 
should learn the training set quicker (simulations in [Stornetta and Huberman, 87] 
reported such a decrease in training time using a _1, +ï¿½ representation.) 
2 
164 Abroad and Tesauro 
0.25 
0.17 
0.08 
0.00 
$ =3d 
$=5d 
$=7d 
I I I ' t I , 
20 27 33 40 47 53 60 
d 
Figure 3: Failure rate vs d with S -- 3d, 5d, 7d. 
We found that not only did the training time decrease with the new representation, 
the generalization of the network improved significantly. The scaling of the failure 
rate with respect to S is unchanged, but for any fixed value of S, the generalization 
is about 5 - 10% better. Also, the scaling with respect to d is still linear, but the 
constant for a fixed performance level is smaller. Although the exact reason for 
the improved generalization is unclear, the following might be a plausible reason. 
A weight is changed only if the corresponding input is non-zero. By the definition 
of the majority function, the average number of units that are on for the positive 
instances is higher than for the negative instances. Hence, using the 0,1 represen- 
tation, the weight changes are more pronounced for the positive instances than for 
the negative instances. Since the weights are changed whenever a pattern is rnis- 
classified, the net result is that the weight change is greater when a positive event 
is misclasshqed than when a negative event is rnisclassified. Thus, there seems to be 
a bias in the 0,1 representation for correc
