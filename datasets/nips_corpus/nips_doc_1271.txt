Noisy Spiking Neurons with Temporal 
Coding have more Computational Power 
than $igmoidal Neurons 
Wolfgang Maass 
Institute for Theoreticell Computer Science 
Technische Universite[et Gre[z, Klosterwiesge[sse 32/2 
A-8010 Graz, Austrie[, e-me[il: maass@igi.tu-gre[z.e[c.e[t 
Abstract 
We exhibit e[ novel we[y of simule[ting sigmoide[l neure[l nets by net- 
works of noisy spiking neurons in tempotell coding. Furthermore 
it is shown theit networks of noisy spiking neurons with tempotell 
coding helve e[ strictly le[rger compute[tione[l power thein sigmoide[l 
neure[1 nets with the se[me number of units. 
1 Introduction and Definitions 
We consider e[ formal model SNN for e[ spiking n_euron network that is basically 
e[ reformule[tion of the spike response model (e[nd of the leaky integrate e[nd fire 
model) without using &functions (see [Maass, 1996e[] or [Me[ass, 1996b] for further 
be[ckground). 
An SNN consists of e[ finite set V of spiking neurons, e[ set E _C V x V of synapses, e[ 
weight Wu, _> 0 and e[ response function eu, � R + - R for each syne[pse (u, v)  E 
(where R + := {x e R: x _> 0}) , and a threshold function Ov' R + - R + for ee[ch 
neuron v  V . 
If Fu C_ R + is the set of firing times of a neuron u, then the potential at the trigger 
zone of neuron ve[t time t is given by 
In e[ noise-free model e[ neuron v fires e[t time t as soon as Pt) reaches Ot - t'), 
where t  is the time of the most recent firing of v . One says then that neuron v 
sends out e[n action potential or spike e[t time t. 
212 W. Maass 
For some specified subset �n C_ V of input neurons one assumes that the firing times 
(spike trains) Fu for neurons u  �n are not defined by the preceding convention, 
but are given from the outside. The firing times Fv for all other neurons v  V are 
determined by the previously described rule, and the output of the network is given 
in the form of the spike trains Fv for a specified set of output neurons Vout C_ V 
$ t 
v 
0 s  t 
t' t 
Figure 1: Typical shapes o,f response functions eu,v(EPSP and IPSP) and threshold 
functions 6).for biological neurons. 
We will assume in our subsequent constructions that all response functions eu,v 
and threshold fimctions Ovin an SNN are stereotyped, i.e. that the response 
functions differ apart from their sign (EPSP or IPSP) only in their delay d,, 
(where du,v := inf {t _> 0: eu,v(t) y 0}) , and that the threshold functions 
only differ by an additive constant (i.e. for all u and v there exists a constant 
such that O,,(t) = O.t) + c,,,.for all t > O) . We refer to a term of the form 
Wu,v' eu,.(t- s) as an _excitatory respectively inhibitory __posts_s_snaptic potential 
(abbreviated: EPSP respectively IPSP). 
Since biological netirons do not always fire in a reliable manner one also considers 
the related model of noisy spiking neurons, where P.(t) is replaced by P �isy(t) := 
Pv(t) + Cry(t) and Ov(t t') is replaced by 0 noisy Ov(t t') +/3v(t t'). 
-  (t-t') := - - 
av(t) and /3.t - t') are allowed to be arbitrary functions with bounded absolute 
value (hence they can also represent systematic noise). 
Furthermore one allows that the current value of the difference D(t) := P�isy(t) - 
noisy 
O, (t - t') does not determine directly the firing time of neuron v, but only its 
current firing probability. We assume that the firing probability approaches 1 if 
D --,  , and 0 if D --, - . We refer to spiking neurons with these two types of 
noise as noisy spiking neurons. 
We will explore in this article the power of analog computations with noisy spiking 
neurons, and we refer to [Magss, 1996a] for restilts about digital computations in 
this model. Details to the results in this article appear in [Maass, 1996b] and 
[Maass, 1997]. 
2 
Fast Simulation of Sigmoidal Neural Nets with Noisy 
Spiking Neurons in Temporal Coding 
So far one has only considered simulations of sigmoidal neural nets by spiking neu- 
rons where each analog variable in the sigmoidal neural net is represented by the 
firing rate of a spiking neuron. However this firing rate interpretation is incon- 
sistent with a number of empirical results about computations in biological neural 
Spiking Neurons have more Computational Power than Sigmoidal Neurons 213 
systems. For example [Thorpe & Imbert, 1989] have demonstrated that visual pat- 
tern analysis and pattern classification can be carried out by humans in just 150 ms, 
in spite of the fact that it involves a minimum of l0 synaptic stages from the retina 
to the temporal lobe. [de Ruyter van Steveninck & Bialek, 1988] have found that 
a blowfly can produce flight torques within 30 ms of a visual stimulus by a neural 
system with several synaptic stages. However the firing rates of neurons involved 
in all these computations are usually below 100 Hz, and interspike intervals tend 
to be quite irregular. Hence one cannot interpret these analog computations with 
spiking neurons on the basis of an encoding of analog variables by firing rates. 
On the other hand experimental evidence has accumulated during the last few years 
which indicates that many biological neural systems use the timing of action poten- 
tials to encode information (see e.g. [Bialek & Rieke, 1992], [Bait & Koch, 1996]). 
We will now describe a new way of simulating sigmoidal neural nets by networks of 
spiking neurons that is based on temporal coding. The key mechanism for this alter- 
native simulation is based on the well known fact that EPSP's and IPSP's are able 
to shift the firing time of a spiking neuron. This mechanism can be demonstrated 
very clearly in our formal model if one assumes that EPSP's rise (and IPSP's fall) 
linearly during a certain initial time period. Hence we assume in the following that 
there exists some constant A > 0 such that each response function e,,v (x) is of the 
form au,v '(x-du,v) with au,v e {-1, 1} for xe [du,v, du,v + A] ,and eu,v(X)-0 
for x e [0, du,v] . 
Consider a spiking netiron v that receives postsynaptic potentials from n presynaptic 
neurons a,..., an � For simplicity we asslime that interspike intervals are so large 
that the firing time tv of neuron v depends just on a single firing time ta of each 
neuron ai, and Ov has returned to its resting value O(0) before v fires again. 
Then if the next firing of v occurs at a time when the postsynaptic potentials 
described by wa,v . ea,v (t - ta) are all in their initial linear phase, its firing time 
tv is determined in the noise-free model for wi := wa,v � ca,v by the equation 
'-i--- wi. (t - ta - d,,) = O(0) , or equivalently 
o(o) O' + 
n q- n (1) 
tv - Ei=i wi Ei=i wi 
This equation reveals the somewhat surprising fact that (for a certain range of 
their parameters) spiking netirons can compute a weighted sum in terms of firing 
times, i.e. temporal coding. One should also note that in the cause where all delays 
da,v have the same value, the weights wi of this weighted sum are encoded in 
the strengths wa,,v of the synapses and their sign ca,v , as in the firing rate 
interpretation. Finally according to (1) the coefficients of the presynaptic firing 
times ta, are automatically normalized, which appears to be of biological interest. 
In the simplest scheme for temporal coding (which is closely related to that in 
[Hopfield, 1995]) an analog variable x  [0, 1] is encoded by the firing time T - -/. x 
of a neuron, where T is assumed to be independent of x (in a biological context T 
might be time-locked to the onset of a stimulus, or to some oscillation) and -), is 
some constant that is determined in the proof of Theorem 2.1 (e.g. -), = A/2 in the 
noise-free case). In contrast to [Hopfield, 1995] we asslime that both the inputs and 
the outputs of computations are encoded in this fashion. This has the advantage 
that one can compose computational modules. 
214 W. Maass 
We will first focus in Theorem 2.1 on the simulation of sigmoidal neural nets that 
employ the piecewise linear linear saturated activation function -: R -- [0, 1] 
defined by r(y) = 0 ify < 0, r(y) = y if0 <_ y _< 1, andr(y) -- 1 ify > 1 
The Theorem 3.1 in the next section will imply that one can simulate with spik- 
ing neurons also sigmoidal neural nets that employ arbitrary continuous activation 
functions. Apart from the previously mentioned assumptions we will assume for 
the proofs of Theorem 2.1 and 3.1 that any EPSP satisfies eu,vx) = 0 for all suffi- 
ciently large x, and eu, (x) _> eu, (du, + A) for all x e [du, + A, du, + A + ?] . 
We assume that each IPSP is continuous, and has value 0 except for some interval 
of R . Furthermore we assume for each EPSP and IPSP that ]eu,vx)l grows at 
most linearly during the interval [du,v+ A, du,v+ A + ?] . In addition we assume 
that 13vx) = 130) for sufficiently large x , and that 13v(x) is sufficiently large for 
0<x<_. 
Theorem 2.1 For any given e, 5 > 0 one can simulate any given feedforward sig- 
moidal neural net N with activation function r by a network AfN,e, of noisy spiking 
neurons in temporal coding. More precisely, for any network input x,...,xm  
[0, 1] the output of AfN, e, differs with probability _> 1 - 5 by at most e from that 
of N . Furthermore the computation time of AfN,e,, depends neither on the number 
of gates in N nor on the parameters e, 5, but only on the number of layers of the 
sigmoidal neural network N . 
We refer to [Maass, 1997] for details of the somewhat complicated proof. One 
employs the mechanism described by (1) to simulate through the firing time of a 
spiking neuron v a sigmoidal gate with activation function 7r for those gate-inputs 
where - operates in its linearly rising range. With the help of an auxiliary spiking 
neuron that fires at time T one can avoid the automatic normalization of the 
weights wi that is provided by (1), and thereby compute a weighted sum with 
arbitrary given weights. In order to simulat
