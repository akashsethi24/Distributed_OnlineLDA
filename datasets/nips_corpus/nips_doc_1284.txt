Online learning from finite training sets: 
An analytical case study 
Peter Sollich* 
Department of Physics 
University of Edinburgh 
Edinburgh EH9 3JZ, U.K. 
P. Solliched. ac. uk 
David Barber t 
Neural Computing Research Group 
Department of Applied Mathematics 
Aston University 
Birmingham B4 7ET, U.K. 
D. Sarberason. ac. uk 
Abstract 
We analyse online learning from finite training sets at non- 
infinitesimal learning rates r/. By an extension of statistical me- 
chanics methods, we obtain exact results for the time-dependent 
generalization error of a linear network with a large number of 
weights N. We find, for example, that for small training sets of 
size p  N, larger learning rates can be used without compromis- 
ing asymptotic generalization performance or convergence speed. 
Encouragingly, for optimal settings of r/ (and, less importantly, 
weight decay A) at given final learning time, the generalization per- 
formance of online learning is essentially as good as that of offiine 
learning. 
I INTRODUCTION 
The analysis of online (gradient descent) learning, which is one of the most common 
approaches to supervised learning found in the neural networks community, has 
recently been the focus of much attention [1]. The characteristic feature of online 
learning is that the weights of a network ('student') are updated each time a new 
training example is presented, such that the error on this example is reduced. In 
offline learning, on the other hand, the total error on all examples in the training 
set is accumulated before a gradient descent weight update is made. Online and 
* Royal Society Dorothy Hodgkin Research Fellow 
t Supported by EPSRC grant GR/J75425: Novel Developments in Learning Theory 
for Neural Networks 
Online Learning from Finite Training Sets: An Analytical Case Study 275 
offiine learning are equivalent only in the limiting case where the learning rate 
/ -4 0 (see, e.g., [2]). The main quantity of interest is normally the evolution of 
the generalization error: How well does the student approximate the input-output 
mapping ('teacher') underlying the training examples after a given number of weight 
updates? 
Most analytical treatments of online learning assume either that the size of the 
training set is infinite, or that the learning rate / is vanishingly small. Both of 
these restrictions are undesirable: In practice, most training sets are finite, and non- 
infinitesimal values of / are needed to ensure that the learning process converges 
after a reasonable number of updates. General results have been derived for the 
difference between online and offiine learning to first order in /, which apply to 
training sets of any size (see, e.g., [2]). These results, however, do not directly 
address the question of generalization performance. The most explicit analysis of 
the time evolution of the generalization error for finite training sets was provided by 
Krogh and Hertz [3] for a scenario very similar to the one we consider below. Their 
r I -4 0 (i.e., offline) calculation will serve as a baseline for our work. For finite r/, 
progress has been made in particular for so-called soft committee machine network 
architectures [4, 5], but only for the case of infinite training sets. 
Our aim in this paper is to analyse a simple model system in order to assess how the 
combination of non-infinitesimal learning rates /and finite training sets (containing 
c examples per weight) affects online learning. In particular, we will consider 
the dependence of the asymptotic generalization error on / and c, the effect of 
finite  on both the critical learning rate and the learning rate yielding optimal 
convergence speed, and optimal values of /and weight decay A. We also compare 
the performance of online and offiine learning and discuss the extent to which infinite 
training set analyses are applicable for finite c. 
2 MODEL AND OUTLINE OF CALCULATION 
We consider online training of a linear student network with input-output relation 
y __-- wTx/x/. 
Here x is an N-dimensional vector of real-valued inputs, y the single real output 
and w the wei._t vector of the network. ,T, denotes the transpose of a vector and 
the factor 1//N is introduced for convenience. Whenever a training example (x, y) 
is presented to the network, its weight vector is updated along the gradient of the 
squared error on this example, i.e., 
(y - wTx/x/)  /(yx/x/ kxxTw) 
Aw = -/ Vw = - 
where r/is the learning rate. We are interested in online learning from finite train- 
ing sets, where for each update an example is randomly chosen from a given set 
{(x ', y'),! a -- 1...p) of p training examples. (The case of cyclical presentation of 
examples [6] is left for future study.) If example p is chosen for update n, the weight 
vector is changed to 
w,+l = {1 - /[x'(x') T + 7]}w, + ly'x'/x/ 
(1) 
Here we have also included a weight decay 7. We will normally parameterize the 
strength of the weight decay in terms of A = 7c (where c = p/N is the number 
276 P. Sollich and D. Barber 
of examples per weight), which plays the same role as the weight decay commonly 
used in offiine learning [3]. For simplicity, all student weights are assumed to be 
initially zero, i.e., w,=0 = 0. 
The main quantity of interest is the evolution of the 9eneralization error of the 
student. We assume that the training examples are generated by a linear 'teacher', 
i.e., y' = w. Tx'/X/+ ' , where  is zero mean additive noise of variance r 2. The 
teacher weight vector is taken to be normalized to w. 2 = N for simplicity, and the 
input vectors are assumed to be sampled randomly from an isotropic distribution 
over the hypersphere x 2 = N. The generalization error, defined as the average of 
the squared error between student and teacher outputs for random inputs, is then 
'g 2]v(W--W*)a  2 where v.=w.-w, 
:  2N Vn ' 
In order to make the scenario analytically tracable, we focus on he limit N   
of a large number of input components and weights, taken a constant number of 
examples per weight a = pin and updates per weigh ('learning time') t = n/N. In 
this limit, he generalization error cg(t) becomes self-averaging and can be calculated 
by averaging boh over he random selection of examples from a given training set 
and over all training sets. Our results can be straightforwardly extended to the ce 
of perceptton teachers with a nonlinear ransfer function,  in [7]. 
The usual statistical mechanical approach to the online learning problem expresses 
, 1 T whose 
he generalization error in terms of 'order parameters like R = Nw nw. 
(self-averaging) time evolution is determined from appropriately averaged update 
equations. This method works because for infinite raining ses, the average or- 
der pameter updates can again be expressed in erms of the order parameters 
alone. For finite training ses, on the oher hand, the updates involve new order 
parameters such  R -  T 
- w n Aw., where A is the correlation matrix of the 
training inputs, A = _x(x) T. Their time evolution is in turn determined 
by order parameters invoking higher powers of A, yielding an infinite hierarchy 
of order parameters. We solve this problem by considering instead order parame- 
ter (generating) functions [8] such  a generalized form of the generalization error 
e(t; h) =  Texp(hA)v,. This allows powers of A to be obtained by differentia- 
vn 
tion with respect to h, resulting in a closed system of (partial differential) equations 
for e(t; h) and R(t; h)=  T exp(hA)w.. 
Wn 
The resulting equations and details of their solution will be given in a future publi- 
cation. The final solution is most easily expressed in terms of the Laplace transform 
of the generalization error 
= = + + (2) 
The functions c(z) (i = 1...4) can be expressed in closed form in terms of a, a 
and A (and, of course, z). The Laplace transform (2) yields directly the ymptotic 
value of the generalization error,  = cg(l  ) = lim40 zg(z), which can be 
calculated analytically. For finite learning times l, %(l) is obtained by numerical 
inversion of the Laplace transform. 
3 RESULTS AND DISCUSSION 
We now discuss the consequences of our main result (2), focusing first on the asymp- 
totic generalization error ca, then the convergence speed for large learning times, 
Online Learning from Finite Training Sets: An Analytical Case Study 277 
ct--0.5 ct=l 
0.4 
0.3 
0.2 
0.1 
1..  
5 0.4 
0.4 
0.3 
0.2 
O. 
0.5 
Figure 1: Asymptotic generalization error eoo vs r/and A. a as shown, er e = 0.1. 
and finally the behaviour at small t. For numerical evaluations, we generally take 
er e = 0.1, corresponding to a sizable noise-to-signal ratio of  m 0.32. 
The asymptotic generalization error eoo is shown in Fig. 1 as a function of r/and A 
for a = 0.5, 1, 2. We observe that it is minimal for A = ere and r/- 0, as expected 
from corresponding results for offiine learning [3]  We also read off that for fixed A, 
eoo is an increasing function of r/: The larger r/, the more the weight updates tend 
to overshoot the minimum of the (total, i.e., offiine) training error. This causes a 
diffusive motion of the weights around their average asymptotic values [2] which 
increases coo. In the absence of weight decay (A - 0) and for a < 1, however, coo 
is independent of r/. In this case the training data can be fitted perfectly; every 
term in the total sum-of-squares training error is then zero and online learning does 
not lead to weight diffusion because all individual updates vanish. In general, the 
relative increase eoo(r/)/eoo(r/- 0)- i due to nonzero r/depends significantly on a. 
For r; = 1 and a = 0.5, for example, this increase is smaller than 6% for all A (at 
er e = 0.1), and for a = i it is at most 13%. This means that in cases where training 
data is limited (p  N), r/can be chosen fairly large in order to optimize le
