Observability of Neural Network 
Behavior 
Max arzon Fernnnda Botelho 
sarzonmhermes. nsc i. nemst. edu bore lhofeherme s. nsc i. menst. edu 
Institute for Intelligent Systems Department of Mathematical Sciences 
Memphis State University 
Memphis, TN 38152 U.S.A. 
Abstract 
We prove that except possibly for small exceptional sets, discrete- 
time analog neural nets are globally observable, i.e. all their cor- 
rupted pseudo-orbits on computer simulations actually reflect the 
true dynamical behavior of the network. Locally finite discrete 
(boolean) neural networks are observable without exception. 
INTRODUCTION 
We address some aspects of the general problem of implementation and robustness 
of (mainly recurrent) autonomous discrete-time neural networks with continuous 
activation (herein referred to as analog networks) and discrete activation (herein, 
boolean networks). There are three main sources of perturbations from ideal oper- 
ation in a neural network. First, the network's parameters may have been contam- 
inated with noie from external sources. Second, the network is being implemented 
in optics or electronics (digital or analog) and inherent measurement limitations 
preclude the use of perfect information on the network's parameters. Third, as has 
been the most common practice so far, neural networks are simulated or imple- 
mented on a digital device, with the consequent limitations on precision to which 
net parameters can be represented. Finally, for these or other reasons, the activation 
functions (e.g. sigmoids) of the network are not known precisely or cannot be evalu- 
ated properly. Although perhaps negligible in a single iteration, these perturbations 
are likely to accumulate under iteration, even in feedforward nets. Eventually, they 
may, in fact, distort the results of the implementation to the point of making the 
simulation useless, if not misleading. 
455 
456 Garzon and Botelho 
There is, therefore, an important difference between the intended operation of an 
idealized neural network and its observable behavior. This is a classical problem in 
systems theory and it has been addressed in several ways. First, the classical no- 
tions of distinguishability and observability in control theory (Sontag, 1990) which 
roughly state that every pair of system's states are distinguishable by different out- 
puts over evolution in finite time. This is thus a notion of local state observability. 
More recently, several results have established more global notions of identit]abiI- 
icy of discrete-time feedfoward (Sussmann, 1992; Chen, Lu, Hecht-Nelson, 1993) 
and continuous-time recurrent neural nets (Albertini and Sontag, 1993a,b), which 
roughly state that for given odd activation functions (such as tanh), the weights 
of a neural network are essentially uniquely determined (up to permutation and 
cell redundancies) by the input/output behavior of the network. These notions do 
assume error-free inputs, weights, and activation functions. 
In general, a computer simulation of an orbit of a given dynamical system in the 
continuuum (known as a pseudo-orbit) is, in fact, far from the orbit in the ideal 
system. Motivated by this problem, Birkhoff introduced the so-called shadowing 
property. A system satisfies the shadowing property if all pseudo-orbits are uniformly 
approximated by actual orbits so that the former capture the long-term behavior 
of the system. Bowen showed that sufficiently hyperbolic systems in real euclidean 
spaces do have the shadowing property (Bowen, 1978). However, it appears difficult 
even to give a characterization of exactly which maps on the interval possess the 
property -see e.g. (Coven, Kan, Yorke, 1988). Precise definitions of all terms can 
be found in section 2. 
By comparison to state observability and identifiability, the shadowing property is 
a type of globaI obserYabiliy of a system through its dynamical behavior. Since 
autonomous recurrent networks can be seen as dynamical systems, it is natural 
to investigate this property. Thus, a neural net is observable in the sense that its 
behavior (i.e. the sequence of its ideal actions on given initial conditions) can be 
observed on computer simulations or discrete implementations, despite inevitable 
concomitant approximations and errors. 
The purpose of this paper is to explore this property as a deterministic model for 
perturbations of neural network behavior in the presence of arbitrary small errors 
from various sources. The model includes both discrete and analog networks. In 
section 4 we sketch a proof that locally finite boolean neural networks (even with 
an infinite number of neurons), are all observable in this sense. This is not true 
in general for analog networks, and section 3 is devoted to sketching necessary and 
sufficient conditions for the relatively few analog exceptions for the most common 
transfer functions: hard-thresholds, a variety of sigmoids (hyperbolic tangent, lo- 
gistic, etc.) and saturated linear maps. Finally, section 5 discusses the results and 
poses some other problems worthy of further research. 
2 DEFINITIONS AND MAIN RESULTS 
This section contains notation and precise definitions in a general setting, so as to 
include discrete-time networks both with discrete and continuous activations. 
Let f: X --} X be a continuous map of a compact metric space with metric I*, * [. 
Observability of Neural Network Behavior 457 
The orbii of z 6 X is the sequence (z, f(z),..., re(z)...}, i.e. a sequence of points 
{x}>o for which x '+ --- f(x), for all k _> 0. Given a number 5 > 0, a &pseudo- 
orbi* is a sequence {x e} so that the distances I < for all k >_ 0. 
Pseudo-orbits arise as trajectories of ideal dynamical processes contaminated by 
errors and noise. In such cases, especially when errors propagate exponentially, 
it is important to know when the numerical process is actually representing some 
meaningful trajectory of the real process. 
DerraiMon 2.1 The map f on a metric space X is (globally) obser'�able (equiva- 
lently, has he shadowing propery, or is raceable) if and only if for every e > 0 
there exists a 6 > 0 so that any 6-pseudo-orbit {z e} is e-approximated by the orbit, 
under f, of some point z  X, i.e. ]z e, fe(z)l < e for all k > O. 
One might observe that computer simulations only run for finite time. On compact 
spaces (as is the case below), observability can be shown to be equivalent to a similar 
property of shadowing finite pseudo-orbits. 
'Analog neural network' here means a finite number n of units (or cells), each of 
which is characterized by an activation (sometimes called output) function cr i : 
1 --* 1, and weigh* matrix W of synaptic strengths between the various units. 
Units can assume real-valued activations i, which are updated synchronously and 
simultaneously at discrete instants of time, according to the equation 
� ,(t + l) = (1) 
The total activation of the network at any time is hence given by a vector � in 
euclidean space R , and the entire network is characterized by a global dynamics 
= (2) 
where W denotes ordinary product and rr is the map acting as ai along the ith 
component. This component in a vector � is denoted i (as opposed to z , the k th 
term of a sequence). The unit hypercube in 1  is denoted I N. An analog network 
is then defined as a dynamical system in a finite-dimensional euclidean space and 
one may then call a neural network (globally) observable if its global dynamics is an 
observable dynamical system. Likewise for boolean networks, which will be defined 
precisely in section 4. 
We end this section with some background facts about observability on the contin- 
uum. It is perhaps surprising but a trivial remark that the identity map of the real 
interval is not observable in this sense, since orbits remain fixed, but pseudo-orbits 
may drift away from the original state and can, in fact, be dense in the interval. 
Likewise, common activation functions of neural networks (such as hard thresholds 
and logistic maps) are not observable. For linear maps, observability has long been 
known to be equivalent to hyperboliciy (all eigenvalues A have 1). Composi- 
tion of observable maps is usually not observable (take, for instance, a hyperbolic 
homeomorphism and its inverse). In contrast, composition of linear and nonob- 
servable activation functions in neural networks are, nevertheless, observable. The 
main take-home message can be loosely summarized as follows. 
Theorem 2.1 Except for a negligible fraction of exceptions, discrete-time analog 
neural nets are observable. All discrete (boolean) neural networks are observable. 
458 Garzon and Botelho 
3 ANALOG NEURAL NETWORKS 
This section contains (a sketch) of necessary and sufficient conditions for analog 
networks to be observable for common types of activations functions. 
3.1 HARD-THRESHOLD ACTIVATION FUNCTIONS 
It is not hard to give necessary and sufficient conditions for observability of nets 
with discrete activation functions of the type 
1 ifu>_Oi 
ai(u) := 0 else. 
where Oi is a theshold characterizing cell i. 
Lemma 3.1 A map f: R ' --} R ' with finite range is observable if and only if it 
is continuous at each point of its range. 
PROOF. The condition is clearly sufficient. If f is continuous at every point of its 
range, small enough perturbations z + of an image fizz) have the same image 
f(+) = f(f(a:)) and hence, for 5 small enough, every 5-pseudo-orbit is traced 
by the first element of the pseudo-orbit. Conversely, assume f is not continuous at a 
point of its range f(z�). Let z , z2,... be a sequence constant under f whose image 
does not converge to f(f�o)) (s.ch a sequence can always be so chosen because 
the range is discrete). Let 
1 
e:--- rain If(z),f(y)l. 
For a given 5 > 0 the pseudo-orbit x�,x,f(x),f2(x),... is not traceable for k 
large enough. Indeed, for any z within e-distance of x �, either
