! I 
Adaptation in Speech Motor Control 
John F. Houde* 
UCSF Keck Center 
Box 0732 
San Francisco, CA 94143 
houdephy. ucsf. edu 
Michael I. Jordan 
MIT Dept. of Brain and Cognitive Sci. 
E10-034D 
Cambridge, MA 02139 
j ordanpsyche. mir. edu 
Abstract 
Human subjects are known to adapt their motor behavior to a 
shift of the visual field brought about by wearing prism glasses 
over their eyes. We have studied the analog of this effect in speech. 
Using a device that can feed back transformed speech signals in 
real time, we exposed subjects to alterations of their own speech 
feedback. We found that speakers learn to adjust their production 
of a vowel to compensate for feedback alterations that change the 
vowel's perceived phonetic identity; moreover, the effect generalizes 
across consonant contexts and to different vowels. 
1 INTRODUCTION 
For more than a century, it has been know that humans will adapt their reaches 
to altered visual feedback [8]. One of the most studied examples of this adaptation 
is prism adaptation, which is seen when a subject reaches to targets while wearing 
image-shifting prism glasses [2]. Initially, the subject misses the targets, but he 
soon learns to compensate and reach accurately. This compensation is retained 
beyond the time that the glasses are worn: when the glasses are removed, the 
subject's reaches now overshoot targets in the direction that he compensated. This 
retained compensation is called adaptation, and its generation from exposure to 
altered sensory feedback is called sensorimotor adaptation (SA). 
In the study reported here, we investigated whether SA could be observed in a 
motor task that is quite different from reaching - speech production. Specifically, 
we examined whether the control of phonetically relevant speech features would 
respond adaptively to altered auditory feedback. By itself, this is an important 
theoretical question because various aspects of speech production have already been 
shown to be sensitive to auditory feedback [5, 1, 4]. Moreover, we were particularly 
*To whom correspondence should be addressed. 
Adaptation in Speech Motor Control 39 
interested in whether speech SA would also exhibit generalization. If so, speech SA 
could be used to examine the organization of speech motor control. For example, 
suppose we observed adaptation of [e] in get. We could then examine whether 
we also see adaptation of [e] in peg. If so, then producing [el in the two different 
words must access a common, adapted representation - evidence for a hierarchical 
speech production system in which word productions are composed from smaller 
units such as phonemes. We could also examine whether adapting [e] in get 
causes adaptation of [ae] in gat. If so, then the production representations of [e] 
and [ae] could not be independent, supporting the idea that vowels are produced by 
controlling a common set of features. Such theories about the organization of the 
speech production system have been postulated in phonology and phonetics, but 
the empirical evidence supporting these theories has generally been observational 
and hence not entirely conclusive [7, 6]. 
2 METHODS 
To study speech SA, we focused on vowel production because the phonetically rel- 
evant features of vowel sounds are formant frequencies, which are feasible to alter 
in real timeJ 
To alter the formants of a subject's speech feedback, we built the apparatus shown 
in Figure 1. The subject wears earphones and a microphone and sits in front of 
a PC video monitor that presents words to be spoken aloud. The signal from the 
microphone is sent to a Digital Signal Processing board, which collects a 64ms 
time interval from which a magnitude spectrum is calculated. From this spectrum, 
formant frequencies and amplitudes are estimated. To alter the speech, the first 
three formant frequencies are shifted, and the shifted formants drive a formant 
synthesizer that creates the output speech sent to the subject's earphones. This 
analysis-synthesis process was accomplished with only 16ms of feedback delay. To 
minimize how much the subject directly heard of his own voice via bone conduction, 
the subject produced only whispered speech, masked with mild noise. 
altered 
feedback 
ear )hones '-.  
PC video monitor _ - .2 
microphone ?'l  ]  
intercepted 
speech 
Formant 
SynthesisJ 
DSP board 
in PC 
Spectral 
Analysis 
Aitered Formants 
I.: 
 / /F1,F2,F3 
! Alteration. 
Formant Estimation 1 
Magnitude Spectrum 
Figure 1: The apparatus used in the study. 
For each subject in our experiment, we shifted formants along the path defined 
by the (F1,F2,F3) frequencies of a subject's productions of the vowels [i], [], [e], [ae], 
1See [3] for detailed discussion of the methods used in this study. 
40 J. E Houde and M. L Jordan 
and [a]. 2 Figure 2 shows examples of this shifting process in (F1,F2) space for the 
feedback transformations that were used in the study. To, shift formants along the 
subject's [i]-[a] path, we extend the path at both ends and vie number the endpoints 
and vowels to make a path position measure that normalizes the distances between 
vowels. The formants of each speech sound F produced by the subject were then 
re-represented in terms of path projection - the path position of nearest path point 
P, and path deviation - the distance D to this point P. Feedback transformations 
were constructed to alter path projections while preserving path deviations. Two 
different transformations were used. The +2.0 transformation added 2.0 to path 
projections: under this transform, if the subject produced speech sound F (a sound 
near [e]), he heard instead sound F+ (a sound near [a]). The subject could com- 
pensate for this transform and hear sound F only by shifting his production of F to 
F- (a sound near [i]). The -2.0 transformation subtracted 2.0 from path projections: 
under this transformation, if the subject produced F, he heard F-. Thus, in this 
case, the subject could compensate by shifting production to F+. 
beg oO F- 
[i 
[ae] ''ip+ 
[an] , s 
end e6 
F+ 
F1 
(a) +2.0 Transformation 
beg 0 F- 
[i 
: 2 D 
[eh] ' 
[ac] 04 , 
P+' D 
[ah]O 5 
end o 6 
F+ 
F1 
(b) -2.0 Tramsformation 
Figure 2: Feedback transformations used in the study. 
These feedback transformations were used in an experiment in which a subject was 
visually prompted to whisper words with a 300ms target duration. Word promptings 
occurred in groups of ten called epochs. Within each epoch, the first six words came 
from a set of training words and the last four came from a set of testing words. 
The subject heard feedback of his first five word productions in each epoch, while 
masking noise blocked his hearing for his remaining five word productions in the 
epoch. Thus, the subject only heard feedback of his production of the first five 
training words and never heard his productions of the testing words. 
2Where possible, we use standard phonetic symbols for vowel sounds: [i] as in seat, 
[5] as in hit, [e] as in get, [a] as in hat, and [a] as in pop. Where font limitations 
prevent us from using these symbols, we use the alternate notation of [i], [ih], [eh], [ae], 
and [ah], respectively, for the same vowel sounds. 
Adaptation in Speech Motor Control 41 
The experiment lasted 2 hours and consisted of 422 epochs divided over five phases: 
1. A 10 minute warmup phase used to acclimate the subject to the experimen- 
tal setup. 
2. A 17 minute baseline phase used to measure formants of the subject's nor- 
real vowel productions. 
3. A 20 minute ramp phase in which the subject's feedback was increasingly 
altered up to a maximum value. 
4. A I hour training phase in which the subject produced words while the 
feedback was maximally altered. 
5. A 17 minute test phase used to measure formants of the subject's post- 
exposure vowel productions while his feedback was maximally altered. 
By the end of the ramp phase, feedback alteration reached its maximum strength, 
which was +2.0 for half the subjects and -2.0 for the other subjects. In addition, 
all subjects were run in a control experiment in which feedback was never altered. 
The two word sets from which prompted words were selected were both sets of 
CVC words. Training words (in which adaptation was induced) were all bilabials 
with [e] as the vowel (pep, peb, bep, and beb). Testing words (in which 
generalization of the training word adaptation was measured) were divided into two 
subsets, each designed to measure a different type of generalization: (1) context 
generalization words, which had the same vowel [e] as the training words but varied 
the consonant context (peg, gep, and teg); (2) vowel target generalization 
words, which had the same consonant context as the training words but varied the 
vowel (pip,, peep,,pap, and pop). 
Eight male MIT students participated in the study. All were native speakers of 
North American English and all were naive to the purpose of the study. 
3 RESULTS 
To illustrate how we measured compensation and adaptation in the experiments, 
we first show the results for an individual subject. Figure 3 shows (F1,F2) plots of 
response of subject OB in both the adaptation experiment (in which he was exposed 
to the -2.0 feedback transformation) and the control experiment. In each figure, the 
dotted line is OB's [i]-[a] path. 
Figure 3(a) shows OB's compensation responses, which were measured from his 
productions of the training words made when he heard feedback of his whispering. 
The solid arrow labeled -2.0 xform shows how much his mean vowel formants 
changed (testing phase - baseline phase) after being exposed to the -2.0 feedback 
transformation. It shows he shifted his production of [e] to something a bit past 
lee], which corresponds to a path projection change of slightly more than one vowel 
interval towards [a]. Thus, since the path projection shift
