An Information-Theoretic Framework for 
Understanding Saccadic Eye Movements 
Tai Sing Lee * 
Department of Computer Science 
Carnegie Mellon University 
Pittsburgh, PA 15213 
tai@cs. cmu. edu 
Stella X. Yu 
Pobotics Institute 
Carnegie Mellon University 
Pittsburgh, PA 15213 
stella@cnbc. cmu. edu 
Abstract 
In this paper, we propose that information maximization can pro- 
vide a unified framework for understanding saccadic eye move- 
ments. In this framework, the mutual information among the cor- 
tical representations of the retinal image, the priors constructed 
from our long term visual experience, and a dynamic short-term 
internal representation constructed from recent saccades provides 
a map for guiding eye navigation. By directing the eyes to loca- 
tions of maximum complexity in neuronal ensemble responses at 
each step, the automatic saccadic eye movement system greedily 
collects information about the external world, while modifying the 
neural representations in the process. This framework attempts 
to connect several psychological phenomena, such as pop-out and 
inhibition of return, to long term visual experience and short term 
working memory. It also provides an interesting perspective on 
contextual computation and formation of neural representation in 
the visual system. 
1 Introduction 
When we look at a painting or a visual scene, our eyes move around rapidly and 
constantly to look at different parts of the scene. Are there rules and principles that 
govern where the eyes are going to look next at each moment? In this paper, we 
sketch a theoretical framework based on information maximization to reason about 
the organization of saccadic eye movements. 
*Both authors are members of the Center for the Neural Basis of Cognition - a joint 
center between University of Pittsburgh and Carnegie Mellon University. Address: Rm 
115, Mellon Institute, Carnegie Mellon University, Pittsburgh, PA 15213. 
Information-Theoretic Framework for Understanding Saccadic Behaviors 835 
Vision is fundamentally a Bayesian inference process. Given the measurement by 
the retinas, the brain's memory of eye positions and its prior knowledge of the 
world, our brain has to make an inference about what is where in the visual scene. 
The retina, unlike a camera, has a peculiar design. It has a small foveal region 
dedicated to high-resolution analysis and a large low-resolution peripheral region 
for monitoring the rest of the visual field. At about 2.5 ï¿½ visual angle away from 
the center of the fovea, visual acuity is already reduced by a half. When we 'look' 
(foveate) at a certain location in the visual scene, we direct our high-resolution 
fovea to analyze information in that location, taking a snap shot of the scene using 
our retina. Figure 1A-C illustrate what a retina would see at each fixation. It 
is immediately obvious that our retinal image is severely limited - it is clear only 
in the fovea and is very blurry in the surround, posing a severe constraint on the 
information available to our inference system. Yet, in our subjective experience, the 
world seems to be stable, coherent and complete in front of us. This is a paradox 
that have engaged philosophical and scientific debates for ages. To overcome the 
constraint of the retinal image, during perception, the brain actively moves the eyes 
around to (1) gather information to construct a mental image of the world, and (2) 
to make inference about the world based on this mental image. Understanding the 
forces that drive saccadic eye movements is important to elucidating the principles 
of active perception. 
A B C D 
Figure 1. A-C: retinal images in three separate fixations. D: a mental mosaic created by 
integrating the retinal images from these three and other three fixations. 
It is intuitive to think that eye movements are used to gather information. Eye 
movements have been suggested to provide a means for measuring the allocation 
of attention or the values of each kind of information in a particular context [16]. 
The basic assumption of our theory is that we move our eyes around to maximize 
our information intake from the world, for constructing the mental image and for 
making inference of the scene. Therefore, the system should always look for and 
attentively fixate at a location in the retinal image that is the most unusual or the 
most unexplained - and hence carries the maximum amount of information. 
2 Perceptual Representation 
How can the brain decide which part of the retinal image is more unusual? First of 
all, we know the responses of V1 simple cells, modeled well by the Gabor wavelet 
pyramid [3,7], can be used to reconstruct completely the retinal image. It is also 
well established that the receptive fields of these neurons developed in such a way 
as to provide a compact code for natural images [8,9,13,14]. The idea of compact 
code or sparse code, originally proposed by Barlow [2], is that early visual neurons 
capture the statistical correlations in natural scenes so that only a small number 
836 T. S. Lee and S. X. Yu 
of cells out of a large set will be activated to represent a particular scene at each 
moment. Extending this logic, we suggest that the complexity or the entropy of 
the neuronal ensemble response of a hypercolumn in V1 is therefore closely related 
to the strangeness of the image features being analyzed by the machinery in that 
hypercolumn. A frequent event will have a more compact representation in the 
neuronal ensemble response. Entropy is an information measure that captures the 
complexity or the variability of signals. The entropy of a neuronal ensemble in a 
hypercolumn can therefore be used to quantify the strangeness of a particular event. 
A hypercolumn in the visual cortex contains roughly 200,000 neurons, dedicated 
to analyzing different aspects of the image in its 'visual window'. These cells are 
tuned to different spatial positions, orientations, spatial frequency, color disparity 
and other cues. There might also be a certain degree of redundancy, i.e. a number 
of neurons are tuned to the same feature. Thus a hypercolumn forms the funda- 
mental computational unit for image analysis within a particular window in visual 
space. Each hypercolumn contains cells with receptive fields of different sizes, many 
significantly smaller than the aggregated 'visual window' of the hypercolumn. The 
entropy of a hypercolumn's ensemble response at a certain time t is the sum of 
entropies of all the channels, given by, 
H(u(R, t)) = - y. y.p(u(R, v, , O, t)) log2p(u(R, v, , O, t)) 
where u(Re, t) denotes [he responses of all complex cell channels inside the visual 
window R5 of a hypercolumn at time t, computed within a 20 msec time window. 
u(, , 0, t) is the response of a V1 complex cell channel of a particular scale  and 
orientation  at spatial location  at t. p(u(R, v, , O, t)) is the probability of cells 
in that channel within the visual window R2 of the hypercolumn firing v number 
of spikes. v can be computed as 
cell channels, modeled by Gabor 
probability p(u(Re, v, r, O, t)) can 
the variations in spatial position 
the power modulus of the corresponding simple 
wavelets [see 7]. -p(u(_R2, v,r,O,t))-1. The 
be computed at each moment in time because of 
of the receptive fields of similar cell within the 
hypercolumn - hence the 'same' cells in the hypercolumn are analyzing different 
image patches, and also because of the redundancy of cells coding similar features. 
The neurons' responses in a hypercolumn are subject to contextual modulation from 
other hypercolumns, partly in the form of lateral inhibition from cells with similar 
tunings. The net observed effect is that the later part of V1 neurons' response, 
starting at about 80 msec, exhibits differential suppression depending on the spatial 
extent and the nature of the surround stimulus. The more similar the surround 
stimulus is to the center stimuli, and the larger the spatial extent of the 'similar 
surround', the stronger is the suppressive effect [e.g. 6]. Simoncelli and Schwartz 
[15] have proposed that the steady state responses of the cells can be modeled by 
dividing the response of the cell (i.e. modeled by the wavelet coefficient or its power 
modulus) by a weighted combination of the responses of its spatial neighbors in order 
to remove the statistical dependencies between the responses of spatial neighbors. 
These weights are found by minimizing a predictive error between the center signal 
from the surround signals. In our context, this idea of predictive coding [see also 14] 
is captured by the concept of mutual information between the ensemble responses 
of the different hypercolumns as given below, 
I(u(R,t);u(gi,t-dt)) - H(u(R,t))- H(u(R,t)lu(gi,t-dt) ) 
= y. y. (u(R,vt,a,O,t),u(gi,vr,a,O,t)) 
0'0 VR,V 
log2 p(u(R,vR, a,O,t),u(,vn,a,O,t)) 
O, t) ), O, t) )]' 
Information-Theoretic Framework for Understanding $accadic Behaviors 837 
where u(Re, t) is the ensemble response of the hypercolumn in question, and u(f2e, t) 
is the ensemble response of the surrounding hypercolumns. p(u(Re, vR, r, O, t)) is the 
probability that cells of a channel in the center hypercolumn assumes the response 
value vR and p(u(f2e, v, r, O, t)) the probability that cells of a similar channel in the 
surrounding hypercolumns assuming the response value vr. tx i the delay by which 
the surround information exerts its effect on the center hypercolumn. The mutual 
information I can be computed from the joint probability of ensemble responses of 
the center and the surround. 
The steady state responses of the V1 neurons, as a result of this contextual modula- 
tion, are said to be more correlated to perceptual pop-out than the neurons' initial 
responses [5,6]. The complexity of the steady state response in the early visual 
cortex is described by the following conditional entropy, 
H(u(R2, t)lu(g2
