Figure of Merit Training for Detection and 
Spotting 
Eric I. Chang and Richard P. Lippmann 
MIT Lincoln Laboratory 
Lexington, MA 02173-0073, USA 
Abstract 
Spotting tasks require detection of target patterns from a background of 
richly varied non-target inputs. The performance measure of interest for 
these tasks, called the figure of merit (FOM), is the detection rate for 
target patterns when the false alarm rate is in an acceptable range. A 
new approach to training spotters is presented which computes the FOM 
gradient for each input pattern and then directly maximizes the FOM 
using backpropagation. This eliminates the need for thresholds during 
training. It also uses network resources to model Bayesian a posteriori 
probability functions accurately only for patterns which have a 
significant effect on the detection accuracy over the false alarm rate of 
interest. FOM training increased detection accuracy by 5 percentage 
points for a hybrid radial basis function (RBF) - hidden Markov model 
(HMM) wordspotter on the credit-card speech corpus. 
1 INTRODUCTION 
Spotting tasks require accurate detection of target patterns from a background of richly var- 
ied non-target inputs. Examples include keyword spotting from continuous acoustic input, 
spotting cars in satellite images, detecting faults in complex systems over a wide range of 
operating conditions, detecting earthquakes from continuous seismic signals, and finding 
printed text on images which contain complex graphics. These problems share three com- 
mon characteristics. First, the number of instances of target patterns is unknown. Second, 
patterns from background, non-target, classes are varied and often difficult to model accu- 
rately. Third, the performance measure of interest, called the figure of merit (FOM), is the 
detection rate for target patterns when the false alarm rate is over a specified range. 
Neural network classifiers are often used for detection problems by training on target and 
background classes, optionally normalizing target outputs using the background output, 
1019 
1020 Chang and Lippmann 
PUTATIVE HITS 
l A l 
I NORMALIZATION AND THRESHOLDING I 
t t 
CLASSIFIER 
INPUT PATTERN 
Figure 1. Block diagram of a spotting system. 
and thresholding the resulting score to generate putative hits, as shown in Figure 1. Putative 
hits in this figure are input patterns which generate normalized scores above a threshold. 
We have developed a hybrid radial basis function (RBF) - hidden Markov model (HMM) 
keyword spotten This wordspotter was evaluated using the NIST credit card speech data- 
base as in (Rohlicek, 1993, Zeppenfeld, 1993) using the same train/evaluation split of the 
training conversations as was used in (Zeppenfeld, 1993). The system spots 20 target key- 
words, includes one general filler class, and uses a Viterbi decoding backtrace as described 
in (Lippmann, 1993) to backpropagate errors over a sequence of input speech frames. The 
performance of this spotting system and its improved versions is analyzed by plotting de- 
tection versus false alarm rate curves as shown in Figure 2. These curves are generated by 
adjusting the classifier output threshold to allow few or many putative hits. Wordspotter pu- 
tative hits used to generate Figure 2 correspond to speech frames when the difference be- 
tween the cumulative log Viterbi scores in output HMM nodes of word and filler models is 
above a threshold. The FOM for this wordspotter is defined as the average keyword detec- 
tion rate when the false alarm rate ranges from 1 to 10 false alarms per keyword per hour. 
The 69.7% figure of merit for this system means that 69.7% of keyword occurrences are 
detected on the average while generating from 20 to 200 false alarms per hour of input 
speech. 
2 PROBLEMS WITH BACKPROPAGATION TRAINING 
Neural network classifiers used for spotting tasks can be trained using conventional back- 
propagation procedures with 1 of N desired outputs and a squared error cost function. This 
approach to training does not maximize the FOM because it attempts to estimate Bayesian 
a posteriori probability functions accurately for all inputs even if a particular input has little 
effect on detection accuracy at false alarm rates of interest. Excessive network resources 
may be allocated to modeling the distribution of common background inputs dissimilar 
from targets and of high-scoring target inputs which are easily detected. This problem can 
be addressed by training only when network outputs are above thresholds. This approach is 
problematic because it is difficult to set the threshold for different keywords, because using 
fixed target values of 1.0 and 0.0 requires careful normalization of network output scores to 
prevent saturation and maintain backpropagation effectiveness, and because the gradient 
calculated from a fixed target value does not reflect the actual impact on the FOM. 
Figure of Merit Training for Detection and Spotting 1021 
Figure 2. 
z 
o 
lOO 
90 
80 
70 
60 
50 
40 
30 
20 
lO 
o 
o 
A SPLIT OF CREDIT-CARD 
TRAINING DATA 
.  FOM BACK-PROP (FOM: 69.7%) 
/ 
........ EMBEDDED REESTIMATION (FOM: 64.5%) 
ISOLATED WORD TRAIN (FOM: 62.5%) 
2 4 6 8 10 
FALSE ALARMS PER KW PER HR 
Detection vs. false alarm rate curve for a 20-word hybrid wordspotter. 
Figure 3 shows the gradient of true hits and false alarms when target values are set to be 1.0 
for true hits and 0.0 for false alarms, the output unit is sigmoidal, and the threshold for a 
putative hit is set to roughly 0.6. The gradient is the derivative of the squared error cost with 
respect to the input of the sigmodal output unit. As can be seen, low-scoring hits or false 
alarms that may affect the FOM are ignored, the gradient is discontinuous at the threshold, 
the gradient does not fall to zero fast enough at high values, and the relative sizes of the hit 
and false alarm gradients do not reflect the true effect of a hit or false alarm on the FOM. 
3 FIGURE OF MERIT TRAINING 
A new approach to training a spotter system called figure of merit training is to directly 
compute the FOM and its derivative. This derivative is the change in FOM over the change 
in the output score of a putative hit and can be used instead of the derivative of a squared- 
error or other cost function during training. Since the FOM is calculated by sorting true hits 
and false alarms separately for each target class and forming detection versus false alarm 
curves, these measures and their derivatives can not be computed analytically. Instead, the 
FOM and its derivative are computed using fast sort routines. These routines insert a new 
THRESHOLD 
il GRADIENT 
0.2 
z 
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 
OUTPUT VALUE 
Figure 3. The gradient for a sigmoid output unit when the target value for true hits is set to 
1.0 and the target value for false alarms is set to 0.0. 
1022 Chang and Lippmann 
putative hit into an already sorted list and calculate the change in the FOM caused by that 
insertion. The running putative hit list used to compute the FOM is updated after every new 
putative hit is observed and it must contain all putative hits observed during the most recent 
past training cycle through all training patterns. The gradient estimate is smoothed over 
nearby putative hit scores to account for the quantized nature of detection versus false alarm 
rate curves. 
Figure 4 shows plots of linearly scaled gradients for the 20-word hybrid wordspotter. Each 
value on the curve represents the smoothed change in the FOM that occurs when a single 
hit or false alarm with the specified normalized log output score is inserted into the current 
putative hit list. Gradients are positive for putative hits corresponding to true hits and neg- 
ative for false alarms. They also fall off to zero for putative hits with extremely high or low 
scores. Shapes of these curves vary across words. The relative importance of a hit or false 
alarm, the normalized output score which results in high gradient values, and the shape of 
the gradient curve varies. Use of a squared error or other cost function with sigmoid output 
nodes would not generate this variety of gradients or automatically identify the range of pu- 
tative hit scores where gradients should be high. Application of FOM training requires only 
the gradients shown in these curves with no supplementary thresholds. Patterns with low 
and high inputs will have a minimal effect during training without using thresholds because 
they produce gradients near zero. 
Different keywords have dramatically different gradients. For example, credit-card is long 
and the detection rate is high. The overall FOM thus doesn't change much if more true hits 
are found. A high scoring false alarm, however, decreases the FOM drastically. There is thus 
a large negative gradient for false alarms for credit-card. The keywords account and check 
are usually short in duration and thus more difficult to detect, thus any increase in number 
of true hits strongly increases the overall FOM. On the other hand, since in this database, 
the words account and check occur much less frequently than credit-card, a high scoring 
false alarm for the words account and check has less impact on the overall FOM. The gra- 
dient for false alarms for these words is thus correspondingly smaller. Comparing the 
curves in Figure 3 with the fixed prototypical curve in Figure 4 demonstrates the dramatic 
differences in gradients that occur when the gradient is calculated to maximize the FOM 
directly instead of using a threshold with sigmoid output nodes. 
ACCOUNT 
0.8 
z 
 -o a 
Figure 4. 
FA 
CHECK 
-0.6 
-0.9 i I i I i I i , I ,  , I , 
-100 0 100 200 300-100 0 100 200 300-100 
PUTATI VE HIT SCORE 
CREDIT-CARD 
HIT 
0 100 00 300 
Figure of merit gradients computed for true hits (HIT) and false alarms (FA) 
with scores ranging from -100 to 300 for the keywords account, check, and 
c
