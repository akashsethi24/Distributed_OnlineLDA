A Study of Parallel Perturbative 
Gradient Descent 
D. Lippe* J. Alspector 
Bellcore 
Morristown, NI 07960 
Abstract 
We have continued our study of a parallel perturbative learning 
method [Alspector et al., 1993] and implications for its implemen- 
tation in analog VLSI. Our new results indicate that, in most cases, 
a single parallel perturbation (per pattern presentation) of the func- 
tion parameters (weights in a neural network) is theoretically the 
best course. This is not true, however, for certain problems and 
may not generally be true when faced with issues of implemen- 
tation such as limited precision. In these cases, multiple parallel 
perturbations may be best as indicated in our previous results. 
1 INTRODUCTION 
Motivated by difficulties in analog VLSI implementation of back-propagation 
[Rumelhart et al., 1986] and related algorithms that calculate gradients based on 
detailed knowledge of the neural network model, there were several similar re- 
cent papers proposing to use a parallel [Alspector et al., 1993, Cauwenberghs, 1993, 
Kirk et al., 1993] or a semi-parallel [Flower and Iabri, 1993] perturbafire technique 
which has the property that it measures (with the physical neural network) rather 
than calculates the gradient. This technique is closely related to methods of stochas- 
tic approximation [Kushner and Clark, 1978] which have been investigated recently 
by workers in fields other than neural networks. [Spall, 1992] showed that averaging 
multiple parallel perturbations for each pattern presentation may be asymptotically 
preferable in the presence of noise. Our own results [Alspector et al., 1993] indicated 
*Present address: Dept. of EECS; MIT; Cambridge, MA 02139; dalippe@mit.edu 
804 D. Lippe, J. Alspector 
that multiple parallel perturbations are also preferable when only limited precision 
is available in the learning rate which is realistic for a physical implementation. In 
this work we have investigated whether multiple parallel perturbations for each pat- 
tern are non-asymptotically preferable theoretically (without noise). We have also 
studied this empirically, to the limited degree that simulations allow, by removing 
the precision constraints of our previous work. 
2 
GRADIENT ESTIMATION BY PARALLEL WEIGHT 
PERTURBATION 
Following our previous work, one can estimate the gradient of the error, E(ff), with 
respect to any weight, wi, by perturbing wi by 5wi and measuring the change in 
the output error, 5E, as the entire weight vector, 7, except for component wi is 
held constant. 
E E(a + ,) - (a) 
5w 5wi 
We now consider perturbing all weights simultaneously. However, we wish to have 
the perturbation vector, 5, chosen uniformly on a hypercube. Note that this 
requires only a random sign multiplying a fixed perturbation and is natural for 
VLSI using a parallel noise generator [Alspector et al., 1991]. 
This leads to the approximation (ignoring higher order terms) 
6E OE 
5wi 
(1) 
The last term has expectation value zero for random and independently distributed 
5wi. The weight change rule 
5E 
Awi= -? Swi ' 
where 7 is a learning rate, will follow the gradient on the average but with consid- 
erable noise. 
For each pattern, one can reduce the variance of the noise term in (1) by repeating 
the random parallel perturbation many times to improve the statistical estimate. If 
we average over P perturbations, we have 
= ;5? = Ow, + 
p=l ' p=l ji 
where p indexes the perturbation number. 
A Study of Parallel Perturbative Gradient Descent 805 
3 THEORETICAL RELATIVE EFFICIENCY 
3.1 BACKGROUND 
Spall [Spall, 1992] shows in an asymptotic sense that multiple perturbations may be 
faster if only a noisy measurement of E(ff) is available, and that one perturbation 
is superior otherwise. His results are asymptotic in that they compare the rate of 
convergence to the local minimum if the algorithms run for infinite time. Thus, his 
results may only indicate that 1 perturbation is superior close to a local minimum. 
Furthermore, his result implicitly assumes that P perturbations per weight update 
takes P times as long as 1 perturbation per weight update. Experience shows 
that the time required to present patterns to the hardware is often the bottleneck 
in VLSI implementations of neural networks [Brown et al., 1992]. In a hardware 
implementation of a perturbative learning algorithm, a few perturbations might be 
performed with no time penalty while waiting for the next pattern presentation. 
The remainder of this section sketches an argument that multiple perturbations 
may be desirable for some problems in a non-asymptotic sense, even in a noise 
free environment and under the assumption of a multiplicative time penalty for 
performing multiple perturbations. On the other hand, the argument also shows 
that there is little reason to believe in practice that any given problem will be 
learned more quickly by multiple perturbations. Space limitations prevent us from 
reproducing the full argument and discussion of its relevance which can be found 
in [Lippe, 1994]. 
The argument fixes a point in weight space and considers the expectation value of 
the change in the error induced by one weight update under both the 1 pertur- 
bation case and the multiple perturbation case. [Cauwenberghs, 1994] contains a 
somewhat related analysis of the relative speed of one parallel perturbation and 
weight perturbation as described in [Jabri and Flower, 1991]. The analysis is only 
truly relevant far from a local minimum because close to a local minimum the vari- 
ance of the change of the error is as important as the mean of the change of the 
error. 
3.2 Calculations 
If P is the number of perturbations, then our learning rule is 
Awi -' --7  5E(P) 
If W is the number of weights, then AE, cMculted to second order in V, is 
= + � 
Expanding E (f) to second order in  (where 5wi = ), we obtn 
w w w 
E 5w(f) 1 2E 5w(f)5 (f) 
= + . (4) 
806 D. Lippe, J. Alspector 
[Lippe, 1994] shows that combining (2)-(4), retaining only first and second order 
terms, and taking expectation values gives 
where 
< zxs >= -.x + 7(r + 
(5) 
Note that first term in (5) is strictly less than or equal to 0 since X is a sum of 
squares x. The second term, on the other hand, can be either positive or negative. 
Clearly then a sufficient condition for learning is that the first term dominates the 
second term. By making ? small enough, we can guarantee that learning occurs. 
Strictly speaking, this is not a necessary condition for learning. However, it is 
important to keep in mind that we are only focusing on one point in weight space. If, 
at this point in weight space, < AE > is negative but the second term's magnitude 
is close to the first term's magnitude, it is not unlikely that at some other point 
in weight space < AE > will be positive. Thus, we will assume that for efficient 
learning to occur, it is necessary that r/ be small enough to make the first term 
dominate the second term. 
Assume that some problem can be successfully learned with one perturbation, at 
learning rate r/(1). Then the first order term in (5) dominates the second order 
terms. Specifically, at any point in weight space we have, for some large constant 
W(1)X >_ W(1)1� q- Zl 
In order to learn with P perturbations, we apparently need 
w(P)X _> w(P) I Y + PZ I (6) 
P p 
The assumption that the first order term of (5) dominates the second order terms 
P Thus, learning is more eft- 
implies that convergence time is proportional to ,--(p-. 
cient in the multiple perturbation case if 
> (1) (7) 
P 
It turns out, as shown in [Lippe, 1994] that the conditions (6) and (7) can be met 
simultaneously with multiple perturbations if  _> 2. 
Xlf we are at a stationary point then the first term in (5) is O. 
A Study of Parallel Perturbative Gradient Descent 807 
It is shown in [Lippe, 1994], by using the fact that the Hessian of a quadratic 
function with a minimum is positive semi-definite, that if E is quadratic and has 
a minimum, then Y and Z have the same sign (and hence   2). Any well 
behaved function acts quadratically sufficiently close to a stationary point. Thus, 
we can not get  AE  more than a factor of P larger by using P perturbations 
near local minima of well behaved functions. Although, as mentioned earlier, we 
are entirely ignoring the issue of the variance of AE, this may be some indication 
of the asymptotic superiority of 1 perturbation. 
3.3 Discussion of Results 
The result that multiple perturbations are superior when -- _ 2 may seem some- 
what mysterious. It sheds some light on our answer to rewrite (5) as 
Y 
< >= + + z). 
For strict gradient descent, the corresponding equation is 
< AE >- AE - -7X + 72Z. 
The difference between strict gradient descent and perturbative gradient descent, 
on average, is the second order term 72-. This is the term which results from not 
following the gradient exactly, and it obviously goes down as P goes up and the 
gradient measurement becomes more accurate. Thus, if Z and Y have different 
signs, P can be used to make the second order term disappear. There is no way 
to know whether this situation will occur frequently. Furthermore, it is important 
to keep in mind that if Y is negative and Z is positive, then raising P may make 
the magnitude of the second order term smaller, but it makes the term itself larger. 
Thus, in general, there is little reason to believe that multiple perturbations will 
help with a randomly chosen problem. 
An example where multiple perturbations help is when we are at a point where 
the error surface is convex along the gradient direction, and concave in most other 
directions. Curvature due to second derivative terms in Y and Z help when the 
gradient direction is followed, but can hurt when we stray from the gradient. In 
this case, Z  0 and possibly Y  0, so multiple perturbations might be preferable 
in order 
