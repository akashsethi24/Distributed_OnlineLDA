A Generic Approach for Identification of 
Event Related Brain Potentials via a 
Competitive Neural Network Structure 
Daniel H. Lange 
Department of Electrical Engineering 
Technion -IIT 
Hifa 32000 
Israel 
e-mail: lange@turbo.technion.ac.il 
Hava T. Siegelmann 
Department of Industrial Engineering 
Technion -IIT 
Hifa 32000 
Israel 
e-mail: iehavaie.technion.ac.il 
Hillel Pratt 
Evoked Potential Laboratory 
Technion- IIT 
Haifa 32000 
Israel 
e-mail: hilleltx.t echnion.ac.il 
Gideon F. Inbar 
Department of Electrical Engineering 
Technion -IIT 
Haifa 32000 
Israel 
e-mail: inbaree.technion.ac.il 
Abstract 
We present a novel generic approach to the problem of Event Related 
Potential identification and classification, based on a competitive Neu- 
ral Net architecture. The network weights converge to the embedded 
signal patterns, resulting in the formation of a matched filter bank. 
The network performance is analyzed via a simulation study, exploring 
identification robustness under low SNR conditions and compared to 
the expected performance from an information theoretic perspective. 
The classifier is applied to real event-related potential data recorded 
during a classic odd-ball type paradigm; for the first time, within- 
session variable signal patterns are automatically identified, dismiss- 
ing the strong and limiting requirement of a-priori stimulus-related 
selective grouping of the recorded data. 
902 D. H. Lange, H. T. Siegelmann, H. Pratt and G. F. Inbar 
1 
INTRODUCTION 
1.1 EVENT RELATED POTENTIALS 
Ever since Hans Berger's discovery that the electrical activity of the brain can be 
measured and recorded via surface electrodes mounted on the scalp, there has been 
major interest in the relationship between such recordings and brain function. The 
first recordings were concerned with the spontaneous electrical activity of the brain, 
appearing in the form of rhythmic voltage oscillations, which later received the term 
electroencephalo#ram or EEG. Subsequently, more recent research has concentrated on 
time-locked brain activity, related to specific events, external or internal to the subject. 
This time-locked activity, referred to also as Event Related Potentials (ERP's), is 
regarded as a manifestation of brain processes related to preparation for or in response 
to discrete events meaningful to the subject. 
The ongoing electrical activity of the brain, the EEG, is comprised of relatively slow 
fluctuations, in the range of 0.1 - 100 Hz, with magnitudes of 10 - 100 uV. ERP's 
are characterized by overlapping spectra with the EEG, but with significantly lower 
magnitudes of 0.1 - 10 uV. The unfavorable Signal to Noise Ratio (SNR) requires 
filtering of the raw signals to enable analysis of the time-locked signals. The common 
method used for this purpose is signal averaging, synchronized to repeated occurrences 
of a specific event. Averaging-based techniques assume a deterministic signal within 
the averaged session, and thus signal variability can not be modeled unless a-priori 
stimulus- or response-based categorization is available; it is the purpose of this paper to 
provide an alternative working method to enhance conventional averaging techniques, 
and thus facilitating identification and analysis of variable brain responses. 
1.2 COMPETITIVE LEARNING 
Competitive learning is a well-known branch of the general unsupervised learning 
theme. The elementary principles of competitive learning are (Rumelhart & Zipset, 
1985): (a) start with a set of units that are all the same except for some randomly 
distributed parameter which makes each of them respond slightly differently to a set 
of input patterns, (b) limit the strength of each unit, and (c) allow the units to com- 
pete in some way for the right to respond to a given subset of inputs. Applying these 
three principles yields a learning paradigm where individual units learn to specialize 
on sets of similar patterns and thus become feature detectors. Competitive learning 
is a mechanism well-suited for regularity detection (Haykin, 1994), where there is a 
population of input patterns each of which is presented with some probability. The 
detector is supposed to discover statistically salient features of the input population, 
without a-priori categorization into which the patterns are to be classified. Thus the 
detector needs to develop its own featural representation of the population of input 
patterns capturing its most salient features. 
1.3 PROBLEM STATEMENT 
The complicated, generally unknown relationships between the stimulus and its asso- 
ciated brain response, and the extremely low SNR of the brain responses which are 
practically masked by the background brain activity, make the choice of a self orga- 
nizing structure for post-stimulus epoch analysis most appropriate. The competitive 
network, having the property that its weights converge to the actual embedded sig- 
nal patterns while inherently averaging out the additive background EEG, is thus an 
evident choice. 
A Generic Approach for Identification of Event Related Brain Potentials 903 
2 THE COMPETITIVE NEURAL NETWORK 
2.1 THEORY 
The common architecture of a competitive learning system appears in Fig. 1. The 
system consists of a set of hierarchically layered neurons in which each layer is connected 
via excitatory connections with the following layer. Within a layer, the neurons are 
divided into sets of inhibitory clusters in which all neurons within a cluster inhibit 
all other neurons in the cluster, which results in a competition among the neurons to 
respond to the pattern appearing on the previous layer. 
Let toji denote the synaptic weight connecting input node i to neuron j. A neuron 
learns by shifting synaptic weights from its inactive to active input nodes. If a neuron 
does not respond to some input pattern, no learning occurs in that neuron. When a 
single neuron wins the competition, each of its input nodes gives up some proportion of 
its synaptic weight, which is distributed equally among the active input nodes, fulfilling: 
- toji= 1. According to the standard competitive learning rule, for a winning neuron 
to an input vector i, the change Atoji is defined by: Atoji -- (i - toil), where 
 is a learning rate coefficient. The effect of this rule is that the synaptic weights 
of a winning neuron are shifted towards the input pattern; thus assuming zero-mean 
additive background EEG, once converged, the network operates as a raaiehed filler 
bank classifier. 
2.2 MATCHED FILTERING 
Fom an information theoretic perspective, once the network has converged, our clas- 
siftcation problem coincides with the general detection problem of known signals in 
additive noise. For simplicity, we shall limit the discussion to the binary decision 
problem of a known signal in additive white Gaussian noise, expandable to the M-ary 
detection in colored noise (Van Trees, 1968). 
Adopting the common assumption of EEG and ERP additivity (Gevins, 1984), and 
distinct signal categories, the competitive NN weights inherently converge to the general 
signal patterns embedded within the background brain activity; therefore the converged 
network operates as a matched /ilter bank. Assuming the simplest binary decision 
problem, the received signal under one hypothesis consists of a completely known signal, 
Vs(l), representing the EP, corrupted by an additive zero-mean Gaussian noise to(t) 
with variance 2; the received signal under the other hypothesis consists of the noise 
to(t) alone. Thus: 
= o < < 
m: = + o < < T 
For convenience we assume that f s2(t)dt - 1, so that//7 represents the signal energy. 
The problem is to observe r(t) over the interval [0, T] and decide whether Ho or H 
is true. It can be shown that the matched tilter is the optimal detector, its impulse 
response being simply the signal reversed in time and shifted: 
k(r) ---- s(T- r) (1) 
Assuming that there is no a-priori knowledge of the probability of signal presence, the 
total probability of error depends only on the SNR and is given by (Van Trees, 1968): 
Fig. 2 presents the probability of true detection: (a) as a function of SNR, for minimized 
error probability, and (b) as a function of the probability of false detection. These 
904 D. H. Lange, H. T. Siegelmann, H. Pratt and G. E Inbar 
results are applicable to our detection problem assuming approximate Gaussian EEG 
characteristics (Gersch, 1970), or optimally by using a pre-whitening approach (Lange 
et. al., 1997). 
Layer 2 
Inhibitory Cluters 
INPUT PATFER N 
Figure 1: The architecture of a compet- 
itive learning structure: learning takes 
place in hierarchically layered units, 
presented as filled (active) and empty 
(inactive) dots. 
Probabtfity of True Detection with Minimum Error 
_o.8 
o;[ 
-40 
SNR In 
Detection1 performance: SNR = +20, +10, 0, -10 and -20 dB 
Pro. ability of False Detection 
Figure 2: Detection performance. Top: 
probability of detection as a function of 
the SNR. Bottom: detection character- 
istics. 
4O 
2.3 NETWORK TRAINING AND CONVERGENCE 
Our net includes a 300-node input layer and a competitive layer consisting of single- 
layered competing neurons. The network weights are initialized with random values 
and trained with the standard competitive learning rule, applied to the normalized 
input vectors: 
(3) 
The training is applied to the winning neuron of each epoch, while increasing the bias of 
the frequently winning neuron to gradually reduce its chance of winning consecutively 
(eliminating the dead neuron effect (Freeman & Skapura, 1992)). Symmetrically, its 
bias is reduced with the winnings of other neurons. 
In order to evaluate the network performance, we explore its convergence by analyzing 
the learning process via the continuously adapting weights: 
pj(n) = ( .. Aw]i ; j = 1,2,...,C (4) 
where C represents the pre-defined number of categories. We define a set of classifica- 
