Spatial Representations in the Parietal 
Cortex May Use Basis Functions 
Alexandre Pouget 
alex@salk.edu 
Terrence J. Sejnowski 
terry@salk.edu 
Howard Hughes Medical Institute 
The Salk Institute 
La Jolla, CA 92037 
and 
Department of Biology 
University of California, San Diego 
Abstract 
The parietal cortex is thought to represent the egocentric posi- 
tions of objects in particular coordinate systems. We propose an 
alternative approach to spatial perception of objects in the pari- 
etal cortex from the perspective of sensorimotor transformations. 
The responses of single parietal neurons can be modeled as a gaus- 
sian function of retinal position multiplied by a sigmoid function 
of eye position, which form a set of basis functions. We show here 
how these basis functions can be used to generate receptive fields 
in either retinotopic or head-centered coordinates by simple linear 
transformations. This raises the possibility that the parietal cortex 
does not attempt to compute the positions of objects in a partic- 
ular frame of reference but instead computes a general purpose 
representation of the retinal location and eye position from which 
any transformation can be synthesized by direct projection. This 
representation predicts that hemineglect, a neurological syndrome 
produced by parietal lesions, should not be confined to egocentric 
coordinates, but should be observed in multiple frames of reference 
in single patients, a prediction supported by several experiments. 
158 Alexandre Pouget, Terrence J. Sejnowski 
I Introduction 
The temporo-parietal junction in the human cortex and its equivalent in monkeys, 
the inferior parietal lobule, are thought to play a critical role in spatial perception. 
Lesions in these regions typically result in a neurological syndrome, called hemine- 
glect, characterized by a lack of motor exploration toward the hemispace contralat- 
eral to the site of the lesion. As demonstrated by Zipser and Andersen [11], the 
responses of single cells in the monkey parietal cortex are also consistent with this 
presumed role in spatial perception. 
In the general case, recovering the egocentric position of an object from its multiple 
sensory inputs is difficult because of the multiple reference frames that must be 
integrated. In this paper, we consider a simpler situation in which there is only 
visual input and all body parts are fixed but the eyes, a condition which has been 
extensively used for neurophysiological studies in monkeys. In this situation, the 
head-centered position of an object, , can be readily recovered from the retinal 
location,/, and current eye position,/, by vector addition: 
--+ (1) 
If the parietal cortex contains a representation of the egocentric position of objects, 
then one would expect to find a representation of the vectors, , associated with 
these objects. There is an extensive literature on how to encode a vector with 
a population of neurons, and we first present two schemes that have been or are 
used as working hypothesis to study the parietal cortex. The first scheme involves 
what is typically called a computational map, whereas the second uses a vectorial 
representation [9]. 
This paper shows that none of these encoding schemes accurately accounts for all 
the response properties of single cells in the parietal cortex. Instead, we propose 
an alternative hypothesis which does not aim at representing  per se; instead, the 
inputs/ and E are represented in a particular basis function representation. We 
show that this scheme is consistent with the way parietal neurons respond to the 
retinal position of objects and eye position, and we give computational arguments 
for why this might be an efficient strategy for the cortex. 
2 Maps and Vectorial Representations 
One way to encode a two-dimensional vector is to use a lookup table for this vector 
which, in the case of a two-dimensional vector, would take the form of a two- 
dimensional neuronal map. The parietal cortex may represent the egocentric loca- 
tion of object, , in a similar fashion. This predicts that the visual receptive field 
of parietal neurons have a fixed position with respect to the head (figure lB). The 
work of Andersen et al. (1985) have clearly shown that this is not the case. As 
illustrated in figure 2A, parietal neurons have retinotopic receptive fields. 
In a vectorial representation, a vector is encoded by N units, each of them coding 
for the projection of the vector along its preferred direction. This entails that the 
activity, h, of a neuron is given by: 
Spatial Representations in the Parietal Cortex May Use Basis Functions 159 
A B Map Representation C Vectorial Representation 
V 
y 
Vy 
V 
00900 
o o 
o o 
o o 
-10 40 0 90 180 
0 (Degree) 
Figure 1: Two neural representations of a vector. A) A vector 17 in cartesian and 
polar coordinates. B) In a map representation, units have a narrow gaussian tuning 
to the horizontal and vertical components of V. Moreover, the position of the peak 
response is directly related to the position of the units on the map. C) In a vectorial 
representation, each unit encodes the projection of  along its preferred direction 
(central arrows). This results in a cosine tuning to the vector angle, 0 . 
l//a is usually called the preferred direction of the cells because the activity is max- 
imum whenever 0 = 0; that is, when  points in the same direction as l//a. Such 
neurons have a cosine tuning to the direction of the egocentric location of objects, 
as shown also in figure 1C. 
Cosine tuning curves have been reported in the motor cortex by Georgopoulos et 
al. (1982), suggesting that the motor cortex uses a vectorial code for the direction 
of hand movement in extrapersonal space. The same scheme has been also used by 
Goodman and Andersen (1990), and Touretzski et al. (1993) to model the encoding 
of egocentric position of objects in the parietal cortex. Touretzski et al. (1993) called 
their representation a sinusoidal array instead of a vectorial representation. 
Using Eq. 1, we can rewrite Eq. 2: 
(3) 
This second equation is linear in 1 and/ and uses the same vectors, lA/,, in both 
dot products. This leads to three important predictions: 
1) The visual receptive fields of parietal neurons should be planar. 
2) The eye position receptive fields of parietal neurons should also be planar; that 
is, for a given retinal positions, the response of parietal neuron should be a linear 
function of eye position. 
160 Alexandre Pouget, Terrence J. Sejnowski 
A 
B 
60[ .-e-ex = o A 
.10 ? I  , ,    , 
40 -20 0 20 40 
Retinal Position (Deg) 
Figure 2: Typical response of a neuron in the parietal cortex of a monkey. A) Visual 
receptive field has a fixed position on the retina, but the gain of the response is 
modulated by eye position (e). (Adpated from Andersen et al., 1085) B) Example 
of an eye position receptive field, also called gain field, for a parietal cell. The nine 
circles indicate the amplitude of the response to an identical retinal stimulation for 
nine different eye positions. Outer circles show the total activity, whereas black 
circles correspond to the total response minus spontaneous activity prior to visual 
stimulation. (Adpated from Zipser et al., 1088) 
$) The preferred direction for retinal location and eye position should be identical. 
For example, if the receptive field is on the right side of the visual field, the gain 
field should also increase with eye positon to the right side. 
The visual receptive fields and the eye position gain fields of single parietal neurons 
have been extensively studied by Andersen et al. [2]. In most cases, the visual 
receptive fields were bell-shaped with one or several peaks and an average radius 
of 22 degrees of visual angle [1], a result that is clearly not consistent with the 
first prediction above. We show in figure 2A an idealized visual receptive field of 
a parietal neuron. The effect of eye position on the visual receptive field is also 
illustrated. The eye position clearly modulates the gain of the visual response. 
The prediction regarding the receptive field for eye position has been borne out by 
statistical analysis. The gain fields of 80% of the cells had a planar component [1, 
11]. One such gain field is shown in figure 2B. 
There is not enough data available to determine whether or not the third prediction 
is valid. However, indirect evidence suggests that if such a correlation exists between 
preferred direction for retinal location and for eye position, it is probably not strong. 
Cells with opposite preferred directions [2, $] have been observed. Purthermore, 
although each hemisphere represents all possible preferred eye position directions, 
there is a clear tendency to overrepresent the contralateral retinal hemifield [1]. 
In conclusion, the experimental data are not fully consistent with the predictions of 
the vectorial code. The visual receptive fields, in particular, are strongly nonlinear. 
If these nonlinearities are computationally neutral, that is, they are averaged out in 
subsequent stages of processing in the cortex, then the vectorial code could capture 
Spatial Representations in the Parietal Cortex May Use Basis Functions 161 
the essence of what the parietal cortex computes and, as such, would provide a valid 
approximation of the neurophysiological data. We argue in the next section that 
the nonlinearities cannot be disregarded and we present a representational scheme 
in which they have a central computational function. 
3 Basis Function Representation 
3.1 
Sensorimotor Coordination and Nonlinear Function 
Approximation 
The function which specified the pattern of muscle activities required to move a 
limb, or the body, to a specific spatial location is a highly nonlinear function of the 
sensory inputs. The cortex is not believed to specify patterns of muscle activation, 
but the intermediate
