794 
A 'Neural' Network that Learns to Play Backgammon 
G. Tesauro 
Center for Complex Systems Research, University of Illinois 
at Urbana-Champaign, 508 S. Sixth St., Champaign, IL 61820 
T. J. $ejnowski 
Biophysics Dept., Johns Hopkins University, Baltimore, MD 21218 
ABSTRACT 
We describe a class of connectionist networks that have learned to play back- 
gammon at an intermediate-to-advanced level. The networks were trained by a 
supervised learning procedure on a large set of sample positions evaluated by a 
human expert. In actual match play against humans and conventional computer 
programs, the networks demonstrate substantial ability to generalize on the basis of 
expert knowledge. Our study touches on some of the most important issues in net- 
work learning theory, including the development of efficient coding schemes and 
training procedures, scaling, generalization, the use of real-valued inputs and out- 
puts, and techniques for escaping from local minima. Practical applications in 
games and other domains are also discussed. 
INTRODUC'ON 
A potentially quite useful testing ground for studying issues of knowledge representation and 
learning in networks can be found in the domain of game playing. Board games such as chess, go, 
backgammon, and Othello entail considerable sophistication and complexity at the advanced level, 
and mastery of expert concepts and strategies often takes years of intense study and practice for 
humans. However, the complexities in board games are embedded in relatively clean structured 
tasks with well-defined rules of play, and well-defined criteria for success and failure. This makes 
them amenable to automated play, and in fact most of these games have been extensively studied 
with conventional computer science techniques. Thus, direct comparisons of the results of network 
leaming can be made with more conventional approaches. 
In this paper, we describe an application of network leaming to the game of backgammon. 
Backgammon is a difficult board game which appears to be well-suited to neural networks, because 
the way in which moves are selected is primarily on the basis of pattern-recognition or judgemen- 
tal reasoning, as opposed to explicit look-ahead, or tree-search computations. This is due to 
the probabilistic dice rolls in backgammon, which greatly expand the branching faclor m each ply in 
the search (to over 400 in typical positions). 
Our leaming procedure is a supervised one  that requires a database of positions ,and moves 
that have been evaluated by an expert teacher. In contrast, in an unsupervised procedure 2-4 
leaming would be based on the consequences of a given move (e.g., whether it led to a won or lost 
position), and explicit teacher instructions would not be required. However, unsupervised learning 
procedures thus far have been much less efficient at reaching high levels of performance than super- 
vised leaming procedures. In part, this advantage of supervised leaming can be traced to the higher 
� American Institute of Physics 1988 
795 
quantity and quality of information available from the teacher. 
Studying a problem of the scale and complexity of backgammon leads one to confront impor- 
tant general issues in network learning. Amongst the most important are scaling and generalization. 
Most of the problems that have been examined with connectionist leaming algorithms are relatively 
small scale and it is not known how well they will perform on much larger problems. Generalization 
is a key issue in learning to play backgammon since it is estimated that there are 102� possible board 
positions, which is far in excess of the number of examples that can be provided during training. In 
this respect our study is the most severe test of generalization in any connectionist network to date. 
We have also identified in this study a novel set of special techniques for training the network 
which were necessary to achieve good performance. A training set based on naturally occurring or 
random examples was not sufficient to bring the network to an advanced level of performance. 
Intelligent data-base design was necessary. Performance also improved when noise was added to 
the training procedure under some circumstances. Perhaps the most important factor in the success 
of the network was the method of encoding the input information. The best performance was 
achieved when the raw input information was encoded in a conceptually significant way, and a cer- 
tain number of pre-computed features were added to the raw information. These lessons may also 
be useful when connectionist learning algorithms are applied to other difficult large-scale problems. 
NETWORK AND DATA BASE SET-LIP 
Our network is trained to select moves (i.e. to produce a real-valued score for any given 
move), rather than to generate them. This avoids the difficulties of having to teach the network the 
concept of move legality. Instead, we envision our network operating in tandem with a pre- 
processor which would take the board position and roll as input, and produce all legal moves as out- 
put. The network would be trained to score each move, and the system would choose the move with 
the highest network score. Furthermore, the network is trained to produce relative scores for each 
move, rather than an absolute evaluation of each final position. This approach would have greater 
sensitivity in distinguishing between close alternatives, and corresponds more closely to the way 
humans actually evaluate moves. 
The current data base contains a total of 3202 board positions, taken from various sources 5. 
For each position there is a dice roll and a set of legal moves of that roll from that position. The 
moves receive commentary from a human expert in the form of a relative score in the range [- 
100,+100], with +100 representing the best possible move and -100 representing the worst possible 
move. One of us (G.T.) is a strong backgammon player, and played the role of human expert in 
entering these scores. Most of the moves in the data base were 
for a human expert to comment on all possible moves. (The 
data in the training procedure will be discussed in the following 
not scored, because it is not feasible 
handling of these unscored lines of 
section.) 
An important result of our study is that in order to achieve the best performance, the data base 
of examples must be intelligently designed, rather than haphazardly accumulated. If one simply 
accumulates positions which occur in actual game play, for example, one will find that certain prin- 
ciples of play will appear over and over again in these positions, while other important principles 
may be used only rarely. This causes problems for the network, as it tends to overlearn the com- 
monly used principles, and not learn at all the rarely used principles. Hence it is necessary to have 
both an intelligent selection mechanism to reduce the number of over-represented situations, and an 
intelligent design mechanism to enhance the number of examples which illustrate under-represented 
situations. This process is described in more detail elsewhere 5. 
We use a deterministic, feed-forward network with ,an input layer, ,an output layer, and either 
one or two layers of hidden units, with full connectivity between adjacent layers. (We have tried a 
number of experiments with restricted receptive fields, and generally have not found them to be use- 
ful.) Since the desired output of the network is a single real value, only one output unit is required. 
796 
The coding of the input patterns is probably the most difficult and most important design 
issue. In its current configuration the input layer contains 459 input units. A location-based 
representation scheme is used, in which a certain number of input units are assigned to each of the 
26 locations (24 basic plus White and Black bar) on the board. The input is inverted if necessary so 
that the network always sees a problem in which White is to play. 
An example of the coding scheme used until very recently is shown in Fig. 1. This is essen- 
tially a unary encoding of the number of men at each board location, with a few exceptions as indi- 
cated in the diagram. This representation scheme worked fairly well, but had one peculiar problem 
in that after training, the network tended to prefer piling large numbers of men on certain points, in 
particular White's 5 point (the 20 point in the 1-24 numbering scheme). Fig. 2 illustrates an example 
of this peculiar behavior. In this position White is to play 5-1. Most humans would play 4-5,4-9 in 
this position; however, the network chose the move 4-9,19-20. This is actually a bad move, because 
it reduces White's chances of making further points in his inner board. The fault lies not with the 
data base used to train the network, but rather with the representation scheme used. In Fig. l a, 
notice that unit 12 is turned on whenever the final position is a point, and the number of men is dif- 
ferent from the initial position. For the 20 point in particular, this unit will develop strong excitatory 
weights due to cases in which the initial position is not a point (i.e., the move makes the point). The 
20 point is such a valuable point to make that the excitation produced by turning unit 12 on might 
overwhelm the inhibition produced by the poor distribution of builders. 
--5 -4 -5 --2 -I 
(o) 0 0 0 0 0 
I 2 5 4 5 
6 7 8 9 I0 
4 ->5 
II 12 13 14 15 16 
S-5 -4 -3-<-2 -I 
(b) El B 13 E! 13 
I 2 3 4 5 
6 7 8 9 I0 
II 12 15 14 15 16 17 18 
Figure 1-- Two schemes used to encode the raw position information in the network's input. 
Illustrated in each case is the encoding of two White men present before the move, and three 
White men present after the move. (a) An essentially unary coding of the number of men at a 
particular board location. Units 1-10 encode the initial position, units 11-16 encode the final 
positio
