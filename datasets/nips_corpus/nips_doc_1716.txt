Regular and Irregular Gallager-type 
Error-Correcting Codes 
Y. Kabashima and T. Murayama 
Dept. of Compt. Intl. & Syst. Sci. 
Tokyo Institute of Technology 
Yokohama 2268502, Japan 
D. Saad and R. Vicente 
Neural Computing Research Group 
Aston University 
Birmingham B4 7ET, UK 
Abstract 
The performance of regular and irregular Gallager-type error- 
correcting code is investigated via methods of statistical physics. 
The transmitted codeword comprises products of the original mes- 
sage bits selected by two randomly-constructed sparse matrices; 
the number of non-zero row/column elements in these matrices 
constitutes a family of codes. We show that Shannon's channel 
capacity may be saturated in equilibrium for many of the regular 
codes while slightly lower performance is obtained for others which 
may be of higher practical relevance. Decoding aspects are con- 
sidered by employing the TAP approach which is identical to the 
commonly used belief-propagation-based decoding. We show that 
irregular codes may saturate Shannon's capacity but with improved 
dynamical properties. 
I Introduction 
The ever increasing information transmission in the modern world is based on re- 
liably communicating messages through noisy transmission channels; these can be 
telephone lines, deep space, magnetic storing media etc. Error-correcting codes play 
a significant role in correcting errors incurred during transmission; this is carried out 
by encoding the message prior to transmission and decoding the corrupted received 
code-word for retrieving the original message. 
In his ground breaking papers, Shannon[I] analyzed the capacity of communication 
channels, setting an upper bound to the achievable noise-correction capability of 
codes, given their code (or symbol) rate, constituted by the ratio between the num- 
ber of bits in the original message and the transmitted code-word. Shannon's bound 
is non-constructive and does not provide a recipe for devising optimal codes. The 
quest for more efficient codes, in the hope of saturating the bound set by Shannon, 
has been going on ever since, providing many useful but sub-optimal codes. 
One family of codes, presented originally by Gallager[2], attracted significant inter- 
est recently as it has been shown to outperform most currently used techniques[3]. 
Gallager-type codes are characterized by several parameters, the choice of which 
defines a particular member of this family of codes. Current theoretical results[3] 
Regular and Irregular Gallager-type Error-Correcting Codes 2 73 
offer only bounds on the error probability of various architectures, proving the ex- 
istence of very good codes under some restrictions; decoding issues are examined 
via numerical simulations. 
In this paper we analyze the typical performance of Gallager-type codes for several 
parameter choices via methods of statistical mechanics. We then validate the an- 
alytical solution by comparing the results to those obtained by the TAP approach 
and via numerical methods. 
2 The general framework 
In a general scenario, a message represented by an N dimensional Boolean vector 
 is encoded to the M dimensional vector jo which is transmitted through a noisy 
channel with some flipping probability p per bit (other noise types may also be 
studied). The received message J is then decoded to retrieve the original message. 
In this paper we analyze a slightly different version of Gallager-type codes termed 
the MN code[3] that is based on choosing two randomly-selected sparse matrices A 
and B of dimensionality M x N and M x M respectively; these are characterized 
by K and L non-zero unit elements per row and C and L per column respectively. 
The finite numbers K, C and L define a particular code; both matrices are known 
to both sender and receiver. Encoding is carried out by constructing the modulo 
2 inverse of B and the matrix B-1A (mod 2); the vector jo_ B-1A  (mod 2,  
Boolean vector) constitutes the codeword. Decoding is carried out by taking the 
product of the matrix B and the received message J- jo +4 (mod 2), corrupted 
by the Boolean noise vector 4, resulting in A+B. The equation 
A + B = AS + B' (mod 2) (1) 
is solved via the iterative methods of Belief Propagation (BP)[3] to obtain the most 
probable Boolean vectors $ and -; BP methods in the context of error-correcting 
codes have recently been shown to be identical to a TAP[4] based solution of a 
similar physical system[5]. 
The similarity between error-correcting codes of this type and Ising spin systems 
was first pointed out by Sourlas[6], who formulated the mapping of a simpler code, 
somewhat similar to the one presented here, onto an Ising spin system Hamiltonian. 
We recently extended the work of Sourlas, that focused on extensively connected 
systems, to the finite connectivity case[5] as well as to the case of MN codes [7]. 
To facilitate the current investigation we first map the problem to that of an Ising 
model with finite connectivity. We employ the binary representation (:hl) of the 
dynamical variables $ and - and of the vectors J and jo rather than the Boolean 
(0, 1) one; the vector jo is generated by taking products of the relevant binary 
message bits j0 __ I'Iie i, where the indices p - (il,...iK) correspond to the 
non-zero elements of B-1A, producing a binary version of jo. As we use statistical 
mechanics techniques, we consider the message and codeword dimensionality (N 
and M respectively) to be infinite, keeping the ratio between them R - N/M, 
which constitutes the code rate, finite. Using the thermodynamic limit is quite 
natural as Gallager-type codes are usually used for transmitting long (10 4- 10 5) 
messages, where finite size corrections are likely to be negligible. To explore the 
system's capabilities we examine the Hamiltonian 
274 Y. Kabashima, T. Murayama, D. Saad and R. Ficente 
The tensor product 7, where 7 = I'Ie,  I'Ije,, j and a = (j,... j), is 
the binary equivalent of A+B, treating both signal (S and index i) d noise 
(w and index j) simultaneously. Elements of the sparse connectivity tensor 
take the value I if the corresponding indices of both signal and noise are chosen 
(i.e., if all corresponding indices of the matrices A and B are 1) d 0 otherwise; 
it h C unit elements per /-index d L per j-index representing the system's 
degree of connectivity. The 5 function provides I if the selected sites' product 
ie Si je rj is in disagreement with the corresponding element , recording 
an error, d 0 otherwise. Notice that this term is not frustrated,  there are 
M+N degrees of freedom and only M constrnts from Eq.(1), and can therefore 
vish at suciently low temperatures. The lt two terms on the right represent 
our prior knowledge in the ce of sparse or bied messages F d of the noise 
level F and require signing certain values to these additive fields. The choice of 
   imposes the restriction of Eq.(1), limiting the solutions to those for which 
the first term of Eq.(2) vanishes, while the lt two terms, scaled with , survive. 
Note that the noise dynic variables r are irrelevant to menuring the retrieval 
 ) The latter monitors the normized mean 
success m =  E i sign<Si)  
overlap between the Bayes-optim retrieved message, shown to correspond to the 
alignment of <Si) to the nearest binary value[6], d the original message; the 
subscript  denotes therm averaging. 
Since the first part of Eq.(2) is invariant under the map Si  Sii, wj  wiQ and 
   ie i je Q = 1, it is useful to decouple the correlation between the 
vectors S, w and , . Rewriting Eq.(2) one obtns a similar expression apart from 
the lt terms on the right which become Fs/  Sn  and Fr/   . 
The random selection of elements in  introduces disorder to the system which 
is treated via methods of statistical physics. More specifically, we calculate the 
partition function Z(, J) = {S,w} exp[-] averaged over the disorder and the 
statistical properties of the message and noise, using the replica method[5, 8, 9]. 
Taking    gives rise to a set of order parameters 
I 1 
i=1 tm i=1 lm 
(2) 
where a, B, .. represem replica indices, and the variables Zi d  come from 
enforcing the restriction of C and L connections per index respectively[5]: 
5 - C = , (3) 
and similarly for the restriction on the j indices. 
To proceed with the calculation one has to make  sumption about the order 
parameters symmetry. The sumption made here, and validated later on, is that 
of replica symmetry in the following representation of the order parameters and the 
related conjugate variables 
q,a.., = aq / aX x t = a?/ 
, 
(4) 
where 1 is the number of replica indices, a. are normalization coefficients, and 
(x), (:), p(y) and () represent probability distributions. Unspecified integrals 
Regular and Irregular Gallager-type Error-Correcting Codes 2 75 
are over the range [-1, +1]. One then obtains an expression for the free energy 
per spin expressed in terms of these probability distributions 1/N (ln Z,ï¿½,v The 
free energy can then be calculated via the saddle point method. Solving the 
equations obtained by varying the free energy w.r.t the probability distributions 
'(x), (), p(y) and (9), is difficult as they generally comprise both delta peaks 
and regular[9] solutions for the ferromagnetic and paramagnetic phases (there is no 
spin-glass solution here as the system is not frustrated). The solutions obtained 
in the case of unbiased messages (the most interesting case as most messages are 
compressed prior to transmission) are for the ferromagnetic phase: 
'(x) = 5(x- 1) , () - 5( - 1) , p(y) - 5(y - 1) , (9) = 5(9 - 1) , (5) 
and for the paramagnetic phase: 
(x) = 5(x), ()=5(), (9)=5(9) 
1 + tanh F 1 - tanh F 
P(Y) - 2 5(y - tanh F) + 2 5(y + tanh F) . (6) 
These solutions obey the saddle point equations. However, it is unclear w
