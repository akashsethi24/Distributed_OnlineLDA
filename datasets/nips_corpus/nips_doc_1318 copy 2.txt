2D Observers for Human 3D Object Recognition? 
Zili Liu 
NEC Research Institute 
Daniel Kersten 
University of Minnesota 
Abstract 
Converging evidence has shown that human object recognition 
depends on familiarity with the images of an object. Further, 
the greater the similarity between objects, the stronger is the 
dependence on object appearance, and the more important two- 
dimensional (2D) image information becomes. These findings, how- 
ever, do not rule out the use of 3D structural information in recog- 
nition, and the degree to which 3D information is used in visual 
memory is an important issue. Liu, Knill, & Kersten (1995) showed 
that any model that is restricted to rotations in the image plane 
of independent 2D templates could not account for human perfor- 
mance in discriminating novel object views. We now present results 
from models of generalized radial basis functions (GRBF), 2D near- 
est neighbor matching that allows 2D affine transformations, and 
a Bayesian statistical estimator that integrates over all possible 2D 
affine transformations. The performance of the human observers 
relative to each of the models is better for the novel views than 
for the familiar template views, suggesting that humans generalize 
better to novel views from template views. The Bayesian estima- 
tor yields the optimal performance with 2D arline transformations 
and independent 2D templates. Therefore, models of 2D arline 
matching operations with independent 2D templates are unlikely 
to account for human recognition performance. 
I Introduction 
Object recognition is one of the most important functions in human vision. To 
understand human object recognition, it is essential to understand how objects are 
represented in human visual memory. A central component in object recognition 
is the matching of the stored object representation with that derived from the im- 
age input. But the nature of the object representation has to be inferred from 
recognition performance, by taking into account the contribution from the image 
information. When evaluating human performance, how can one separate the con- 
830 Z Liu and D. Kersten 
tributions to performance of the image information from the representation? Ideal 
observer analysis provides a precise computational tool to answer this question. An 
ideal observer's recognition performance is restricted only by the available image 
information and is otherwise optimal, in the sense of statistical decision theory, 
irrespective of how the model is implemented. A comparison of human to ideal 
performance (often in terms of efficiency) serves to normalize performance with re- 
spect to the image information for the task. We consider the problem of viewpoint 
dependence in human recognition. 
A recent debate in human object recognition has focused on the dependence of recog- 
nition performance on viewpoint [1, 6]. Depending on the experimental conditions, 
an observer's ability to recognize a familiar object from novel viewpoints is impaired 
to varying degrees. A central assumption in the debate is the equivalence in view- 
point dependence and recognition performance. In other words, the assumption is 
that viewpoint dependent performance implies a viewpoint dependent representa- 
tion, and that viewpoint independent performance implies a viewpoint independent 
representation. However, given that any recognition performance depends on the 
input image information, which is necessarily viewpoint dependent, the viewpoint 
dependence of the performance is neither necessary nor sufficient for the viewpoint 
dependence of the representation. Image information has to be factored out first, 
and the ideal observer provides the means to do this. 
The second aspect of an ideal observer is that it is implementation free. Con- 
sider the GRBF model [5], as compared with human object recognition (see be- 
low). The model stores a number of 2D templates {Ti} of a 3D object O, 
and recognizes or rejects a stimulus image S by the following similarity measure 
Eici exp (liT/- Sll 2/2a2), where ci and rr are constants. The model's performance 
as a function of viewpoint parallels that of human observers. This observation has 
led to the conclusion that the human visual system may indeed, as does the model, 
use 2D stored views with GRBF interpolation to recognize 3D objects [2]. Such a 
conclusion, however, overlooks implementational constraints in the model, because 
the model's performance also depends on its implementations. Conceivably, a model 
with some 3D information of the objects can also mimic human performance, so 
long as it is appropriately implemented. There are typically too many possible 
models that can produce the same pattern of results. 
In contrast, an ideal observer computes the optimal performance that is only limited 
by the stimulus information and the task. We can define constrained ideals that are 
also limited by explicitly specified assumptions (e.g., a class of matching operations). 
Such a model observer therefore yields the best possible performance among the 
class of models with the same stimulus input and assumptions. In this paper, 
we are particularly interested in constrained ideal observers that are restricted in 
functionally significant aspects (e.g., a 2D ideal observer that stores independent 
2D templates and has access only to 2D arline transformations). The key idea is 
that a constrained ideal observer is the best in its class. So if humans outperform 
this ideal observer, they must have used more than what is available to the ideal. 
The conclusion that follows is strong: not only does the constrained ideal fail to 
account for human performance, but the whole class of its implementations are also 
falsified. 
A crucial question in object recognition is the extent to which human observers 
model the geometric variation in images due to the projection of a 3D object onto a 
2D image. At one extreme, we have shown that any model that compares the image 
to independent views (even if we allow for 2D rigid transformations of the input 
image) is insufficient to account for human performance . At the other extreme, it 
is unlikely that variation is modeled in terms of rigid transformation of a 3D object 
2D Observers for Human 3D Object Recognition ? 831 
template in memory. A possible intermediate solution is to match the input image 
to stored views, subject to 2D arline deformations. This is reasonable because 2D 
arline transformations approximate 3D variation over a limited range of viewpoint 
change. 
In this study, we test whether any model limited to the independent comparison 
of 2D views, but with 2D arline flexibility, is sufficient to account for viewpoint 
dependence in human recognition. In the following section, we first define our ex- 
perimental task, in which the computational models yield the provably best possible 
performance under their specified conditions. We then review the 2D ideal observer 
and GRBF model derived in [4], and the 2D affine nearest neighbor model in [8]. 
Our principal theoretical result is a closed-form solution of a Bayesian 2D affine ideal 
observer. We then compare human performance with the 2D affine ideal model, as 
well as the other three models. In particular, if humans can classify novel views of 
an object better than the 2D affine ideal, then our human observers must have used 
more information than that embodied by that ideal. 
2 The observers 
Let us first define the task. An observer looks at the 2D images of a 3D wire 
frame object from a number of viewpoints. These images will be called templates 
{Ti}. Then two distorted copies of the original 3D object are displayed. They 
are obtained by adding 3D Gaussian positional noise (i.i.d.) to the vertices of the 
original object. One distorted object is called the target, whose Gaussian noise has 
a constant variance. The other is the distractor, whose noise has a larger variance 
that can be adjusted to achieve a criterion level of performance. The two objects 
are displayed from the same viewpoint in parallel projection, which is either from 
one of the template views, or a novel view due to 3D rotation. The task is to choose 
the one that is more similar to the original object. The observer's performance is 
measured by the variance (threshold) that gives rise to 75% correct performance. 
The optimal strategy is to choose the stimulus S with a larger probability p (OIS). 
From Bayes' rule, this is to choose the larger of p (SIO). 
Assume that the models are restricted to 2D transformations of the image, and 
cannot reconstruct the 3D structure of the object from its independent templates 
{Ti}. Assume also that the prior probability p(Ti) is constant. Let us represent S 
and Ti by their (x,y) vertex coordinates: ( X Y )T, where X = (x,x2,... ,x'), 
Y = (y,y2,...,y'). We assume that the correspondence between S and Ti is 
solved up to a reflection ambiguity, which is equivalent to an additional template: 
T = ( X r yr )T, whereX r = (x',...,x =,x ),Yr = (y,,...,y=,y). We still 
denote the template set as {Ti}. Therefore, 
p(S]O) = Ep(S[Ti)p(Ti). 
(1) 
In what follows, we will compute p(SITi)p(Ti), with the assumption that S = 
Y (Ti) + N (0, crI=,), where N is the Gaussian distribution, I=, the 2n x 2n identity 
matrix, and Y a 2D transformation. For the 2D ideal observer, Y is a rigid 2D 
rotation. For the GRBF model, Y assigns a linear coefficient to each template 
Ti, in addition to a 2D rotation. For the 2D affine nearest neighbor model, Y 
represents the 2D affine transformation that minimizes IlS -Ti][ 2, after S and Ti 
are normalized in size. For the 2D affine ideal observer, Y represents all possible 
2D affine transformations applicable to Ti. 
832 Z Liu and D. Kersten 
2.1 The 2D ideal observer 
The templates are the original 2D images, their mirror reflections, and 2D rotations 
(in angle ï¿½5) in the image plane.
