Tonal Music as a Componential Code: 
Learning Temporal Relationships Between and 
Within Pitch and Timing Components 
Catherine Stevens 
Department of Psychology 
University of Queensland 
QLD 4072 Australia 
kates @psych.psy.uq.oz.au 
Janet Wiles 
Depts of Psychology & Computer Science 
University of Queensland 
QLD 4072 Australia 
janetw@ cs.uq.oz.au 
Abstract 
This study explores the extent to which a network that learns the 
temporal relationships within and between the component features of 
Western tonal music can account for music theoretic and psychological 
phenomena such as the tonal hierarchy and rhythmic expectancies. 
Predicted and generated sequences were recorded as the representation of 
a 153-note waltz melody was learnt by a predictive, recurrent network. 
The network learned transitions and relations between and within pitch 
and timing components: accent and duration values interacted in the 
development of rhythmic and metric structures and, with training, the 
network developed chordal expectancies in response to the activation of 
individual tones. Analysis of the hidden unit representation revealed 
that musical sequences are represented as transitions between states in 
hidden unit space. 
1 INTRODUCTION 
The fundamental features of music, derivable from frequency, time and amplitude 
dimensions of the physical signal, can be described in terms of two systems - pitch and 
timing. The two systems are frequently disjoined and modeled independently of one 
another (e.g. Bharucha & Todd, 1989; Rosenthal, 1992). However, psychological 
evidence suggests that pitch and timing factors interact (Jones, 1992; Monaban, Kendall 
1085 
1086 Stevens and Wiles 
& Carterette, 1987). The pitch and timing components can be further divided into tone, 
octave, duration and accent which can be regarded as a quasi-componential code. The 
important features of a componential code are that each component feature can be viewed 
as systematic in its own right (Fodor & Pylyshyn, 1988). The significance of 
componential codes for learning devices lies in the productivity of the system - a small 
(polynomial) number of training examples can generalise to an exponential test set 
(Brousse & Smolensky, 1989; Phillips & Wiles, 1993). We call music a quasi- 
componential. code as there are significant interactions between, as well as within, the 
component features (we adopt this term from its use in describing other cognitive 
phenomena, such as reading, Plaut & McClelland, 1993). 
Connectionist models have been developed to investigate various aspects of musical 
behaviour including composition (Hild, Feulner & Menzel, 1992), performance (Sayegh, 
1989), and perception (Bharucha & Todd, 1989). The models have had success in 
generating novel sequences (Mozer, 1991), or developing properties characteristic of a 
listener, such as tonal expectancies (Todd, 1988), or reflecting properties characteristic of 
musical structure, such as hierarchical organisation of notes, chords and keys (Bharucha, 
1992). Clearly, the models have been designed with a specific application in mind and, 
although some attention has been given to the representation of musical information 
(e.g. Mozer, 1991; Bharucha, 1992), the models rarely explain the way in which musical 
representations are constructed and learned. These models typically process notes which 
vary in pitch but are of constant duration and, as music is inherently temporal, the 
temporal properties of music must be reflected in both representation and processing. 
There is an assumption implicit in cognitive modeling in the information processing 
framework that the representations used in any cognitive process are specified a priori 
(often assumed to be the output of a perceptual process). In the neural network 
framework, this view of representation has been challenged by the specification of a dual 
mechanism which is capable of learning representations and the processes which act upon 
them. Since the systematic properties of music are inherent in Western tonal music as 
an environment, they must also be reflected in its representation in, and processes of, a 
cognitive system. Neural networks provide a mechanism for learning such 
representations and processes, particularly with respect to temporal effects. 
In this paper we study how representations can be learned in the domain of Western tonal 
music. Specifically, we use a recurrent network trained on a musical prediction task to 
construct representations of context in a musical sequence (a well-known waltz), and then 
test the extent to which the learned representation can account for the classic phenomena 
of music cognition. We see the representation construction as one aspect of learning and 
memory in music cognition, and anticipate that additional mechanisms of music 
cognition would involve memory processes that utilise these representations (e.g. 
Stevens & Latimer, 1992), although they are beyond the scope of the present paper. For 
example, Mozer (1992) discusses the development of higher-order, global representations 
at the level of relations between phrases in musical patterns. By contrast, the present 
study focusses on the development of representations at the level of relations between 
individual musical events. We expect that the additional mechanisms would, in part, 
develop from the behavioural aspects of music cognition that are made explicit at this 
early, representation construction stage. 
Tonal Music as a Componential Code 1087 
2 METHOD & RESULTS 
A simple recurrent network (Elman, 1989), consisting of 25 input and output units, and 
20 hidden and context units, was trained according to Elman's prediction paradigm and 
used Backprop Through Time (BPTT) for one time step. The training data comprised the 
fin'st 2 sections of The Blue Danube by Johann Strauss wherein each training pattern 
represented one event, or note, in the piece, coded as components of tone (12 values), rest 
(1 value), octave (3 values), duration (6 values) and accent (3 values). 
In the early stages of training, the network learned to predict the prior probability of 
events (see Figure 1). This type of information could be encoded in the bias of the 
output units alone, as it is independent of temporal changes m the input patterns. After 
further training, the network learned to modify its predictions based on the input event 
(purely feedforward information) and, later still, on the context in which the event 
occurred (see Figure 2). Note that an important aspect of this type of recurrent network 
is that the representation of context is created by the network itself (Elman, 1989) and is 
not specified a priori by the network designer or the environment (Jordan, 1986). In this 
way, the context can encode the information m the environment which is relevant to the 
prediction task. Consequently, the network could, in principle, be adapted to other styles 
of music without modification of the design, or input and output representations. 
a. Output vector 
b, Target histogram 
AA#B CC#DD#E F F#GG#4 5 6 1 2 3 4 6 
tones octaves durations 
8 SWVR 
accent rest 
Figure 1: Comparison of output vector for the first event at Epoch 4 (a) and a histogram 
of the target vector averaged over all events (b). The upper graph is the predicted output 
of Event 1 at Epoch 4. The lower graph is a histogram of all the events in the piece, 
created by averaging all the target vectors. The comparison shows that the net learned 
initially to predict the mean target before learning the variations specific to each event. 
1088 Stevens and Wiles 
Elxx:h 64 
EDoch_4 _ 
Epoch 2 
fl 
n rl rl 8 
 fl .... J'l , _ 7 
N fl N rl 6 
fl__ rl ,rl .... N , _ 5 
fl R I't n 4 
fl__  _fl rl _ 3 
,,:l fl N , _ 2 
A A#B C C#DIE F F#GG4 5 6 I 2 3 4 6 8 S WV R event 
toems octaves durations accent rest 
Figure 2: Evolution of the first eight events (predicted). The first block (targets) shows 
the correct sequence of events for the four components. In the second block (Epoch 2), 
the net is beginning to predict activation of strong and weak accents. In the third block 
(Epoch 4), the transition from one octave to another is evident. By the fourth block 
(Epoch 64), all four components are substantially correct. The pattern of activation 
across the output vector can be interpreted as a statistical description of each musical 
event. In psychological terms, the pattern of activation reflects the harmonic or chordal 
expectancies induced by each note (Bharucha, 1987) and characteristic of the tonal 
hierarchy (Kmmhansl & Shepard, 1979). 
3.1 NETWORK PERFORMANCE 
The performance of the network as it learned to master The Blue Danube was recorded at 
log steps up to 4096 epochs. One recording comprised the output predicted by the 
network as the correct event was recycled as input to the network (similar to a teacher- 
forcing paradigm). The second recording was generated by feeding the best guess of the 
Tonal Music as a Componential Code 1089 
output back as input. The accent - the lilt of the waltz - was incorporated very early in 
the training. Despite numerous errors in the individual events, the sequences were clearly 
identifiable as phrases from The Blue Danube and, for the most part, errors in the tone 
component were consistent with the tonality of the piece. The errors are of 
psychological importance and the overall performance indicated that the network learnt 
the typical features of The Blue Danube and the waltz genre. 
3.2 INTERACTIONS BETWEEN ACCENT & DURATION 
Western tonal music is characterised by regularities in pitch and timing components. For 
example, the occurrence of particular tones and durations in a single composition is 
structured and regular given that only a limited number of the possible combinations 
occur. Therefore, one way to gauge performance of the network is to compare the 
regularities extracted and represented 
