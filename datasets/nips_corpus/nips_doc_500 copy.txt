VISIT: A Neural Model of Covert Visual 
Attention 
Subutal Ahmad* 
Siemens Research and Development, 
ZFE ST SN6, Otto-Hahn Ring 6, 
8000 Munich 83, Germany. 
Amad%bsun4eztivax. siemens. corn 
Abstract 
Visual attention is the ability to dynamically restrict processing to a subset 
of the visual field. Researchers have long argued that such a mechanism is 
necessary to efficiently perform many intermediate level visual tasks. This 
paper describes VISIT, a novel neural network model of visual attention. 
The current system models the search for target objects in scenes contain- 
ing multiple distractors. This is a natural task for people, it is studied 
extensively by psychologists, and it requires attention. The network's be- 
havior closely matches the known psychophysical data on visual search 
and visual attention. VISIT also matches much of the physiological data 
on attention and provides a novel view of the functionality of a number of 
visual areas. This paper concentrates on the biological plausibility of the 
model and its relationship to the primary visual cortex, pulvinar, superior 
colliculus and posterior parietal areas. 
1 INTRODUCTION 
Visual attention is perhaps best understood in the context of visual search, i.e. 
the detection of a target object in images containing multiple distractor objects. 
This task requires solving the binding problem and has been extensively studied in 
psychology (see[16] for a review). The basic experimental finding is that a target 
object containing a single distinguishing feature can be detected in constant time, 
independent of the number of distractors. Detection based on a conjunction of 
features, however, takes time linear in the number of objects, implying a sequential 
search process (there are exceptions to this general rule). It is generally accepted 
'Thanks to Steve Omohundro, Anne Treisman, Joe Malpeli, and Bill Baird for enlight- 
ening discussions. Much of this reseaxch wa conducted at the International Computer 
Science Institute, Berkeley, CA. 
420 
VISIT.' A Neural Model of Covert Visual Attention 421 
I ttigh Level Recosnkion 
/ 
Gatext Fatur Maps 
/_ 
Priority Network 
/ 
e. atur Map 
Figure 1: Overview of VISIT 
that some form of covert attention ! is necessary to accomplish this task. The 
following sections describe VISIT, a connectionist model of this process. The current 
paper concentrates on the relationships to the physiology of attention, although the 
psychological studies are briefly touched on. For further details on the psychological 
aspects see[1, 2]. 
2 OVERVIEW OF VISIT 
We first outline the essential characteristics of VISIT. Figure 1 shows the basic ar- 
chitecture. A set of features are first computed from the image. These features are 
analogous to the topographic maps computed early in the visual system. There is 
one unit per location per feature, with each unit computing some local property of 
the image. Our current implementation uses four feature maps: red, blue, horizon- 
tal, and vertical. A parallel global sum of each feature map's activity is computed 
and is used to detect the presence of activity in individual maps. 
The feature information is fed through two different systems: a gating network and 
a priority network. The gating network implements the focus - its function is to 
restrict higher level processing to a single circular region. Each gate unit receives the 
coordinates of a circle as input. If it is outside the circle, it turns on and inhibits 
corresponding locations in the gated feature maps. Thus the network can filter 
image properties based on an external control signal. The required computation is 
a simple second order weighted sum and takes two time steps[1]. 
 Covert attention refers to the ability to concentrate processing on a single image region 
without any overt actions such as eye movements. 
422 Ahmad 
The priority network ranks image locations in parallel and encodes the information 
in a manner suited to the updating of the focus of attention. There are three 
units per location in the priority map. The activity of the first unit represents the 
location's relevance to the current task. It receives activation from the feature maps 
in a local neighborhood of the image. The value of the i'th such unit is calculated 
z,y6RF J6F 
where Af=y is the activation of the unit computing feature f at location (z, y). 
denotes the receptive field of unit i, P! is the priority given to feature map f, and 
is a monotonically increasing function such as the sigmoid. P! is represented as the 
real valued activation of individual units and can be dynamically adjusted according 
to the task. Thus by setting P! for a particular feature to i and all others to 0, 
only objects containing that feature will influence the priority map. Section 2.1 
describes a good strategy for setting PI' The other two units at each location 
encode an error vector, i.e. the vector difference between the units' location and 
center of the focus. These vectors are continually updated as the focus of attention 
moves around. To shift the focus to the most relevant location, the network simply 
adds the error vector corresponding to the highest priority unit to the activations 
of the units representing the focii's center. Once a location has been visited, the 
corresponding relevance unit is inhibited, preventing the network from continually 
attending to the highest priority location. 
The control networks are responsible for mediating the information flow between 
the gating and priority networks, as well as incorporating top-down knowledge. The 
following section describes the part which sets the priority values for the feature 
maps. The rest of the networks are described in detail in [1]. Note that the control 
functions are fully implemented as networks of simple units and thus requires no 
homunculus to oversee the process. 
2.1 SWIFT: A FAST SEARCH STRATEGY 
The main function of SWIFT is to integrate top-down and bottom-up knowledge to 
efficiently guide the search process. Top down information about the target features 
are stored in a set of units. Let T be this set of features. Since the desired object 
must contain all the features of T, any of the corresponding feature maps may be 
searched. Using the ability to weight feature maps differently, the network removes 
the influence of all but one of the features in T. By setting this map's priority 
to 1, and all others to 0, the system will effectively prune objects which do not 
contain this feature. SWIF To minimize search time, it should choose the feature 
corresponding to the smallest number of objects. Since it is difficult to count the 
number of objects in parallel, the network chooses the map with the minimal total 
activity as the one likely to contain the minimal number of objects. (If the target 
features are not known in advance, SWIFT chooses the minimal feature map over 
all features. The net effect is to always pick the most distinctive feature.) 
2Hence the name SWIFT: Search With Features Thrown out. 
VISIT.' A Neural Model of Covert Visual Attention 423 
2.2 RELATIONSHIP TO PSYCHOPHYSICAL DATA 
The run time behavior of the system closely matches the data on human visual 
search. Visual attention in people is known to be very quick, taking as little as 40-80 
msecs to engage. Given that cortical neurons can fire about once every 10 msecs, this 
leaves time for at most 8 sequential steps. In VISIT, unlike other implementations 
of attention[10], the calculation of the next location is separated from the gating 
process. This allows the gating to be extremely fast, requiring only 2 time steps. 
Iterative models, which select the most active object through lateral inhibition, 
require time proportional to the distance in pixels between maximally separated 
objects. These models are not consistent with the 80msecs time requirement. 
During visual search, SWIFT always searches the minimal feature map. The critical 
variable that determines search time is M, the number of objects in the minimal 
feature map. Search time will be linear in M. It can be shown that VISIT plus 
SWIFT is consistent with all of Treisman's original experiments including single 
feature search, conjunctive search, 2:1 slope ratios, search asymmetries, and illusory 
conjuncts[16], as well as the exceptions reported in[5, 14]. With an assumption 
about the features that are coded (consistent with current physiological knowledge), 
the results in[V, 11] can also be modeled. (This is described in more detail in [2]). 
3 PHYSIOLOGY OF VISUAL ATTENTION 
The above sections have described the general architecture of VISIT. There is a 
fairly strong correspondence between the modules in VISIT and the various visual 
areas involved in attention. The rest of the paper discusses these relationships. 
3.1 TOPOGRAPHIC FEATURE MAPS 
Each of the early visual areas, LGN, V1, and V2, form several topographic maps 
of retinal activity. In V1 alone there are a thousand times as many neurons as 
there are fibers in the optic nerve, enough to form several hundred feature maps. 
There is a diverse list of features thought to be computed in these areas, including 
orientations, colors, spatial frequencies, motion, etc.[6]. These areas are analogous 
to the set of early feature maps computed in VISIT. 
In VISIT there are actually two separate sets of feature maps: early features com- 
puted directly from the image and gated feature maps. It might seem inefficient to 
have two copies of the same features. An alternate possibility is to directly inhibit 
the early feature maps themselves, and so eliminate the need for two sets. However, 
in a focused state, such a network would be unable to make global decisions based 
on the features. With the configuration described above, at some hardware cost, 
the network can efficiently access both local and global information simultaneously. 
SWIF
