83O 
Invariant Object Recognition Using a Distributed Associative Memory 
Harry Wechsler and George Lee Zimmerman 
Department of Electrical Engineering 
University of Minnesota 
Minneapolis, MN 55455 
Abstract 
This paper describes an approach to 2-dimensional object recognition. Complex-log con- 
formal mapping is combined with a distributed associative memory to create a system 
which recognizes objects regardless of changes in rotation or scale. Recalled information 
from the memorized database is used to classify an object, reconstruct the memorized ver- 
sion of the object, and estimate the magnitude of changes in scale or rotation. The system 
response is resistant to moderate amounts of noise and occlusion. Several experiments, us- 
ing real, gray scale images, are presented to show the feasibility of our approach. 
Introduction 
The challenge of the visual recognition problem stems from the fact that the projec- 
tion of an object onto an image can be confounded by several dimensions of variability 
such as uncertain perspective, changing orientation and scale, sensor noise, occlusion, and 
non-uniform illumination. A vision system must not only be able to sense the identity of an 
object despite this variability, but must also be able to characterize such variability -- be- 
cause the variability inherently carries much of the valuable information about the world. 
Our goal is to derive the functional characteristics of image representations suitable for in- 
variant recognition using a distributed associative memory. The main question is that of 
finding appropriate transformations such that interactions between the internal structure 
of the resulting representations and the distributed associative memory yield invariant 
recognition. As Simon [1] points out, all mathematical derivation can be viewed simply as 
a change of representation, making evident what was previously true but obscure. This 
view can be extended to all problem solving. Solving a problem then means transforming it 
so as to make the solution transparent. 
We approach the problem of object recognition with three requirements: 
classification, reconstruction, and characterization. Classification implies the ability to dis- 
tinguish objects that were previously encountered. Reconstruction is the process by which 
memorized images can be drawn from memory given a distorted version exists at the in- 
put. Characterization involves extracting information about how the object has changed 
from the way in which it was memorized. Our goal in this paper is to discuss a system 
which is able to recognize memorized 2-dimensional objects regardless of geometric dis- 
tortions like changes in scale and orientation, and can characterize those transformations. 
The system also allows for noise and occlusion and is tolerant of memory faults. 
The following sections, Invariant Representation and Distributed Associative 
Memory, respectively, describe the various components of the system in detail. The Experi- 
ments section presents the results from several experiments we have performed on real 
data. The paper concludes with a discussion of our results and their implications for future 
research. 
@ American Institute of Physics 1988 
831 
1. Invariant Representation 
The goal of this section is to examine the various components used to produce the 
vectors which are associated in the distributed associative memory. The block diagram 
which describes the various functional units involved in obtaining an invariant image 
representation is shown in Figure 1. The image is complex-log conformally mapped so that 
rotation and scale changes become translation in the transform domain. Along with the 
conformal mapping, the image is also filtered by a space variant filter to reduce the effects 
of aliasing. The conformally mapped image is then processed through a Laplacian in order 
to solve some problems associated with the conformal mapping. The Fourier transform of 
both the conformally mapped image and the Laplacian processed image produce the four 
output vectors. The magnitude output vector 1'11 is invariant to linear transformations of 
the object in the input image. The phase output vector qb 2 contains information concern- 
ing the spatial properties of the object in the input image. 
1.1 Complex-Log Mapping and Space Variant Filtering 
The first box of the block diagram given in Figure 1 consists of two components: 
Complex-log mapping and space variant filtering. Complex-log mapping transforms an 
image from rectangular coordinates to polar exponential coordinates. This transformation 
changes rotation and scale into translation. If the image is mapped onto a complex plane 
then each pixel (x,y) on the Cartesian plane can be described mathematically by z = x + 
jy. The complex-log mapped points w are described by 
w = In(z) = ln(Izl) + jO (1) 
z 
where Iz I =(x 2 +y2) and 0 z =tan-l(y/x). 
Our system sampled 256x256 pixel images to construct 64x64 complex-log mapped 
images. Samples were taken along radial lines spaced 5.6 degrees apart. Along each radial 
line the step size between samples increased by powers of 1.08. These numbers are derived 
from the number of pixels in the original image and the number of samples in the 
complex-log mapped image. An excellent examination of the different conditions involved 
in selecting the appropriate number of samples for a complex-log mapped image is given in 
[2]. The non-linear sampling can be split into two distinct parts along each radial line. To- 
ward the center of the image the samples are dense enough that no anti-aliasing filter is 
needed. Samples taken at the edge of the image are large and an anti-aliasing filter is 
necessary. The image filtered in this manner has a circular region around the center which 
corresponds to an area of highest resolution. The size of this region is a function of the 
number of angular samples and radial samples. The filtering is done, at the same time as 
the sampling, by convolving truncated Bessel functions with the image in the space 
domain. The width of the Bessel functions main lobe is inversely proportional to the eccen- 
tricity of the sample point. 
A problem associated with the complex-log mapping is sensitivity to center 
misalignment of the sampled image. Small shifts from the center causes dramatic distor- 
tions in the complex-log mapped image. Our system assumes that the object is centered in 
the image frame. Slight misalignments are considered noise. Large misalignments are con- 
sidered as translations and could be accounted for by changing the gaze in such a way as 
to bring the object into the center of the frame. The decision about what to bring into the 
center of the frame is an active function and should be determined by the task. An exam- 
ple of a system which could be used to guide the translation process was developed by 
Anderson and Burt [3]. Their pyramid system analyzes the input image at different tern- 
832 
833 
poral and spatial resolution levels. Their smart sensor was then able to shift its fixation 
such that interesting parts of the image (ie. something large and moving) was brought into 
the central part of the frame for recognition. 
1.2 Fourier Transform 
The second box in the block diagram of Figure 1 is the Fourier transform. The 
Fourier transform of a 2-dimensional image f(x,y) is given by 
oo oo 
F(u,v) = f f f(x,y)e -j(ux+vy) dx dy (2) 
and can be described by two 2-dimensional functions corresponding to the magnitude 
IF(u,v)l and phase F(U,V). The magnitude component of the Fourier transform which is 
invariant to translaUon, carries much of the contrast information of the image. The phase 
component of the Fourier transform carries information about how things ar placed in an 
image. Translation of f(x,y) corresponds to the addition of a linear phase cpmponent. The 
complex-log mapping transforms rotation and scale into translation and tile magnitude of 
the Fourier transform is invariant to those translations so that I. I1 vill not change 
significantly with rotation and scale of the object in the image. 
1.3 Laplacian 
The Laplacian that we use is a difference-of-Gaussians (DOG) approximation to the 
V2G function as given by Marr [4]. 
The result of convolving the Laplacian with an image can be viewed as a two step process. 
The image is blurred by a Gaussian kernel of a specified width a. Then the isotropic 
second derivative of the blurred image is computed. The width of the Gaussian kernel is 
chosen such that the conformally mapped image is visible -- approximately 2 pixels in our 
experiments. The Laplacian sharpens the edges of the object in the image and sets any re- 
gion that did not change much to zero. Below we describe the benefits from using the La- 
placian. 
The Laplacian eliminates the stretching problem encountered by the complex-log 
mapping due to changes in object size. When an object is expanded the complex-log 
mapped image will translate. The pixels vacated by this translation will be filled with 
more pixels sampled from the center of the scaled object. These new pixels will not be 
significantly different than the displaced pixels so the result looks like a stretching in the 
complex-log mapped image. The Laplacian of the complex-log mapped image will set the 
new pixels to zero because they do not significantly change from their surrounding pixels. 
The Laplacian eliminates high frequency spreading due to the finite structure of the 
discrete Fourier transform and enhances the differences between memorized objects by ac- 
centuating edges and de-emphasizing areas of little change. 
2. Distributed Associative Memory (DAM) 
The particular form of distributed associative memory that we deal with in this pa- 
per is a memory matrix which modifies the flow of information. Stimulus vectors are asso- 
ciated with response vectors and the result of this association is spread over 
