Factorial Learning and the EM Algorithm 
Zoubin Ghahramani 
zoubin@psyche.mit.edu 
Department of Brain & Cognitive Sciences 
Massachusetts Institute of Technology 
Cambridge, MA 02139 
Abstract 
Many real world learning problems are best characterized by an 
interaction of multiple independent causes or factors. Discover- 
ing such causal structure from the data is the focus of this paper. 
Based on Zemel and I-Iinton's cooperative vector quantizer (CVQ) 
architecture, an unsupervised learning algorithm is derived from 
the Expectation-Maximization (EM) framework. Due to the com- 
binatorial nature of the data generation process, the exact E-step 
is computationally intractable. Two alternative methods for com- 
puting the E-step are proposed: Gibbs sampling and mean-field 
approximation, and some promising empirical results are presented. 
1 Introduction 
Many unsupervised learning problems fall under the rubric of factorial learning. 
that is, the goal of the learning algorithm is to discover multiple independent causes, 
or factors, that can well characterize the observed data (Barlow, 1989; Pedlich, 
1993; Hinton and Zemel, 1994; Saund, 1995). Such learning problems often arise 
naturally in response to the actual process by which the data have been generated. 
For instance, images may be generated by combining multiple objects, or varying 
colors, locations, and poses, with different light sources. Similarly, speech signals 
may result from an interaction of factors such as the tongue position, lip aperture, 
glottal state, communication line, and background noises. The goal of factoriM 
learning is to invert this data generation process, discovering a representation that 
will both parsimoniously describe the data and reflect its underlying causes. 
A recent approach to factoriM learning uses the Minimum Description Length 
(MDL) principle (Pissanen, 1989) to extract a compact representation of the input 
(Zemel, 1993; Hinton and Zemel, 1994). This has resulted in a learning architecture 
618 Zoubin Ghahramani 
called Cooperative Vector Quantization (CVQ), in which a set of vector quantiz- 
ers cooperates to reproduce the input. Within each vector quantizer a competitive 
learning mechanism operates to select an appropriate vector code to describe the 
input. The CVQ is related to algorithms based on mixture models, such as soft 
competitive clustering, mixtures of experts (Jordan and Jacobs, 1994), and hidden 
Markov models (Baum et al., 1970), in that each vector quantizer in the CVQ is 
itself a mixture model. However, it generalizes this notion by allowing the mixture 
models to cooperate in describing features in the data set, thereby creating a dis- 
tributed representations of the mixture components. The learning algorithm for the 
CVQ uses MDL to derive a cost function composed of a reconstruction cost (e.g. 
sum squared error), representation cost (negative entropy of the vector code), and 
model complexity (description length of the network weights), which is minimized 
by gradient descent. 
In this paper we first formulate the factoriM learning problem in the framework of 
statistical physics (section 2). Through this formalism, we derive a novel learning 
algorithm for the CVQ based on the Expectation-Maximization (EM) algorithm 
(Dempster et al., 1977) (section 3). The exact EM algorithm is intractable for this 
and related factorial learning problems--however, a tractable mean-field approxi- 
mation can be derived. Empirical results on Gibbs sampling and the mean-field 
approximation are presented in section 4. 
2 Statistical Physics Formulation 
The CVQ architecture, shown in Figure 1, is composed of hidden and observable 
units, where the observable units, y, are real-valued, and the hidden units are 
discrete and organized into vectors si, i -- 1,...,d. The network models a data 
generation process which is assumed to proceed in two stages. First, a factor is 
independently sampled from each hidden unit vector, si, according to its prior 
probability density, 'i. Within each vector the factors are mutually exclusive, i.e. 
if sij = 1 for some j, then si = 0, Vk  j. The observable is then generated from 
a Gaussian distribution with mean =1 Wisi. 
IOOOO0] y 
VO, VO 
Notation: 
d number of vectors 
k number of hidden units per vector 
p number of outputs 
N number of patterns 
sij hidden unit j in vector i 
si vector i of units (si = [Sil,..., si]) 
Wi weight matrix from si to output 
y network output (observable) 
Figure 1. The factoriM learning architecture. 
Defining the energy of a particular configuration of hidden states and outputs as 
d d k 
y) = 11y - - 
i=1 i=1 j=l 
(1) 
Factorial Learning and the EM Algorithm 619 
the Boltzmann distribution 
1 
p(s,y) - Z.t,.e-  exp{-7/(s,y)}, (2) 
exactly recovers the probability model for the CVQ. The causes or factors are repre- 
sented in the multinomial variables si and the observable in the multivariate Gaus- 
sian y. The unclamped partition function, Z.t,.ee , can be evaluated by summing 
and integrating over all the possible configurations of the system to obtain 
Z.t,.ee =  jgy exp{-7-/(s, y)}dy- (2r) p/2, (3) 
which is constant, independent of the weights. This constant partition function 
results in desirable properties, such as the lack of a Boltzmann machine-like sleep 
phase (Neal, 1992), which we will exploit in the learning algorithm. 
The system described by equation (1) 1 can be thought of as a special form of the 
Boltzmann machine (Ackley et al., 1985). Expanding out the quadratic term we see 
that there are pairwise interaction terms between every unit. The evaluation of the 
partition function (3) tells us that when y is unclamped the quadratic term can be 
integrated out and therefore all si are independent. However, when y is clamped 
all the si become dependent. 
3 The EM Algorithm 
Given a set of observable vectors, the goal of the unsupervised learning algorithm 
is to find weight matrices such that the network is most likely to have generated 
the data. If the hidden causes for each observable where known, then the weight 
matrices could be easily estimated. However, the hidden causes cannot be inferred 
unless these weight matrices are known. This chicken-and-egg problem can be solved 
by iterating between computing the expectation of the hidden causes given the 
current weights and maximizing the likelihood of the weights given these expected 
causes--the two steps forming the basis of the Expectation-Maximization (EM) 
algorithm (Dempster et al., 1977). 
Formally, from (2) we obtain the expected log likelihood of the parameters 
Q(qb, qb') = (-7-/(s, y) -log Zfree)c, (4) 
where qb denotes the current parameters, qb {Wi d 
-- }i=1' and (')c, denotes expecta- 
tion given 4 and the clamped observables. The E-step of EM consists of computing 
this expected log likelihood. As the only random variables are the hidden causes, 
this simplifies to computing the (si) and T 
(sisj)c terms appearing in the quadratic 
expansion of 7/. Once these terms have bedn computed, the M-step consists of 
maximizing Q with respect to the parameters. Setting the derivatives to zero we 
obtain a linear system, 
d 
OQ 
i=1 
 For the remainder of the paper we will ignore the second term in (1), thereby assuming 
equal priors on the hidden states. Relaxing this assumption and estimating priors from 
the data is straightforward. 
620 Zoubin Ghahramani 
which can be solved via the normal equations, 
W(axkxv) -- SS T SS T SS T S 
(xk? (xkxv) 
where s is the vector of concatenated si and the subscripts denote matrix size. 
For models in which the observable is a monotonic differentiable function of i Wisi, 
i.e. generalized linear models, let squares estimates of the weights for the M-step 
can be obtained iteratively by the method of scoring (McCullagh and Nelder, 1989). 
3.1 E-step: Exact 
The difficulty arises in the E-step of the algorithm. The expectation of hidden unit 
j in vector i given pattern y is: 
(si.)c = = lly; W) P(ylsj = 1; W)rj 
k k k 
= = = 
j=l jai=l j=l 
To compute this expectation it is necessary to sum over all possible configurations of 
the other hidden units. If each vector quantizer has k hidden units, each expectation 
has time complexity of O(kd-1), i.e. O(Nk d) for a full E-step. The exponential time 
is due inherently to the cooperative nature of the model--the setting of one vector 
only determines the observable if all the other vectors are fixed. 
3.2 E-step: Gibbs sampling 
Rather than summing over all possible hidden unit patterns to compute the ex- 
act expectations, a natural approach is to approximate them through a Monte 
Carlo method. As with Boltzmann machines, the CVQ architecture lends itself 
well to Gibbs sampling (Geman and Geman, 1984). Starting from a clamped 
observable y and a random setting of the hidden units {sj}, the setting of each 
vector is updated in turn stochastically according to its conditional distribution 
s ,--, p(sly, {sj}j;i; W). Each conditional distribution calculation requires k for- 
ward passes through the network, one for each possible state of the vector being 
updated, and k Gaussian distance calculations between the resulting predicted and 
clamped observables. If all the probabilities are bounded away from zero this pro- 
cess is guaranteed to converge to the equilibrium distribution of the hidden units 
given the observable. The first and second-order statistics, for (si)c and (sisf)c re- 
spectively, can be collected using the sj's visited and p(s lY, {sj)j;W) calculated 
during this sampling process. These estimated expectations are then used in the 
E-step. 
3.3 E-step: Mean-field approximation 
Although Gibbs sampling is generally much more efficient than exact calculations, 
it too can be computationally demanding. A more promising approach is to ap- 
proximate the intractable system with a tractable mean-field approximation (Parisi, 
1
