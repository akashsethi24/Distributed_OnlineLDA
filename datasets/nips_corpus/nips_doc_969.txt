Learning Stochastic Perceptrons Under 
k-Blocking Distributions 
Mario Marchand 
Ottawa-Carleton Institute for Physics 
University of Ottawa 
Ottawa, Ont., Canada KiN 6N5 
mario@physics.uottawa. ca 
Saeed Hadjifaradji 
Ottawa-Carleton Institute for Physics 
University of Ottawa 
Ottawa, Ont., Canada KiN 6N5 
saeed@physics.uottawa. ca 
Abstract 
We present a statistical method that PAC learns the class of 
stochastic perceptrons with arbitrary monotonic activation func- 
tion and weights wi  (-1, 0, +1} when the probability distribution 
that generates the input examples is member of a family that we 
call k-blocking distributions. Such distributions represent an impor- 
tant step beyond the case where each input variable is statistically 
independent since the 2k-blocking family contains all the Markov 
distributions of order k. By stochastic perceptron we mean a per- 
ceptron which, upon presentation of input vector x, outputs i with 
probability f(i WiXi -- )' Because the same algorithm works for 
any monotonic (nondecreasing or nonincreasing) activation func- 
tion f on Boolean domain, it handles the well studied cases of 
sigmods and the usual radial basis functions. 
I INTRODUCTION 
Within recent years, the field of computational learning theory has emerged to pro- 
vide a rigorous framework for the design and analysis of learning algorithms. A 
central notion in this framework, known as the Probably Approximatively Cor- 
rect (PAC) learning criterion (Valiant, 1984), has recently been extended (Hassler, 
1992) to analyze the learnability of probabilistic concepts (Kearns and Schapire, 
1994; Schapire, 1992). Such concepts, which are stochastic rules that give the prob- 
ability that input example x is classified as being positive, are natural probabilistic 
280 Mario Marchand, Saeed Hadjifaradji 
extensions of the deterministic concepts originally studied by Valiant (1984). 
Motivated by the stochastic nature of many real-world learning problems and by 
the indisputable fact that biological neurons are probabilistic devices, some prelimi- 
nary studies about the PAC learnability of simple probabilistic neural concepts have 
been reported recently (Golea and Marchand, 1993; Golea and Marchand, 1994). 
However, the probabilistic behaviors considered in these studies are quite specific 
and clearly need to be extended. Indeed, only classification noise superimposed 
on a deterministic signurn function was considered in Golea and Marchand (1993). 
The probabilistic network, analyzed in Golea and Marchand (1994), consists of a 
linear superposition of signum functions and is thus solvable as a (simple) case of 
linear regression. What is clearly needed is the extension to the non-linear cases 
of sigmoYds and radial basis functions. Another criticism about Golea and Marc- 
hand (1993, 1994) is the fact that their learnability results was established only 
for distributions where each input variable is statistically independent from all the 
others (sometimes called product distributions). In fact, very few positive learning 
results for non-trivial p-concepts classes are known to hold for larger classes of dis- 
tributions. Therefore, in an effort to find algorithms that will work in practice, we 
introduce in this paper a new family of distributions that we call k-blocking. As we 
will argue, this family has the dual advantage of avoiding malicious and unnatural 
distributions that are prone to render simple concept classes unlearnable (Lin and 
Vittel 1991) and of being likely to contain several distributions found in practice. 
Our main contribution is to present a simple statistical method that PAC learns (in 
polynomial time) the class of stochastic perceptrons with monotonic (but otherwise 
arbitrary) activation functions and weights wi {-1, 0, +1} when the input exam- 
ples are generated according to any distribution member of the k-blocking family. 
Due to space constraints, only a sketch of the proofs is presented here. 
2 DEFINITIONS 
The instance (input) space, I n, is the Boolean domain {-1, +1} n. The set of all 
input variables is denoted by X. Each input example x is generated according to 
some unknown distribution D on I n. We will often use pt)(x), or simply p(x), to 
denote the probability of observing the vector value x under distribution D. If U 
and V are two disjoint subsets of X, xrr and xv will denote the restriction (or 
projection) of x over the variables of U and V respectively and pr)(xrlxv) will 
denote the probability, under distribution D, of observing the vector value xrr (for 
the variables in U) given that the variables in V are set to the vector value xv. 
Following Kearns and Schapire (1994), a probabilistic concept (p-concept) is a map 
c: I n --, [0, 1] for which c(x) represents the probability that example x is classified 
as positive. More precisely, upon presentation of input x, an output of a = 1 is 
generated (by an unknown target p-concept) with probability c(x) and an output 
of a = 0 is generated with probability 1 - c(x). 
A stoclastic perceptton is a p-concept parameterized by a vector of n weights wi 
and a activation function f(.) such that, the probability that input example x is 
Learning Stochastic Perceptrons under k-Blocking Distributions 281 
classified as positive is given by 
i----1 
We consider the case of a non-linear function f(.) since the linear case can be solved 
by a standard least square approximation like the one performed by Kearns in 
Schapire (1994) for linear sums of basis functions. We restrict ourselves to the case 
where f(.) is monotonic i.e. either nondecreasing or nonincreasing. But since any 
nonincreasing f(.) combined with a weight vector w can always be represented by a 
nondecreasing f(.) combined with a weight vector -w, we can assume without loss 
of generality that the target stochastic perceptron has a nondecreasing f(.). Hence, 
we allow any sigmoid-type of activation function (with arbitrary threshold). Also, 
since our instance space Z n is on a n-sphere, eq. 1 also include any nonincreasing 
radial basis function of the type b(z 2) where z = Ix - w[ and w is interpreted as 
the center of b. The only significant restriction is on the weights where we allow 
only for wi  (-1, 0, +1). 
As usual, the goal of the learner is to return an hypothesis h which is a good ap- 
proximation of the target p-concept c. But, in contrast with decision rule learning 
which attempts to filter out the noisy behavior by returning a deterministic hy- 
pothesis, the learner will attempt the harder (and more useful) task of modeling 
the target p-concept by returning a p-concept hypothesis. As a measure of error 
between the target and the hypothesis p-concepts we adopt the variation distance 
dv (',') defined as: 
err(h,c) = dv(h,c) ae2 EpD(x)lb(x) -c(x)l (2) 
x 
Where the summation is over all the 2 n possible values of x. Hence, the same D is 
used for both training and testing. The following formulation of the PAC criterion 
(Valiant, 1984; Hassler, 1992) will be sufficient for our purpose. 
Definition I Algorithm A is said to PA C learn the class C of p-concepts by using 
the hypothesis class H (of p-concepts) under a family Z) of distributions on instance 
space I n, iff for any c  C, any D  Z), any 0 < e, 5  1, algorithm A returns in a 
time polynomial in (l/e, 1/5, n), an hypothesis h  H such that with probability at 
least i - 5, err(h, c)  e. 
3 K-BLOCKING DISTRIBUTIONS 
To learn the class of stochastic perceptrons, the algorithm will try to discover each 
weight wi that connects to input variable xi by estimating how the probability 
of observing a positive output (a = 1) is affected by hard-wiring variable xi to 
some fixed value. This should clearly give some information about wi when xi 
is statistically independent from all the other variables as was the case for Golea 
and Marchand (1993) and Schapire (1992). However, if the input variables are 
correlated, then the process of fixing variable xi will carry over neighboring variables 
which in turn will affect other variables until all the variables are perturbed (even 
in the simplest case of a first order Markov chain). The information about wi will 
282 Mario Marchand, Saeed Hadjifaradji 
then be smeared by all the other weights. Therefore, to obtain information only 
on wi, we need to break this chain reaction by fixing some other variables. The 
notion of blocking sets serves this purpose. 
Loosely speaking, a set of variables is said to be a blocking set  for variable xi 
if the distribution on all the remaining variables is unaffected by the setting of xi 
whenever all the variables of the blocking set are set to a fixed value. More precisely, 
we have: 
Definition 2 Let B be a subset of X and let U = X - (B U {xi}). Let xB and xv 
be the restriction of x on B and U respectively and let b be an assignment for xB. 
Then B is said to be a blocking set for variable xi (with respect to D), iff: 
pD(XU[XB = b, xi = +1) = piv(xv[x = b, xi = -1) for all b and xv 
In addition, if B is not anymore a blocking set when we remove anyone of its 
variables, we then say that B is a minimal blocking set for variable xi. 
We thus adopt the following definition for the k-blocking family. 
Definition 3 Distribution D on :n is said to be k-blocking iff IBil 
1, 2... n when each Bi is a minimal blocking set for variable xi. 
for/= 
The k-blocking family is quite a large class of distributions. In fact we have the 
following property: 
Property ! All Markov distributions of kth order are members of the 2k-blocking 
family. 
Proof: By kth order Markov distributions, we mean distributions which can be 
exactly written as a Chow(k) expansion (see Hoeffgen, 1993) for some permuta- 
tion of the variables. We prove it here (by using standard techniques such as 
in Abend et. al, 1965) for first order Markov distributions, the generalization for 
k  i is straightforwa
