Spatial Decorrelation in Orientation 
Tuned Cortical Cells 
Alexander Dimitrov 
Department of Mathematics 
University of Chicago 
Chicago, IL 60637 
a-dimitrov@uchicago.edu 
Jack D. Cowan 
Department of Mathematics 
University of Chicago 
Chicago, IL 60637 
cowan@mat h.uchicago.edu 
Abstract 
In this paper we propose a model for the lateral connectivity of 
orientation-selective cells in the visual cortex based on information- 
theoretic considerations. We study the properties of the input sig- 
nal to the visual cortex and find new statistical structures which 
have not been processed in the retino-geniculate pathway. Applying 
the idea that the system optimizes the representation of incoming 
signals, we derive the lateral connectivity that will achieve this for 
a set of local orientation-selective patches, as well as the complete 
spatial structure of a layer of such patches. We compare the results 
with various physiological measurements. 
I Introduction 
In recent years much work has been done on how the structure of the visual sys- 
tem reflects properties of the visual environment (Atick and Redlich 1992; Attneave 
1954; Barlow 1989). Based on the statistics of natural scenes compiled and studied 
by Field (1987) and Ruderman and Bialek (1993), work was done by Atick and 
Redlich (1992) on the assumption that one of the tasks of early vision is to re- 
duce the redundancy of input signals, the results of which agree qualitatively with 
numerous physiological and psychophysical experiments. Their ideas were further 
strengthened by research suggesting the possibility that such structures develop via 
simple correlation-based learning mechanisms (Atick and Redlich 1993; Dong 1994). 
A s suggested by Atick and Li (1994), further higher-order redundancy reduction 
of the luminosity field in the visual processing system is unlikely, since it gives 
little benefit in information compression. In this paper we apply similar ideas to a 
different input signal which is readily available to the system and whose statistical 
properties are lost in the analysis of the luminosity signal. We note that after the 
Spatial Decorrelation in Orientation Tuned Cortical Cells 853 
application of the retinal mexican hat filter the most obvious salient features 
that are left in images are sharp changes in luminosity, for which the filter is not 
optimal, i.e. local edges. Such edges have correlations which are very different 
from the luminosity autocorrelation of natural images (Field 1987), and have zero 
probability measure in visual scenes, so they are lost in the ensemble averages used 
to compute the autocorrelation function of natural images. We know that this 
signal is projected to a set of direction-sensitive units in V1 for each distinct retinal 
position, thereby introducing new redundancy in the signal. Thus the necessity for 
compression and use of factorial codes arises once again. 
Since local edges are defined by sharp changes in the luminosity field, we can use 
a derivative operation to pick up the pertinent structure. Indeed, if we look at the 
gradient of the luminosity as a vector field, its magnitude at a point is proportional 
to the change of luminosity, so that a large magnitude signals the possible presence of 
a discontinuity in the luminosity profile. Moreover, in two dimensions, the direction 
of the gradient vector is perpendicular to the direction of the possible local edge, 
whose presence is given by the magnitude. These properties define a one-to-one 
correspondence between large gradients and local edges. 
The structure of the network we use reflects what is known about the structure of 
V1. We select as our system a layer of direction sensitive cells which are laterally 
connected to one another, each receiving input from the previous layer. We assume 
that each unit receives as input the directional derivative of the luminosity signal 
along the preferred visuotopic axis of the cell. This implies that locally the input to 
a cell is proportional to the cosine of the angle between the unit's preferred direction 
and the local gradient (edge). Thus each unit receives a broadly tuned signal, with 
HW-HH approximately 60 �. With this feed-forward structure, the idea that the 
system is trying to decorrelate its inputs suggests a way to calculate the lateral 
connections that will perform this task. This calculation, and a further study of the 
statistical properties of the input is the topic of the paper. 
2 Mathematical Model 
Let G(x) = (Gl(x), G2(x)) be the gradient of luminosity at x. Assume that there 
is a set of N detectors with activity Oi at x, each with a preferred direction hi. 
Let the input from the previous layer to each detector be the directional derivative 
along its preferred direction. 
ICrad(L(x)).nil- I 
(1) 
There are long range correlations in the inputs to the network due both to the 
statistical structure of the natural images and the structure of the input. The 
simplest of them are captured in the two-point correlation matrix Rij(Xl, x2) --< 
l/}(xx)l(x2) >, where the averaging is done across images. Then / is a block 
matrix, with an N x N matrix at each spatial position (xx, x2). 
We formulate the problem in terms of a recurrent kernel W, so that 
O--V+W*O 
(2) 
The biological interpretation of this is that V is the effective input to V1 from 
the LGN and W specifies the lateral connectivity in V1. This equation describes 
the steady state of the linear dynamical system 0 = -O + W * O + V. The 
854 A. Dimitrov and J. D. Cowan 
above recurrent system has a solution for O not an eigenfunction of W in the form 
O -- (6 - W)-1. V - K � V. This suggests that there is an equivalent feed-forward 
system with a transfer function K - (6- W) -1 and we can consider only such 
systems. 
The corresponding feed-forward system is a linear system that acts on the input 
V(x) to produce an output O(x) = (K. V)(x) _= f K(x,y) . V(y)dy. If we use Bar- 
low's redundancy reduction hypothesis (Barlow 1989), this filter should decorrelate 
the output signal. This is achieved by requiring that 
,(x - x2) ~ < o() o o(2) >=< (c. v)() o ('. v)() >, 
(x-z2) ~ K.R.K T 
() 
The aim then is to solve (3) for K. Obviously, this is equivalent to K T � K .-, R - 
(assuming K and R are non-singular), which has a solution K ~ R-�, unique up 
to a unitary transformation. The corresponding recurrent filter is then 
W=6-K -t =8-pR� (4) 
This expression suggests an immediate benefit in the use of lateral kernels by the 
system. As (4) shows, the filter does not now require inverting the correlation matrix 
and thus is more stable than a feed-forward filter. This also helps preserve the local 
structure of the autocorrelator in the optimal filter, while, because of the inversion 
process, a feed-forward system will in general produce non-local, non-topographic 
solutions. 
To obtain a realistic connectivity structure, we need to explicitly include the effects 
of noise on the system. The system is then described by O1 = V q- N1 q- M � kV � 
(Ox q-N), where N is the input noise and N is the noise, generated by individual 
units in the recurrently connected layer. Similarly to a feed-forward system (Atick 
and Redlich 1992), we can modify the decorrelation kernel kV derived from (2) to 
M � W. The form of the correction M, which minimizes the effects of noise on 
the system, is obtained by minimizing the distance between the states of the two 
systems. If we define x2(M) -< IO - Ox I  > as the distance function, the solution 
�)�2(M) -- 0 will give us the appropriate kernel. A solution to this problem is 
to OM -- 
M � w = - (R + N + N) � (p R/ + )-l (5) 
We see that it has the correct asymptotics as N, N approach zero. The filter be- 
haves well for large N2, turning mostly into a low-pass filter with large attenuation. 
It cannot handle well large N and reaches -cx proportionally to N. 
3 Results 
3.1 Local Optimal Linear Filter 
As a first calculation with this model, consider its implications for the connectivity 
between units in a single hypercolumn. This allows for a very simple application 
of the theory and does not require any knowledge of the input signal under very 
general assumptions. 
We assume that direction selective cells receive as input from the previous layer the 
projection of the gradient onto their preferred direction. Thus they act as directional 
Spatial Decorrelation in Orientation Tuned Cortical Cells 855 
derivatives, so that their response to a signal with the luminosity profile L(x) and 
no input from other lateral units is �(x) = IGrad(L(x)).nil = Id/dni(L(x))l 
With this assumption the outputs of the edge detectors are correlated. Define a 
(local) correlation matrix R/j =< �Vj >. By assumption (1), V = I a Cos(a - 
a)l , where a and a are random, independent variables, denoting the magnitude 
and direction of the local gradient and a is the preferred angle of the detector. 
Assuming spatially isotropic local structure for natural scenes, we can calculate the 
average of/i by integrating over a uniform probability measure in a. Then 
(6) 
where A =< a 2 > can be factored because of the assumption of statistical inde- 
pendence. By the homogeneity assumption, lij is a function of the relative angle 
[ai -- aj[ only. This allows us to easily calculate the integral in (6) from its Fourier 
series. Indeed, in Fourier space  is just the square of the power spectrum of the 
underlying signal, i.e., cos(P) on [0, r]. Thus we obtain the form of/ analytically. 
Knowing the local correlations, we can find a recurrent linear filter which decorre- 
lates the outputs after it is applied. This filter is W = 6 - p R-� (Sec.2), unique 
up to a unitary transformation. 
w 
1 
0.8 
0.6 
0.4 
0.2 
- -75 -50 -25 25 50 75 
-0.:2 
-0.4 
Figure 1: Local recurrent filter in the presence of noise. The connection strength H; 
depends only on the relative angle 
