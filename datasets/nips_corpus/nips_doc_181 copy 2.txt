248 
A CONNECTIONIST EXPERT SYSTEM 
THAT ACTUALLY WORKS 
Gary Bradshaw 
Psychology 
Richard Fozzard 
Computer Science 
University of Colorado 
Boulder, CO 80302 
fozzard@boulder.colorado.edu 
Louis Ceci 
Computer Science 
ABSTRACT 
The Space Environment Laboratory in Boulder has collaborated 
with the University of Colorado to construct a small expert 
system for solar flare forecasting, called THEO. It performed as 
well as a skilled human forecaster. We have constructed 
TheoNet, a three-layer back-propagation connectionist net- 
work that learns to forecast flares as well as THEO does. 
TheoNet's success suggests that a connectionist network can 
perform the task of knowledge engineering automatically. A 
study of the internal representations constructed by the network 
may give insights to the microstructure of reasoning processes 
in the human brain. 
INTRODUCTION 
Can neural network learning algorithms let us build expert systems 
automatically, merely by presenting the network with data from the problem 
domain? We tested this possibility in a domain where a traditional expert 
system has been developed that is at least as good as the expert, to see if the 
connectionist approach could stand up to tough competition. 
Knowledge-based expert systems attempt to capture in a computer program the 
knowledge of a human expert in a limited domain and make this knowledge 
available to a user with less experience. Such systems could be valuable as an 
assistant to a forecaster or as a training tool. In the past three years, the Space 
Environment Laboratory (SEL) in Boulder has collaborated with the Computer 
Science and Psychology Departments at the University of Colorado to construct 
a small expert system emulating a methodology for solar flare forecasting 
developed by Pat Mcintosh, senior solar physicist at SEL. The project 
convincingly demonstrated the possibilities of this type of computer assistance, 
which also proved to be a useful tool for formally expressing a methodology, 
verifying its performance, and instructing novice forecasters. The system, 
A Connectionist Expert System that Actually Works 249 
named THEO (an OPS-83 production system with about 700 rules), performed as 
well as a skilled human forecaster using the same methods, and scored well 
compared with actual forecasts in the period covered by the test data [Lewis 
and Dennett 1986]. 
In recent years connectionist (sometimes called non-symbolic or neural) 
network approaches have been used with varying degrees of success to simulate 
human behavior in such areas as vision and speech learning and recognition 
[Hinton 1987, Lehky and Sejnowski 1988, Sejnowski and Rosenberg 1986, Elman 
and Zipset 1987]. Logic (or symbolic) approaches have been used to simulate 
human (especially expert) reasoning [see Newell 1980 and Davis 1982]. There 
has developed in the artificial intelligence and cognitive psychology 
communities quite a schism between the two areas of research and the same 
problem has rarely been attacked by both approaches. It is hardly our intent to 
debate the relative merits of the two paradigms. The intent of this project is to 
directly apply a connectionist learning technique (multi-layer back- 
propagation) to the same problem, even the very same database used in an 
existing successful rule-based expert system. At this time we know of no current 
work attempting to do this. 
Forecasting, as described by those who practice it, is a unique combination of 
informal reasoning within very soft constraints supplied by often incomplete 
and inaccurate data. The type of reasoning involved makes it a natural 
application for traditional rule-based approaches. Solar and flare occurrence 
data are often inconsistent and noisy. The nature of the data, therefore, calls 
for careful handling of rule strengths and certainty factors. Yet dealing with 
this sort of data is exactly one of the strengths claimed for connectionist 
networks. It may also be that some of the reasoning involves pattern matching 
of the different categories of data. This is what led us to hope that a 
connectionist network might be able to learn the necessary internal 
representations to cope with this task. 
TECHNICAL APPROACH 
The TheoNet network model has three layers of simple, neuron-like processing 
elements called units. The lowest layer is the input layer and is clamped to a 
pattern that is a distributed representation of the solar data for a given day. 
For the middle (hidden) and upper (output) layers, each unit's output 
(called activation) is the weighted sum of all inputs from the units in the 
layer below: 
yj = 1 where: xj = yoji-Oj (1) 
1 +e-Xj i 
where Yi is the activation of the ith unit in the layer below, wji is the weight 
on the connection from the ith to the jth unit, and 0j is the threshold of the jth 
250 Fozzard, Bradshaw and Ceci 
unit. The weights are initially set to random values between -1.0 and +1.0, but 
are allowed to vary beyond that range. A least mean square error learning 
procedure called back-propagation is used to modify the weights incrementally 
for each input data pattern presented to the network. This compares the output 
unit activations with the correct (what actually happened) solar flare 
activity for that day. This gives the weight update rule: 
Awji(t+l) =-ï¿½VE(t) + oAwji(t) 
(2) 
where VE(t) is the partial derivative of least mean square error, e is a 
parameter called the learning rate that affects how quickly the network 
attempts to converge on the appropriate weights (if possible), and c is called 
the momentum which affects the amount of damping in the procedure. This is 
as in [Hinton 1987], except that no weight decay was used. Weights were 
updated after each presentation of an input/output pattern. 
The network was constructed as shown in Figure 1. The top three output units 
are intended to code for each of the three classes of solar flares to be forecasted. 
The individual activations are currently intended to correspond to the relative 
likelihood of a flare of that class within the next 24 hours (see the analysis of 
the results below). The 17 input units provide a distributed coding of the ten 
categories of input data that are currently fed into the default mode of the 
expert system THEO. That is, three binary (on/off) units code for the seven 
classes of sunspots, two for spot distribution, and so on. The hidden units 
mediate the transfer of activation from the input to the output units and 
provide the network with the potential of forming internal representations. 
Each layer is fully interconnected with the layer above and/or below it, but 
there are no connections within layers. 
RESULTS 
The P3 connectionist network simulator from David Zipser of University of 
California at San Diego's parallel distributed processing (PDP) group was used 
to implement and test TheoNet on a Symbolics 3653 workstation. This 
simulator allowed the use of Lisp code to compile statistics and provided an 
interactive environment for working with the network simulation. 
The network was trained and tested using two sets of data of about 500 
input/output pairs (solar data/flare occurrence) each from the THEO database. 
Many of these resulted in the same input pattern (there were only about 250 
different input patterns total), and in many cases the same input would result in 
different flare results in the following 24 hours. The data was from a low flare 
frequency period (about 70-80 flares total). These sorts of inconsistencies in the 
data make the job of prediction difficult to systematize. The network would be 
A Connectionist Expert System that Actually Works 251 
OUTPUT: 
Flare probability by class 
C M X 
D=011 
A---011 O---01 growth yes no above 5 
reduced less than M1 small 
.O 03 
'= 
INPUT SOLAR DATA 
1. Modified Zurich class (7 possible values: A/B/C/D/E/F/H) 
2. Largest spot size (6 values: X/R/S/A/H/K) 
3. Spot distribution (4 values: X/O/I/C) 
4. Activity (reduced / unchanged) 
5. Evolution (decay / no growth / or growth) 
6. Previous flare activity (less than M1 / M1 / more than M1) 
7. Historically complex (yes/no) 
8. Recently became complex on this pass (yes/no) 
9. Area (small/large) 
10. Area of the largest spot (up to 5 / above 5) 
Figure 1. Architecture of TheoNet 
252 Fozzard, Bradshaw and Ceci 
trained on one data set and then tested on the other (it did not matter which 
one was used for which). 
Two ways of measuring performance were used. An earlier simulation tracked a 
simple measure called overall-prediction-error. This was the average 
difference over one complete epoch of input patterns between the activation of 
an output unit and the correct value it was supposed to have. This is directly 
related to the sum-squared error used by the back-propagation method. 
While the overall-prediction-error would drop quickly for all flare classes 
after a dozen epoches or so (about 5 minutes on the Symbolics), individual 
weights would take much longer to stabilize. Oscillations were seen in weight 
values if a large learning rate was used. When this was reduced to 0.2 or lower 
(with a momentum of 0.9), the weights would converge more smoothly to their 
final values. 
Overall-prediction-error however, is not a good measure of performance since 
this could be reduced simply by reducing average activation (a Just-Say-No 
network). Analyzing performance of an expert system is best done using 
measures from the problem domain. Forecasting problems are essentially 
probabilistic, requiring the detection of signal from noisy data. Thus 
forecasting techniques and systems are often analyzed using signal detection 
theory [Spoehr and Lehmkuhie 1982]. 
The system was modified to calculate P(H), the probability of a hit, and 
P(FA), the probability of a false alarm, over each epoch. These parameters 
depend on the response bias, which determines the activation lev
