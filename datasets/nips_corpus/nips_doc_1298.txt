Bayesian Robustification for Audio Visual 
Fusion 
Javier Movellan * 
movellancogsci. ucsd. edu 
Department of Cognitive Science 
University of California, San Diego 
La Jolla, CA 92092-0515 
Paul Mineiro 
prnineirocogsci. ucsd. edu 
Department of Cognitive Science 
University of California, San Diego 
La Jolla, CA 92092-0515 
Abstract 
We discuss the problem of catastrophic fusion in multimodal recog- 
nition systems. This problem arises in systems that need to fuse 
different channels in non-stationary environments. Practice shows 
that when recognition modules within each modality are tested in 
contexts inconsistent with their assumptions, their influence on the 
fused product tends to increase, with catastrophic results. We ex- 
plore a principled solution to this problem based upon Bayesian 
ideas of competitive models and inference robustification: each 
sensory channel is provided with simple white-noise context mod- 
els, and the perceptual hypothesis and context are jointly esti- 
mated. Consequent]y, context deviations are interpreted as changes 
in white noise contamination strength, automatically adjusting the 
influence of the module. The approach is tested on a fixed lexicon 
automatic audiovisual speech recognition problem with very good 
results. 
i Introduction 
In this paper we address the problem of catastrophic fusion in automatic multimodal 
recognition systems. We explore a principled solution based on the Bayesian ideas of 
competitive models and inference robustification (Clark &: Yuille, 1990; Box, 1980; 
O'Hagan, 1994). For concreteness, consider an audiovisual car telephony task which 
we will simulate in later sections. The task is to recognize spoken phone numbers 
based on input from a camera and a microphone. We want the recognition system to 
work on environments with non-stationary statistical properties: at times the video 
signal (V) may be relatively clean and the audio signal (A) may be contaminated by 
sources like the radio, the engine, and friction with the road. At other times the A 
signal may be more reliable than the V signal, e.g., the radio is off, but the talker's 
mouth is partially occluded. Ideally we want the audio-visual system to combiae 
the A and V sources optimally given the conditions at hand, e.g., give more weight 
to whichever channel is more reliable at that time. At a minimum we expect that 
for a wide variety of contexts, the performance after fusion should not be worse than 
the independent unimodal systems (Bernstein &: Benoit, 1996). When component 
modules can significantly outperform the overall system after fusion, catastrophic 
fusion is said to have occurred. 
* To whom correspondence should be addressed. 
Bayesian Robustification for Audio Visual Fusion 743 
Fixed vocabulary audiovisual speech recognition (AVSR) systems typically con- 
sist of two independent modules, one dedicated to A signals and one to V signals 
(Bregler, Hild, Manke & Waibel, 1993; Wolff, Prasad, Stork & Hennecke, 1994; 
Adjondani & Benoit, 1996; Movellan & Chadderdon, 1996). From a Bayesian per- 
spective this modularity reflects an assumption of conditional independence of A 
and V signals (i.e., the likelihobd function factorizes) 
p(xaxvl:iAaAv) p(xal:iA)p(xvi:iAv), (1) 
where Xa and Xv are the audio and video data, :i is a perceptual interpretation 
of the data (e.g., the word one) and (Aa, Av} are the audio and video models 
according to which these probabilities are calculated, e.g., a hidden Markov model, 
a neural network, or an exemplar model. Training is also typically modularized: the 
A module is trained to maximize the likelihood of a sample of A signals while the V 
module is trained on the corresponding sample of V signals. At test time new data 
are presented to the system and each module typically outputs the log probability 
of its input given each perceptual alternative. Assuming conditional independence, 
Bayes' rule calls for an affine combination of modules 
tb -- argmax {10gp(:ilXaXvhav)) 
= argmax{logp(xl:ih) + logp(xvl:ihv) + logp(:i)) (2) 
where tb is the interpretation chosen by the system, and p(wi) is the prior probability 
of each alternative. This fusion rule is optimal in the sense that it minimizes the 
expected error: no other fusion rule produces smaller error rates, provided the 
models {ha, hv) and the assumption of conditional independence are correct. 
Unfortunately a naive application of Bayes' rule to AVSR produces catastrophic 
fusion. The A and V modules make assumptions about the signals they receive, 
either explicitly, e.g., a well defined statistical model, or implicitly, e.g., a black- 
box trained with a particular data sample. In our notation these assumptions are 
reflected by the fact that the log-likelihoods are conditional on models: 
The fact that modules make assumptions implies that they will operate correctly 
only within a restricted context, i.e, the collection of situations that meet the as- 
sumptions. In practice one typically finds that Bayes' rule assigns more weight to 
modules operating outside their valid context, the opposite of what is desired. 
2 Competitive Models and Bayesian Robustification 
Clark and Yuille (1990) and Yuille and Bulthoff (1996) analyzed information inte- 
gration in sensory systems from a Bayesian perspective. Modularity is justified in 
their view by the need to make assumptions that disambiguate the data available to 
the perceptual system (Clark & Yuille, 1990, p. 5). However, this produces modules 
which are valid only within certain contexts. The solution proposed by Clark and 
Yuille (1990) is the creation of an ensemble of models each of which specializes on 
a restricted context and automatically checks whether the context is correct. The 
hope is that by working with such an ensemble of models, robustness under a variety 
of contexts can be achieved (Clark & Yuille, 1990, p. 13). 
Box (1980) investigated the problem of robust statistical inference from a Bayesian 
perspective. He proposed extending inference models with additional nuisance 
parameters a, a process he called Bayesian robustification. The idea is to replace 
an implicit assumption about the specific value of a with a prior distribution over 
a, representing uncertainty about that parameter. 
The approach here combines the ideas of competitive models and robustification. 
Each of the channels in the multimodal recognition system is provided with extra 
744 J. Movellan and P. Mineiro 
parameters that represent non-stationary properties of the environment, what we 
call a context model. By doing so we effectively work with an infinite ensemble of 
models each of which compete on-line to explain the data. As we will see later even 
unsophisticated context models provide superior performance when the environment 
is non-stationary. 
We redefine the estimation problem as simultaneously choosing the most probable 
A and V context parameters and the most probable perceptual interpretation 
tb = argmax {maxp(wirrarrv,XaXvav) } (3) 
/ayi O'a 
where aa and a. are the context parameters for the audio and visual channels 
and wi are the different perceptual interpretations. One way to think of this joint 
decision approach is that we let all context models compete and we let only the 
most probable context models have an influence on the fused percept. Hereafter we 
refer to this approach as competitive fusion. 
Assuming conditional independence of the audio and video data and uninformative 
priors for (era, a,, we have 
tb = argmax {logp(o:i) + 
(4) 
[axlogp(xalwi�'aAa)] + [axlogp(x, lwi�',A,)] } � 
Thus conditional independence allows a modular implementation of competitive 
fusion, i.e., the A and V channels do not need to talk to each other until the time 
to make a joint decision, as follows. 
1. For each wi obtain conditional estimates of the context parameters for the 
audio and video signals: 
^2 A 
aais, = argmax { 10gp(XalWirraAa) }, (5) 
O' a 
and 
2 A 
vl, = argmax { logp(xvlWiO'vAv) ). 
O'v 
2. Find the best wi using the conditional context estimates. 
5 - argmax {logp(wi) + 10gp(XalWiS'alJka ) + 10gp(XvliS'vlJkv) 
(6) 
(7) 
3 Application to AVSR 
Competitive fusion can be easily applied to Hidden Markov Models (HMM), an 
architecture closely related to stochastic neural networks and arguably the most 
successful for AVSR. Typical hidden Markov models used in AVSR are defined by 
� Markovian state dynamics: P(qt+ IqO - p(qt+llqt), where qt is the state at 
time t and q-t = (ql,' qt), 
� Conditionally independent sensor models linking observations to states 
f(xtlqt), typically a mixture of multivariate Gaussian densities 
f(xtlqt) = p(milqt)(27r) -N/2 ]']]--1/2 exp(d(xt,qt,lai,y.)) ' (8) 
i 
Bayesian Robustification for Audio Visual Fusion 745 
where N is the dimensionality of the data, mi is the mixture label, P(mi[qt) 
is the mixture distribution for state qt, i is the centroid for mixture 
Y, is a covariance matrix, and d is the Mahalanobis norm 
d(xt,qt,]gi,) = (xt - ]gi)t-l(xa - ]i). 
(9) 
The approach explored here consists on modeling contextual changes as variations 
on the variance parameters. This corresponds to modeling non-stationary proper- 
ties of the environments as variations in white noise power within each channel. 
Competitive fusion calls for on-line maximization of the variance parameters at the 
same time we optimize with respect to the response alternative. 
tb = argmax logp(wi) + 
[mE,axlogp(xalwiYa)a) ] 
(10) 
The maximization with respect to the variances can be easily integrated into stan- 
dard HMM packages by simply applying the EM learning algorithm (Dampster, 
Laird & Rubin, 1977) on the variance parameters at test time. Thus the only dif- 
ference between the standard approach and competitive fusion is that we retrain 
the variance parameters of each HMM at test time. In practice this training takes 
only one or two iterations of the
