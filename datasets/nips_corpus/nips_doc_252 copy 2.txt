558 Rohwer 
The 'Moving Targets' Training Algorithm 
Richard Rohwer 
Centre for Speech Technology Research 
Edinburgh University 
80, South Bridge 
Edinburgh EH1 1HN SCOTLAND 
ABSTRACT 
A simple method for training the dynamical behavior of a neu- 
ral network is derived. It is applicable to any training problem 
in discrete-time networks with arbitrary feedback. The algorithm 
resembles back-propagation in that an error function is minimized 
using a gradient-based method, but the optimization is carried out 
in the hidden part of state space either instead of, or in addition to 
weight space. Computational results are presented for some simple 
dynamical training problems, one of which requires response to a 
signal 100 time steps in the past. 
1 INTRODUCTION 
This paper presents a minimization-based algorithm for training the dynamical be- 
havior of a discrete-time neural network model. The central idea is to treat hidden 
nodes as target nodes with variable training data. These moving targets are 
varied during the minimization process. Werbos (Werbos, 1983} used the term 
moving targets to describe the qualitative idea that a network should set itseft 
intermediate objectives, and vary these objectives as information is accumulated on 
their attainability and their usefulness for achieving overall objectives. The (coin- 
cidentally) like-named algorithm presented here can be regarded as a quantitative 
realization of this qualitative idea. 
The literature contains several temporal training algorithms based on minimization 
of an error measure with respect to the weights. This type of method includes 
the straightforward extension of the back-propagation method to back-propagation 
The 'Moving Targets' Training Algorithm 559 
through time (Rumelhart, 1986), the methods of Rohwer and Forrest (Rohwer, 
1987), Pearlmutter (Pearlmutter, 1989), and the forward propagation of derivatives 
(Robinson, 1988, Williams 1989a, Williams 1989b, Kuhn, 1990). A careful compar- 
ison of moving targets with back-propagation in time and teacher forcing appears in 
(Rohwer, 1989b). Although applicable only to fixed-point training, the algorithms 
of Almeida (Alineida, 1989) and Pineda (Pineda, 1988) have much in common with 
these dynamical training algorithms. The formal relationship between these and 
the method of Rohwer and Forrest is spelled out in (Rohwer 1989a). 
2 
NOTATION AND STATEMENT OF THE TRAINING 
PROBLEM 
Consider a neural network model with arbitrary feedback as a dynamical system in 
which the dynamical variables xit change with time according to a dynamical law 
given by the mapping 
:,:,, = ) 
.i 
x0t = bias constant 
(1) 
unless specified otherwise. The weights w i are arbitrary parameters representing 
the connection strength from node 3' to node i. f is an arbitrary differentiable 
function. Let us call any given variable xi the activation on node i at time t. It 
represents the total input into node i at time t. Let the %utput of each node be 
denoted by Yi = f(xi). Let node 0 be a %ias node, assigned a positive constant 
activation so that the weights wio can be interpreted as activation thresholds. 
In normal back-propagation, a network architecture is defined which divides the 
network into input, hidden, and target nodes. The moving targets algorithm makes 
itself applicable to arbitrary training problems by defining analogous concepts in a 
manner dependent upon the training data, but independent of the network archi- 
tecture. Let us call a node-time pair an event. To define a training problem, the 
set of all events must be divided into three disjoint sets, the input events I, target 
events T, and hidde n events H. A node may participate in different types of event 
at different times. For every input event (it)  I, we require training data Xi with 
which to overrule the dynamical law (1) using 
::,:. = x. .r. (2) 
(The bias events (0t) can be regarded as a special case of input events.) For each 
target event (it)  T, we require training data Xi to specify a desired activation 
value for event (0t). No notational ambiguity arises from referring to input and 
target data with the same symbol X because I and T are required to be disjoint 
sets. The training data says nothing about the hidden events in H. There is no 
restriction on how the initial events (i0) are classified. 
560 Rohwer 
3 THE MOVING TARGETS METHOD 
Like back-propagation, the moving targets training method uses (arbitrary) gradient- 
based minimization techniques to minimize an error function such as the output 
deficit 
= (s) 
where y. = f(x.) and Y = f(X.). A modification of the output deficit error gave 
the best results in numerical experiments. However, the most elegant formalism 
follows from an activation deficit error function: 
= } - x.l (4) 
so this is what we shall use to present the formalism. 
The basic idea is to treat the hidden node activations as variable target activations. 
Therefore let us denote these variables as Xit, just as the (fixed) targets and inputs 
are denoted. Let us write the computed activation values xit of the hidden and 
target events in terms of the inputs and (fixed and moving) targets of the previous 
time step. Then let us extend the sum in (4) to include the hidden events, so the 
error becomes 
- x. (s) 
E= 
(it)ETUH ' 
This is a function of the weights wO. , and because there are no x's present, the full 
dependence on wiy is explicitly displayed. We do not actually have desired values 
for the Xi, with (it)  H. But any values for which weights can be found which 
make (5) vanish would be suitable, because this would imply not only that the 
desired targets are attained, but also that the dynamical law is followed on both 
the hidden and target nodes. Therefore let us regard E as a function of both the 
weights and the moving targets Xi, (it)  H. This is the essence of the method. 
The derivatives with respect to all of the independent variables can be computed 
and plugged into a standard minimization algorithm. 
The reason for preferring the activation deficit form of the error (4) to the output 
deficit form (3) is that the activation deficit form makes (5) purely quadratic in the 
weights. Therefore the equations for the minimum, 
dE/dw O. = aE/aw o. = o, 
(6) 
form a linear system, the solution of which provides the optimal weights for any 
given set of moving targets. Therefore these equations might as well be used to 
define the weights as functions of the moving targets, thereby making the error (5) 
a function of the moving targets alone. 
The 'Moving Targets' Training Algorithm 561 
The derivation of the derivatives with respect to the moving targets is spelled out 
in (Rohwer, 1989b). The result is: 
dE 
x. : }__] x,,.+ , ,,.+ , ,L - x.., (7) 
i 
where 
and 
x. = o (a) ï¿½ 3' u f/ (s) 
ft  
dx 
(9) 
(zo) 
where M ()-I is the inverse of M(), the correlation matrix of the node outputs 
defined by 
n??=  x.,r,,,_, r,.,,_,. (z) 
In the event that any of the matrices M are singular, a pseudo-inversion method 
such as singular value decomposition (Press, 1988) can be used to define a unique 
solution among the infinite number available. 
Note also that (11) calls for a separate matrix inversion for each node. However if 
the set of input nodes remains fixed for all time, then all these matrices are equal. 
3.1 FEEDFORWARD VERSION 
The basic ideas used in the moving targets algorithm can be apphed to feedfor- 
ward networks to provide an alternative method to back-propagation. The hidden 
node activations for each training example become the moving target variables. 
Further details appear in (Rohwer, 1989b}. The moving targets method for feedfor- 
ward nets is analogous to the method of Grossman, Meir, and Domany (Grossman, 
1990a, 1990b} for networks with discrete node values. Birmiwal, Sarwal, and Sinha 
(BirmiwM, 1989} have developed an algorithm for feedforward networks which in- 
corporates the use of hidden node values as fundamental variables and a linear 
562 Rohwer 
system of equations for obtaining the weight matrix. Their algorithm differs from 
the feedforward version of moving targets mainly in the (inessential) use of a specific 
minimization algorithm which discards most of the gradient information except for 
the signs of the various derivatives. Heileman, Georgiopoulos, and Brown (Heile- 
man, 1989) also have an algorithm which bears some resemblance to the feedforward 
version of moving targets. Another similar algorithm has been developed by Krogh, 
Hertz, and Thorbergasson (Krogh, 1989, 1990). 
4 COMPUTATIONAL RESULTS 
A set of numerical experiments performed with the activation deficit form of the 
algorithm (4} is reported in (Rohwer, 1989b}. Some success was attained, but 
greater progress was made after changing to a quartic output deficit error function 
with temporal weighting of errors: 
1 
Equartic --  E (1.0+ c&i)(yi,- Yit} 4. (13) 
Here a is a small positive constant. The quartic function is dominated by the terms 
with the greatest error. This combats a tendency to fail on a few infrequently seen 
state transitions in order to gain unneeded accuracy on a large number of similar, 
low-error state transitions. The temporal weighting encourages the algorithm to 
focus first on late-time errors, and then work back in time. In some cases this 
helped with local minimum difficulties. A difficulty with convergence to chaotic 
attractors reported in (Rohwer, 1989b) appears to have mysteriously disappeared 
with the adoption of this error measure. 
4.1 MINIMIZATION ALGORITHM 
Further progress was made by altering the minimization algorithm. Originally the 
conjugate gradient algorithm (Press, 1988) was used, with a linesearch algorithm 
from Fletcher (Fletcher, 1980). The new algorithm might be called 'curvature 
avoidance . The change in the gradient with each linesearch is used to update 
a moving average esti
