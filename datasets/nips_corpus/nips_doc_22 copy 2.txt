73O 
Analysis of distributed representation of 
constituent structure in connectionist systems 
Paul Smolensky 
Department of Computer Science, University of Colorado, Boulder, CO 80309-0430 
Abstract 
A general method, the tensor product representation, is described for the distributed representation of 
value/variable bindings. The method allows the fully distributed representation of symbolic structures: 
the roles in the structures, as well as the fillers for those roles, can be arbitrarily non-local. Fully and 
partially localized special cases reduce to existing cases of connectionist representations of structured 
data; the tensor product representation generalizes these and the few existing examples of fully 
distributed representations of structures. The representation saturates gracefully as larger structures 
are represented; it permits recursive construction of complex representations from simpler ones; it 
respects the independence of the capacities to generate and maintain multiple bindings in parallel; it 
extends naturally to continuous structures and continuous representational patterns; it permits values to 
also serve as variables; it enables analysis of the interference of symbolic structures stored in 
associative memories; and it leads to characterization of optimal distributed representations of roles 
and a recirculation algorithm for learning them. 
Introduction 
Any model of complex information processing in networks of simple processors must solve the 
problem of representing complex structures over network elements. Connectionist models of realistic 
natural language processing, for example, must employ computationally adequate representations of 
complex sentences. Many connectionists feel that to develop connectionist systems with the 
computational power required by complex tasks, distributed representations must be used: an 
individual processing unit must participate in the representation of multiple items, and each item must 
be represented as a pattern of activity of multiple processors. Connectionist models have used more or 
less distributed representations of more or less complex structures, but little if any general analysis of 
the problem of distributed representation of complex information has been carded out. This paper 
reports results of an analysis of a general method called the tensor product representation. 
The language-based formalisms traditional in AI permit the construction of arbitrarily complex 
structures by piecing together constituents. The tensor product representation is a connectionist 
method of combining representations of constituents into representations of complex structures. If the 
constituents that are combined have distributed representations, completely distributed representations 
of complex structures can result: each part of the network is responsible for representing multiple 
constituents in the structure, and each constituent is represented over multiple units. The tensor 
product representation is a general technique, of which the few existing examples of fully distributed 
representations of structures are particular cases. 
The tensor product representation rests on identifying natural counterparts within connectionist 
computation of certain fundamental elements of symbolic computation. In the present analysis, the 
problem of distributed representation of symbolic structures is characterized as the problem of taking 
complex structures with certain relations to their constituent symbols and mapping them into activity 
vectors--patterns of activation--with corresponding relations to the activity vectors representing their 
constituents. Central to the analysis is identifying a connectionist counterpart of variable binding: a 
method for binding together a distributed representation of a variable and a distributed representation 
of a value into a distributed representation of a variable/value binding--a representation which can 
co-exist on exactly the same network units with representations of other variable/value bindings, with 
American Institute of Physics 1988 
731 
limited confusion of which variables are bound to which values. 
In summary, the analysis of the tensor product representation 
(1) provides a general technique for constructing fully distributed representations of 
arbitrarily complex structures; 
(2) clarifies existing representations found in particular models by showing what particular 
design decisions they embody; 
(3) allows the proof of a number of general computational properties of the representation; 
(4) identifies natural counterparts within connectionist computation of elements of symbolic 
computation, in particular, variable binding. 
The recent emergence to prominence of the connectionist approach to AI raises the question of the 
relation between the nonsymbolic computation occurring in connectionist systems and the symbolic 
computation traditional in AI. The research reported here is part of an attempt to marry the two types 
of computation, to develop for AI a form of computation that adds crucial aspects of the power of 
symbolic computation to the power of connectionist computation: massively parallel soft constraint 
satisfaction. One way to marry these approaches is to implement serial symbol manipulation in a 
connectionist system ,2. The research described here takes a different tack. In a massively parallel 
system the processing of symbolic structures--for example, representations of parsed sentences--need 
not be limited to a series of elementary manipulations: indeed one would expect the processing to 
involve massively parallel soft constraint satisfaction. But in order for such processing to occur, a 
satisfactory answer must be found for the question: How can symbolic structures, or structured data in 
general, be naturally represented in connectionist systems? The difficulty here tums on one of the 
most fundamental problems for relating symbolic and connectionist computation: How can variable 
binding be naturally performed in connectionist systems? 
This paper provides an overview of a lengthy analysis reported elsewhere 3 of a general 
connectionist method for variable binding and an associated method for representing structured data. 
The purpose of this paper is to introduce the basic idea of the method and survey some of the results; 
the reader is referred to the full report for precise definitions and theorems, more extended examples, 
and proofs. 
The problem 
Suppose we want to represent a simple structured object, say a sequence of elements, in a 
connectionist system. The simplest method, which has been used in many models, is to dedicate a 
network processing unit to each possible element in each possible position 4. This is a purely local 
representation. One way of looking at the purely local representation is that the binding of 
constituents to the variables representing their positions is achieved by dedicating a separate unit to 
every possible binding, and then by activating the appropriate individual units. 
Purely local representations of this sort have some advantages ï¿½, but they have a number of serious 
problems. Three immediately relevant problems are these: 
(1) The number of units needed is #elements * #positions; most of these processors are 
inactive and doing no work at any given time. 
(2) The number of positions in the structures that can be represented has a fixed, rigid upper 
limit. 
(3) If there is a notion of similar elements, the representation does not take advantage of this: 
similar sequences do not have similar representations. 
The technique of distributed representation is a well-known way of coping with the first and third 
problems -4. If elements are represented as patterns of activity over a population of processing units, 
and if each unit can participate in the representation of many elements, then the number of elements 
that can be represented is much greater than the number of units, and similar elements can be 
represented by similar patterns, greatly enhancing the power of the network to learn and take 
advantage of generalizations. 
732 
Distributed representations of elements in structures (like sequences) have been successfully used 
in many models ,4,5.5-s. For each position in the structure, a pool of units is dedicated. The element 
occurring in that position is represented by a pattern of activity over the units in the pool. 
Note that this technique goes only part of the way towards a truly distributed representation of the 
entire structure. While the values of the variables def'ming the roles in the structure are represented by 
distributed patterns instead of dedicated units, the variables themselves are represented by localized, 
dedicated pools. For this reason I will call this type of representation semi-local. 
Because the representation of variables is still local, semi-local representations retain the second of 
the problems of purely local representations listed above. While the generic behavior of connectionist 
systems is to gradually overload as they attempt to hold more and more information, with dedicated 
pools representing role variables in structures, there is no loading at all until the pools are 
exhausted--and then there is complete saturation. The pools are essentially registers, and the 
representation of the structure as a whole has more of the characteristics of von Neumann storage than 
connectionist representation. A fully distributed connectionist representation of structured data would 
saturate gracefully. 
Because the representation of variables in semi-local representations is local, semi-local 
representations also retain part of the third problem of purely local representations. Similar elements 
have similar representations only if they occupy exactly the same role in the structure. A notion of 
similarity of roles cannot be incorporated in the semi-local representation. 
T
