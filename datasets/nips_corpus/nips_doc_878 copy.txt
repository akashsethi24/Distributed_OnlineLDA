An Integrated Architecture of Adaptive Neural Network 
Control for Dynamic Systems 
Liu Ke '2 Robert L. Tokaf Brian D.McVey z 
Center for Nonlinear Studies, 2Applied Theoretical Physics Division 
Los Alamos National Laboratory, Los Alarnos, NM, 87545 
Abstract 
In this study, an integrated neural network control architecture for nonlinear dynamic systems is 
presented. Most of the recent emphasis in the neural network control field has no error feedback as the 
control input, which rises the lack of adaptation problem. The integrated architecture in this paper 
combines feed forward control and error feedback adaptive control using neural networks. The paper 
reveals the different internal functionality of these two kinds of neural network controllers for certain 
input styles, e.g., state feedback and error feedback. With error feedback, neural network controllers 
learn the slopes or the gains with respect to the error feedback, producing an error driven adaptive 
contrbl systems. The results demonstrate that the two kinds of control scheme can be combined to 
realize their individual advantages. Testing with disturbances added to the plant shows good tracking 
and adaptation with the integrated neural control architecture. 
1 INTRODUCTION 
Neural networks are used for control systems because of their capability to approximate nonlinear 
system dynamics. Most neural network control architectures originate from work presented by 
Narendra[1], Psaltis[2] and Lightbody[3]. In these architectures, an identification neural network is 
trained to function as a model for the plant. Based on the neural network identification model, a neural 
network controller is trained by backpropagating the error through the identification network. After 
training, the identification network is replaced by the real plant. As is illustrated in Figure 1, the 
controller receives external inputs as well as plant state feedback inputs. Training procedures are 
employed such that the networks approximate feed forward control surfaces that are functions of 
external inputs and state feedbacks of the plant (or the identification network during training). 
It is worth noting that in this architecture, the error between the plant output and the desired output of 
the reference model is not fed back to the controller, after the training phase. In other words, this error 
information is ignored when the neural network applies its control. It is well known in control theory 
that the error feedback plays a significant role in adaptation. Therefore, when model uncertainty or 
noise/disturbances are present, a feed forward neural network controller with only state feedback will 
not adaptively update the control signal. On line training for the neural controller has been proposed to 
obtain adaptive ability[Ill3]. However, the stability for the on line training of the neural network 
controller is unresolved[ 1] [4]. 
In this study, an additional nonlinear recurrent network is combined with the feed forward neural 
network controller to form an adaptive controller. This added neural network uses feedback error 
between the reference model output and the plant output as an input. In addition, the system's external 
1032 Liu Ke, Robert L. Tokar, Brian D. McVey 
inputs and the plant states are also input to the feedback network. This architecture is used in the control 
community, but not with neural network components. The approach differs from a conventional error 
feedback controller, such as a gain scheduled PID controller, in that the neural network error feedback 
controller implements a continuous nonlinear gain scheduled hypersurface, and after training, adaptive 
model reference control for nonlinear dynamic systems is achieved without further parameter 
computation. The approach is tested on well-known nonlinear control problems in the neural network 
literature, and good results are obtained. 
2 NEURAL NETWORK CONTROL 
In this section, several different neural network control architectures are presented. In these structures, 
identification neural networks, viewed as accurate models for real plants, are used. 
2.1 NEURAL NETWORK FEED FORWARD CONTROL 
The neural network controllers are trained by backpropagation of errors through a well trained neural 
identification network. In this architecture, the state variable y(t) of the system is sent back to the neural 
network, and the external input x(t) also is input to the network. With these inputs, the neural network 
establishes a feed forward mapping from the external input x(t) to the control signal u(t). This control 
mapping is expressed as a function of the external input x(t) and the plant state y(t): 
u(t)=f(x(t), y(t)) (1) 
where x(t)=[x(t), x(t-1) .... ]*, andy(t)=[y(t), y(t-1) .... ]*. 
This neural network control architecture is denoted in this study as feed forward neural control even 
though it includes state feedback. Neural control with error feedback is denoted as feedback neural 
control. 
x(t) qRef. Model] x(t) 
 Control NN 
e(t+l) 
ID NN 
4 
) I qRef' Modell e(t+l)( 
 NN ID NN 
y(t+l) 
Figure 1 Neural Network Control Architecture. 
ID NN represents the identification network. 
Ref. Model means reference model, and NN 
means neural network. 
Figure 2 Neural Network Feedback Control 
Architecture 
) 
y(t+l) 
During the training phases, based on the assumption that the neural identification network provides a 
model for the plant, the gradient information needed for error backpropagation is obtained by calculating 
the JacobJan of the identification network. The following equation describes this process for the control 
architecture shown in Figure 1. If the cost function is defined as E, then the gradient of the cost function 
with respect to weight w of the neural controller is 
An Integrated Architecture of Adaptive Neural Network Control for Dynamic Systems 1033 
E E u 
w uw 
I3 3u 3E 
+ + 
3Yt_l 3 Yt-1 
 Yt-1 
w 
(2) 
where u is the control signal andyt4 is the plant feedback state. 
After the training stage, the neural network supplies a control law. Because neural networks have the 
ability to approximate any arbitrary nonlinear functions[5], a feed forward neural network can build a 
nonlinear controller, which is crucial to the use of the neural network in control engineering. Also, since 
all the parameters of the neural network identification model and the neural network controller are 
obtained from learning through samples, mathematically untraceable features of the plant can be 
extracted from the samples and imbedded into the control system. 
However, because the feed forward controller has no error feedback, the controller can not adapt to the 
disturbances occurring in the plant or the reference model. This problem is of substantial importance in 
the context of adaptive control. In the next subsection, error feedback between the reference models 
and the plant outputs is introduced into neural network controllers for adaptation. 
2.2 NEURAL ADAPTIVE CONTROL WITH ERROR FEEDBACK 
It is known that feedback errors from the system are important for adaptation. Due to the flexibility of the 
neural network architecture, the error between the reference model and the plant can be sent back to the 
controller as an extra input. In such an architecture, neural networks become nonlinear gain scheduled 
controllers with smooth continuous gains. Figure 2 shows the architecture for the feedback neural control. 
With this architecture, the neural network control surface is not the fixed mapping from the x(t) to u(t) 
for each state y(t), but instead it learns the slope or the gain referring to the feedback error e(t) for 
control. This gain is a continuous nonlinear function of the external input x(t) and the state feedback 
y(t). Figure 3 shows the recurrent network architecture of the feedback neural controller. The output 
node needs to be recurrent because the output without the recurrent link from the neural controller is 
only a correction to the old control signal, and the new control signal should be the combination of old 
control signal and the correction. The other nodes of the network can be feed forward or recurrent. If 
we denote the weight for the output node's recurrent link as wb, then the output from the recurrent link is 
wbu(t-1). The following equation describes the feedback network. 
u(t) = wbu(t- 1)+f(x(t), y(t), e(t)) (3) 
where f(.) is a nonlinear function established by the network for which the recurrent link output is not 
included and e(t)=[e(t), e(t-1) .... ]*. 
To compare the control gain expression with conventional control theory, consider the Taylor series 
expansion of the network forward mapping f(.), equation (3) becomes 
u(t) = %u(t- 1) + f'(x(t), y(t)) e(t)+ f(x(t), y(t)) e2(t)+... 
where f'(x(t), y(t))=[ 3f(x(t), y(t), e(t))/3e(t), 3f(x(t), y(t), e(t))/3e(t-1) .... ]. If high 
ignored and g(.) representsf'(.), we get 
(4) 
order terms are 
u(t) = wbu(t-1)+ g(x(t), y(t)) e(t) (5) 
1034 Liu Ke, Robert L. Tokar, Brian D. McVey 
which is a gain scheduled controller and the gain is the function of external input x(t) and the plant state 
y(t). It is clear that when %=1.0, g(.) is a constant vector and e(t)=[e(0, e(t-1), e(t-2)] T, the feedback 
neural network controller degenerates to a discrete PID controller. Because the neural network can 
approximate arbitrary nonlinear functions through learning, the neural network feedback controller can 
generate a nonlinear continuous gain hypersurface. 
x(t) 
e(t) 
y(t) 
Figure 3 Feedback Neural Network Controller 
FF control 
control 
qReL Model[ 
ID NN [_.1) 
Z[' I (t+l) 
Figure 4 Integrated NN Control Architeture. 
In the training process, error backpropagating through the identification network is used. The process is 
similar to the training of a feed forward neural controller, but the resulting control surface is completely 
different due to the different inputs. Af
