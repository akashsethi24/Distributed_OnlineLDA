Spike-Based Compared to Rate-Based 
Hebbian Learning 
Richard Kempter* 
Institut ffir Theoretische Physik 
Technische Universitiit Mfinchen 
D-85747 Garching, Germany 
Wulfram Gerstner 
Swiss Federal Institute of Technology 
Center of Neuromimetic Systems, EPFL-DI 
CH-1015 Lausanne, Switzerland 
J. Leo van Hemmen 
Institut fiir Theoretische Physik 
Technische Universitiit Mfinchen 
D-85747 Garching, Germany 
Abstract 
A correlation-based learning rule at the spike level is formulated, 
mathematically analyzed, and compared to learning in a firing-rate 
description. A differential equation for the learning dynamics is 
derived under the assumption that the time scales of learning and 
spiking can be separated. For a linear Poissonian neuron model 
which receives time-dependent stochastic input we show that spike 
correlations on a millisecond time scale play indeed a role. Corre- 
lations between input and output spikes tend to stabilize structure 
formation, provided that the form of the learning window is in 
accordance with Hebb's principle. Conditions for an intrinsic nor- 
malization of the average synaptic weight are discussed. 
1 Introduction 
Most learning rules are formulated in terms of mean firing rates, viz., a continuous 
variable reflecting the mean activity of a neuron. For example, a 'Hebbian' (Hebb 
1949) learning rule which is driven by the correlations between presynaptic and 
postsynaptic rates may be used to generate neuronal receptive fields (e.g., Linsker 
1986, MacKay and Miller 1990, Wimbauer et al. 1997) with properties similar to 
those of real neurons. A rate-based description, however, neglects effects which are 
due to the pulse structure of neuronal signals. During recent years experimental and 
*emaih kempter@physik.tu-muenchen.de (corresponding author) 
126 R. Kempter, W. Gerstner and J. L. van Hemmen 
theoretical evidence has accumulated which suggests that temporal coincidences 
between spikes on a millisecond or even sub-millisecond scale play an important 
role in neuronal information processing (e.g., Bialek et al. 1991, Cart 1993, Abeles 
1994, Gerstner et al. 1996). Moreover, changes of synaptic efficacy depend on 
the precise timing of postsynaptic action potentials and presynaptic input spikes 
(Markram et al. 1997, Zhang et al. 1998). A synaptic weight is found to increase, if 
presynaptic firing precedes a postsynaptic spike and decreased otherwise. In contrast 
to the standard rate models of Hebbian learning, the spike-based learning rule 
discussed in this paper takes these effects into account. For mathematical details 
and numerical simulations the reader is referred to Kempter et al. (1999). 
2 Derivation of the Learning Equation 
2.1 Specification of the Hebb Rule 
We consider a neuron that receives input from N >> I synapses with efficacies Ji, 
I _< i _< N. We assume that changes of Ji are induced by pre- and postsynaptic 
spikes. The learning rule consists of three parts. (i) Let tp be the time of the mth 
input spike arriving at synapse i. The arrival of the spike induces the weight Ji to 
change by an amount w in which can be positive or negative. (ii) Let t ' be the n th 
output spike of the neuron under consideration. This event triggers the change of all 
N efficacies by an amount w �ut which can also be positive or negative. (iii) Finally, 
time differences between input spikes influence the change of the efficacies. Given 
a time difference s = t? - t n between input and output spikes, Ji is changed by an 
amount W(s) where the learning window W is a real valued function (Fig. 1). The 
learning window can be motivated by local chemical processes at the level of the 
synapse (Gerstner et al. 1998, Senn et al. 1999). Here we simply assume that such 
a learning window exist and take some (arbitrary) functional dependence W(s). 
0 
W[a.U.s 
Figure 1: An example of a learning win- 
dow W as a function of the delay s = 
t - t n between a postsynaptic firing time 
t n and presynaptic spike arrival t? at 
synapse i. Note that for s < 0 the presy- 
naptic spike precedes postsynaptic firing. 
Starting at time t with an efficacy Ji(t), the total change AJi(t) = Ji(t + T) - Ji(t) 
in a time interval 7- is calculated by summing the contributions of all input and 
output spikes in the time interval [t, t + 7']. Describing the input spike train at 
synapse i by a series of 5 functions, $}n(t) =Em 5(t - t?), and, similarly, output 
spikes by $�ut(t): Yn 5(t - tn), we can formulate the rules (i)(iii)' 
Xa(t)=fdt' W in sn(t t) 
t 
+ w �ut $�ut(t') +/dt 't W(t t') in ,t Sour 
- & (t) (t') 
t 
(1) 
2.2 Separation of Time Scales 
The total change AJi(t) is subject to noise due to stochastic spike arrival and, 
possibly, stochastic generation of output spikes. We therefore study the expected 
development of the weights Ji, denoted by angular brackets. We make the substi- 
tution s = t - t' on the right-hand side of (1), divide both sides by 7-, and take 
Spike-Based Compared to Rate-Based Hebbian Learning 12 7 
the expectation value: 
(AJi)(t) 1 ft+T [ win w �ut (s�ut) 
= -- dt' (s}n)(t ') q- (tt)] 
T T Jr 
l ft+7- 
+0 dt' ds W(s) (oq}n(t ' + s) s�ut(tt)) 
(2) 
We may interpret (s}n)(t) for I <_ i _< N and (q�ut)(t) as instantaneous firing 
rates.  They may vary on very short time scales - shorter, e.g., than average 
interspike intervals. Such a model is consistent with the idea of temporal coding, 
since it does not rely on temporally averaged mean firing rates. 
We note, however, that due to the integral over time on the right-hand side of (2) 
temporal averaging is indeed important. If T is much larger than typical interspike 
in in 
intervals, we may define mean firing rates v i (t) = and 
(S i )(t) /]�ut (t) ---- (S�ut)(t) 
where we have used the notation f(t) = T - ft+v-dr' f(t'). The mean firing rates 
t 
must be distinguished from the previously defined instantaneous rates (S} n) and 
(S �ut) which are defined as an expectation value and have a high temporal resolu- 
in and v �ut vary slowly (time scale of the 
tion. In contrast, the mean firing rates v i 
order of T) as a function of time. 
If the learning time T is much larger than the width of the learning window, the 
integration over s in (2) can be extended to run from -o to o without introducing 
a noticeable error. With the definition of a temporally averaged correlation, 
Ci(s;t) = (S}n(t + s)S�ut(t)) , (3) 
the last term on the right of (2) reduces to f_ ds W(s) Ci(s; t). Thus, correlations 
between pre- and postsynaptic spikes enter spike-based Hebbian learning through 
Ci convolved with the learning window W. We remark that the correlation Ci(s; t) 
may change as a function of s on a fast time scale. Note that, by definition, s < 0 
implies that a presynaptic spike precedes the output spike - and this is when we 
expect (for excitatory synapses) a positive correlation between input and output. 
As usual in the theory of Hebbian learning, we require learning to be a slow process. 
The correlation Ci can then be evaluated for a constant Ji and the left-hand side 
of (2) can be rewritten as a differential on the slow time scale of learning 
J(t) _= J, win in wout 
-- v i (t) + v�ut(t) + dsW(s) Ci(s;t) (4) 
2.3 Relation to Rate-Based Hebbian Learning 
In neural network theory, the hypothesis of Hebb (Hebb 1949) is usually formulated 
as a learning rule where the change of a synaptic efficacy Ji depends on the corre- 
lation between the mean firing rate v}n of the i th presynaptic and the mean firing 
rate your of a postsynaptic neuron, viz., 
in /]out in tout in)2 (/]out)2 
i: ao q- al /2 i q- a2 q- a3/]i q- a4 (/2 i q- a 5 , (5) 
where a0, a, a2, as, a4, and as are proportionality constants. Apart from the decay 
in yout proportional to the product of input and 
term a0 and the 'Hebbian' term Yi 
XAn example of rapidly changing instantaneous rates can be found in the auditory 
system. The auditory nerve carries noisy spike trains with a stochastic intensity modulated 
at the frequency of the applied acoustic tone. In the barn owl, a significant modulation of 
the rates is seen up to a frequency of 8 kHz (e.g., Cart 1993). 
128 R. Kempter,  Gerstner and Y. L. van Hemmen 
output rates, there are also synaptic changes which are driven separately by the pre- 
and postsynaptic rates. The parameters a0,..., as may depend on Ji. Equation (5) 
is a general formulation up to second order in the rates; see, e.g., (Linsker 1986). 
To get (5) from (4) two approximations are necessary. First, if there are no correla- 
tions between input and output spikes apart from the correlations contained in the 
rates, we can approximate {sn(t + s)q�ut(t))  {sn)(t + s)/q�ut).(t). Second, if 
these rates change slowly as compared to 7-, then we have Ci (s; t) m ul n (t-]-$)/yout (t). 
Since we have assumed that the learning time 7- is long compared to the width of 
in 
the learning window, we may simplify further and set v}n(t + s) m vi (t), hence 
f-%o dsW(s)Ci(s;t)  l?V'(0)u}n(t)u�ut(t), where IV(O) = dsW(s). We may 
now identify ITV(0) with a3. By further comparison of (5) with (4) we identify 
w in with a and w �ut with a2, and we are able to reduce (4) to (5) by setting 
a0 = a4: a5 = 0. 
The above set of of assumption which is necessary to derive (5) from (4) does, 
however, not hold in general. According to the results of Markram et al. (1997) the 
width of the learning window in cortical pyramidal cells is in .the range of  100 ms. 
A mean rate formulation thus requires that all changes of the activity are slow on 
a time scale of 100 ms. This is not necessarily the case. The existence of oscillatory 
activity in the cortex in the range of 50 Hz implies activity changes every 20ms. 
Much faster activity changes on a time scale of I ms and below are found in the 
auditory system (e.g., Cart 1993). Furthermore, beyond the correlations between 
mean activities additional correlations between spikes m
