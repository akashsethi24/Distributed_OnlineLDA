Benchmarking Feed-Forward Neural Networks: 
Models and Measures 
Leonard G. C. Hamey 
Computing Discipline 
Macquarie University 
NSW 2109 
AUSTRALIA 
Abstract 
Existing metrics for the learning performance of feed-forward neural networks do 
not provide a satisfactory basis for comparison because the choice of the training 
epoch limit can determine the results of the comparison. I propose new metrics 
which have the desirable property of being independent of the training epoch 
limit. The efficiency measures the yield of correct networks in proportion to the 
training effort expended. The optimal epoch limit provides the greatest efficiency. 
The learning performance is modelled statistically, and asymptotic performance 
is estimated. Implementation details may be found in (Hamey, 1992). 
1 Introduction 
The empirical comparison of neural network training algorithms is of great value in the 
development of improved techniques and in algorithm selection for problem solving. In 
view of the great sensitivity of learning times to the random starting weights (Kolen and 
Pollack, 1990), individual trial times such as reported in (Rumelhart, et al., 1986) are almost 
useless as measures of learning performance. 
Benchmarking experiments normally involve many training trials (typically N - 25 or 
100, although Tesauro and Janssens (1988) use N = 10000). For each trial i, the training 
time to obtain a correct network ti is recorded. Trials which are not successful within a 
limit of T epochs are considered failures; they are recorded as ti = T. The mean successful 
training time iT is defined as follows. 1167 
1168 
T -' -]ti<T i 
$ 
where $ is the number of successful trials. The median successful time T is the epoch at 
which 5'/2 trials are successes. It is common (e.g. Jacobs, 1987; Kruschke and Movellan, 
1991; Veitch and Holmes, 1991) to report the mean and standard deviation along with the 
success rate AT -- 5'IN, but the results are strongly dependent on the choice of T as shown 
by Fahlman (1988). The problem is to characterise training performance independent of T. 
Tesauro and Janssens (1988) use the harmonic mean  as the average learning rate. 
This minimizes the contribution of large learning times, so changes in T will have little 
effect on [H. However, H is not an unbiased estimator of the mean, and is strongly 
influenced by the shortest learning times, so that training algorithms which produce greater 
variation in the learning times are preferred by this measure. 
Fahlman (1988) allows the learning program to restart an unsuccessful trial, incorporating 
the failed training time in the total time for that trial. This method is realistic, since a failed 
trial would be restarted in a problem-solving situation. However, Fahlman's averages are 
still highly dependent upon the epoch limit T which is chosen beforehand as the restart 
point. 
The present paper proposes new performance measures for feed-forward neural networks. 
In section 4, the optimal epoch limit TE is defined. TE is the optimal restart point for 
Fahlman's averages, and the efficiency e is the scaled reciprocal of the optimised Fahlman 
average. In sections 5 and 6, the asymptotic learning behaviour is modelled and the mean 
and median are corrected for the truncation effect of the epoch limit T. Some benchmark 
results are presented in section 7, and compared with previously published results. 
2 Performance Measurement 
For benchmark results to be useful, the parameters and techniques of measurement and 
training must be fully specified. Training parameters include the network structure, the 
learning rate /, the momentum term a and the range of the initial random weights I-r, r]. 
For problems with binary output, the correctness of the network response is defined by a 
threshold re--responses less than rc are considered equivalent to 0, while responses greater 
than 1 - rc are considered equivalent to 1. For problems with analog output, the network 
response is considered correct if it lies within r of the desired value. In the present paper, 
only binary problems are considered and the value r = 0.4 is used, as in (Fahlman 1988). 
3 The Training Graph 
The training graph displays the proportion of correct networks as a function of the epoch. 
Typically, the tail of the graph resembles a decay curve. It is evident in figure 1 that the 
Benchmarking Feed-Forward Neural Networks: Models and Measures 1169 
1.0-- 
0.8-- 
0.6- 
0.4- 
0.2 
' BP 
DE 
0.0 
I I [ I 
0 2000 4000 6000 8000 10000 
Epoch Limit 
Figure 1: Typical Training Graphs: Back-Propagation (r/= 0.5, c = 0) and Descending 
Epsilon (r/= 0.5, c = 0) on Exclusive-Or (2-2-1 structure, N = 1000, T = 10000). 
success rate for either algorithm may be significantly increased if the epoch limit was raised 
beyond 10000. The shape of the training graph varies depending upon the problem and 
the algorithm employed to solve it. Descending epsilon (Yu and Simmons, 1990) solves a 
higher proportion of the exclusive-or trials with T = 10000, but back-propagation would 
have a higher success rate if T = 3000. This exemplifies the dramatic effect that the choice 
of T can have on the comparison of training algorithms. 
Two questions naturally arise from this discussion: What is the optimal value for T? and 
What happens as T ---, co?. These questions will be addressed in the following sections. 
4 Efficiency and Optimal T. 
Adjusting the epoch limit T in a learning algorithm affects both the yield of correct networks 
and the effort expended on unsuccessful trials. To capture the total yield for effort ratio, we 
define the efficiency E(t) of epoch limit t as follows. 
E(t) - 1000 -t,<t 1 
El51 min(t,ti) 
The efficiency graph plots the efficiency against of the epoch limit. The efficiency graph for 
back-propagation (figure 2) exhibits a strong peak with the efficiency reducing relatively 
quickly if the epoch limit is too large. In contrast, the efficiency graph for descending 
epsilon exhibits an extremely broad peak with only a slight drop as the epoch limit is 
increased. This occurs because the asymptotic success rate (A in section 5) is close to 
1170 Hamey 
2.0-- 
0.0 
 BP 
DE 
I I I I I 
2000 4000 6000 8000 10000 
Epoch Limit 
Figure 2: Efficiency Graphs: Back-Propagation (r/ = 0.3, a = 0.9) and Descending 
Epsilon (r/- 0.3, a - 0.9) on Exclusive-Or (2-2-1 structure, N - 1000, T -- 10000). 
1.0; in such cases, the efficiency remains high over a wider range of epoch limits and 
near-optimal performance can be more easily achieved for novel problems. 
The efficiency benchmark parameters are derived from the graph as shown in figure 3. The 
epoch limit TE at which the peak efficiency occurs is the optimal epoch limit. The peak 
efficiency e is a good performance measure, independent of T when T > TE. Unlike [u, it 
is not biased by the shortest learning times. The peak efficiency is the scaled reciprocal of 
Fahlman's (1988) average for optimal T, and incorporates the failed trials as a performance 
penalty. The optimisation of training parameters is suggested by Tesauro and Janssens 
(1988), but they do not optimise T. For comparison with other performance measures, the 
unscaled optimised Fahlman average  - 1000/e may be used instead of e. 
The prediction of the optimal epoch limit T for novel problems would help reduce wasted 
computation. The range parameters T and Tm show how precisely Tmust be set to obtain 
efficiency within 50% of optimal--if two algorithms are otherwise similar in performance, 
the one with a wider range (Tn, TE2) would be preferred for novel problems. 
5 Asymptotic Performance: T ca 
In the training graph, the proportion of trials that ultimately learn correctly can be estimated 
by the asymptote which the graph is approaching. I statistically model the tail of the graph 
by the distribution F(t) = 1 - [a(t - To) + 1]- and thus estimate the asymptotic success 
rate A. Figure 4 illustrates the model parameters. Since the early portions of the graph 
are dominated by initialisation effects, To, the point where the model commences to fit, 
is determined by applying the Kolmogorov-Smirnov goodness-of-fit test (Stephens 1974) 
Benchmarking Feed-Forward Neural Networks: Models and Measures 1171 
l 
e 
0.0 
0 
Epoch Limit 
Figure 3: Efficiency Parameters in Relation to the Efficiency Graph. 
for all possible values of To. The maximum likelihood estimates of a and k are found by 
using the simplex algorithm (Caceci and Cacheris, 1984) to directly maximise the following 
log-likelihood equation. 
ï¿½(t) 
M[lna+lnk-ln(1-(a(T-To)+l)-:)] - 
(k+l) E ln(a(ti-To)+l) 
To<t<T 
where M is the number of trials recording times in the range (To, T). The asymptotic 
success rate , is then obtained as follows. 
A=7+ 
A:r(1-7) 
F(T) 
In practice, the statistical model I have chosen is not suitable for all learning algorithms. For 
example, in preliminary investigations I have been unable to reliably model the descending 
epsilon algorithm (Yu and Simmons, 1990). Further study is needed to develop more 
widely applicable models. 
6 Corrected Measures 
The mean , and the median iT are based upon only those trials that succeeded in T epochs. 
The asymptotic learning model predicts additional success for t > T epochs. Incorporating 
1172 Hamey 
0.8-- 
0.6- 
0.4- 
0.2-- 
0.0 
0 To T  
Epoch Limit 
Figure 4: Parameters for the Model of Asymptotic Performance. 
the predicted successes, the corrected mean c estimates the mean successful learning time 
as T --+ co. 
The corrected median c is the epoch for which ,X/2 of the trials are successes. It estimates 
the median successful learning time as T ---, co. 
7 Benchmark Results for Back-Propagation 
Table 1 presents optimised results for two popular benchmark problems: the 2-2-1 
exclusive-or problem (Rumelhart, et al., 1986, page 334), and the 10-5-10 encoder/decoder 
problem (Fahlman, 1988). Both problems 
