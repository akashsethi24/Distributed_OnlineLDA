MELONET I: Neural Nets for Inventing 
Baroque-Style Chorale Variations 
Dorninik HSrnel 
dominik@ira.uka.de 
Institut ffir Logik, Komplexit/it und Deduktionssysteme 
Universitiit Fridericiana Karlsruhe (TH) 
Am Fasanengarten 5 
D-76128 Karlsruhe, Germany 
Abstract 
MELONET I is a multi-scale neural network system producing 
baroque-style melodic variations. Given a melody, the system in- 
vents a four-part chorale harmonization and a variation of any 
chorale voice, after being trained on music pieces of composers like 
J. S. Bach and J. Pachelbel. Unlike earlier approaches to the learn- 
ing of melodic structure, the system is able to learn and reproduce 
high-order structure like harmonic, motif and phrase structure in 
melodic sequences. This is achieved by using mutually interacting 
feedforward networks operating at different time scales, in combi- 
nation with Kohonen networks to classify and recognize musical 
structure. The results are chorale partitas in the style of J. Pachel- 
bel. Their quality has been judged by experts to be comparable to 
improvisations invented by an experienced human organist. 
I INTRODUCTION 
The investigation of neural information structures in music is a rather new, excit- 
ing research area bringing together different disciplines such as computer science, 
mathematics, musicology and cognitive science. One of its aims is to find out what 
determines the personal style of a composer. It has been shown that neural network 
models - better than other AI approaches - are able to learn and reproduce style- 
dependent features from given examples, e.g., chorale harmonizations in the style 
of Johann Sebastian Bach (Hild et al., 1992). However when dealing with melodic 
sequences, e.g., folk-song style melodies, all of these models have considerable dif- 
ficulties to learn even simple structures. The reason is that they are unable to 
capture high-order structure such as harmonies, motifs and phrases simultaneously 
occurring at multiple time scales. To overcome this problem, Mozer (Mozer, 1994) 
888 D. Hrnel 
proposes context units that learn reduced descriptions of a sequence of individual 
notes. A similar approach in MELONET (Feulner et HSrnel, 1994) uses delayed 
update units that do not fire each time their input changes but rather at discrete 
time intervals. Although these models perform well on artificial sequences, they 
produce melodies that suffer from a lack of global coherence. 
The art of melodic variation has a long tradition in Western music. Almost every 
great composer has written music pieces inventing variations of a given melody, e.g., 
Mozart's famous variations KV 265 on the melody Ah! Vous dirai-je, Maman, 
also known as Twinkle twinkle little star. At the beginning of this tradition there 
is the baroque type of chorale variations. These are organ or harpsichord variations 
of a chorale melody composed for use in the Protestant church. A prominent repre- 
sentative of this kind of composition is J. Pachelbel (1653 - 1706) who wrote about 
50 chorale variations or partitas on various chorale melodies. 
2 TASK DESCRIPTION 
Given a chorale melody, the learning task is achieved in two steps: 
1. A chorale harmonization of the melody is invented. 
2. One of the voices of the resulting chorale is chosen 
melodic variations. 
and provided with 
Both subtasks are directly learned from music examples composed by J. Pachelbel 
and performed in an interactive composition process which results in a chorale 
variation of the given melody. The first task is performed by HARMONET, a 
neural network system which is able to harmonize melodies in the style of various 
composers like J. S. Bach. The second task is performed by the neural network 
system MELONET I, presented in the following. For simplicity we have considered 
melodic variations consisting of 4 sixteenth notes for each melody quarter note. 
This is the most common variation type used by baroque composers and presents a 
good starting point for even more complex variation types, since there are enough 
music examples for training and testing the networks, and because it allows the 
representation of higher-scale elements in a rather straightforward way. 
HARMONET is a system producing four-part chorales in various harmonization 
styles, given a one-part melody. It solves a musical real-world problem on a perfor- 
mance level appropriate for musical practice. Its power is based on a coding scheme 
capturing musically relevant information, and on the integration of neural networks 
and symbolic algorithms in a hierarchical system, combining the advantages of both. 
The details are not discussed in this paper. See (Hild et al., 1992) or (HSrnel et 
Ragg, 1996a) for a detailed account. 
3 A MULTI-SCALE NEURAL NETWORK MODEL 
The learning goal is twofold. On the one hand, the results produced by the system 
should conform to musical rules. These are melodic and harmonic constraints such 
as the correct resolving of dissonances or the appropriate use of successive interval 
leaps. On the other hand, the system should be able to capture stilistic features 
from the learning examples, e.g., melodic shapes preferred by J. Pachelbel. The 
observation of musical rules and the aesthetic conformance to the learning set can 
be achieved by a multi-scale neural network model. The complexity of the learning 
task is reduced by decomposition in three subtasks (see Figure 1): 
MELONET I.' Neural Nets for Inventing Baroque-Style Chorale Variations 889 
k=tmod4 
Harmony T T T S 3 TD T 
MCT. 1 MT MT~i MT. 
spernel 
MC-r 
N- l-lr MCt 
subnel 
Figure 1: Structure of the system and process of composing a new melodic variation. 
A melody (previously harmonized by HARMONET) is passed to the supernet which 
predicts the current motif class MC, from a local window given by melody notes Mz 
to M'+2 and preceding motif class MC,_. A similar procedure is performed at a 
lower time scale by the subnet which predicts the next motif note Nt based on MCr, 
current harmony H, and preceding motif note Nt_. The result is then returned 
to the supernet through the motif classifier to be considered when computing the 
next motif class MCr+. 
1. A melody variation is considered at a higher time scale as a sequence of 
melodic groups, so-called motifs. Each quarter note of the given melody 
is varied by one motif. Before training the networks, motifs are classified 
according to their similarity. 
2. One neural network is used to learn the abstract sequence of motif classes. 
Motif classes are represented in a 1-of-n coding form where n is a fixed 
number of classes. The question it solves is: What kind of motif fits' a 
melody note depending on melodic context and the motif that has occurred 
before? No concrete notes are fixed by this network. It works at a higher 
scale and will therefore be called supernet in the following. 
3. Another neural network learns the implementation of abstract motif classes 
into concrete no[es depending on a given harmonic context. It produces 
a sequence of sixteenth notes - four notes per motif- that result in a 
melodic variation of the given melody. Because it works one scale below 
the supernet, it is called subnet. 
4. The subnet sometimes invents a sequence of notes that does not coincide 
890 D. H6rnel 
with the motif class determined by the supernet. This motif will be consid- 
ered when computing the next motif class, however, and should therefore 
match the notes previously formed by the subnet. It is therefore reclassified 
by the motif classifier before the supernet determines the next motif class. 
The motivation of this separation into supernet and subnet arised from the following 
consideration: Having a neural network that learns sequences of sixteenth notes, it, 
would be easier for this network to predict notes given a contour of each motif, i.e. 
a sequence of interval directions to be produced for each quarter note. Consider 
a human organist who improvises a melodic variation of a given melody in real 
time. Because he has to take his decisions in a fraction of a second, he must at 
least have some rough idea in mind about what kind of melodic variation should 
be applied to the next melody note to obtain a meaningful continuation of the 
variation. Therefore, a neural network was introduced at a higher time scale, the 
training of which really improved the overall behavior of the system and not just 
shifted the learning problem to another time scale. 
4 MOTIF CLASSIFICATION AND RECOGNITION 
In order to realize learning at different time scales as described above, we need 
a recognition component to find a suitable classification of motifs. This can be 
achieved using unsupervised learning, e.g., agglomerative hierarchical clustering or 
Kohonen's topological feature maps (Kohonen, 1990). The former has the disadvan- 
tage however that an appropriate distance measure is neded which determines the 
similarity between small sequences of notes respectively intervals, whereas the latter 
allows to obtain appropriate motif classes through self-organization within a two- 
dimensional surface. Figure 2 displays the motif representation and distribution of 
motif contours over a 10x10 Kohonen feature mtp. In MELONET I, the Kohonen 
algorithm is applied to all motifs contained in the training set. Afterwards a corre- 
sponding motif classification tree is recursively built from the Kohonen map. While 
cutting this classification tree at lower levels we can get more and more classes. One 
important problem remains to find an appropriate number of classes for the given 
learning task. This will be discussed in section 6. 
1 st interval 
2nd interval 
3rd interval 
Josze Idmm J 
,nner 
Figure 2: Motif representation example (left) and motif contour distribution (right) 
over a 10x10 Kohonen feature map developed from one Pachelbel chorale variation 
(initial update area 6x6, initial 
