Comparison of three classification techniques, 
CART, C4.5 and Multi-Layer Perceptrons 
A C Tsoi tt A Pearson 
Department of Electrical EngineeringDepartment of Computer Science 
University of Queensland Aust Defence Force Academy 
St Lucia, Queensland 4072 Campbell, ACT 2600 
Australia Australia 
Abstract 
In this paper, after some introductory remarks into the classification prob- 
lem as considered in various research communities, and some discussions 
concerning some of the reasons for ascertaining the performances of the 
three chosen algorithms, viz., CART (Classification and Regression Tree), 
C4.5 (one of the more recent versions of a popular induction tree tech- 
nique known as ID3), and a multi-layer perceptron (MLP), it is proposed 
to compare the performances of these algorithms under two criteria: classi- 
fication and generalisation. It is found that, in general, the MLP has better 
classification and generalisation accuracies compared with the other two 
algorithms. 
I Introduction 
Classification of data into categories has been pursued by a number of research 
communities, viz., applied statistics, knowledge acquisition, neural networks. 
In applied statistics, there are a number of techniques, e.g., clustering algorithms 
(see e.g., Hartigan), CART (Classification and Regression Trees, see e.g., Breiman 
et al). Clustering algorithms are used when the underlying data naturally fall into a 
number of groups, the distance among groups are measured by various metrics [Har- 
tigan]. CART [Breiman, et all has been very popular among applied statisticians. 
It assumes that the underlying data can be separated into categories, the decision 
boundaries can either be parallel to the axis or they can be a linear combination 
of these axes 1. Under certain assumptions on the input data and their associated 
In CART, and C4.5, the axes are the same as the input features 
963 
964 Tsoi and Pearson 
output categories, its properties can be proved rigorously [Breiman et al]. The way 
in which CART organises its data set is quite sophisticated. For example, it grows 
a number of decision trees by a cross validation method. 
Knowledge acquisition is an important topic in expert systems studies, see e.g., 
Charniak, McDermott. In this case, one is presented with a subset of input output 
examples drawn from the set of all possible input output examples exhibited by the 
underlying system. The problem is how to distill a set of rules describing the set 
of input output examples. The rules are often expressed in the form ofif statement 
1, then statement 2, else statement 3. Once this set of rules is obtained, it can 
be used in a knowledge base for inference or for consulting purposes. It is trivial 
to observe that the rules can be represented in the form of a binary tree structure. 
In the process of building this binary tree, the knowledge acquisition system must 
learn about the set of input output examples. Often this problem is pursued in the 
machine learning community, see e.g., Michalski et al. 
One of the most popular induction tree algorithms is known as ID3, or its later 
variants, known as C4 (see e.g., Quinlan, Utgoff). There has not been any explicit 
mention of the underlying assumptions on the data. However, it can be postulated 
that for an induction tree technqiue to work efficiently, there must be some under- 
lying assumptions on the data set considered. By analogy with CART, it can be 
observed that an important underlying assumption must be that the data can be 
divided into categories, the decision boundaries must be parallel to the axes (i.e., it 
does not find a linear combination of the underlying axes to form a possible decision 
boundary). In contrast to CART, and similar technqiues, it does not yet have a 
rigorous theoretical basis. Its learning algorithm, and the way in which it organises 
the data set are somewhat different from CART. 
Recently, there is considerable activities in the study of yet another classification 
method, known generally as an artificial neural network (ANN) approach (see e.g., 
Hecht-Nielson). In this approach, the idea is to use a system consisting of artifi- 
cial neurons with very simple internal dynamics, interconnected to each other for 
modelling a given set of input output examples. In this approach, one selects an 
architecture of interconnection of artificial neurons, and a learning algorithm for 
finding the unknown parameters in the architecture. A particular popular ANN ar- 
chitecture is known as a multi-layer perceptron (MLP). In this architecture, signal 
travels in only one direction, i.e., there is no feedback from the output to the input. 
A simple version of this architecture, consisting of only input and output layers 
of neurons was popularised by Rosenblatt in the 1950's and 1960's. An improved 
version incorporating possibly more than one layer of hidden layer neurons has been 
used in the more recent past. A learning algorithm for finding the set of unknown 
parameters in this architecture while minimising a least square criterion is known 
as a back propagation algorithm. (see e.g., Rumelhart, McClelland). 
There have been much analysis recently in understanding why a MLP can be used 
in classifying given input output examples, and what underlying assumptions are 
required (see e.g., Cybenko, Hornik et al). It can be proved that the MLP can 
be used to approximate any given nonlinear input output mapping given certain 
not too restrictive assumptions on the mapping, and the underlying input output 
variables. 
Comparison of Three Classification Techniques 965 
Given that the three methods mentioned above, viz., CART, C4.5 (the latest version 
of the C4 Induction Tree methodology), and MLP, all enjoy popularity in their 
respective research communities, and that they all perform classification based on 
a given set of input output examples, a natural question to ask is: how do they 
perform as compared with one another. 
There might be some objections to why a comparison among these algorithms is 
necessary, since each is designed to operate under some predetermined conditions. 
Secondly, even if it is shown that a particular algorithm performs better for a set of 
particular examples, there is no guarantee that the algorithm will perform better 
under a different set of circumstances. Thus, this may throw some doubt on the 
desirability of making a comparison among these algorithms. 
As indicated above, each algorithm has some underlying assumptions on the con- 
struction of a data model, whether these assumptions are made explicit or not. In 
a practical problem, e.g., power system forecasting [Atlas et al] it is not possible 
to determine the underlying assumptions in the data. But on an artificially gen- 
erated example, it is possible to constrain the data so that they would have the 
desirable characteristics. From this, it is possible to at least make some qualitative 
statements concerning the algorithms. These qualitative statements may guide a 
practitioner to watch out for possible pitfalls in applying a particular algorithm to 
practical problems. ttence, it is worthwhile to carry out comparison studies. 
The comparison question is not new. In fact there are already a number of stud- 
ies carried out to compare the performances of some of or all three algorithms 
mentioned 2. For example, Atlas et al compared the performances of CART and 
MLP. In addition they have considered the performances of these two algorithms to 
a practical problem, viz., the power system forecasting. Dietterich et al compared 
the performances of ID3 and MLP, and have applied them to the Text to Speech 
mapping problem. In general, their conclusions are that the MLP is more accurate 
in performing generalisation on unseen examples, while the ID3 or CART is much 
faster in performing the classficiation task. 
In this paper, we will consider the performances of all three algorithms, viz., CART, 
C4.5 and MLP on two criteria: 
Classification capabilities 
Generalisation capabilities 
In order to ascertain how these algorithms will perform, we have chosen to study 
their performances using a closed set of input output examples. In this aspect, we 
have chosen a version of the Penzias example, first considered by Denker et al. This 
class of problems has been shown to require at least one hidden layer in a MLP 
architecture, indicating that the relationship between the input and output is non- 
linear. Secondly, the problem complexity depends on the number of input neurons 
(in Cart and C4.5, input features). Hence it is possible to test the algorithms using 
a progressively complex set of examples. 
We have chosen to compare the algorithms tinder the two critieria because of the 
2Both Atlas et al, and Diettrich et al were brought to our attention during the confer- 
ence. Hence some of their conclusions wcrc only communicated to us at that time 
966 Tsoi and Pearson 
fact that some of them, at least, in the case of CART, were designed for classi- 
fication purposes. It was not originally intended for generalisation purposes. By 
generalisation, we mean that the trained system is used to predict the categories of 
unseen examples when only the input variables are given. The predicted categories 
are then compared with the true categories to ascertain how well the trained system 
has performed. 
The separate comparison is necessary because of the fact that classification and 
generalisation are rather different. In classification studies, the main purpose is to 
train a system to classify the given set of input output examples. The characteristics 
are: good model of the data; good accuracy in classifying the given set of examples. 
In generalisation, the main goal is to provide a good accuracy of prediction of output 
categories on the set of unseen examples. It does not matter much if the results of 
applying the trained data model to the t
