Compositionality, MDL Priors, and 
Object Recognition 
Elie Bienenstock (elie@dam.brown.edu) 
Stuart Geman (geman@dam.brown.edu) 
Daniel Potter (dfp@daxn.brown.edu) 
Division of Applied Mathematics, 
Brown University, Providence, RI 02912 USA 
Abstract 
Images are ambiguous at each of many levels of a contextual hi- 
erarchy. Nevertheless, the high-level interpretation of most scenes 
is unambiguous, as evidenced by the superior performance of hu- 
mans. This observation argues for global vision models, such as de- 
formable templates. Unfortunately, such models are computation- 
ally intractable for unconstrained problems. We propose a composi- 
tional model in which primitives are recursively composed, subject 
to syntactic restrictions, to form tree-structured objects and object 
groupings. Ambiguity is propagated up the hierarchy in the form 
of multiple interpretations, which are later resolved by a Bayesian, 
equivalently minimum-description-length, cost functional. 
i Bayesian decision theory and compositionality 
In his Essay on Probability, Laplace (1812) devotes a short chapter--his Sixth 
Principle--to what we call today the Bayesian decision rule. Laplace observes 
that we interpret a regular combination, e.g., an arrangement of objects that 
displays some particular symmetry, as having resulted from a regular cause rather 
than arisen by chance. It is not, he argues, that a symmetric configuration is less 
likely to happen by chance than another arrangement. Rather, it is that among all 
possible combinations, which are equally favored by chance, there are very few of 
the regular type: On a table we see letters arranged in this order, Constantinople, 
and we judge that this arrangement is not the result of chance, not because it is 
less possible than the others, for if this word were not employed in any language 
Compositionality, MDL Priors, and Object Recognition 839 
we should not suspect it came from any particular cause, but this word being in use 
amongst us, it is incomparably more probable that some person has thus arranged 
the aforesaid letters than that this arrangement is due to chance. In this example, 
regularity is not a mathematical symmetry. Rather, it is a convention shared among 
language users, whereby Constantinople is a word, whereas Ipctneolnosant, a string 
containing the same letters but arranged in a random order, is not. 
Central in Laplace's argument is the observation that the number of words in the 
language is smaller, indeed incomparably smaller, than the number of possible 
arrangements of letters. Indeed, if the collection of 14-letter words in a language 
made up, say, half of all 14-letter strings--a rich language indeed--we would, upon 
seeing the string Constantinople on the table, be far less inclined to deem it a word, 
and far more inclined to accept it as a possible coincidence. The sparseness of al- 
lowed combinations can be observed at all linguistic articulations (phonetic-syllabic, 
syllabic-lexical, lexical-syntactic, syntactic-pragmatic, to use broadly defined levels), 
and may be viewed as a form of redundancy--by analogy to error-correcting codes. 
This redundancy was likely devised by evolution to ensure efficient communication 
in spite of the ambiguity of elementary speech signals. The hierarchical composi- 
tional structure of natural visual scenes can also be thought of as redundant: the 
rules that govern the composition of edge elements into object boundaries, of in- 
tensities into surfaces etc., all the way to the assembly of 2-D projections of named 
objects, amount to a collection of drastic combinatorial restrictions. Arguably, this 
is why in all but a few--generally hand-crafted--cases, natural images have a unique 
high-level interpretation in spite of pervasive low-level ambiguity--this being amply 
demonstrated by the performances of our brains. 
In sum, compositionality appears to be a fundamental aspect of cognition (see also 
von der Malsburg 1981, 1987; Fodor and Pylyshyn 1988; Bienenstock, 1991, 1994, 
1996; Bienenstock and Geman 1995). We propose here to account for mental com- 
putation in general and scene interpretation in particular in terms of elementary 
composition operations, and describe a mathematical framework that we have de- 
veloped to this effect. The present description is a cursory one, and some notions 
are illustrated on two simple examples rather than formally defined--for a detailed 
account, see Geman et al. (1996), Potter (1997). The binary-image example refers 
to an N x N array of binary-valued pixels, while the Laplace-Table example refers 
to a one-dimensional array of length N, where each position can be filled with one 
of the 26 letters of the alphabet or remain blank. 
2 Labels and composition rules 
The objects operated upon axe denoted wi,i = 1, 2,..., k. Each composite object 
w carries a label, I = L(w), and the list of its constituents, (w,w2,...). These 
uniquely determine w, so we write w = l(w,w2,...). A scene $ is a collection of 
primitive objects. In the binary-image case, a scene $ consists of a collection of 
black pixels in the N x N array. All these primitives carry the same label, L(w) = p 
(for Point), and a parameter r(w) which is the position in the image. In Laplace's 
Table, a scene $ consists of an arrangement of characters on the table. There are 26 
primitive labels, A,B ,...,Z, and the parameter of a primitive w is its position 
I _ r(w) _ N (all primitives in such a scene must have different positions). 
An example of a composite w in the binary-image case is an arrangement composed 
840 E. Bienenstock, S. Geman and D. Potter 
of a black pixel at any position except on the rightmost column and another black 
pixel to the immediate right of the first one. The label is Horizontal Linelet, 
denoted L(co) = hl, and there are N(N - 1) possible horizontal linelets. Another 
non-primitive label, Vertical Linelet, or vl, is defined analogously. An example 
of a composite co for Laplace's Table is an arrangement of 14 neighboring primi- 
tives carrying the labels C, 0, N, S,..., E in that order, wherever that 
arrangement will fit. We then have L(co) = Constantinople, and there are N - 13 
possible Constantinople objects. 
The composition rule for label type I consists of a binding function, Bl, and a set 
of allowed binding-function values, or binding support, $: denoting by f the set 
of all objects in the model, we have, for any co,...,wn 6 f, B(w,.-.,con) 6 
$  l(w,... ,w) e f. In the binary-image example, Bh(w,w2) = Bv(co,w2) - 
(L(w),L(w),r(w)-r(w)), Sh = ((p,p, (1,0)))and Svl = ((p,p, (0, 1)))define 
the hl- and vl-composition rules, p+p  hl and p+p  vl. In Laplace's Table, C+ 
0 ...  E  Constantinpole is an example of a 14-ary composition rule, where we 
must check the label and position of each constituent. One way to define the binding 
function and support for this rule is: B(co,.. ',co4) = (L(co),-.., L(co4),r(co) - 
r(co), r(coa) - r(co), � � � ,r(co4) - r(co)) and S = (C,-..,E, 1,2,-.., 13). 
We now introduce recursive labels and composition rules: the label of the composite 
object is identical to the label of one or more of its constituents, and the rule may 
be applied an arbitrary number of times, to yield objects of arbitrary complexity. 
In the binary-image case, we use a recursive label c, for Curve, and an associated 
binding function which creates objects of the form hl + p -+ c, vl + p - c, c + p - c, 
p + hl - c, p + vl - c, p + c - c, and c+c - c. The reader may easily 
fill in the details, i.e., define a binding function and binding support which result 
in c-objects being precisely curves in the image, where a curve is of length at 
least 3 and may be self-intersecting. In the previous examples, primitives were 
composed into compositions; here compositions are further composed into more 
complex compositions. In general, an object co is a labeled tree, where each vertex 
carries the name of an object, and each leaf is associated with a primitive (the 
association is not necessarily one-to-one, as in the case of a self-intersecting curve). 
Let A/[ be a model--i.e., a collection of labels with their binding functions and 
binding supports--and f the set of all objects in A/[. We say that object co 6 
f covers ,5 if ,5 is precisely the set of primitives that make up co's leaves. An 
interpretation I of ,5 is any finite collection of objects in f such that the union 
of the sets of primitives they cover is ,5. We use the convention that, for all A/[ 
and ,5, I0 denotes the trivial interpretation, defined as the collection of (unbound) 
primitives in ,5. In most cases of interest, a model A/[ will allow many interpretations 
for a scene ,5. For instance, given a long curve in the binary-image model, there 
will be many ways to recursively construct a c-labeled tree that covers exactly 
that curve. 
3 The MDL formulation 
In Laplace's Table, a scene consisting of the string Constantinople admits, in 
addition to Io, the interpretation I = (co), where co is a Constantinople- 
object. We wish to define a probability distribution D on interpretations such that 
D(I)  D(Io), in order to realize Laplace's incomparably more probable. Our 
Compositionality, MDL Priors, and Object Recognition 841 
definition of D will be motivated by the following use of the Minimum Description 
Length (MDL) principle (Rissanen 1989). Consider a scene $ and pretend we want 
to transmit $ as quickly as possible through a noiseless channel, hence we seek to 
encode it as efficiently as possible, i.e., with the shortest possible binary code c. We 
can always use the trivial interpretation I0: the codeword c(Io) is a mere list of n 
locations in $. We need not specify labels, since there is only one primitive label in 
this example. The length, or cost, of this code for $ is lc(I
