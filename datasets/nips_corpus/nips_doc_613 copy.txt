A Knowledge-Based Model of Geometry Learning 
Geoffrey Towell 
Siemens Corporate Research 
755 College Road East 
Princeton, NJ 08540 
toweli @ learning. siemens. com 
Richard Lehrer 
Educational Psychology 
University of Wisconsin 
1025 West Johnson St. 
Madison, WI 53706 
Iehrer@vms. macc. wisc. edu 
Abstract 
We propose a model of the development of geometric reasoning in children that 
explicitly involves learning. The model uses a neural network that is initialized 
with an understanding of geometry similar to that of second-grade children. 
Through the presentation of a series of examples, the model is shown to develop 
an understanding of geometry similar to that of fifth-grade children who were 
trained using similar materials. 
1 Introduction 
One of the principal problems in instructing children is to develop sequences of examples 
that help children acquire useful concepts. In this endeavor it is often useful to have a 
model of how children learn the material, for a good model can guide an instructor towards 
particularly effective examples. In short, good models of learning help a teacher maximize 
the utility of the example presented. 
The particular problem with which we are concerned is learning about conventional 
concepts in geometry, like those involved in identifying, and recognizing similarities and 
differences among, shapes. This is a difficult subject to teach because children (and adults) 
have a complex set of informal rules for geometry (that are often at odds with conventional 
rules). Hence, instruction must supplant this informal geometry with a common formalism. 
To be efficient in their instruction, teachers need a model of geometric learning which, at 
the very least: 
1. can represent children's understanding of geometry prior to instruction, 
2. can describe how understanding changes as a result of instruction, 
3. can predict the effect of differing instructional sequences. 
In this paper we describe a neural network based model that has these properties. 
887 
888 Towell and Lehrer 
An extant model of geometry learning, the van Hiele model [6] represents children's 
understanding as purely perceptual -- appearances dominate reasoning. However, our 
research suggests that children's reasoning is better characterized as a mix of perception 
and rules. Moreover, unlike the model we propose, the van Hiele model can neither be used 
to test the effectiveness of instruction prior to trying that instruction on children nor can it 
be used to describe how understanding changes as a result of a specific type of instruction. 
Briefly, our model uses a set of rules derived from interviews with first and second 
grade children [ 1, 2], to produce a stereotypical informal conception of geometry. These 
rules, described in more detail in Section 2.1, give our model an explicit representation 
of pre-instructional geometry understanding. The rules are then translated into a neural 
network using the KBANN algorithm [3]. As a neural network, our model can test the effect 
of differing instructional sequences by simply training two instances with different sets of 
examples. The experiments in Section 3 take advantage of this ability of our model; they 
show that it is able to accurately model the effect of two different sets of instruction. 
2 A New Model 
This section describes the initial state of our model and its implementation as a neural 
network. The initial state of the model is intended to reproduce the decision processes 
of a typical child prior to instruction. The methodology used to derive this information 
and a brief description of this information both are in the first subsection. In addition, 
this subsection contains a small experiment that shows the accuracy of the initial state of 
the model. In the next subsection, we briefly describe the translation of those rules into a 
neural network. 
2.1 The initial state of the model 
Our model is based upon interviews with children in first and second grade [ 1, 2]. In these 
interviews, children were presented with sets of three figures such as the triad in Figure 1. 
They were asked which pair of the three figures is the most similar and why they made 
their decision. These interviews revealed that, prior to instruction, children base judgments 
of similarity upon the seven attributes in Table 1. 
For the triad discrimination task, children find ways in which a pair is similar that is not 
shared by the other two pairs. For instance, B and C in Figure 1.2 are both pointy but A 
is not. As a result, the modal response of children prior to instruction is that {B C) is the 
most similar pair. This decision making process is described by the rules in Table 2. 
In addition to the rules in Table 2, we include in our initial model a set of rules that describe 
templates for standard geometric shapes. This addition is based upon interviews with 
children which suggest that they know the names of shapes such as triangles and squares, 
and that they associate with each name a small set of templates. Initially, children treat 
these shape names as having no more importance than any of the attributes in Table 1. So, 
our model initial treats shape names exactly as one of those attributes. Over time children 
learn that the names of shapes are very important because they are diagnostic (the name 
indicates properties). Our hope was that the model would make a similar transition so that 
the shape names would become sufficient for similarity determination. 
Note that the rules in Table 2 do not always yield a unique decision. Rather, there are 
A Knowledge-Based Model of Geometry Learning 889 
Table 1: Attributes used by 
:hildren prior to instruction. 
Attribute name Possible values Attribute name Possible values 
Tilt 0, 10, 20, 30, 40 
Area small, medium, large 
Pointy yes, no 
2 long & short yes, no 
Slant yes, no 
Shape skinny, medium, fat 
Direction -,--}, T, l 
Table 2: Rules for similarity judgment in the triad discrimination task. 
IF fi-val(fil?, att?) = fi-val(fi2?, att?) THEN 
same-att-value(fil?, fi2?, att?). 
IF not(same-att-value(fil?, fi3?, att?)) AND fill?  fi3? 
AND fi2?  fi3? THEN unq-sim(fil?, fi2?, att?). 
IF c(unq-sim(fil?, fi2?, att?)) > 
c(unq-sim(fil?, fi2?, att?))AND 
c(unq-sim(fil?, fi3?, att?))> c(unq-sim(fi2?, fi3?, att?)) 
AND fill?  fi3? AND fi2? fi3? THEN 
most-similar (fill ?, fi2?) . 
Labels followed by a '?' indicate variables. 
fig-val(fig?, att?) returns the value of att? in fig? 
c0 counts the number of instances. 
A B C A B C 
Figure 1: Triads used to test learning. 
triads for which these rules cannot decide which pair is most similar. This is not often 
the case for a particular child, who usually finds one attribute more salient than another. 
Yet, frequently when the rules cannot uniquely identify the most similar pair, a classroom 
of children is equally divided. Hence, the model may not accurately predict an individual 
response, but is it usually correct at identifying the modal responses. 
To verify the accuracy of the initial state of our model, we used the set of nine testing triads 
shown in Figure 1 which were developed for the interviews with children. As shown in 
Table 3, the model matches very nicely responses obtained from a separate sample of 48 
second grade children. Thus, we believe that we have a valid point from which to start. 
2.2 The translation of rule sets into a neural network 
We translate rules sets into neural networks using the KBANN algorithm [3] which uses a 
set of hierarchically-structured rules in the form of propositional Horn clauses to set the 
topology and initial weights of an artificial neural network. Because the rules in Table 2 are 
890 Towell and Lehrer 
Table 3: Initial responses by the model. 
Initial Model BC BC AC AC BC AB/BC AC AB/BC AC/BC 
Second GradeChildren BC BC AC AC BC AB/BC AC AB AC/BC 
Answers in the initial model row indicate the responses generated by the initial rules. 
More than response in a column indicates that the rules could not differentiate among two 
pairs. 
Answers in the second grade row are the modal responses of second grade children. More 
than one answer in a column indicates that equal numbers of children judged the pairs most 
similar. 
Table 4: Properties used to describe figures. 
Property name values Property name values 
Convex Yes No 
# Sides 3 4 5 6 8 
# Angles 3 4 5 6 8 
All Sides Equal Yes No 
# Right Angles 0 1 2 3 4 
All Angles Equal Yes No 
# Equal Angles 0 2 3 4 5 6 8 
# Pairs Equal Opposite Angles 
# Pairs Opposite Sides Equal 
# Pairs Parallel Sides 
Adjacent Angles = 180 
# Lines of Symmetry 
# Equal Sides 
01234 
01234 
01234 
YesNo 
01234568 
0234568 
not in propositional form, they must be expanded before they can be accepted by KBANN. 
The expansion turns a simple set of three rules into an ugly set of approximately 100 rules. 
Figure 2 is a high-level view of the structure of the neural network that results from the 
rules. In this implementation we present all three figures at the same time and all decisions 
are made in parallel. Hence, the rules described above must be repeated at least three 
times. In the neural network that results from the rule translation, these repeated rules are 
not independent. Rather they are linked so that modifications of the rules are shared across 
every pairing. Thus, the network cannot learn a rule which applies only to one pair. 
Finally, the model begins with the set of 13 properties listed in Table 4 in addition to the 
attributes of Table 1. (Note that we use attribute to refer to the informal, visual features 
in Table 1 and property to refer to the symbolic features in Table 4.) As a result, each 
figure is described to the model as a 74 position vector (18 positions encode the attributes; 
the remaining 56 positions encode the properties). 
3 An Experiment Using the Model 
One of the points we made in the introduction 
