An Analog VLSI Splining Network 
Doiel B. Schwartz and Vijay K. Sama]am 
GTE Laboratories, Inc. 
40 Sylvan Rd. 
Waltham, MA 02254 
Abstract 
We have produced a VLSI circuit capable of learning to approximate ar- 
bitrary smooth of a single variable using a technique closely related to 
splines. The circuit effectively has 512 knots space on a uniform grid and 
has full support for learning. The circuit also can be used to approximate 
multi-variable functions as sum of splines. 
An interesting, and as of yet, nearly untapped set of applications for VLSI imple- 
mentation of neural network learning systems can be found in adaptive control and 
non-linear signal processing. In most such applications, the learning task consists 
of approximating a real function of a small number of continuous variables from 
discrete data points. Special purpose hardware is especially interesting for applica- 
tions of this type since they generally require real time on-line learning and there 
can be stiff constraints on the power budget and size of the hardware. Frequently, 
the already difficult learning problem is made more complex by the non-stationary 
nature of the underlying process. 
Conventional feed-forward networks with sigmoidal units are clearly inappropriate 
for applications of this type. Although they have exhibited remarkable performance 
in some types of time series prediction problems (for example, Wiegend, 1990 and 
Atlas, 1990), their learning rates in general are too slow for on-line learning. On-line 
performance can be improved most easily by using networks with more constrained 
architecture, effectively making the learning problem easier by giving the network a 
hint about the learning task. Networks that build local representations of the data, 
such as radial basis functions, are excellent candidates for these type of problems. 
One great advantage of such networks is that they require only a single layer of 
units. If the position and width of the units are fixed, the learning problem is linear 
1008 
An Analog VLSI Splining Network 1009 
in the coefficients and local. By local we mean the computation of a weight change 
requires only information that is locally available to each weight, a highly desirable 
property for VLSI implementation. If the learning algorithm is allowed to adjust 
both the position and width of the units then many of the advantages of locally 
tuned units are lost. 
A number of techniques have been proposed for the determination of the width 
and placement of the units. One of the most direct is to center a unit at every 
data point and to adjust the widths of the units so the receptive fields overlap 
with those of neighboring data points ( Broomhea!, 1989 ). The proliferation of 
units can be limited by using unsupervised clustering techniques to clump the data 
followed by the allocation of units to fit the clumps (Moody, 1989). Others have 
advocated assigning new units only when the error on a new data point is larger than 
a threshold and otherwise making small adjustments in the weights and parameters 
of the existing units (Platt, 1990). All of these methods suffer from the common 
problem of requiring an indeterminate quantity of resources in contrast with the 
fixed resources available from most VLSI circuits. Even worse, when used with 
non-stationary processes a mechanism is needed to deallocate units as well as to 
allocate them. The resource allocation/deallocation problem is a serious barrier to 
implementing these algorithms as autonomous VLSI microsystems. 
A Splining Network 
To avoid the resource allocation problem we propose a network that uses all of 
its weights and units regardless of the problem. We avoid over parameterization 
of the training data by building constraints on smoothness into the network, thus 
reducing the number of degrees of freedom available to the training process. In 
its simplest guise, the network approximates arbitrary 1-d smooth functions with a 
linear superposition of locally tuned units spaced on a uniform grid, 
(1) 
where a is the radius of the unit's receptive field and the wi are the weights. J'o is a 
bump of width a such as a gaussian or a cubic spline basis function. Mathematically 
the network is closely related to function approximation using B-splines (Lancaster, 
1986) with uniformly spaced knots. However, in B-spline interpolation the overlap 
of the basis functions is normally determined by the degree of the spline whereas 
we use the degree of overlap as a free parameter to constrain the smoothness of 
the network's output. As mentioned earlier, the network is linear in its weights 
so gradient descent with a quadratic cost function (LMS) is an effective training 
procedure. 
The weights needed for this network can easily be implemented in CMOS with an 
array of transconductance amplifiers. The amplifiers are wired as voltage followers 
with their outputs tied together and the weights are represented by voltages I 
at the non-inverting inputs of the amplifiers. If the outputs of the locally tuned 
units are represented by unipolar currents Ii these currents can be used to bias the 
1010 Schwarfz and Samalam 
transconductance amplifiers and the result is (Mead,1989) 
Vo,. = 
provided that care is taken to control the non-linearities of the amplifiers. However, 
while the weights have a simple implementation in analog VLSI circuitry, the input 
units do not. A number of circuits exist whose transfer characteristics can be shaped 
to be a suitable bump but none of those known to the authors allow the width of 
the bump to be adjusted over a wide range without the use of resistors. 
(enerating the Receptive Fields 
Input units with tunable receptive fields can be generated quite efficiently by break- 
ing them up into two layers of circuitry as shown in figure 1. The input layer place 
encodes the input signal - i.e. only one or perhaps a small cluster of units is active 
at a time. The output of the place encoding units either injects or controls the 
output 
[] 
/ 
Input 
] [] 
\ /\ 
weight 
spreading 
layer 
place 
encoding 
Figure 1: An architecture that allows the width and shape of the receptive fields to 
be varied over a wide range. The elements of the 'spreading layer' are passive and 
can sink current to ground. 
injection of current into the laterally connected spreading layer. The elements in 
the spreading layer all contain ground terminals and the current sunk by each one 
determines the bias current applied to the associated weight. Clearly, the distribu- 
tion of currents flowing to ground through the spreading layer form a smooth bump 
such that when excitation is applied to tap j of the spreading layer, 
ii = lof(i- j) 
where f,(i) is the bump called for by equation 1. In our earliest realizations of 
this network the input layer was a crude flash A-to-D converter and the input 
to the circuit was analog. In the current generation the input is digital with the 
place encoding performed by a conventional address decoder. If desired, input 
quantization can be avoided by using a layer of amplifiers that generate smooth 
bumps of fixed width to generate the input place encoding. 
An Analog VLSI Splining Network 1011 
The simplest candidate to implement the spreading layer in conventional CMOS 
is a set of diode connected n-channel transistors laterally connected by n-channel 
pass transistors. The gate voltages of the diode connected transistors determine 
the bias currents Ii of the weights. Ignoring the body effect and assuming weak 
inversion in the current sink, this type of networks tends to gives bumps with rather 
sharp peaks, Ii ' }'. Ioe -l'il, where [j[ is the distance from the point where the 
excitation is applied. Figure 2 shows a more sophisticated version of this circuit 
in which the output of the place encoding units applies excitation to the spreading 
network through a p-channel transistor. The shape of the bumps can be softened by 
to weights 
_ r.I-L   bias 
voltages 
T Y T 
from place encoder 
Figure 2: A schematic of a section of the spreading layer. Roughly speaking, the 
n-channel pass transistor controls the extent of the tails of the bumps and the 
p-channel pass transistor and the cascode transistor control its width. 
limiting the amount of current drawn by the current sinks with an n-channel cascode 
transistor in series with the current sink. Some experimental results for this type of 
circuit are shown in figure 3a. More control can be obtained by using complementary 
pass transistors. The use of p-channel pass transistors alone unexpectedly results 
in bumps that are nearly square (figure 3b). These can be smoothed by using a 
using both flavors of pass transistor simultaneously (figure 3c). 
The Weights 
As described earlier, the implementation of the output weights is based on the 
computation of means by the well known follower-aggregation circuit. With typical 
transconductance amplifiers, this averaging is linear only when the voltages being 
averaged are distributed over a voltage range of no more than a few time UQ = kT/e 
in weak inversion. In the circuits described here the linear range has been widened 
to nearly a volt by reducing the transconductance of the readout amplifiers through 
the combination of low width to length ratio input transistors and relatively large 
tail currents. 
The weights I are stored on MOS capacitors and are programmed by the gated 
transconductance amplifier shown in figure 4. Since this amplifier computes the 
1012 Schwartz and Samalam 
ï¿½ II 
; I I 
i Il I 
I II 
: I J I 
: I I ; 
; I I 
r I I 
; iI ' I : 
j i I 
: ' I 
: .1 .I ,.I I J 
10 20 30 40 50 
Tap Number 
0 10 20 
30 4'0 50 
Figure 3: Experimental measurements of the receptive field shapes obtained from 
different types of networks. (a) n-channel transistors for several gate voltages. (b) 
p-channel transistors for several gate voltages. (c) Both n-chan
