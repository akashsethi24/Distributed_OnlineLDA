Contour Organisation with the EM 
Algorithm 
J. A. F. Leite and E. R. Hancock 
Department of Computer Science 
University of York, York, Y01 5DD, UK. 
Abstract 
This paper describes how the early visual process of contour organ- 
isation can be realised using the EM algorithm. The underlying 
computational representation is based on fine spline coverings. Ac- 
cording to our EM approach the adjustment of spline parameters 
draws on an iterative weighted least-squares fitting process. The 
expectation step of our EM procedure computes the likelihood of 
the data using a mixture model defined over the set of spline cover- 
ings. These splines are limited in their spatial extent using Gaus- 
sian windowing functions. The maximisation of the likelihood leads 
to a set of linear equations in the spline parameters which solve the 
weighted least squares problem. We evaluate the technique on the 
localisation of road structures in aerial infra-red images. 
1 Introduction 
Dempster, Laird and Rubin's EM (expectation and maximisation) [1] algorithm was 
originally introduced as a means of finding maximum likelihood solutions to prob- 
lems posed in terms of incomplete data. The basic idea underlying the algorithm 
is to iterate between the expectation and maximisation modes until convergence is 
reached. Expectation involves computing a posteriori model probabilities using a 
mixture density specified in terms of a series of model parameters. In the max- 
imisation phase, the model parameters are recomputed to maximise the expected 
value of the incomplete data likelihood. In fact, when viewed from this perspective, 
the updating of a posteriori probabilities in the expectation phase would appear 
to have much in common with the probabilistic relaxation process extensively ex- 
ploited in low and intermediate level vision [9, 2]. Maximisation of the incomplete 
Contour Organisation with the EM Algorithm 881 
data likelihood is reminiscent of robust estimation where outlier reject is employed 
in the iterative re-computation of model parameters [7]. 
It is these observations that motivate the study reported in this paper. We are 
interested in the organisation of the output of local feature enhancement operators 
into meaningful global contour structures [13, 2]. Despite providing one of the clas- 
sical applications of relaxation labelling in low-level vision [9], successful solutions 
to the iterative curve reinforcement problem have proved to be surprisingly elusive 
[8, 12, 2]. Recently, two contrasting ideas have offered practical relaxation operat- 
ors. Zucker et al [13] have sought biologically plausible operators which draw on 
the idea of computing a global curve organisation potential and locating consistent 
structure using a form of local snake dynamics [11]. In essence this biologically 
inspired model delivers a fine arrangement of local splines that minimise the curve 
organisation potential. Hancock and Kittler [2], on the other hand, appealed to a 
more information theoretic motivation [4]. In an attempt to overcome some of the 
well documented limitations of the original Rosenfeld, Hummel and Zucker relaxa- 
tion operator [9] they have developed a Bayesian flamework for relaxation labelling 
[4]. Of particular significance for the low-level curve enhancement problem is the un- 
derlying statistical framework which makes a clear-cut distinction between the roles 
of uncertain image data and prior knowledge of contour structure. This framework 
has allowed the output of local image operators to be represented in terms of Gaus- 
sian measurement densities, while curve structure is represented by a dictionary of 
consistent contour structures [2]. 
While both the fine-spline coverings of Zucker [13] and the dictionary-based re- 
laxation operator of Hancock and Kittler [2] have delivered practical solutions to 
the curve reinforcement problem, they each suffer a number of shortcomings. For 
instance, although the fine spline operator can achieve quasi-global curve organisa- 
tion, it is based on an essentially ad hoc local compatibility model. While being 
more information theoretic, the dictionary-based relaxation operator is limited by 
virtue of the fact that in most practical applications the dictionary can only realist- 
ically be evaluated over at most a 3x3 pixel neighbourhood. Our aim in this paper 
is to bridge the methodological divide between the biologically inspired fine-spline 
operator and the statistical flamework of dictionary-based relaxation. We develop 
an iterative spline fitting process using the EM algorithm of Dempster et al [1]. 
In doing this we retain the statistical flamework for representing filter responses 
that has been used to great effect in the initialisation of dictionary-based relaxa- 
tion. However, we overcome the limited contour representation of the dictionary by 
drawing on local cubic splines. 
2 Prerequisites 
The practical goal in this paper is the detection of line-features which manifest 
themselves as intensity ridges of variable width in raw image data. Each pixel 
is characterised by a vector of measurements, z_ i where i is the pixel-index. This 
measurement vector is computed by applying a battery of line-detection filters of 
various widths and orientations to the raw image. Suppose that the image data 
is indexed by the pixel-set I. Associated with each image pixel is a cubic spline 
parameterisation which represents the best-fit contour that couples it to adjacent 
feature pixels. The spline is represented by a vector of parameters denoted by 
882 J. A. E Leite and E. R. Hancock 
3 T 
-qi = (q' q' q' qi ) � 
indexed i. The spline 
the pixel indexed j is 
j. We can write the 
2 3 
S_i, j = (1, $i,j, $i,j, $i,j 
the predicted vertical 
Let (xi,yi) represent the position co-ordinates of the pixel 
variable, $i,j --- Xi --Xj associated with the contour connecting 
the horizontal displacement between the pixels indexed i and 
cubic spline as an inner product F(si,j, _qi) - _qiT._si,j where 
)T. Central to our EM algorithm will be the comparison of 
spline displacement with its measured value ri,j -- Yi -- Yj. 
In order to initialise the EM algorithm, we require a set of initial spline probabilities 
which we denote by x(_q?). Here we use the multi-channel combination model 
recently reported by Leite and Hancock [5] to compute an initial multi-scale line- 
feature probability. Accordingly, if E is the variance-covariance matrix for the 
components of the filter bank, then 
[ 1 Tv,-1 ] 
r(_q?) = 1 -- exp [--z_ i z. z_ i 
(1) 
The remainder of this paper outlines how these initial probabilities are iteratively re- 
fined using the EM algorithm. Because space is limited we only provide an algorithm 
sketch. Essential algorithm details such as the estimation of spline orientation and 
the local receptive gating of the spline probabilities are omitted for clarity. Full 
details can be found in a forthcoming journal article [6]. 
3 Expectation 
Our basic model of the spline organisation process is as follows. Associated with 
each image pixel is a spline parameterisation. Key to our philosophy of exploiting 
a mixture model to describe the global contour structure of the image is the idea 
that the pixel indexed i can associate to each of the putative splines residing in a 
local Gaussian window Ni. We commence by developing a mixture model for the 
conditional probability density for the filter response _z i given the current global 
spline description. If (n) _ {97),V i 6 I} is the global spline description at 
iteration n of the EM process, then we can expand the mixture distribution over a 
set of putative splines that may associate with the image pixel indexed i 
)(_qj ) (2) 
jNi 
The components of the above mixture density are the conditional measurement 
densities p(z_il () .__j ). The conditional 
_qj ) and the spline mixing proportions 
measurement densities represent the likelihood that the datum z_ originates from the 
spline centred on pixel j. The mixing proportions, on the other hand, represent the 
fractional contribution to the data arising from the jth parameter vector i.e. _q). 
Since we are interested in the maximum likelihood estimation of spline parameters, 
we turn our attention to the likelihood of the raw data, i.e. 
p(z_i, Vi � I[(b �) = IIP(z_il(I, �) (3) 
The expectation step of the EM algorithm is aimed at estimating the log-likelihood 
using the parameters of the mixture distribution. In other words, we need to av- 
erage the likelihood over the space of potential pixel-spline assignments. In fact, 
Contour Organisation with the EM Algorithm 883 
it was Dempster, Laird and Rubin [1] who observed that maximising the weighted 
log-likelihood was equivalent to maximising the conditional expectation of the like- 
lihood for a new parameter set given an old parameter set. For our spline fitting 
problem, maximisation of the expectation of the conditional likelihood is equivalent 
to maximising the weighted log-likelihood function 
(n) In p(z_il_q(j + ) 
(_% Iz_i) ) 
(4) 
The a posteriori probabilities P(95 M [z_i) may be computed from the corresponding 
components of the mixture density p(z_i[q M) using the Bayes formula 
q!,) ]x(q!,)] (5) 
- YkeN, P(Z-i[_, , ,_, , 
For notational convenience, and to make the weighting role of the a posteriori prob- 
 (M = p(q}MIz_i). Once updated parameter 
abilities explicit we use the shorthand .vi, j _ 
estimates _q?) become available through the maximisation of this criterion, im- 
proved estimates of the mixture components may be obtained by substitution into 
equation (6). The updated mixing proportions, (_q?+)), required to determine 
the new weights  (M 
'vi, j are computed from the newly available density components 
using the following estimator 
I_qi ) (_qi) 
7r (n+l) 
)= p(z 
I_q ) 
jeN, Y-kelP(Z-j (n) (n) 
(6) 
In order to proceed with the development of a spline fi
