Learning with ensembles: How 
over-fitting can be useful 
Peter Sollich 
Department of Physics 
University of Edinburgh, U.K. 
P. Solliched. ac.uk 
Anders Krogh* 
NORDITA, Blegdamsvej 17 
2100 Copenhagen, Denmark 
kroghsanger. ac. uk 
Abstract 
We study the characteristics of learning with ensembles. Solving 
exactly the simple model of an ensemble of linear students, we 
find surprisingly rich behaviour. For learning in large ensembles, 
it is advantageous to use under-regularized students, which actu- 
ally over-fit the training data. Globally optimal performance can 
be obtained by choosing the training set sizes of the students ap- 
propriately. For smaller ensembles, optimization of the ensemble 
weights can yield significant improvements in ensemble generaliza- 
tion performance, in paxticulax if the individual students are sub- 
ject to noise in the training process. Choosing students with a wide 
range of regularization parameters makes this improvement robust 
against changes in the unknown level of noise in the training data. 
I INTRODUCTION 
An ensemble is a collection of a (finite) number of neural networks or other types 
of predictors that are trained for the same task. A combination of many differ- 
ent predictors can often improve predictions, and in statistics this idea has been 
investigated extensively, see e.g. [1, 2, 3]. In the neural networks community, en- 
sembles of neural networks have been investigated by several groups, see for instance 
[4, 5, 6, 7]. Usually the networks in the ensemble are trained independently and 
then their predictions are combined. 
In this paper we study an ensemble of linear networks trained on different but 
overlapping training sets. The limit in which all the networks are trained on the 
full data set and the one where all the data sets are different has been treated in 
[8]. In this paper we treat the case of intermediate training set sizes and overlaps 
*Present address: The Sanger Centre, Hinxton, Cambs CB10 1RQ, UK. 
Learning with Ensembles: How Overfitting Can Be Useful 191 
exactly, yielding novel insights into ensemble learning. Our analysis also allows us to 
study the effect of regularization and of having different predictors in an ensemble. 
2 GENERAL FEATURES OF ENSEMBLE LEARNING 
We consider the task of approximating a target function f0 from R / to R. It 
will be assumed that we can only obtain noisy samples of the function, and the 
(now stochastic) target function will be denoted y(x). The inputs x are taken 
to be drawn from some distribution P(x). Assume now that an ensemble of K 
independent predictors f(x) of y(x) is available. A weighted ensemble average is 
denoted by a bar, like 
y(x)- Ewf(x), (1) 
which is the final output of the ensemble. One can think of the weight w as the 
belief in predictor k and we therefore constrain the weights to be positive and sum 
to one. For an input x we define the error of the ensemble e(x), the error of the 
kth predictor e(x), and its ambiguity a(x) 
4x) 
a(x) 
= (y(x)-?(x)) 2 
= (y(x)- 2 
= (f,(x)- ?(x)) 2. 
(2) 
(4) 
= 
= 
The ensemble error can be written as e(x) = (x)- (x) [7], where 
we(x) is the average error over the individual predictors and 
 wa(x) is the average of their ambiguities, which is the variance of the output 
over the ensemble. By averaging over the input distribution P(x) (and implicitly 
over the target outputs y(x)), one obtains the ensemble generalization error 
where e(x) averaged over P(x) is simply denoted e, and similarly for  and . The 
first term on the right is the weighted average of the generalization errors of the indi- 
vidual predictors, and the second is the weighted average of the ambiguities, which 
we refer to as the ensemble ambiguity. An important feature of equation (5) is that 
it separates the generalization error into a term that depends on the generalization 
errors of the individual students and another term that contains all correlations be- 
tween the students. The latter can be estimated entirely from unlabeled data, i.e., 
without any knowledge of the target function to be approximated. The relation (5) 
also shows that the more the predictors differ, the lower the error will be, provided 
the individual errors remain constant. 
In this paper we assume that the predictors are trained on a sample of p examples 
of the target function, (x,y), where y = f0(x ) + r/ and r/ is some additive 
noise (tz = 1,...,p). The predictors, to which we refer as students in this context 
because they learn the target function from the training examples, need not be 
trained on all the available data. In fact, since training on different data sets will 
generally increase the ambiguity, it is possible that training on subsets of the data 
will improve generalization. An additional advantage is that, by holding out for 
each student a different part of the total data set for the purpose of testing, one 
can use the whole data set for training the ensemble while still getting an unbiased 
estimate of the ensemble generalization error. Denoting this estimate by , one has 
� 
 = �test -- a (6) 
where �test' - k WkCtest,k is the average of the students' test errors. As already 
pointed out, the estimate  of the ensemble ambiguity can be found from unlabeled 
data. 
192 P. SOLLICH, A. KROGH 
So far, we have not mentioned how to find the weights w. Often uniform weights 
are used, but optimization of the weights in some way is tempting. In [5, 6] the 
training set was used to perform the optimization, i.e., the weights were chosen to 
minimize the ensemble training error. This can easily lead to over-fitting, and in [7] 
it was suggested to minimize the estimated generalization error (6) instead. If this 
is done, the estimate (6) acquires a bias; intuitively, however, we expect this effect 
to be small for large ensembles. 
3 ENSEMBLES OF LINEAR STUDENTS 
In preparation for our analysis of learning with ensembles of linear students we now 
briefly review the case of a single linear student, sometimes referred to as 'linear 
perceptron learning'. A linear student implements the input-output mapping 
i wT x 
f(x): 
parameterized in terms of an N-dimensional parameter vector w with real compo- 
nents; the scaling factor 1/v/- is introduced here for convenience, and ...T denotes 
the transpose of a vector. The student parameter vector w should not be con- 
fused with the ensemble weights . The most common method for training such 
a linear student (or parametric inference models in general) is minimization of the 
sum-of-squares training error 
E --- E(y  - f(x)) 2 + ,w 2 
where p = 1,...,p numbers the training examples. To prevent the student from 
fitting noise in the training data, a weight decay term Aw 2 has been added. The size 
of the weight decay parameter A determines how strongly large parameter vectors 
are penalized; large A corresponds to a stronger regularization of the student. 
For a linear student, the global minimum of E can eily be found. However, 
in practical applications using non-linear networks, this is generally not true, and 
training can be thought of  a stochastic process yielding a different solution each 
time. We crudely model this by considering white noise added to gradient descent 
updates of the parameter vector w. This yields a limiting distribution of parameter 
vectors P(w)  exp(-E/2T), where the 'temperature' T measures the amount of 
noise in the training process. 
We focus our analysis on the 'thermodynamic limit' N   at constant normalized 
number of training examples, a = piN. In this limit, quantities such  the training 
or generalization error become self-averaging, i.e., their averages over all training 
sets become identical to their typical values for a particular training set. Assume 
now that the training inputs x are chosen randomly and independently from a 
Gaussian distribution P(x)  exp(-x2), and that training outputs are generated 
by a linear target function corrupted by additive noise, i.e., y = w[x/+ ?, 
where the ? are zero mean noise variables with variance a 2. Fixing the length of the 
parameter vector of the target function to w = N for simplicity, the generalization 
error of a linear student with weight decay A and learning noise T becomes [9] 
 = ( + )C + ( - ) OC 
0x' (7) 
On the r.h.s. of this equation we have dropped the term arising from the noise on 
the target function alone, which is simply a2, and we shall follow this convention 
throughout. The 'response function' G is [10, 11] 
C= (-,X)= (--- X + g(1-,- X) + 4X)/2X. (8) 
Learning with Ensembles: How Overfitting Can Be Useful 193 
For zero training noise, T = 0, and for any c, the generalization error (7 l is mini- 
mized when the weight decay is set to , = r2; its value is then r2G(a, r), which 
is the minimum achievable generalization error [9]. 
3.1 ENSEMBLE GENERALIZATION ERROR 
We now consider an ensemble of K linear students with weight decays , and 
learning noises T (k = 1...K). Each student has an ensemble weight w and 
is trained on Nc training examples, wi(h students k and 1 sharing Nct training 
examples (of course, c = c). As above, we consider noisy training data generated 
by a linear target function. The resulting ensemble generalization error can be 
calculated by diagrammatic [10] or response function [11] methods. We refer the 
reader to a forthcoming publication for details and only state the result: 
where 
= E (9) 
kl 
pp + 2(1 - p)(1 - pz)ot/(oot) T 
ez = 1 - (1 - p)(1 - pz)az/(aaz) + p6. (10) 
Here p is defined  p = G(a,). The Kronecker delta in the 1 term 
of (10) arises because the training noises of different students are uncorrelated. The 
generalization errors and ambiguities of the individual students are 
I lm 
the result for the e can be shown to agree with the single student result (7). In 
the following sections, we shall 
