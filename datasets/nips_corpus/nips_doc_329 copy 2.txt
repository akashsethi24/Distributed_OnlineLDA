Distributed Pecursive Structure Processing 
Graldine Legendre 
Department of 
Linguistics 
Yoshiro Miyata 
Optoelectronic 
Computing Systems Center 
University of Colorado 
Boulder, CO 80309-0430* 
Paul Smolensky 
Department of 
Computer Science 
Abstract 
Harmonic grammar (Legendre, et al., 1990) is a connectionist theory of lin- 
guistic well-formedness based on the assumption that the well-formedness 
of a sentence can be measured by the harmony (negative energy) of the 
corresponding connectionist state. Assuming a lower-level connectionist 
network that obeys a few general connectionist principles but is otherwise 
unspecified, we construct a higher-level network with an equivalent har- 
mony function that captures the most linguistically relevant global aspects 
of the lower level network. In this paper, we extend the tensor product 
representation (Smolensky 1990) to fully recursire representations of re- 
cursively structured objects like sentences in the lower-level network. We 
show theoretically and with an example the power of the new technique 
for parallel distributed structure processing. 
1 Introduction 
A new technique is presented for representing recursire structures in connectionist 
networks. It has been developed in the context of the framework of Harmonic 
Grammar (Legendre et al. 1990a, 1990b), a formalism for theories of linguistic 
well-formedness which involves two basic levels: At the lower level, elements of the 
problem domain are represented as distributed patterns of activity in a network; At 
the higher level, the elements in the domain are represented locally and connection 
weights are interpreted as soft rules involving these elements. There are two aspects 
that are central to the framework. 
*The authors are listed in alphabetical order. 
592 Legendre, Miyata, and Smolensky 
First, the connectionist well-formedness measure harmony (or negative energy), 
which we use to model linguistic well-formedness, has the properties that it is p- 
reserved between the lower and the higher levels and that it is maximized in the 
network processing. Our previous work developed techniques for deriving harmonies 
at the higher level from linguistic data, which allowed us to make contact with ex- 
isting higher-level analyses of a given linguistic phenomenon. 
This paper concentrates on the second aspect of the framework: how particular 
linguistic structures such as sentences can be efficiently represented and processed 
at the lower level. The next section describes a new method for representing tree 
structures in a network which is an extension of the tensor product representation 
proposed in (Smolensky 1990) that allows recursire tree structures to be represented 
and various tree operations to be performed in parallel. 
2 Recursire tensor product representations 
A tensor product representation of a set of structures S assigns to each s  S a 
vector built up by superposing role-sensitive representations of its constituents. A 
role decomposition of S specifies the constituent structure of s by assigning to it 
an unordered set of filler-role bindings. For example, if S is the set of strings from 
the alphabet {a,b, c}, and s = cba, then we might choose a role decomposition in 
which the roles are absolute positions in the string (rl = first, r2 = second, ...) 
and the constituents are the filler/role bindings {b/r,, a/ra, c/r}.  
In a tensor product representation a constituent - i.e., a filler/role binding - is 
represented by the tensor (or generalized outer) product of vectors representing the 
filler and role in isolation: fir is represented by the vector v = ��r, which is in fact 
a second-rank tensor whose elements are conveniently labelled by two subscripts and 
defined simply by vop = �orp. 
Where do the filler and role vectors f and r come from? In the most straightforward 
case, each filler is a member of a simple set F (e.g. an alphabet) and each role is 
a member of a simple set R and the designer of the representation simply specifies 
vectors representing all the elements of F and R. In more complex cases, one or 
both of the sets F and R might be sets of structures which in turn can be viewed as 
having constituents, and which in turn can be represented using a tensor product 
representation. This recursive construction of the tensor product representations 
leads to tensor products of three or more vectors, creating tensors of rank three and 
higher, with elements conveniently labelled by three or more subscripts. 
The recursive structure of trees leads naturally to such a recursive construction of 
a tensor product representation. (The following analysis builds on Section 11.7.2 of 
(Smolensky 1990.)) We consider binary trees (in which every node has at most two 
children) since the techniques developed below generalize immediately to trees with 
higher branching factor, and since the power of binary trees is well attested, e.g., 
by the success of Lisp, whose basic datastructure is the binary tree. Adopting the 
conventions and notations of Lisp, we assume for simplicity that the terminal nodes 
The other major kind of role decomposition considered in (Smolensky 1990) is contex- 
tual roles; under one such decomposition, one constituent of cba is b in the role 'preceded 
by c and followed by a' . 
Distributed Recursive Structure Processing 593 
of the tree (those with no children), and only the terminal nodes, are labelled by 
symbols or atoms. The set of structures S we want to represent is the union of a set 
of atoms and the set of binary trees with terminal nodes labelled by these atoms. 
One way to view a binary tree, by analogy with how we viewed strings above, is as 
having a large number of positions with various locations relative to the root: we 
adopt positional roles r labelled by binary strings (or bit vectors) such as z = 0110 
which is the position in a tree accessed by caddar = car(cdr(cdr(car))), that 
is, the left child (0; car) of the right child (1; cdr) of the right child of the left child 
of the root of the tree. Using this role decomposition, each constituent of a tree is 
an atom (the filler) bound to some role r specifying its location; so if a tree s has 
a set of atoms {fi} at respective locations (zi}, then the vector representing s is 
s = t�rx,. 
A more recursire view of a binary tree sees it as having only two constituents: the 
atoms or subtrees which are the left and right children of the root. In this fully 
recursire role decomposition, fillers may either be atoms or trees: the set of possible 
fillers F is the same as the original set of structures S. 
The fully recursire role decomposition can be incorporated into the tensor product 
framework by making the vector spaces and operations a little more complex than 
in (Smolensky 1990). The goal is a representation obeying, �s,p, q 6 S: 
s = cons(p, q) = s = p�r 0 + q�r I (1) 
Here, s = cons(p,q) is the tree with left subtree p and right subtree q, while 
s,p and q are the vectors representing s,p and q. The only two roles in this 
recursive decomposition are r0, 'l: the left and right children of root. These roles 
are represented by two vectors r 0 and r 1. 
A fully recursire representation obeying Equation 1 can actually be constructed 
from the positional representation, by assuming that the (many) positional role 
vectors are constructed recursively from the (two) fully recursire role vectors ac- 
cording to: 
rx0=rx�r 0 rxl =rx�r 1. 
For example, r0110 = r0�rl�rl�r 0. 2 Thus the vectors representing positions 
at depth d in the tree are tensors of rank d (taking the root to be depth 0). As 
an example, the tree s -- cons(i, cons(B, �)) -- cons(p, q), where p -- A and q = 
cons(B, �), is represented by 
s = A�r 0 + B�r01 + C�r11 = A�r 0 + B�r0�r 1+ C�rl�r 1 
= A�r 0 + (B�r 0 + C�rl)�r I = p�r 0 + q�r 1, 
in accordance with Equation 1. 
The complication in the vector spaces needed to accomplish this recursire analysis 
is one that allows us to add together the tensors of different ranks representing 
different depths in the tree. All we need do is take the direct sum of the spaces of 
tensors of different rank; in effect, concatenating into a long vector all the elements 
2By adopting this definition of rx, we are essentially taking the recursire structure that 
is implicit in the subscripts z label!ing the positional role vectors, and mapping it into the 
structure of the vectors themselves. 
594 Legendre, Miyata, and Smolensky 
of the tensors. For example, in s - cons(l, cons(B, C)), depth 0 is O, since s isn't an 
atom; depth I contains A, represented by the tensor S O) and depth 2 
9P = A9r0p' 
contains B and �, represented by �(2) 
'9PP -- B9r0prlp + C9rlprlp' The tree 
 a whole is then represented by the sequence s = {S ), p, pp,,...} where 
the tensor for depth O, S �), and the tensors for depths d 
p...p, are aH zero. 
We let V denote the vector space of such sequences of tensors of rank 0, rank 
... , up to some mamum depth D which may be infinite. Two elements of V are 
added (or superimposed) simply by adding together the tensors of corresponding 
rank. This is our vector space for representing trees. 3 
The vector operation cons for building the representation of a tree from that of its 
two subtrees is given by Equation 1. As an operation on V this can be written: 
o) e(') .}, 
p ' p P  �.  p  p P  �. 
{0, P�)r0p., _(1) {0, O)rlp, () , 
rpr0p,...} + p rlp  .. 
(Here, 0 denotes the zero vector in the space representing atoms.) In terms of 
matrices multiplying vectors in V, this can be written 
cons(p, q) = Wcons 0 p + Wcons I q 
(parael to Equation 1) where the non-zero elements of the matrix Wcons 0 are 
WconsOpp...papa+,pp...pa  r0pa+ 
and Wcons I is gotten by replacing r 0 with r 1. 
Taking the car or c of a tree - extracting the left or right child - in the recursive 
decomposition
