Robot Docking using Mixtures of Gaussians 
Matthew Williamson* 
Roderick Murray-Smith t 
Volker Hansen 
Abstract 
This paper applies the Mixture of Gaussians probabilistic model, com- 
bined with Expectation Maximization optimization to the task of sum- 
marizing three dimensional range data for a mobile robot. This provides 
a flexible way of dealing with uncertainties in sensor information, and al- 
lows the introduction of prior knowledge into low-level perception mod- 
ules. Problems with the basic approach were solved in several ways: the 
mixture of Gaussians was reparameterized to reflect the types of objects 
expected in the scene, and priors on model parameters were included 
in the optimization process. Both approaches force the optimization to 
find 'interesting' objects, given the sensor and object characteristics. A 
higher level classifier was used to interpret the results provided by the 
model, and to reject spurious solutions. 
1 Introduction 
This paper concerns an application of the Mixture ofGaussians (MoG) probabilistic model 
(Titterington et al., 1985) for a robot docking application. We use the Expectation- 
Maximization (EM) approach (Dempster et al., 1977) to fit Gaussian sub-models to a sparse 
3d representation of the robot's environment, finding walls, boxes, etc.. We have modified 
the MoG formulation in three ways to incorporate prior knowledge about the task, and the 
sensor characteristics: the parameters of the Gaussians are recast to constrain how they fit 
the data, priors on these parameters are calculated and incorporated into the EM algorithm, 
and a higher level processing stage is included which interprets the fit of the Gaussians on 
the data, detects misclassifications, and providing prior information to guide the model- 
fitting. 
The robot is equipped with a LIDAR 3d laser range-finder (PIAP, 1995) which it uses to 
identify possible docking objects. The range-finder calculates the time of flight for a light 
pulse reflected off objects in the scene. The particular LIDAR used is not very powerful, 
making objects with poor reflectance (e.g., dark, shiny, or surfaces not perpendicular to the 
*Corresponding author: MIT AI Lab, Cambridge, MA, USA. mat:t:0aJ_. mi. t:. edu 
* Dept. of Mathematical Modelling, Technical University of Denmark. rod0 J_mm. dt:u. dk 
* DaimlerChrysler, Alt-Moabit 96a, Berlin, Germany. hans on@ dbag. bln. da iml erbenz. com 
946 M. M. Williamson, R. Murray-Smith and V. Hansen 
laser beam) invisible. The scan pattern is also very sparse, especially in the vertical direc- 
tion, as shown in the scan of a wall in Figure 1. However, if an object is detected, the range 
returned is accurate (+ 1-2cm). When the range data is plotted in Cartesian space it forms 
a number of sparse clusters, leading naturally to the use of MoG clustering algorithms to 
make sense of the scene. While the Gaussian assumption is not an ideal model of the data, 
the generality of MoG, and its ease of implementation and analysis motivated its use over a 
more specialized approach. The sparse nature of the data inspired the modifications to the 
MoG formulation described in this paper. 
Model-based object recoghition from dense range images has been widely reported (see 
(Arman and Aggarwal, 1993) for a review), but is not relevant in this case given the sparse- 
ness of the data. Denser range images could be collected by combining multiple scans, but 
the poor visibility of the sensor hampers the application of these techniques. The advantage 
of the MoG technique is that the segmentation is soft, and perception proceeds iteratively 
during learning. This is especially useful for mobile robots where evidence accumulates 
over time, and the allocation of attention is time and state-dependent. The EM algorithm is 
useful since it is guaranteed to converge to a local maximum. 
The following sections of the paper describe the re-parameterization of the Gaussians to 
model plane-like clusters, the formulation of the priors, and the higher level processing 
which interprets the clustered data in order to both move the robot and provide prior infor- 
mation to the model-fitting algorithm. 
-04. 
-0.6. 
-08. 
-1 
yaxm n m xaxis in m 
Figure 1: Plot showing data from a LIDAR scan of a wall, plotted in Cartesian space. The 
robot is located at the origin, with the y axis pointing forward, a: to the right, and z up. The 
sparse scan pattern is visible, as well as the visibility constraint: the wall extends beyond 
where the scan ends, but is invisible to the LIDAR due to the orientation of the wall 
2 Mixture of Gaussians model 
The range-finder returns a set of data, each of which is a position in Cartesian space xi = 
(xi, yi, z). The complete set of data D -- {x... xtv } is modeled as being generated by a 
mixture density 
M 
p(x.) = p(x. li, 
i=l 
where we use a Gaussian as the sub-model, with mean/i, variance Ei and weight i, which 
mes the probability of a pmicul data point: 
M 
Robot Docla'ng Using Mixtures of Gaussians 947 
Given a set of data D, the most likely set of parameters is found using the EM algorithm. 
This algorithm has a number of advantages, such as guaranteed convergence to a local 
minimum, and efficient computational performance. 
In 3D Cartesian space, the Gaussian sub-models form ellipsoids, where the size and orien- 
tation are determined by the covariance matrix E. In the general case, the EM algorithm 
can be used to learn all the parameters of Ei. The sparseness of the LIDAR data makes 
this parameterization inappropriate, as various odd collections of points could be clustered 
together. By changing the parameterization of E, to better model plane-like structures, the 
system can be improved. The reparameterization is most readily expressed in terms of the 
eigenvalues Ai and eigenvectors V/of the covariance matrix Ei = ViAiVi -1. 
The covariance matrix of a normal approximation to a plane-like vertical structure will 
have a large eigenvalue in the z direction, and in the x-y plane one large and one small 
eigenvalue. Since Ei is symmetrical, the eigenvectors are orthogonal, V -1 = Vi T = l/i, 
and Ei can be written: 
cos0i -sin0i 0 0 7ai 0 cos0i -sin0, 0 , 
0 0 1 0 0 b, 0 0 1 
where Oi is the angle of orientation of the ith sub-model in the x-y plane, ai scales the 
cluster in the x and y directions, and bi scales in the z direction. The constant 7 controls 
the aspect ratio of the ellipsoid in the x-y plane. 
The optimal values of these parameters (a, b) are found using EM, first calculating the 
probability that data point x, is modeled by Gaussian i, (h,) for every data point Xn and 
every Gaussian i, 
ili1-1/2 exp (- 1 
- - 
in : M -1/2 1 
(x - (x -  
This responsibility is then used as a weighting for the updates to the other parameters, 
i  hix i =1 ( 2 rn hm(Xl - i)(x2 - i2) ) 
= E= hm '  tan-' E= hm[(x=, - ,,)2 _ (x=2 - i2) 2] 
ï¿½ = (, - - + - cose) + - + - 
= = - 
where x is the first element of x etc. and  coesponds to the prQection of the data into 
the plane of the cluster. It is important to update the means i first, and use the new values 
to update the other parameters. 2 Figure 2 shows a typical model response on real LIDAR 
data. 
2.1 Practicalities of application, and results 
Starting values for the model parameters are important, as EM is only guaranteed to find a 
local optimum. The Gaussian mixture components are initialized with a large covariance, 
allowing them to pick up data and move to the correct positions. We found that initializing 
the means/zi to random data points, rather than randomly in the input space, tended to 
By experimentation, a value of 7 of 0.01 was found to be reasonable for this application. 
2Intuition for the Oi update can be obtained by considering that (x, - ttx) is the x component of 
the distance between x, and tt, which is Ixn -tt I cos 0, and similarly (x,2 - tt2) is Ix, -tt I sin 0, 
so tan20 - sin20 __ 2sinOcosO __ 2(Xl--/al)(Xn2--/a2) 
cos20 -- cos 2 O--sin 2 0 -- (Xrl--/il)2--(xr2--/2) 2' 
948 M. M. Williamson, R. Murray-Smith and 14. Hansen 
Figure 2: Example of clustering of the 3d data points. The left hand graph shows the view 
from above (the :-/plane), and the right graph shows the view from the side (the /-z 
plane), with the robot positioned at the origin. The scene shows a box at an oblique angle, 
with a wall behind. The extent of the plane-like Gaussian sub-models is illustrated using 
the ellipses, which are drawn at a probability of 0.5. 
work better, especially given the sensor characteristics--if the LIDAR returned a range 
measurement, it was likely to be part of an interesting object. 
Despite the accuracy of measurement, there are still outlying data points, and it is impos- 
sible to fully segment the data into separate objects. One simple solution we found was 
to define a junk Gaussian. This is a sub-model placed in the center of the data, with a 
large covariance E. This Gaussian then becomes responsible for the outliers in the data (i.e. 
sparsely distributed data over the whole scene, none of which are associated with a specific 
object), allowing the object-modeling Gaussians to work undistracted. 
The use of EM with the a, b, 0 parameterization found and represented plane-like data clus- 
ters better than models where all the elements of the covariance matrix were free to adapt. 
It also tended to converge faster, probably due to the reduced numbers of parameters in the 
covariance matrix (3 as opposed to 6). Although the algorithm is constrained to find planes, 
the parameterization was flexible enough to model other objects such as thin vertical lines 
(say from a table leg). The only problem with the algorithm was that it occasionally found 
poor local minimum solutions, such as illustrated in Figure 3. This is a common problem 
with least squares based clustering methods (Duda and Hart, 1973). 
x y 
