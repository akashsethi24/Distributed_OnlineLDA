Rapid Visual Processing using Spike Asynchrony 
Simon J. Thorpe & Jacques Gautrais 
Centre de Recherche Cerveau & Cognition 
F-31062 Toulouse 
France 
email thorpe @cerco.ups-tlse.fr 
Abstract 
We have investigated the possibility that rapid processing in the visual 
system could be achieved by using the order of firing in different 
neurones as a code, rather than more conventional firing rate schemes. 
Using SPIKENET, a neural net simulator based on integrate-and-fire 
neurones and in which neurones in the input layer function as analog- 
to-delay converters, we have modeled the initial stages of visual 
processing. Initial results are extremely promising. Even with activity 
in retinal output cells limited to one spike per neuron per image 
(effectively ruling out any form of rate coding), sophisticated processing 
based on asynchronous activation was nonetheless possible. 
1. INTRODUCTION 
We recently demonstrated that the human visual system can process previously unseen 
natural images in under 150 ms (Thorpe et al, 1996). Such data, together with previous 
studies on processing speeds in the primate visual system (see Thorpe & Imbert, 1989) 
put severe constraints on models of visual processing. For example, temporal lobe 
neurones respond selectively to faces only 80-100 ms after stimulus onset (Oram & 
Perrett, 1992; Rolls & Tovee, 1994). To reach the temporal lobe in this time, 
information from the retina has to pass through roughly ten processing stages (see Fig. 
1). If one takes into account the surprisingly slow conduction velocities of intraconical 
axons (< 1 ms-l, see Nowak & Bulllet, 1997) it appears that the computation time 
within any cortical stage will be as little as 5-10 ms. Given that most conical neurones 
will be firing below 100 spikes.s -, it is difficult to escape the conclusion that processing 
can be achieved with only one spike per neuron. 
902 S. J. Thorpe and J. Gautrais 
Retina LGN V1 V2 V4 PIT AIT 
O 
O 
o 
o 
o 
o 
o 
o 
o 
o 
o-o 
-oo 
- o 
 o 
 0 
 0 
 0 
30-50 ms 40-60 ms 50-70 ms 60-80 ms 70-90 ms 80-100 ms 
Figure 1 � Approximate latencies for neurones in different stages of the visual primate 
visual system (see Thorpe & Imbert, 1989; Nowak & Bullier, 1997). 
Such constraints pose major problems for conventional firing rate codes since at least two 
spikes are needed to estimate a neuron's instantaneous firing rate. While it is possible to 
use the number of spikes generated by a population of cells to code analog values, this 
turns out to be expensive, since to code n analog values, one needs n-1 neurones. 
Furthermore, the roughly Poisson nature of spike generation would also seriously limit 
the amount of information that can be transmitted. Even at 100 spikes.s -I, there is a 
roughly 35% chance that the neuron will generate no spike at all within a particular 10 
ms window, again forcing the system to use large numbers of redundant cells. 
An alternative is to use information encoded in the temporal pattern of firing produced in 
response to transient stimuli (Mainen & Sejnowski, 1995). In particular, one can treat 
neurones not as analog to frequency converters (as is normally the case) but rather as 
analog to delay converters(Thorpe, 1990, 1994). The idea is very simple and uses the fact 
that the time taken for an integrate-and-fire neuron to reach threshold depends on input 
strength. Thus, in response to an intensity profile, the 6 neurones in figure 2 will tend to 
fire in a particular order - the most strongly activated cells firing first. Since each neuron 
fires one and only one spike, the firing rates of the cells contain no information, but there 
is information in the order in which the cells fire (see also Hopfield, 1995). 
Figure 2 : An example of spike order 
coding. Because of the intrinsic properties 
of neurones the most strongly activated 
neurones will fire first. The sequence 
B>A>F>C>E>D is one ot the 720 (i.e. 
6!) possible orders in which the 6 neurones 
can fire, each of which reflects a different 
intensity profile. Note that such a code can 
be used to send information very quickly. 
To test the plausibility of using spike order rather than firing rate as a code, we have 
developed a neural network simulator SPIKENET and used it to model the initial stages 
of visual processing. Initial results are very encouraging and demonstrate that 
sophisticated visual processing can indeed be achieved in a visual system in which only 
one spike per neuron is available. 
Rapid Visual Processing using Spike Asynchrony 903 
2. SPIKENET SIMULATIONS 
SPIKENET has been developed in order to simulate the activity of large numbers of 
integrate-and-fire neurones. The basic neuronal elements are simple, and involve only a 
limited number of parameters, namely, an activation level, a threshold and a membrane 
time constant. The basic propagation mechanism involves processing the list of neurones 
that fed during the previous time step. For each spiking neuron, we add a synaptic 
weight value to each of its targets, and, if the target neuron's activation level exceeds its 
threshold, we add it to the list of spiking neurones for the next time step and reset its 
activation level by subtracting the threshold value. When a target neuron is affected for 
the first time on any particular time step, its activation level is recalculated to simulate an 
exponential decay over time. One of the great advantages of this kind of event-driven 
simulator is its computational efficiency - even very large networks of neurones can be 
simulated because no processor time is wasted on inactive neurones. 
2.1 ARCHITECTURE 
As an initial test of the possibility of single spike processing, we simulated the 
propagation of activity in a visual system architecture with three levels (see Figure 3). 
Starting from a gray-scale image (180 x 214 pixels) we calculate the levels of activation 
in two retinal maps, one corresponding to ON-center retinal ganglion cells, the other to 
OFF-center cells. This essentially corresponds to convolving the image with two 
Mexican-hat type operators. However, unlike more classic neural net models, these 
activation levels are not used to determine a continuous output value for each neuron, nor 
to calculate a firing rate. Instead, we treat the cells as analog-to-delay converters and 
calculate at which time step each retinal unit will fire. Because of their receptive field 
organization, cells which fire at the shortest latencies will correspond to regions in the 
image where the local contrast is high. Note, however, that each retinal ganglion cell will 
fire once and once only. While this is clearly not physiologically realistic (normally, cells 
firing at a short latencies go on to fire further spikes at short intervals) our aim was to see 
what sort of processing can be achieved in the absence of rate coding. 
The ON- and OFF-center cells each make excitatory connections to a large number of 
cortical maps in the second level of the network. Each map contains neurones with a 
different pattern of afferent connections which results in orientation and spatial frequency 
selectivity similar to that described for simple-type neurones in striate cortex. In these 
simulations we used 32 different filters corresponding to 8 different orientations (each 
separated by 45 � ) and four different scales or spatial frequencies. This is functionally 
equivalent to having one single cortical map (equivalent to area V1) in which each point 
in visual space corresponds to a hypercolumn containing a complete set of orientation and 
spatial frequency tuned filters. 
Units in the third layer receive weighted inputs from all the simple units corresponding to 
a particular region of space with the same orientation preference and thus roughly 
correspond to complex cells in area V1. 
904 S. J. Thorpe and J. Gautrais 
Layer 3 
Orientation and Spatial 
Frequency tuned 
Complex cell 
(=205 000 units) 
Orientation and Spatial 
Frequency tuned 
Simple cells 
(=410 000 units) 
Layer 1 
ON- and OFF-center cells 
(=77 000 units) 
Image 
180 x 214 pixels 
Figure 3: Architecture used in the present simulations 
One unusual feature of the propagation process used in SPIKENET is that the post- 
synaptic effect of activating a synapse is not fixed, but depends on how many inputs have 
already been activated. Thus, the earliest firing cells produce a maximal post-synaptic 
effect (100%), but those which fire later produce less and less response. Specifically, the 
sensitivity of the post-synaptic neuron decreases by a fixed percentage each time one of its 
inputs fires. The phenomenon is somewhat similar to the sorts of activity-dependent 
synaptic depression described recently by Markram & Tsodyks (1996) and others, but 
differs in that the depression affects all the inputs to a particular neuron. The net result is 
to make the post-synaptic cell sensitive to the order in which its inputs are activated. 
2.2 SIMULATION RESULTS 
When a new image is presented to the network, spikes are generated asynchronously in 
the ON- and OFF-center cells of the retina in such a way that information about regions 
of the image with high local contrast (i.e. where there are contours present) are sent to the 
cortex first. Progressively, neurons in the second layer become more and more excited, 
and, after a variable number of time steps, the first cells in the second layer will start to 
Rapid Visual Processing using Spike Asynchrony 905 
reach threshold and fire. Note that, as in the first layer, the earliest firing units will be 
those for whom the pattern of input activation best matches their receptive field structure. 
Layer 
ON-center 
Cells 
80 ms 
Layer 2 
Simple cells 
Orientation 
45 � 
./ 
Layer 3 
C pl 
Orientation 
45 � 
Figure 4: Development of activity in 3 of the maps 
Figure 4 illustrates this process for just three maps. The top row shows the location of 

