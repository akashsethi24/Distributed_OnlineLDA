Combined Neural Network and Rule-Based 
Framework for Probabilistic Pattern Recognition 
and Discovery 
Hayit K. Greenspan and Rodney Goodman 
Department of Electrical Engineering 
California Institute of Technology, 116-81 
Pasadena, CA 91125 
Rama Chellappa 
Department of Electrical Engineering 
Institute for Advanced Computer Studies and Center for Automation Research 
University of Maryland, College Park, MD 20742 
Abstract 
A combined neural network and rule-based approach is suggested as a 
general framework for pattern recognition. This approach enables unsu- 
pervised and supervised learning, respectively, while providing probability 
estimates for the output classes. The probability maps are utilized for 
higher level analysis such as a feedback for smoothing over the output la- 
bel maps and the identification of unknown patterns (pattern discovery). 
The suggested approach is presented and demonstrated in the texture - 
analysis task. A correct classification rate in the 90 percentile is achieved 
for both unstructured and structured natural texture mosaics. The advan- 
tages of the probabilistic approach to pattern analysis are demonstrated. 
1 INTRODUCTION 
In this work we extend a recently suggested framework (Greenspan et a1,1991) for 
a combined neural network and rule-based approach to pattern recognition. This 
approach enables unsupervised and supervised learning, respectively, as presented 
444 
A Framework for Probabilistic Pattern Recognition and Discovery 445 
in Fig. 1. In the unsupervised learning phase a neural network clustering scheme is 
used for the quantization of the input features. A supervised stage follows in which 
labeling of the quantized attributes is achieved using a rule based system. This 
information theoretic technique is utilized to find the most informative correlations 
between the attributes and the pattern class specification, while providing proba- 
bility estimates for the output classes. Ultimately, a minimal representation for a 
library of patterns is learned in a training mode, following which the classification 
of new patterns is achieved. 
The suggested approach is presented and demonstrated in the texture - analysis 
task. Recent results (Greenspan et al, 1991) have demonstrated a correct classifica- 
tion rate of 95 - 99% for synthetic (texton) textures and in the 90 percentile for 2 - 3 
class natural texture mosaics. In this paper we utilize the output probability maps 
for high-level analysis in the pattern recognition process. A feedback based on the 
confidence measures associated with each class enables a smoothing operation over 
the output maps to achieve a high degree of classification in more difficult (natural 
texture) pattern mosaics. In addition, a generalization of the recognition process 
to identify unknown classes (pattern discovery), in itself a most challenging task, 
is demonstrated. 
2 FEATURE EXTRACTION STAGE 
The initial stage for a classification system is the feature extraction phase through 
which the attributes of the input domain are extracted and presented towards fur- 
ther processing. The chosen attributes are to form a representation of the input 
domain, which encompasses information for any desired future task. 
In the texture-analysis task there is both biological and computational evidence 
supporting the use of Gabor filters for the feature - extraction phase (Malik and 
Perona, 1990; Bovik et al, 1990). Gabor functions are complex sinusoidal gratings 
modulated by 2-D Gaussian functions in the space domain, and shifted Gaussians in 
the frequency domain. The 2-D Gabor filters form a complete but non-orthogonal 
basis which can be used for image encoding into multiple spatial frequency and ori- 
entation channels. The Gabor filters are appropriate for textural analysis as they 
have tunable orientation and radial frequency bandwidths, tunable center frequen- 
cies, and optimally achieve joint resolution in space and spatial frequency. 
In this work, we use the Log Gabor pyramid, or the Gabor wavelet decomposition 
to define an initial finite set of filters. We implement a pyramidal approach in the 
filtering stage reminiscent of the Laplacian Pyramid (Burt and Adelson, 1983). In 
our simulations a computationally efficient scheme involves a pyramidal represen- 
tation of the image which is convolved with fixed spatial support oriented Gabor 
filters. Three scales are used with 4 orientations per scale (0,90,45,-45 degrees), to- 
gether with a non-oriented component, to produce a 15-dimensional feature vector 
for every local window in the original image, as the output of the feature extraction 
stage. 
The pyramidal approach allows for a hierarchical, multiscale framework for the 
image analysis. This is a desirable property as it enables the identification of features 
at various scales of the image and thus is attractive for scale-invariant pattern 
446 
Greenspan, Goodman, and Chellappa 
recognition. 
GABOR FILTERS UNSUPERVlSED SUPERVISED 
LEARNING LEARNING 
Kohonen NN Rule-System 
/ N-Dimensional N-Dimensional 
Win low Continuous Quantized 
of Input Image Feature- Vector Feature- Vector 
TEXTURE 
CLASSES 
FEATURE-EXTRACTION UNSUPERVISED SUPERVISED 
PHASE LEARNING LEARNING 
Figure 1: System Block Diagram 
3 QUANTIZATION VIA UNSUPERVISED LEARNING 
The unsupervised learning phase can be viewed as a preprocessing stage for achiev- 
ing yet another, more compact representation, of the filtered input. The goal is to 
quantize the continuous valued features which are the result of the initial filtering 
stage. The need for discretization becomes evident when trying to learn associations 
between attributes in a statistically-based framework, such as a rule-based system. 
Moreover, in an extended framework, the network can reduce the dimension of the 
feature domain. This shift in representation is in accordance with biological based 
models. 
The output of the filtering stage consists of N (=15) continuous valued feature maps; 
each representing a filtered version of the original input. Thus, each local area of the 
input image is represented via an N-dimensional feature vector. An array of such 
N-dimensional vectors, viewed across the input image, is the input to the learning 
stage. We wish to detect characteristic behavior across the N-dimensional feature 
space for the family of textures to be learned. By projecting an input set of samples 
onto the N-dimensional space, we search for clusters to be related to corresponding 
code-vectors, and later on, recognized as possible texture classes. A neural-network 
quantization procedure, based on Kohonen's model (Kohonen, 1984) is utilized for 
this stage. 
In this work each dimension, out of the N-dimensional attribute vector, is indi- 
vidually clustered. All samples are thus projected onto each axis of the space and 
A Framework for Probabilistic Pattern Recognition and Discovery 447 
one-dimensional clusters are found; this scalar quantization case closely resembles 
the K-means clustering algorithm. The output of the preprocessing stage is an 
N-dimensional quantized vector of attributes which is the result of concatenating 
the discrete valued codewords of the individual dimensions. Each dimension can be 
seen to contribute a probabilistic differentiation onto the different classes via the 
clusters found. As some of the dimensions are more representative than others, it 
is the goal of the supervised stage to find the most informative dimensions for the 
desired task (with the higher differentiation capability ) and to label the combined 
clustered domain. 
4 
SUPERVISED LEARNING VIA A RULE-BASED 
SYSTEM 
In the supervised stage we utilize the existing information in the feature maps for 
higher level analysis, such as input labeling and classification. In particular we need 
to learn a classifier which maps the output attributes of the unsupervised stage to 
the texture class labels. Any classification scheme could be used. However, we 
utilize a rule - based information theoretic approach which is an extension of a 
first order Bayesian classifier, because of its ability to output probability estimates 
for the output classes (Goodman et al, 1992). The classifier defines correlations 
between input features and output classes as probabilistic rules of the form: If 
Y = y then X - x with prob. p, where Y represents the attribute vector and 
X is the class variable. A data driven supervised learning approach utilizes an 
information theoretic measure to learn the most informative links or rules between 
the attributes and the class labels. Such a measure was introduced as the J measure 
(Smyth and Goodman, 1991) which represents the information content of a rule as 
the average bits of information that attribute values y give about the class X. 
The most informative set of rules via the J measure is learned in a training stage, 
following which the classifier uses them to provide an estimate of the probability 
of a given class being true. When presented with a new input evidence vector, Y, 
a set of rules can be considered to fire. The classifier estimates the log posterior 
probability of each class given the rules that fire as: 
log p( xlrules that fire) = logp(x) +  Wj 
(P(xlY) 
W1 = 1ï¿½g k, p- / 
where p(x) is the prior probability of the class x, and I/Vj represents the evidential 
support for the class as provided by rule j. Each class estimate can now be com- 
puted by accumulating the weights of evidence incident it from the rules that fire. 
The largest estimate is chosen as the initial class label decision. The probability 
estimates for the output classes can now be used for feedback purposes and further 
higher level processing. 
The rule-based classification system can be mapped into a 3 layer feed forward 
architecture as shown in Fig. 2. The input layer contains a node for each attribute. 
448 Greenspan, Goodman, and Chellappa 
The h
