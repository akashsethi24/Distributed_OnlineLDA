Blind Separation of Radio Signals in 
Fading Channels 
Kari Torkkola 
Motorola, Phoenix Corporate Research Labs, 
2100 E. Elliot Rd, MD EL508, Tempe, AZ 85284, USA 
email: A540AAï¿½email.mot. com 
Abstract 
We apply information maximization / maximum likelihood blind 
source separation [2, 6] to complex valued signals mixed with com- 
plex valued nonstationary matrices. This case arises in radio com- 
munications with baseband signals. We incorporate known source 
signal distributions in the adaptation, thus making the algorithms 
less blind. This results in drastic reduction of the amount of data 
needed for successful convergence. Adaptation to rapidly changing 
signal mixing conditions, such as to fading in mobile communica- 
tions, becomes now feasible as demonstrated by simulations. 
I Introduction 
In SDMA (spatial division multiple access) the purpose is to separate radio signals 
of interfering users (either intentional or accidental) from each others on the basis 
of the spatial characteristics of the signals using smart antennas, array processing, 
and beamforming [5, 8]. Supervised methods typically use a variant of LMS (least 
mean squares), either gradient based, or algebraic, to adapt the coefficients that 
describe the channels or their inverses. This is usually a robust way of estimating 
the channel but a part of the signal is wasted as predetermined training data, and 
the methods might not be fast enough for rapidly varying fading channels. 
Unsupervised methods either rely on information about the antenna array manifold, 
or properties of the signals. Former approaches might require calibrated antenna 
arrays or special array geometries. Less restrictive methods use signal properties 
only, such as constant modulus, finite alphabet, spectral self-coherence, or cyclo- 
stationarity. Blind source separation (BSS) techniques typically rely only on source 
signal independence and non-Gaussiaity assumptions. 
Our aim is to separate simultaneous radio signals occupying the same frequency 
band, more specifically, radio signals that carry digital information. Since linear 
mixtures of antenna signals end up being linear mixtures of (complex) baseband 
signals due to the linearity of the downconversion process, we will apply BSS at 
the baseband stage of the receiver. The main contribution of this paper is to 
show that by making better use of the known signal properties, it is possible to 
devise algorithms that adapt much faster than algorithms that rely only on weak 
assumptions, such as source signal independence. 
We will first discuss how the probability density functions (pdf) of baseband DPSK 
signals could be modelled inca way that can efficiently be used in blind separation 
algorithms. We will incorporate those models into information maximization and 
Blind Separation of Radio Signals in Fading Channels 757 
into maximum likelihood approaches [2, 6]. We will then continue with the maxi- 
mum likelihood approach and other modulation techniques, such as QAM. Finally, 
we will show in simulations, how this approach results in an adaptation process that 
is fast enough for fading channels. 
2 Models of baseband signal distributions 
In digital communications the binary (or n-ary) information is transmitted as dis- 
crete combinations of the amplitude and/or the phase of the carrier signal. After 
downconversion to baseband the instantaneous amplitude of the carrier can be ob- 
served as the length of a complex valued sample of the baseband signal, and the 
phase of the carrier is discernible as the phase angle of the same sample. Possible 
combinations that depend on the modulation method employed, are called sym- 
bol constellations. N-QAM (quadrature amplitude modulation) utilizes both the 
amplitude and the phase, whereby the baseband signals can only take one of N 
possible locations on a grid on the complex plane. In N-PSK (phase shift keying) 
the amplitude of the baseband signal stays constant, but the phase can take any 
of N discrete values. In DPSK (differential phase shift keying) the information is 
encoded as the difference between phases of two consecutive transmitted symbols. 
The phase can thus take any value, and since the amplitude remains constant, the 
baseband signal distribution is a circle on the complex plane. 
Information maximization BSS requires a nonlinear function that models the cu- 
mulative density function (cdf) of the data. This function and its derivative need 
to be differentiable. In the case of a circular complex distribution with uniformly 
distributed phase, there is only one important direction of deviation, the radial 
direction. A smooth cdf G for a circular distribution at the unit circle can be 
constructed using the hyperbolic tangent function as 
G(z) - tanh(w(Iz ] - 1)) (1) 
and the pdf, differentiated in the radial direction, that is, with respect to [z] is 
0 
9(z) = Oizltanh(w(izl - 1))- w(1- tanh2(w(]z]- 1))) (2) 
where z = x + iy is a complex valued variable, and the parameter w controls the 
steepness of the slope of the tanh function. Note that this is in contrast to more 
commonly used coordinate axis directions to differentiate and to integrate to get 
the pdf from the cdf and vice versa. These functions are plotted in Fig. 1. 
11 
0.25 
a) CDF b) PDF 
Figure 1: Radial tanh with w=2.0 (equations 1 and 2). 
Note that we have not been worrying about the pdf integrating to unity. Thus we 
could leave the first multiplicative constant w out of the definition of 9. Scaling will 
not be important for our purposes of using these functions as the nonlinearities in 
the information maximization BSS. Note also that when the steepness w approaches 
infinity, the densities approach the ideal density of a DPSK source, the unit circle. 
Many other equally good choices are possible where the ideal density is reached as 
a limit of a parameter value. For example, the radial section of the circular ridge 
of the pdf could be a Gaussian. 
758 K. Torkkola 
3 The information maximization adaptation equation 
The information maximization adaptation equation to learn the unmixing matrix 
W using the natural gradient is [2] 
AW oc (!)u T + I)W where !)j = ouj ouj (3) 
Vector u -- Wx denotes a time sample of the separated sources, x denotes the 
corresponding time sample of the observed mixtures, and yj is the nonlinear function 
approximating the cdf of the data, which is applied to each component of the u. 
Now we can insert (1) into yj. Making use of Olzl/Oz = z/Izl this yields for 
uj 
^ 0 0 tann(w([uj I _ 1)) = -2wyj [ujl (4) 
YJ -- Oy j Ouj 
When (4) is inserted into (3) we get 
where (.)j denotes a vector with elements of varying j. Here, we have replaced 
the transpose operator by the hermitian operator H, since we will be processing 
complex data. We have also added a subscript to w as these parameters can be 
learned, too. We will not show the adaptation equations due to lack of space. 
4 Connection to the maximum likelihood approach 
Pearlmutter and Parra have shown that (3) can be derived from the maximum 
likelihood approach to density estimation [6]. The same fact has also been pointed 
out by others, for example, by Cardoso [3]. We will not repeat their straightforward 
derivation, but the final adaptation equation is of the following form: 
where u = Wx are the sources separated from mixtures x, and fj(u; wj) is the pdf 
of source j parametrized by wj. This is exactly the form of Bell and Sejnowski when 
fj is taken to be the derivative of the necessary nonlinearity gj, which was assumed 
to be close to the true cdf of the source. Thus the information maximization 
approach makes implicit assumptions about the cdf's of the sources in the form of 
the nonlinear squashing function, and does implicit density estimation, whereas in 
the ML approach the density assumptions are made explicit. This fact makes it 
more intuitive and lucid to derive the adaptation for other forms of densities, and 
also to extend it to complex valued variables. 
Now, we can use the circular pdf's (2) depicted in Fig. I as the densities fj (omitting 
scaling) fj(u;wj) - 1 -tanh2(wj([uj]- 1)). where the steepness w acts as the 
single parameter of the density. Now we need to compute its derivative 
0 uj 
fj(u;wj)- Ouf(u;wj) ---2tanh(w(lu[- 1))f(uj;w)wlu I (7) 
Inserting this into (6) and changing transpose operators into hermitians yields 
c - u  W, (8) 
which is exactly the information maximization rule (5). Notice that at this time 
we did not have to ponder what would be an appropriate way to construct the cdf 
from the pdf for complex valued distributions. 
Blind Separation of Radio Signals in Fading Channels 759 
5 Modifications for QAM and other signal constellations 
So far we have only looked at signals that lie on the unit circle, or that have a 
constant modulus. Now we will take a look at other modulation techniques, in which 
the alphabet is constructed as discrete points on the complex plane. An example 
is the QAM (quadrature amplitude modulation), in which the signal alphabet is a 
regular grid. For example, in 4-QAM, the alphabet could be -44 ---- {1+i, -1+i, -1-i, 
1-i}, or any scaled version of-44. 
In the ideal pdf of 4-QAM, each symbol is represented just as a point. Again, we 
can construct a smoothed version of the ideal pdf as the sum of bumps over all 
of the alphabet where the ideal pdf will be approached by increasing w. 
g(u) = - ta.h(wl - uJ)) (9) 
k 
Now the density for each source j will be 
fj(uj;wj) = E(1 - tanh2(wkJuj - ukl) ) (10) 
k 
where wj is now a vector of parameters w. In practice each w would be equal in 
which case a single parameter w will suffice. 
This density function could now be inserted into (6) resulting in the weight update 
equation. However, since fj(uj; wj) is a sum of multiple components, f'/f will not 
have a particularly simple form. In essence, for each sample to be processed, we 
would 
