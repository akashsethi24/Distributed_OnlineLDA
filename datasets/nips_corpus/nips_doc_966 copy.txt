H Optimal Training Algorithms and 
their Relation to Backpropagation 
Babak Hassibi* 
Information Systems Laboratory 
Stanford University 
Stanford, CA 94305 
Thomas Kailath 
Information Systems Laboratory 
Stanford University 
Stanford, CA 94305 
Abstract 
We derive global H a optimal training algorithms for neural net- 
works. These algorithms guarantee the smallest possible prediction 
error energy over all possible disturbances of fixed energy, and are 
therefore robust with respect to model uncertainties and lack of 
statistical information on the exogenous signals. The ensuing es- 
timators are infinite-dimensional, in the sense that updating the 
weight vector estimate requires knowledge of all previous weight 
esimates. A certain finite-dimensional approximation to these es- 
timators is the backpropagation algorithm. This explains the lo- 
cal H a optimality of backpropagation that has been previously 
demonstrated. 
I Introduction 
Classical methods in estimation theory (such as maximum-likelihood, maximum 
entropy and least-squares) require a priori knowledge of the statistical properties 
of the exogenous signals. In some applications, however, one is faced with model 
uncertainties and lack of statistical information, which has led to an increasing 
interest in minimax estimation (see e.g., Zames 1981, Khargonekar and Nagpal 
1991, and the references therein) with the belief that the resulting so-called H �� 
algorithms will be more robust and less sensitive to parameter variations. 
*Contact author: Information Systems Laboratory, Stanford University, Stanford CA 
94305. Phone (415) 723-1538. Fax (415) 723-8473. E-mail: hassibi@rascals.stanford.edu. 
192 Babak Hassibi, Thomas Kailat 
In (Hassibi, Sayed and Kailath, 1994) we have shown that LMS (Widrow and Hoff, 
1960) and backpropagation (Rumelhart and Mclelland, 1986), the currently most 
widely used adaptive algorithms that have long been considered to be approximate 
H 2 (or least-squares) solutions, are indeed H  optimal and locally H  optimal al- 
gorithms, respectively. This, in our view, connects earlier work in learning theory to 
more recent ideas in robust estimation, and explains why LMS and backpropagation 
have found wide applicability in such a diverse range of problems. 
The local H �� optimality of backpropagation implies that backpropagation min- 
imizes the energy gain from the disturbances to the prediction errors, only if the 
initial condition is close enough to the true weight vector and if the disturbances are 
small enough. In this paper we derive global H �� optimal estimators that minimize 
the energy gain from the disturbances to the prediction errors for all initial condi- 
tions and disturbances. The resulting estimator (given by Theorem 1) has growing 
memory, which we refer to as being infinite-dimensional, since updating the weight 
vector estimate requires knowledge of all previous weight estimates. When the un- 
derlying model is linear, we show that this infinite-dimensional estimator reduces 
to the finite-dimensional LMS filter. When the underlying model is nonlinear, the 
infinite-dimensionality of the estimator may prohibit its practical applicablity, and 
one needs to construct finite-dimensional approximations to this estimator. We 
consider two such approximations here: one yields the backpropagation algorithm, 
and the other is a second-order algorithm based on the Newton-Raphson iteration. 
There are, no doubt, a wide variety of other approximations which should be worthy 
of further scrutiny. 
2 Robust Estimation 
In estimation problems one assumes a certain model (say an FIR filter in adaptive 
filtering, or a neural network), observes a corrupted version of the output of this 
model, and wants to estimate the parameters associated with this model (say the 
weights of the FIR filter or neural network). Most estimation algorithms make some 
assumption about the nature of the disturbances, and then proceed to estimate the 
parameters using some optimality criterion. To be more specific, we shall consider 
the following two cases. 
2.1 The Linear Case 
Suppose that we observe an output sequence {di} that obeys the following linear 
model 
di = xiw + vi, (1) 
where x/ = [ xi xi2 ... xi, ] is a known input vector, w is the unknown 
weight vector that we intend to estimate, and .[vi) is an unknown disturbance 
sequence. Let wi = .T'(do, d,..., di) denote the estimate of the weight vector given 
the inputs .[xj) and the outputs {dj) from time 0 up to and including time i. The 
most widely used estimate wi, is one that satisfies the following H  criterion 
TW]2 
mn I-]w- w_]  + Idj - xj , (2) 
j=0 
where u is a positive constant that reflects a priori knowledge as to how close w is 
to the initial estimate w_. The exact solution to the above criterion is given by 
the RLS algorithm (Haykin, 1991): 
Wi -- Wi-1 - ]p,i(di - 3/Tw), w-1 (3) 
H��Optimal Training Algorithms and Their Relation to Backpropagation 193 
where w_x denotes the initial value, 
and 
Pi xi 
kp,i - 1 q- xiT pixi 
t ' Po=P I' 
Pi+x : Pi 1 q- xiPix i 
If we assume that in the model (1) the w - w_ and {vi} are zero-mean indepen- 
dent Gaussian random variables with variances/I and 1, respectively, then the cost 
function in (2) is simply the associated log-likelihood function. Thus the estimate 
given by minimizing (2) will be the maximum-likelihood estimate of the weight vec- 
tor w. In particular, it can be shown that under these assumptions, RLS minimizes 
the expected prediction energy 
i 
E lie liP- E Ix'm - xwj_112. 
j=O 
Note that the LMS algorithm is an approximation to RLS where kp,i is replaced 
by IXi, so that the estimates are updated along the direction of the instantaneous 
gradient of (2)' 
Wi = Wi--1 q- lJzi(di - giTw), W-x. (4) 
2.2 The Nonlinear Case 
Suppose now that we observe an output sequence {di} that obeys the following 
nonlinear model 
= g(w) + v,, (5) 
where gi(.) is a known nonlinear function (with bounded first and second order 
derivatives), w is the unknown weight vector we intend to estimate, and {vi} is an 
unknown disturbance sequence. In a neural network context the index i in gi(.) 
will correspond to the nonlinear function that maps the weight vector to the output 
when the ith input pattern is presented, i.e., gi(w) - g(xi, w) where xi is the ith 
input pattern. As before we shall denote by wi = .T(d0,..., di) the estimate of the 
weight vector using measurements up to and including time i. The H 2 criterion for 
finding the estimate is 
mn ju-Xlw - w_112 q- Idj -gj(w)l 2 . 
j=0 
(6) 
As in the linear case, if we assume that in the model (5) the disturbances w - w_ 
and {vi} are zero-mean independent Gaussian random variables with variances uI 
and 1, respectively, then the cost function in (6) is the log-likelihood function and 
the weight vector that minimizes it is the maximum-likelihood estimate. However, 
contrary to the linear case, the solution to (6) will not, in general, minimize the 
expected prediction error energy. 
In the nonlinear case exact solutions to (6) do not exist, and the backpropagation 
algorithm is a generalization of the LMS algorithm where once more the estimates 
are updated along the negative direction of the instantaneous gradient of the log- 
likelihood function: 
agi , '(di gi(wi)), W_l. 
wi = wi- + Iww Wi-) - (7) 
Generalizations of the RLS algorithm to the nonlinear setting are the second order 
Gauss-Newton methods. 
194 Babak Hassibi, Thomas Kailat 
2.3 The Question of Robustness 
In view of the above discussion we have seen that He-optimal estimation strategies 
(see (2) and (6)) are maximum-likelihood and minimize the expected prediction 
error energy (in the linear case), if we assume that the disturbances are zero-mean 
independent Gaussian random variables. However, the question that begs itself 
is what the performance of such estimators will be if the assumptions on the dis- 
turbances are violated, or if there are modelling errors in our model so that the 
disturbances must include the modelling errors? In other words 
- is it possible that small disturbances and modelling errors may lead to large esti- 
mation errors? 
Obviously a nonrobust algorithm would be one for which the above is true, and a 
robust algorithm would be one for which small disturbances lead to small estimation 
errors. (For example in the adaptive filtering problem, where we assumed an FIR 
model, the true model may be IIR, but we neglect the tail of the filter since its 
components are small. However, unless one uses a robust estimation algorithm, it 
is conceivable that this small modelling error may result in large estimation errors.) 
The problem of robust estimation is thus an important one, and is worthy of study 
in its own right. Rather surprisingly, it had not received much attention until 
quite recently. The H � criterion has been introduced (Zames, 1981) as a means 
of studying such questions in the contexts of estimation and control. This is the 
subject of the next section. 
3 The H � Problem 
The H � estimation formulation is an attempt to address the robustness question 
raised in the previous section. The idea is to come up with estimators that minimize 
(or in the suboptimal case bound) the maximum energy gain from the disturbances 
to the estimation errors. This will guarantee that if the disturbances are small (in 
energy) then the estimation errors will be as small as possible (in energy), no matter 
what the disturbances are. In other words the maximum energy gain is minimized 
over all possible disturbances. The robustness of the H � estimators arises from 
this fact. Since they make no assumption about the disturbances, they have to 
accomodate for all conceivable disturbances, and are thus over-conservative. 
We once more assume that we observe an output sequence {di} that obeys the 
following nonlinear model 
= vi, (8) 
where gi(.) is 
