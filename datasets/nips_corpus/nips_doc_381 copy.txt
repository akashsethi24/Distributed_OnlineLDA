Connectionist Approaches to the Use of 
Markov Models for Speech Recognition 
Herv Bourlard 
t L & H Speechproducts 
Koning Albert I 10n, 64 
1780 Wemmel, BELGIUM 
Nelson Morgan $ & Chuck Wooters $ 
$ Intl. Comp. Sc. Institute 
1947, Center St., Suite 600 
Berkeley, CA 94704, USA 
ABSTRACT 
Previous work has shown the ability of Multilayer Perceptrons 
(MLPs) to estimate emission probabilities for Hidden Markov Mod- 
els (HMMs). The advantages of a speech recognition system incor- 
porating both MLPs and HMMs are the best discrimination and 
the ability to incorporate multiple sources of evidence (features, 
temporal context) without restrictive assumptions of distributions 
or statistical independence. This paper presents results on the 
speaker-dependent portion of DARPA's English language Resource 
Management database. Results support the previously reported 
utility of MLP probability estimation for continuous speech recog- 
nition. An additional approach we are pursuing is to use MLPs as 
nonlinear predictors for autoregressive HMMs. While this is shown 
to be more compatible with the HMM formalism, it still suffers 
from several limitations. This approach is generalized to take ac- 
count of time correlation between successive observations, without 
any restrictive assumptions about the driving noise. 
1 INTRODUCTION 
We have been working on continuous speech recognition using moderately large 
vocabularies (1000 words) [1,2]. While some of our research has been in speaker- 
independent recognition [3], we have primarily used a German speaker-dependent 
213 
21 Boutlard, Morgan, and Woofers 
database called SPICOS [1,2]. In our previously reported work, we developed a 
hybrid MLP/HMM algorithm in which an MLP is trained to generate the output 
probabilities of an HMM [1,2]. Given speaker-dependent training, we have been able 
to recognize 50-60 % of the words in the SPICOS test sentences. While this is not a 
state-of-the-art level of performance, it was accomplished with single-state phoneme 
models, no triphone or allophone representations, no function word modeling, etc., 
and so may be regarded as a baseline system. The main point to using such a 
simple system is simplicity for comparison of the effectiveness of alternate proba- 
bility estimation techniques. While we are working on extending our technique to 
more complex systems, the current paper describes the application of the baseline 
system (with a few changes, such as different VQ features) to the speaker-dependent 
portion of the English language Resource Management (RM) database (continuous 
utterances built up from a lexicon of roughly 1000 words) [4]. While this exercise 
was primarily intended to confirm that the previous result, which showed the utility 
of MLPs for the estimation of HMM output probabilities, was not restricted to the 
limited data set of our first experiments, it also shows how to improve further the 
initial scheme. 
However, potential problems remain. In order to improve local discrimination, the 
MLP is usually provided with contextual inputs [1,2,3] or recurrent links. Unfor- 
tunately, in these cases, the dynamic programming recurrences of the Viterbi algo- 
rithm are no longer stricly valid when the local probabilities are generated by these 
contextual MLPs. To solve this problem, we have started considering, as initially 
proposed in [9] and [10], another approach in which MLP is used as a nonlinear 
predictor. Along this line, a new approach is suggested and preliminary results are 
reported. 
2 METHODS AND RESULTS 
As shown by both theoretical [5] and experimental [1] results, MLP output values 
may be considered to be estimates of a posterJori probabilities. Either these or 
some other related quantity (such as the output normalized by the prior probability 
of the corresponding class) may be used in a Viterbi search to determine the best 
time-warped succession of states to explain the observed speech measurements. 
This hybrid approach has the potential of exploiting the interpolating capabilities 
of MLPs while using Dynamic Time Warping (DTW) to capture the dynamics of 
speech. As described in [2], the practical application of the technique requires cross- 
validation during training to determine the stopping point, division by the priors at 
the output to generate likelihoods, optimized word transition penalties, and training 
sentence alignment via iterations of the Viterbi algorithm. 
For the RM data, initial development was done on a single speaker to confirm that 
the techniques we developed previously [2] were still applicable. Although we ex- 
perimented slightly with this data, the system we ended up with was substantially 
unchanged, with the exception of the program modifications required to use differ- 
ent vector quantized (VQ) features. Input features used were based on the front 
Connectionist Approaches to the Use of Markov Models for Speech Recognition 215 
end for SRI's DECIPHER system [6], including vector quantized mel-cepstrum (12 
coefficients), vector-quantized difference of mel-cepstrum, quantized energy, and 
quantized difference of energy. Both vector quantization codebooks contained 256 
prototypes, while energy and delta energy were quantized into 25 levels. A feature 
vector was calculated for each 10 ms of input speech. Since each feature was rep- 
resented by a simple binary input vector with only one bit 'on', each 10 ms frame 
of speech signal was represented by a 562-dimensional binary vector with only 4 
bits 'on'. Some experiments were run with no context (i.e., only one frame was 
input to the network for each classification). To show the advantage of contextual 
information, other experiments were run with nine frames of input to the network, 
allowing four frames of contextual information on each side of the current frame 
being classified. In this case, the input field contained 9 x 562 = 5058 units. The 
size of the output layer was kept fixed at 61 units, corresponding to the 61 phonemes 
to be recognized. As we found in our SPICOS experiments, a hidden layer was not 
useful for this problem, probably because of the high dimension of the binary input 
space and, as a consequence, of the large number of parameters. Of course, it could 
be argued that a hidden layer should reduce this huge number of parameters, and 
thus improve generalization. However, networks with no hidden units always out- 
performed experimental systems with hidden layers, on both the frame and word 
levels. The ability of the mple? nets to generalize well, despite the sheer number 
of parameters, was probably due''o the cross-validation technique used during the 
MLP training [7]. However, as shown in [3], hidden layers are useful for the case 
of continuous input features. In this case, the dimension of the input layer of the 
MLP is much lower (even with contextual information), so that large hidden layers 
(e.g., 1000 units) may be useful. 
For each speaker, we used 400 sentences for training, 100 for cross-validation, and 
a final 100 for recognition tests. Starting from an initial segmentation (derived 
from the average length of the phonemes), a Viterbi algorithm was then iterated 
with standard emission probabilities (i.e., by counting, no contextual information 
and assuming independence of the features) to generate a final segmentation which 
provided us with initial targets for the MLP training. Training of the MLP was 
done by an error-back propagation algorithm, using an entropy criterion. In each 
iteration, the complete training set was presented, and the parameters were up- 
dated after each training pattern (stochastic gradient). To avoid overtraining of 
the MLP, improvement on the cross-validation set was checked after each iteration. 
If the classification rate on the cross-validation set had not improved more than a 
small threshold, the learning rate of the gradient procedure was reduced by a factor 
of two. Compared with the results reported in [11], it has been observed recently 
that it was still possible to improve significantly the recognition performance [11] by 
starting from a lower initial learning constant and by adapting the segmentation of 
the training sentences to the MLP. This has been done by using the final segmenta- 
tion of the standard Viterbi as a new starting point of a Viterbi training embedding 
now the MLP for estimating the emission probabilities. In this case, each iteration 
of the Viterbi is followed by a new optimization of the MLP (according to the new 
216 Bourlard, Morgan, and Wooters 
Table 1: Word Recognition Performance on RM database 
Perplexlty = 1000 
peaker ME ILP(9) I + FWM 
jws04 48.2 62.3 
bef03 39.3 56.7 
cmr02 59.5 70.9 
dtb03 49.8 61.2 
das12 63.8 76.5 81.8 
ers07 45.4 58.3 
dms04 58.0 69.1 
tab07 60.8 70.5 
hxs06 60.9 76.3 
rkm05 37.9 53.8 60.2 
pgh01 50.4 63.6 
mean 52.2 65.4 
segmentation generated by the Viterbi alignment). Recognition performance result- 
ing of this process are reported in the column MLP(9) of Table 1. Comparison 
with results presented in [11] clearly shows the additional improvement (which was 
also observed at the frame level) that can be gained from such modifications. 
3 RECOGNITION AND DISCUSSION 
For recognition, the output layer of the MLP was evaluated for each frame, and 
(after division by the prior probability of each phoneme) was used as emission 
probabilities in a discrete HMM system. In this case, each phoneme k was thus 
associated with a single conditional density evaluated on the k-th output unit of the 
MLP. In our system, in order to model state duration, each phoneme was modeled by 
an HMM with a single state q repeated D/2 times, where D is the prior estimate 
of the duration of the phoneme as observed on the training set. Only selfioops 
and sequential transitions were permitted. A Viterbi decoding was then used for 
recognition of the first thirty sentences of the
