Maximum-Likelihood Continuity Mapping 
(MALCOM): An Alternative to HMMs 
David A. Nix 
dnix@lanl. gov 
Computer Research & Applications 
CIC-3, MS B265 
Los Alamos National Laboratory 
Los Alamos, NM 87545 
John E. Hogden 
hogden@ 1 anl. gov 
Computer Research & Applications 
CIC-3, MS B265 
Los Alamos National Laboratory 
Los Alamos, NM 87545 
Abstract 
We describe Maximum-Likelihood Continuity Mapping (MALCOM), an 
alternative to hidden Markov models (HMMs) for processing sequence 
data such as speech. While HMMs have a discrete hidden space con- 
strained by a fixed finite-automaton architecture, MALCOM has a con- 
tinuous hidden space--a continuity map that is constrained only by a 
smoothness requirement on paths through the space. MALCOM fits into 
the same probabilistic framework for speech recognition as HMMs, but 
it represents a more realistic model of the speech production process. 
To evaluate the extent to which MALCOM captures speech production 
information, we generated continuous speech continuity maps for three 
speakers and used the paths through them to predict measured speech 
articulator data. The median correlation between the MALCOM paths 
obtained from only the speech acoustics and articulator measurements 
was 0.77 on an independent test set not used to train MALCOM or the 
predictor. This unsupervised model achieved correlations over speak- 
ers and articulators only 0.02 to 0.15 lower than those obtained using an 
analogous supervised method which used articulatory measurements as 
well as acoustics.. 
1 INTRODUCTION 
Hidden Markov models (HMMs) are generally considered to be the state of the art in speech 
recognition (e.g., Young, 1996). The strengths of the HMM framework include a rich math- 
ematical foundation, powerful training and recognition algorithms for large speech corpora, 
and a probabilistic framework that can incorporate statistical phonology and syntax (Mor- 
gan & Bourlard, 1995). However, HMMs are known to be a poor model of the speech 
production process. While speech production is a continuous, temporally evolving pro- 
cess, HMMs treat speech production as a discrete, finite-state system where the current 
state depends only on the immediately preceding state. Furthermore, while HMMs are 
designed to capture temporal information as state transition probabilities, Bourlard et al., 
Maximum-Likelihood Continuity Mapping (MALCOM) : An Alternative to HMMs 745 
(1995) suggest that when the transition probabilities are replaced by constant values, recog- 
nition results do not significantly deteriorate. That is, while transitions are often considered 
the most perceptually relevent component of speech, the conventional HMM framework is 
poor at capturing transition information. 
Given these deficiencies, we are considering alternatives to the HMM approach that main- 
tain its strengths while improving upon its weaknesses. This paper describes one such 
model called Maximum-Likelihood Continuity Mapping (MALCOM). We first review a 
general statistical framework for speech recognition so that we can compare the HMM and 
MALCOM formulations. Then we consider what the abstract hidden state represents in 
MALCOM, demonstrating empirically that the paths through MALCOM's hidden space 
are closely related to the movements of the speech production articulators. 
2 A GENERAL FRAMEWORK FOR SPEECH RECOGNITION 
Consider an unknown speech waveform that is converted by a front-end signal-processing 
module into a sequence of acoustic vectors X. Given a space of possible utterances, W, 
the task of speech recognition is to return the most likely utterance W* given the observed 
acoustic sequence X. Using Bayes' rule this corresponds to 
w* = argax P(Wlx) = argx 
P(XIW)P(W) 
P(X) 
(1) 
In recognition, P(X) is typically ignored because it is constant over all W, and the pos- 
terior P(W IX) is estimated as the product of the prior probability of the word sequence, 
P(W), and the probability that the observed acoustics were generated by the word se- 
quence, P(XIW). The prior P(W) is estimated by a language model, while the production 
probability P(XIW ) is estimated by an acoustic model. In continuous speech recognition, 
the product of these terms must be maximized over W; however, in this paper, we will re- 
strict our attention to the form of the acoustical model only. Every candidate utterance W 
corresponds to a sequence of word/phone models M such that P(XIW ) = P(XIM,o), 
and each Mo considers all possible paths through some hidden space. Thus, for each 
candidate utterance, we must calculate 
P(XIM) =/� P(XIY, M)P(YIM)dY, 
(2) 
where Y is some path through the rtidden space. 
2.1 HIDDEN MARKOV MODELS 
Because HMMs are finite-state machines with a given fixed architecture, the path � 
through the hidden space corresponds to series of discrete states, simplifying the integral 
of Eq. (2) to a sum. However, to avoid computing the contribution of all possible paths, the 
Viterbi approximation considering only the single path that maximizes Eq. (2)--is fre- 
quently used without much loss in recognition performance (Morgan & Bourlard, 1995). 
ThUS, 
P(XIM )  argvmaxP(XlY, M)P(YIM ). (3) 
The first term corresponds to the product of the emission probabilities of the acoustics given 
the state sequence and is typically estimated by mixtures of high-dimensional Gaussian 
densities. The second term corresponds to the product of the state transition probabilities. 
However, because Bourlard et al. (1995) found that this second term contributes little to 
recognition performance, the modeling power of the conventional HMM must reside in 
the first term. Training the HMM system involves estimating both the emission and the 
746 D. A. Nix and J. E. Hogden 
transition probabilities from real speech data. The Baum-Welch/forward-backward algo- 
rithm (e.g., Morgan & Scofield, 1994) is the standard computationally efficient algorithm 
for iteratively estimating these distributions. 
2.2 MAXIMUM-LIKELIHOOD CONTINUITY MAPPING (MALCOM) 
In contrast to HMMs, the multi-dimensional MALCOM hidden space is continuous--there 
are an infinite number states and paths through them. While the HMM is constrained by 
a fixed architecture, MALCOM is constrained by the notion of continuity of the hidden 
path. That is, the path must be smooth and continuous: it may not carry any energy above 
a given cutoff frequency. Unlike the discrete path in an HMM, the smooth hidden path 
in MALCOM attempts to emulate the motion of the speech articulators in what we call a 
continuity map (CM). 
Unless we know how to evaluate the integral of Eq. (2) (which we currently do not), we 
must also make the Viterbi approximation and approximate P(XI.Mo ) by considering 
only the single path that maximizes the likelihood of the acoustics X given the utterance 
model .Mo, resulting in Eq. (3) once again. Analogously, the first term, P(XIY, 
corresponds to the acoustic generation probability given the hidden path, and the second 
term corresponds to the probability of the hidden path given the utterance model. This 
paper focuses on the first term because this is the term that produces conventional HMM 
performance.  
Common to all .Mo is a set of N probability density functions (pdfs) (I> that define the CM 
hidden space, modeling the likelihood of Y given X for an N-code vector quantization 
(VQ) of the acoustic space. Because these pdfs are defined over the low-dimensional CM 
space instead of the high-dimensional acoustic space (e.g., 6 vs. 40+), MALCOM requires 
many fewer parameters to be estimated than the corresponding HMM. 
3 THE MALCOM ALGORITHM 
We now turn to developing an algorithm to estimate both the CM pdfs (I> and the corre- 
sponding paths � that together maximize the likelihood of a given time series of acoustics, 
� = P(XIY, (I>). This is an extension of the method first proposed by Hogden (1995), in 
which he instead maximized P(Y[X, (I>) using vowel data from a single speaker. Starting 
with random but smooth �, the MALCOM training algorithm generates a CM by iterating 
between the following two steps: (1) Given Y, reestimate (I> to maximize �; and (2) Given 
(I>, reestimate smooth paths � to maximize �. 
3.1 LOG LIKELIHOOD FUNCTION 
To specify the log likelihood function �, we make two dependence claims and one inde- 
pendence assumption. First we claim that Yt depends (to at least some small extent) on all 
other y in the utterance, an expression of the continuity constraint described above. We 
make another natural claim that xt depends on Yt, that the path configuration at time t in- 
fluences the corresponding acoustics. However, we do make the conditional independence 
assumption that 
Z; = P(XIY, = II P(xtly,, (4) 
t=l 
Note that Eq. (4) does not assume that each xt is independent of xt- (as is often assumed 
in data modeling); it only assumes that the conditioning of xt on Yt is independent from 
1 However, we are currently developing a model of P(Y [.A//) to replace the corresponding (and 
useless) term in the conventional HMM formulation as well (Hogden et al., 1998). 
Maximum-Likelihood Continuity Mapping (MALCOM): An Alternative to HMMs 747 
t- 1 to t. For example, because xt depends on Yt, Yt depends on all other y (the smoothness 
constraint), and xt-  depends on Yt- , xt is not assumed to be independent of all other xs 
in the utterance. 
With a log transformation and an invocation of Bayes' rule, we obtain the MALCOM log 
likelihood function: 
ln� =  [lnP(ytlxt, (I)) + in P(xt) -In P(ytl(I))]. (5) 
t=l 
We model each P(Yt [xt, (I)) by a probability density function (pdf) p[yt [xt, (I)j (xt)], where 
the particular model (I)j depends on which of the N VQ codes xt is assigned to. Here we 
use a simple multi-dimensional Gaussian for each pdf, but we are currently exploring the 
use of multi-modal mixtures of Gaussians to represent the pdfs for sounds such as stop 
consonant
