Inverse Dynamics 
of Speech Motor Control 
Makoto Hirayama Eric Vatikiotis-Bateson Mitsuo Kawato* 
ATR Human Information Processing Research Laboratories 
2-2 Hikaridai, Seika-cho, Soraku-gun, Kyoto 619-02, Japan 
Abstract 
Progress has been made in COml)utational implementation of speech 
production based on physiological data. An inverse dynamics 
model of the speech articulator's musculo-skeletal system. which 
is tile maI)ping from articulator trajectories to electromyographic 
(EMG) signals, was modeled using tile acquired forward dynamics 
model and temporal (smoothness of EMG activation) and range 
constraints. This inverse dynamics model allows the use of a faster 
speech motor control scheme, which can be applied to phoneme-to- 
speech synthesis via musclo-skeletal system dynamics, or to future 
use in speech recognition. Tile forward acoustic model, which is the 
mapping from articulator trajectories to tile acoustic parameters, 
was improved by adding velocity and voicing information inputs 
to distinguish acoustic parameter differences caused by cha%es in 
source characteristics. 
1 INTRODUCTION 
Modeling speech articulator dynamics is important not only for speech science, 
but also for speech processing. This is because many issues in speech phenomena, 
such as coarticulation or generation of aperiodic sources, are caused by temporal 
properties of speech articulator behavior due to musculo-skeletal system dynamics 
and constraints on neuro-motor command activation. 
*Also, Laboratory of Parallel Distributed Processing, Research Institute for Electronic 
Science, ttokkaido University, Sapporo, Hokkaido 060, Japan 
1043 
1044 Hirayama, Vatikiotis-Bateson, and Kawato 
We haw proposed using neural networks for a computational implementation of 
speech production based on physiological activities of speech articulator muscles. 
In previous works (ttirayama, Vatikiotis-Bateson, Kawato and Jordan 1992; Hi- 
rayarea, Vatikiotis-Bateson, Itonda, Koike and Kawato 1993), a neural network 
learned the forward dynamics, relating motor commands to muscles and the ensu- 
ing articulator behavior. From movement trajectories, the forward acoustic network 
generated the acoustic PARCOR parameters (Itakura and Saito, 1969) that were 
then used to synthesize the speech acoustics. A cascade neural network containing 
the forward dynamics model along with a suitable smoothness crilerion was used 
to produce a continuous motor command from a sequence of discrete articulatory 
targets corresponding to tile phoneme input string. 
Along the same line, we have extended our model of speech motor control. In this 
paper, we focus on modeling tile inverse dynamics of tile musculo-skeletal system. 
Having an inverse dynamics model allows us to use a faster control scheme, which 
permits l)honeme-to-speech synthesis via musculo-skeletal system dynamics, and 
ultimately may be useful in speech recognition. Tile final section of this paper 
reports inprovements in the forward acoustic model, which were made by incor- 
porating articulator velocity and voicing information to distinguish tile acoustic 
parameter differences caused by changes in source characteristics. 
2 
INVERSE DYNAMICS MODELING OF 
MUSCULO-SKELETAL SYSTEM 
From the viewpoint of control theory, an inverse dynamics model of a controlled 
object plays an essential role in feedforward control. That is, all accurate inverse dy- 
namics model outputs an appropriate control sequence that realizes a given desired 
trajectory by using only feedforward control without any feedback information, so 
long as there is no perturbation from the environment. For speech articulators, the 
main control scheme callnot rely upon feedback control because of sensory feedback 
delays. Thus, we believe that tile inverse dynamics model is essential for biological 
motor control of speech and for any eflicient speech synthesis algorithm based on 
physiological data. 
However, the speech articulator system is an excess-degrees-of-fi'eedom system, 
thus the mapping from articulator trajectory (position, velocity, acceleration) to 
electromyographic (EMG) activity is one-to-many. That is, different EMG com- 
binations exist for the same articulator trajectory (for example, co-contraction of 
agonist and antagonist muscle pairs). Consequently, we applied the forward mod- 
eling approach to learning all inverse model (Jordan and Runaelhart, 1992), i.e., 
constrained supervised learning, as shown in Figure 1. The inpuls of tile inverse 
Trajectory I Controll ::rajecto 
1 Inverse [ , Forward 
I Mode',,[,:: I Mode' 
-- Error 
Figure 1: Inverse dynamics modeling using a forward dynamics model (Jordan and 
Rumelhart, 1992). 
Inverse Dynamics of Speech Motor Control 1045 
..... Actual EMG 
1.0- 
 -- optimal EMG by IDM 
: 0.8- 
- 0.6- 
 0.4- 
 0.2-- 
0.0-- 
0 1 2 3 4 
Time (s) 
Figure 2: After learning, the iuverse model output optimal EMG (anterior belly of 
the digas[rio) [or jaw lowering is compared wih actual EMG [or the test trajectory. 
dynamics model are articulator positions, velocities, and accelerations; the outputs 
are rectified, integrated, and filtered EMG for relevant nmscles. The forward dy- 
namics model previously reported (Ilirayama et al., 1993) was used for determining 
the error signals of the inverse dynamics model. 
To choose a realistic EMG pattern from among diverse possible sclutions, we use 
both temporal and range constraints. The temporal constraint is related to the 
smoothness of EMG activation, i.e., minimizing EMG activation change (Uno, 
Suzuki, and Kaxvat. o, 1989). The minimum and maximum values of the range 
constraint were chosen using values obtained from the experimental data. Direct 
inverse modeling (Albus, 1975) was used to determine weights, which were then sup- 
plied as initial weights to the constrained supervised learning algorithm of Jordan 
and Rumelhart's (1992) inverse dynamics modeling method. 
Figure 2 shows an example of the inverse dynamics model output after learning, 
when a real articulator trajectory, not included in the training set, was given as 
the input. Note that the network output cannot be exactly the same as the actual 
EMG, as the network chooses a unique optimal EMG from many possible EMG 
patterns that appear in the actual EMG for the trajectory. 
.... Experimental data 
-0.3  --- Direct inverse modeling 
-- Inverse modeling using FDM 
c ' ' ;': .:''. ..' .--. . .. ' 
O -0.5 -- / ' : '' . , '- ' ,'< . 
r ], . ,. ...,, ,,,, .. 
O 
o_ -0.6 -- 
-0.7 -- :' 
I I I I 
0 1 2 3 4 
Time (s) 
Figure 3: Trajectories generated by the forward dynamics network for the two 
methods of inverse dynamics modeling compared with the desired trajectory (ex- 
perimental data). 
1046 Hirayama, Vatikiotis-Bateson, and Kawato 
Since the inverse dynamics model was obtained by learning, when the desired tra- 
jectory is given to the inverse dynamics model, an articulator trajectory can be 
generated with the forward dynamics network previously reported (IIirayama et al., 
1993). Figure 3 compares trajectories generated by the forward dynamics network 
using EMG derived fi'om the direct inverse dynamics method or the constrained su- 
pervised learning algorithm (which uses the forward dynamics model to determine 
the inverse dynmnics model's optimar' EMG). The latter method yielded a 30.0 % 
average reduction in acceleration prediction error over the direct method, thereby 
bringing the model output trajectory closer to the experimental data. 
3 
TRAJECTORY FORMATION USING FORWARD 
AND INVERSE RELAXATION MODEL 
Previously, to generate a. trajectory from discrete phoneme-specific via-points, we 
used a cascade neural network (c.f., IIirayama et al., 1992). The inverse dynamics 
model allows us to use an alternative network proposed by Wada and Kawato (1993) 
(Figure 4). The network uses both the forward and inverse models of the controlled 
object, and updates a giwm initial rough trajectory passing through the via-points 
according to the dynamics of the controlled object and a smoothness constraint on 
the control input. The computation time of the network is much shorter than that 
of the cascade neural network (Wada and Kawato, 1993). 
Figure 5 shows a forward dynamics model output trajectory driven by the model- 
generated motor control signals. Unlike Wada and Kawato's original model (1993) 
in which generated trajectories always pass through via-points, our trajectories were 
generated from smoothed motor control signals (i.e., after applying the smoothness 
constraint) and, consequently, do not, pass through the exact via-points. In this 
paper, a typical value for each phoneme from experimental data was chosen as the 
target via-point and xvas given in Cartesian coordinates relative to the maxillary 
incisor. Although firther investigation is needed to refine the phoneme-specific 
target specifications (e.g. lip aperture targets), reasonable coarticulated trajectories 
were obtained fi'om series of discrete via-point targets (Figure 5). For engineering 
applications such as text-to-speech synthesizers using articulatory synthesis, this 
kind of technique is necessary because realistic coarticulated trajectories must serve 
as input [o [he articulatory synthesizer. 
/  / / u / // / s / Articu/atory Targets 
I Trajectory Approximation I 
( Trajectory  
Ilnvers i Dynamics Model I I Forward Dynamics Model ! 
 ISmoothness Constraint J ) 
 Motor Control Signal 
Figure 4: Speech trajectory formatiou scheme modified from the forward and inverse 
relaxation neural network model (Wada and Kawa[o, 1993). 
Inverse Dynamics of Speech Motor Control 1047 
>- -o.4 - 
v 
-- Network output 
....... Experimental data 
� � - Phoneme specific targets 
I I I I I I 
0.0 0.2 0.4 0.6 0.8 1.0 1.2 
Time (s) 
Figure 5: Jaw trajectory generated by the forward and inverse relaxation model. 
The output of the forward dynamics 
