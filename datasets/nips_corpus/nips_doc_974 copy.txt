Convergence Properties of the K-Means 
Algorithms 
Lon Bottou 
Neuristique, 
28 rue des Petites Ecuries, 
75010 Paris, France 
leonneurist ique. fr 
Yoshua Bengio* 
Dept. I.R.O. 
Universit de Montrdal 
Montreal, Qc H3C-3J7, Canada 
bengioyiro. umontreal. ca 
Abstract 
This paper studies the convergence properties of the well known 
K-Means clustering algorithm. The K-Means algorithm can be de- 
scribed either as a gradient descent algorithm or by slightly extend- 
ing the mathematics of the EM algorithm to this hard threshold 
case. We show that the K-Means algorithm actually minimizes the 
quantization error using the very fast Newton algorithm. 
I INTRODUCTION 
K-Means is a popular clustering algorithm used in many applications, including the 
initialization of more computationally expensive algorithms (Gaussian mixtures, 
Radial Basis Functions, Learning Vector Quantization and some Hidden Markov 
Models). The practice of this initialization procedure often gives the frustrating 
feeling that K-Means performs most of the task in a small fraction of the overall 
time. This motivated us to better understand this convergence speed. 
A second reason lies in the traditional debate between hard threshold (e.g. K- 
Means, Viterbi Training) and soft threshold (e.g. Gaussian Mixtures, Baum Welch) 
algorithms (Nowlan, 1991). Soft threshold algorithms are often preferred because 
they have an elegant probabilistic framework and a general optimization algorithm 
named EM (expectation-maximization) (Dempster, Laird and Rubin, 1977). In the 
case of a gaussian mixture, the EM algorithm has recently been shown to approxi- 
mate the Newton optimization algorithm (Xu and Jordan, 1994). We prove in this 
*also, AT&T Bell Labs, Holmdel, NJ 07733 
586 l_on Bottou, Yoshua Bengio 
paper that the corresponding hard threshold algorithm, K-Means, minimizes the 
quantization error using exactly the Newton algorithm. 
In the next section, we derive the K-Means algorithm as a gradient descent pro- 
cedure. Section 3 extends the mathematics of the EM algorithm to the case of 
K-Means. This second derivation of K-Means provides us with proper values for 
the learning rates. In section 4 we show that this choice of learning rates opti- 
mally rescales the parameter space using Newton's method. Finally, in section 5 
we present and discuss a few experimental results comparing various versions of the 
K-Means algorithm. The 5 clustering algorithms presented here were chosen for a 
good coverage of the algorithms related to K-Means, but this paper does not have 
the ambition of presenting a literature survey on the subject. 
2 K-MEANS AS A GRADIENT DESCENT 
Given a set of P examples (xi), the K-Means algorithm computes k prototypes 
w = (w) which minimize the quantization error, i.e., the average distance between 
each pattern and the closest prototype: 
1 nn(xi - w)' 
i i 
(1) 
Writing si(w) for the subscript of the closest prototype to example xi, we have 
1 
E(w) = (2) 
i 
2.1 GRADIENT DESCENT ALGORITHM 
We can then derive a gradient descent algorithm for the quantization error: 
OE(w) This leads to the following batch update equation (updating pro- 
AW -- --t Ow 
totypes after presenting all the examples)' 
-wn) ifk=si(w) 
Aw: = y. ;t(xi otherwise. (3) 
$ 
We can also derive a corresponding online algorithm which updates the prototypes 
after the presentation of each pattern xi: 
0/,(zi, 
Aw = --t Ow , i.e., 
AWL={ ;t(xi-- w) ifk=si(w) 
otherwise. 
(4) 
The proper value of the learning rate et remain to be specified in both batch and 
online algorithms. Convergence proofs for both algorithms (Bottou, 1991) exist 
for decreasing values of the learning rates satisfying the conditions  et = c and 
 et 2 < c. Following (Kohonen, 1�89), we could choose et = eo/t. We prove 
however in this paper that there exist a much better choice of learning rates. 
Convergence Properties of the K-Means Algorithms 587 
3 K-MEANS AS AN EM STYLE ALGORITHM 
3.1 EM STYLE ALGORITHM 
mizes Q(w , w) where w is the previous set of prototypes. 
compute the explicit solution of this minimization problem. 
OQ(w t, w)/Owt, = 0 yields: 
The following derivation of K-Means is similar to the derivation of (MacQueen, 
1967). We insist however on the identity between this derivation and the mathe- 
matics of EM (Liporace, 1976) (Dempster, Laird and Rubin, 1977). 
Although K-Means does not fit in a probabilistic framework, this similarity holds 
for a very deep reason: The semi-ring of probabilies (+, +, x) and the idempo- 
tent semi-ring of hard-threshold scores (, Min, +) share the most significant al- 
gebraic properties (Bacceli, Cohen and Olsder, 1992). This assertion completely 
describes the similarities and the potential differences between soft-threshold and 
hard-threshold algorithms. A complete discussion however stands outside the scope 
of this paper. 
The principle of EM is to introduce additional hidden variables whose knowledge 
would make the optimization problem easier. Since these hidden variables are un- 
known, we maximize an auxiliary function which averages over the values of the 
hidden variables given the values of the parameters at the previous iteration. In 
our case, the hidden variables are.the assignments si(w) of the patterns to the pro- 
totypes. Instead of considering the expected value over the distribution on these 
hidden variables, we just consider the values of the hidden variables that minimize 
the cost, given the previous values of the parameters: 
1 
 W t 2 
Q(w', w) der  (x, -- ,() 
i 
The next step consists then in finding a new set of prototypes w t which mini- 
We can analytically 
Solving the equation 
1 
w ;vk  
i: =s(w) 
(5) 
where Nk is the number of examples assigned to prototype w. 
consists in repeatedly replacing w by w t using update equation (6) until convergence. 
Since si(w ) is by definition the best assignment of patterns xi to the prototypes 
w, we have the following inequality: 
1 
(w,) - Q(w',w) =  (, ' , ' - w' , 
- w ( ) - (zi 8() <_0 
i 
Using this result, the identity E(w) = Q(w, w) and the definition of w t, we can 
derive the following inequality: 
(w') - (w) = (w') - Q(w', w) + Q(w', w) - Q(w, w) 
_ Q(w', w) - Q(w, w) _ o 
The algorithm 
Each iteration of the algorithm thus decreases the otherwise positive quantization 
error E (equation 1) until the error reaches a fixed point where condition w * = w* 
is verified (unicity of the minimum of Q(., w*)). Since the assignment functions 
si(w) are discrete, there is an open neighborhood of w* on which the assignments 
are constant. According to their definition, functions E(.) and Q(., w*) are equal 
on this neighborhood. Being the minimum of function Q(., w*), the fixed point w* 
of this algorithm is also a local minimum of the quantization error E. E2 
588 Ldon Bottou, Yoshua Bengio 
3.2 BATCH K-MEANS 
The above algorithm (5) can be rewritten in a form similar to that of the batch 
gradient descent algorithm (3). 
if k = s(zi, w) 
otherwise. (6) 
This algorithm is thus equivalent to a batch gradient descent with a specific, pro- 
1 
totype dependent, learning rate N-' 
3.3 ONLINE K-MEANS 
The online version of our EM style update equation (5) is based on the computation 
of the mean pt of the examples xl, � � ', xt with the following recursive formula: 
1 (Zt+l -- 
1 (t t t - Xt+l) : t t - t- 
tt+l -- t+l 
Let us introduce new variables n which count the number of examples so far 
assigned to prototype w. We can then rewrite (5) as an online update applied 
after the presentation of each pattern xi: 
1 ifk = s(xi,w) 
An = 0 otherwise. 
{ l(xi-w,) ifk=s(xi,w) 
Aw = k otherwise. (7) 
This algorithm is equivalent to an online gradient descent (4) with a specific, proto- 
type dependent, learning rate h-' Unlike in the batch case, the pattern assignments 
s(xi, w) are thus changing after each pattern presentation. Before applying this al- 
gorithm, we must of course set n to zero and w to some initial value. Various 
methods have been proposed including initializing w with the first k patterns. 
3.4 CONVERGENCE 
General convergence proofs for the batch and online gradient descent (Bottou, 1991; 
Driancourt, 1994) directly apply for all four algorithms. Although the derivatives 
are undefined on a few points, these theorems prove that the algorithms almost 
surely converge to a local minimum because the local variations of the loss function 
are conveniently bounded (semi-differentiability). Unlike previous results, the above 
convergence proofs allow for non-linearity, non-differentiability (on a few points) 
(Bottou, 1991), and replacing learning rates by a positive definite matrix (Drian- 
court, 1994). 
4 K-MEANS AS A NEWTON OPTIMIZATION 
We prove in this section that Batch K-Means (6) applies the Newton algorithm. 
4.1 THE HESSIAN OF K-MEANS 
Let us compute the Hessian H of the K-Means cost function (2). This matrix 
contains the second derivatives of the cost E(w) with respect to each pair of pa- 
rameters. Since E(w) is a sum of terms L(xi, w), we can decompose H as the sum 
Convergence Properties of the K-Means Algorithms 589 
of matrices Hi for each term of the cost function: 
1 
L(xi, w) = min (xi - wk) 2. 
Furthermore, the Hi can be decomposed in blocks corresponding to each pair of 
prototypes. Since L(xi, w) depends only on the closest prototype to pattern xi, all 
these blocks are zero except block (si(w), si(w)) which is the identity matrix. Sum- 
ming the partial Hessian matrices Hi thus gives a diagonal matrix whose diagonal 
elements are the counts of examples N assigned to each prototype. 
H __ 
o 
N2I 
0 0 
We can thus write the Newton update of the parameters as follows: 
Aw= -H -OE(w) 
0w 
which can be exactly rewritten as the batch EM style algorithm (6) presented earlier: 
(xi-w) ifk=s(xi,w) 
Aw = Z  otherwise. (8) 
4.2 CONVERGENCE SPEED 
When optimizing a quod
