662 
AN ADAPTIVE AND HETERODYNE FILTERING PROCEDURE 
FOR THE IMAGING OF MOVING OBJECTS 
F. H. Schuling, H. A. K. Mastebroek and W. H. Zaagman 
Biophysics Department, Laboratory for General Physics 
Westersingel 34, 9718 CM Groningen, The Netherlands 
ABSTRACT 
Recent experimental work on the stimulus velocity dependent time resolving 
power of the neural units, situated in the highest order optic ganglion of the 
blowfly, revealed the at first sight amazing phenomenon that at this high level of 
the fly visual system, the time constants of these units which are involved in the 
processing of neural activity evoked by moving objects, are -roughly spoken- 
inverse proportional to the velocity of those objects over an extremely wide range. 
In this paper we will discuss the implementation of a two dimensional heterodyne 
adaptive filter construction into a computer simulation model. The features of this 
simulation model include the ability to account for the experimentally observed 
stimulus-tuned adaptive temporal behaviour of time constants in the fly visual 
system. The simulation results obtained, clearly show that the application of such 
an adaptive processing procedure delivers an improved imaging technique of 
moving patterns in the high velocity range. 
A FEW REMARKS ON THE FLY VISUAL SYSTEM 
The visual system of the diptera, including the blowfly Calliphora 
erythrocephala (Mg.) is very regularly organized and allows therefore very precise 
optical stimulation techniques. Also, long term electrophysiological recordings can 
be made relatively easy in this visual system. For these reasons the blowfly (which 
is well-known as a very rapid and 'clever' pilot) turns out to be an extremely 
suitable animal for a systematic study of basic principles that may underlie the 
detection and further processing of movement information at the neural level. 
In the fly visual system the input retinal mosaic structure is precisely 
mapped onto the higher order optic ganglia (lamina, medulla, lobula). This means 
that each neural column in each ganglion in this visual system corresponds to a 
certain optical axis in the visual field of the compound eye. In the lobula complex 
a set of wide-field movement sensitive neurons is found, each of which integrates 
the input signals over the whole visual field of the entire eye. One of these wide 
field neurons, that has been classified as H1 by Hausen I has been extensively 
studied both anatomically 2, 3, 4 as well as electrophysiologically 5, 6, 7 The 
obtained results generally agree very well with those found in behavioral 
optomotor experiments on movement detection 8 and can be understood in terms of 
Reichardts correlation model 9, 10 
The H1 neuron is sensitive to horizontal movement and directionally 
selective: very high rates of action potentials (spikes) up to 300 per second can be 
recorded from this element in the case of visual stimuli which move horizontally 
inward, i.e. from back to front in the visual field (preferred direction), whereas 
movement horizontally outward, i.e. from front to back (null direction) suppresses 
its activity. 
American Institute of Physics 1988 
663 
EXPERIMENTAL RESULTS AS A MODELLING BASE 
When the H1 neuron is stimulated in its preferred direction with a step wise 
pattern displacement, it will respond with an increase of neural activity. By 
repeating this stimulus step over and over one can obtain the averaged response: 
after a 20 ms latency period the response manifests itself as a sharp increase in 
average firing rate followed by a much slower decay to the spontaneous activity 
level. Two examples of such averaged responses are shown in the Post Stimulus 
Time Histograms (PSTH's) of figure 1. Time to peak and peak height are related 
and depend on modulation depth, stimulus step size and spatial extent of the 
stimulus. The tail of the responses can be described adequately by an exponential 
decay toward a constant spontaneous firing rate: 
R(t)=c+a � e(-t/r) 
(l) 
For each setting of the stimulus parameters, the response parameters, 
defined by equation (1), can be estimated by a least-squares fit to the tail of the 
PSTH. The smooth lines in figure 1 are the results of two such fits. 
1%0 = . �/ 
50 
150 W= II�/s 
s0lt'! 
o 200 oo 6oo 80o 
hrne Irnsl 
t(ms) 
300 
3O 
� M=0.40 
o M=010 
 M =o 05 
o 
o 
o 
0.3 I 3 I00 300 
W {'Is ) 
Fig. 1 
Fig.2 
Averaged responses (PSTH's) obtained from the H1 neuron, being 
adapted to smooth stimulus motion with velocities 0.36�/s (top) and 
11 �/s (bottom) respectively. The smooth lines represent least-squares 
fits to the PSTH's of the form R(t)=c+a.e(-t/r). Values of r for the 
two PSTH's are 331 and 24 ms respectively (de Ruyter van Steveninck et 
al.7). 
Fitted values of r as a function of adaptation velocity for three 
modulation depths M. The straight line is a least-squares fit to represent 
the data for M=0.40 in the region w=0.3-100�/s. It has the form 
r=a.w-/ with a=150 ms and/=0.7 (de Ruyter van Steveninck et al.7). 
664 
Figure 2 shows fitted values of the response time constant r as a function of 
the angular velocity of a moving stimulus (a square wave grating in most 
experiments) which was presented to the animal during a period long enough to let 
its visual system adapt to this moving pattern and before the step wise pattern 
displacement (which reveals r) was given. The straight line, described by 
(2) 
(with W in �/s and y in ms) represents a least-squares fit to the data over the 
velocity range from 0.36 to 125 �/s. For this range, r varies from 320 to roughly 
10 ms, with a--150__10 ms and /=0.7_0.05. Defining the adaptation range of r as 
that interval of velocities for which r decreases with increasing velocity, we may 
conclude from figure 2 that within the adaptation range, y is not very sensitive to 
the modulation depth. 
The outcome of similar experiments with a constant modulation depth of the 
pattern (M=0.40) and a constant pattern velocity but with four different values of 
the contrast frequency fc (i.e. the number of spatial periods per second that 
traverse an individual visual axis as determined by the spatial wavelength ns of the 
pattern and the pattern velocity v according to fc=V/s) reveal also an almost 
complete independency of the behaviour of y on contrast frequency. Other 
experiments in which the stimulus field was subdivided into regions with different 
adaptation velocities, made clear that the time constants of the input channels of 
the H1 neuron were set locally by the values of the stimulus velocity in each 
stimulus sub-region. Finally, it was found that the adaptation of y is driven by 
the stimulus velocity, independent of its direction. 
These findings can be summarized qualitatively as follows: in steady state, 
the response time constants y of the neural units at the highest level in the fly 
visual system are found to be tuned locally within a large velocity range 
exclusively by the magnitude of the velocity of the moving pattern and not by its 
direction, despite the directional selectivity of the neuron itself. We will not go 
into the question of how this amazing adaptive mechanism may be hard-wired in 
the fly visual system. Instead we will make advantage of the results derived thus 
far and attempt to fit the experimental observations into an image processing 
approach. A large number of theories and several distinct classes of algorithms to 
encode velocity and direction of movement in visual systems have been suggested 
by, for example, Marr and Ullman 11 and van Santen and Sperling 12 
We hypothesize that the adaptive mechanism for the setting of the time 
constants leads to an optimization for the overall performance of the visual system 
by realizing a velocity independent representation of the moving object. In other 
words: within the range of velocities for which the time constants are found to be 
tuned by the velocity, the representation of that stimulus at a certain level within 
the visual circuitry, should remain independent of any variation in stimulus 
velocity. 
OBJECT MOTION DEGRADATION: MODELLING 
Given the physical description of motion and a linear space invariant model, 
the motion degradation process can be represented by the following convolution 
integral: oo oo 
g(x,y)--f ;(h(x-u,y-v) � f(u,v)) dudv (3) 
665 
where f(u,v) is the object intensity at position (u,v) in the object coordinate 
frame, h(x-u,y-v) is the Point Spread Function (PSF) of the imaging system, 
which is the response at (x,y) to a unit pulse at (u,v) and g(x,y) is the image 
intensity at the spatial position (x,y) as blurred by the imaging system. Any 
possible additive white noise degradation of the already motion blurred image is 
neglected in the present considerations. 
For a review of principles and techniques in the field of digital image 
degradation and restoration, the reader is referred to Harris 13, Sawchuk TM, 
Sondhi 15, Nahi 16, Aboutalib eta/. 17, 18, Hildebrand19, Rajala de Figueiredo 20 
It has been demonstrated first by Aboutalib et al. 17 that for situations in which 
the motion blur occurs in a straight line along one spatial coordinate, say along the 
horizontal axis, it is correct to look at the blurred image as a collection of 
degraded line scans through the entire image. The dependence on the vertical 
coordinate may then be dropped and eq. (3) reduces to: 
g(x) h(x-u) � f(u)du (4) 
Given the mathematical description of the relative movement, the 
corresponding PSF can be derived exactly and equation (4) becomes: 
g(x)= fR h<x- u) � f(u)du (5) 
where R is the extent of the motion blur. Typically, a discrete version of (5), 
applicable for digital image processing purposes, is described by: 
L 
g(k)--T. h(k-1)-f(1) ; k=l .... ,N (6) 
1 
where k and 1 take on integer values and L is related to the motion blur extent. 
According to Aboutalib et al. 18 a scalar difference equation model (M,a,b,c) 
