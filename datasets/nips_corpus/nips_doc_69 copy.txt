432 
Performance Measures for Associative Memories 
that Learn and Forget 
Anthony Kuh 
Department of Electrical Engineering 
University of Hawaii at Manoa 
Honolulu HI, 96822 
ABSTRACT 
Recently, many modifications to the McCulloch/Pitts model have been proposed 
where both learning and forgetting occur. Given that the network never saturates (ceases 
to function effectively due to an overload of information), the learning updates can con- 
tinue indefinitely. For these networks, we need to introduce performance measures in addi- 
tion to the information capacity to evaluate the different networks. We mathematically 
define quantities such as the plasticity of a network, the efficacy of an information vector, 
and the probability of network saturation. From these quantities we analytically compare 
different networks. 
1. Introduction 
Work has recently been undertaken to quantitatively measure the computational 
aspects of network models that exhibit some of the attributes of neural networks. The 
McCulloch/Pitts model discussed in [1] was one of the earliest neural network models to be 
analyzed. Some computational properties of what we call a Hopfield Associative Memory 
Network (HAMN) similar to the McCulloch/Pitts model was discussed by Hopfield in [2]. 
The HAMN can be measured quantitatively by defining and evaluating the information 
capacity as [2-6] have shown, but this network fails to exhibit more complex computational 
capabilities that neural network have due to its simplified structure. The HAMN belongs 
to a class of networks which we call static. In static networks the learning and recall pro- 
cedures are separate. The network first learns a set of data and after learning is complete, 
recall occurs. In dynamic networks, as opposed to static networks, updated learning and 
associative recall are intermingled and continual. In many applications such as in adaptive 
communications systems, image processing, and speech recognition dynamic networks are 
needed to adaptively learn the changing information data. This paper formally develops 
and analyzes some dynamic models for neural networks. Some existing models [7-10] are 
analyzed, new models are developed, and measures are formulated for evaluating the per- 
formance of different dynamic networks. 
In [2-6], the asymptotic information capacity of the HAMN is defined and evaluated. 
In [4-5], this capacity is found by first assuming that the information vectors (IVs) to be 
stored have components that are chosen randomly and independently of all other com- 
ponents in all IVs. The information capacity then gives the maximum number of IVs that 
can be stored in the HAMN such that IVs can be recovered with high probability during 
retrieval. At or below capacity, the network with high probability, successfully recovers 
the desired IVs. Above capacity, the network quickly degrades and eventually fails to 
recover any of the desired IVs. This phenomena is sometimes referred to as the forgetting 
catastrophe [10]. In this paper we will refer to this phenomena as network saturation. 
There are two ways to avoid this phenomena. The first method involves learning a 
limited number of IVs such that this number is below capacity. After this learning takes 
place, no more learning is allowed. Once learning has stopped, the network does not 
change (defined as static) and therefore lacks many of the interesting computational 
American Institute of Physics 1988 
433 
capabilities that adaptive learning and neural network models have. The second method is 
to incorporate some type of forgetting mechanism in the learning structure so that the 
information stored in the network can never exceed capacity. This type of network would 
be able to adapt to the changing statistics of the IVs and the network would only be able 
to recall the most recently learned IVs. This paper focuses on analyzing dynamic networks 
that adaptively learn new information and do not exhibit network saturation phenomena 
by selectively forgetting old data. The emphasis is on developing simple models and much 
of the analysis is performed on a dynamic network that uses a modified Hebbian learning 
rule. 
Section 2 introduces and qualitatively discusses a number of network models that are 
classified as dynamic networks. This section also defines some pertinent measures for 
evaluating dynamic network models. These measures include the plasticity of a network, 
the probability of network saturation, and the efficacy of stored IVs. A network with no 
plasticity cannot learn and a network with high plasticity has interconnection weights that 
exhibit large changes. The efficacy of a stored IV as a function of time is another impor- 
tant parameter as it is used in determining the rate at which a network forgets informa- 
tion. 
In section 3, we mathematically analyze a simple dynamic network referred to as the 
Attenuated Linear Updated Learning (ALUL) network that uses linear updating and a 
modified Hebbian rule. Quantities introduced in section 3 are analytically determined for 
the ALUL network. By adjusting the attenuation parameter of the ALUL network, the 
forgetting factor is adjusted. It is shown that the optimal capacity for a large ALUL net- 
work in steady state defined by (2.13,3.1) is a factor of e less than the capacity of a 
HAMN. This is the tradeoff that must be paid for having dynamic capabilities. We also 
conjecture that no other network can perform better than this network when a worst case 
criterion is used. Finally, section 4 discusses further directions for this work along with pos- 
sible applications in adaptive signal processing. 
2. Dynamic Associative Memory Networks 
The network models discussed in this paper are based on the concept of associative 
memory. Associative memories are composed of a collection of interconnected elements 
that have data storage capabilities. Like other memory structures, there are two opera- 
tions that occur in associative memories. In the learning operation (referred to as a write 
operation for conventional memories), information is stored in the network structure. In 
the recall operation (referred to as a read operation for conventional memories), informa- 
tion is retrieved from the memory structure. Associative memories recall information on 
the basis of data content rather than by a specific address. The models that we consider 
will have learning and recall operations that are updated in discrete time with the activa- 
tion state X(j) consisting of N cells that take on the values {-1,1). 
2.1. Dynamic Network Measures 
General associative memory networks are described by two sets of equations. I1' we 
let X(j) represent the activation state at time j and W(k) represent the weight matrix or 
interconnection state at time k then the activation or recall equation is described by 
X(/+ 1)= f(X(j),W(k)), j>_0, k>_0, X(0)= _5( (2.1) 
where .r is the data probe vector used for recall. The learning algorithm or interconnec- 
tion equation is described by 
W(k+l)= g(V(i),O<i<k,W(O)) (2.2) 
where { V(i)} are the information vectors (IV)s to be stored and W(0)is the initial state of 
the interconnection matrix. Usually the learning algorithm time scale is much longer than 
434 
the recall equation time scale so that W in (2.1) can be considered time invariant. Often 
(2.1) is viewed as the equation governing short term memory and (2.2) is the equation 
governing long term memory. From the Hebbian hypothesis we note that the data probe 
vectors should have an effect on the interconnection matrix W. If a number of data probe 
vectors recall an IV V(1), the strength of recall of the IV V(i) should be increased by 
appropriate modification of W. If another IV is never recalled, it should gradually be for- 
gotten by again adjusting terms of W. Following the analysis in [4,5] we assume that all 
components of IVs introduced are independent and identically distributed Bernoulli random 
1 
variables with the probability of a I or -1 being chosen equal to . 
Our analysis focuses on learning algorithms. Before describing some dynamic learning 
algorithms we present some definitions. A network is defined as dynamic if given some 
period of time the rate of change of W is never nonzero. In addition we will primarily dis- 
cuss networks where learning is gradual and updated at discrete times as shown in (2.2). 
By gradual, we want networks where each update usually consists of one IV being learned 
and/or forgotten. IVs that have been introduced recently should have a high probability of 
recovery. The probability of recall for one IV should also be a monotonic decreasing func- 
tion of time, given that the IV is not repeated. The networks that we consider should also 
have a relatively low probability of network saturation. 
Quantitatively, we let e(k,l,i) be the event that an IV introduced at time I can be 
recovered at time k with a data probe vector which is of Hamming distance i from the 
desired IV. The efficacy of network recovery is then given as p(k,l,i) = ?r(e(k,l,i)). In 
the analysis performed we say a a vector V can recover V(l), if V(l)= A(V) where A(o) 
is a synchronous activation update of all cells in the network. The capacity for dynamic 
networks is then given by 
C(k,i,e)= maxm-Pr(r(e(k,l,i),O_<l<k)=m)> 1-e 0<i< ---N (2.3) 
-- 2 
where r(X) gives the cardinality of the number of events that occur in the set 35. Closely 
related to the capacity of a network is netsyork saturation. Saturation occurs when the 
network is overloaded with IVs such that few or none of the IVs can be successfully 
recovered. When a network at time 0 starts to learn Ivs, at some time l < j we have that 
C(l,i,e)_>C(j,i,e). For k_>l the network saturation probability is defined by S(k,rn) 
where $ describes the probability that the network cannot recover m Ivs. 
Another important measure in analyzing the performance of dynamic networks is 
