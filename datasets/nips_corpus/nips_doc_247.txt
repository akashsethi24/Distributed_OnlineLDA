68 Baird 
Associative Memory in a Simple Model of 
Oscillating Cortex 
Bill Baird 
Dept Molecular and Cell Biology, 
U.C.Berkeley, Berkeley, Ca. 94720 
ABSTRACT 
A generic model of oscillating cortex, which assumes minimal 
coupling justified by known anatomy, is shown to function as an 
sociative memory, using previously developed theory. The network 
has explicit excitatory neurons with local inhibitory interneuron 
feedback that forms a set of nonlinear oscillators coupled only by 
long range excitatogy connections. Using a local Hebb-like learning 
rule for primary and higher order synapses at the ends of the long 
range connections, the system learns to store the kinds of oscil- 
lation amplitude patterns observed in olfactory and visual cortex. 
This rule is derived from a more general projection algorithm 
for recurrent analog networks, that analytically guarantees content 
addressable memory storage of continuous periodic sequences -- 
capacity: N/2 Fourier components for an N node network -- no 
spurious attractors. 
1 Introduction 
This is a sketch of recent results stemming from work which is discussed completely 
in [1, 2, 3]. Patterns of 40 to 80 hz oscillation have been observed in the large 
scale activity of olfactory cortex [4] and visual neocortex [5], and shown to predict 
the olfactory and visual pattern recognition responses of a trained animal. It thus 
appears that cortical computation in general may occur by dynamical interaction of 
resonant modes, as has been thought to be the case in the olfactory system. Given 
the sensitivity of neurons to the location and arrival times of dendritic input, the 
Associative Memory in a Simple Model of Oscillating Cortex 69 
sucessive volleys of pulses that are generated by the collective oscillation of a neu- 
ral net may be ideal for the formation and reliable longe range transmission of the 
collective activity of one cortical area to another. The oscillation can serve a macro- 
scopic clocking function and entrain the relevant microscopic activity of disparate 
cortical regions into well defined phase coherent macroscopic collective states which 
overide uncorrelated microscopic activity. If this view is correct, then oscillatory 
network modules form the actual cortical substrate of the diverse sensory, motor, 
and cognitive operations now studied in static networks, and it must ultimately be 
shown how those functions can be accomplished with these dynamic networks. 
In particular, we are interested here in modeling category learning and object recog- 
nition, after feature preprocessing. Equivalence classes of ratios of feature outputs 
in feature space must be established as prototype objects or categories that are 
invariant over endless sensory instances. Without categories, the world never re- 
peats. This is the kind of function generally hypothesized for prepyriform cortex 
in the olfactory system[6], or inferotemporal cortex in the visual system. It is a 
different oscillatory network function from the feature binding, or clustering role 
that is hypothesized for phase labels in primary visual cortex [5], or from the 
decision states hypothesized for the olfactory bulb by Li and Hopfield. In these 
preprocessing systems, there is no modification of connections, and no learning of 
particular perceptual objects. For category learning, full adaptive cross coupling 
is required so that all possible input feature vectors may be potential attractors. 
This is the kind of anatomical structure that characterizes prepyriform and infer- 
otemporal cortex. The columns there are less structured, and the associational 
fiber system is more prominent than in primary cortex. Man shares this same high 
level association cortex structure with cats and rats. Phylogenetically, it is the 
preprocessing structures of primary cortex that have grown and evolved to give us 
our expanded capabilities. While the bulk of our pattern recognition power may be 
contributed by the clever feature preprocessing that has developed, the object clas- 
siftcation system seems the most likely locus of the learning changes that underlie 
our daily conceptual evolution. That is the phenomenon of ultimate interest in this 
work. 
2 Minimal Model of Oscillating Cortex 
Analog state variables, recurrence, oscillation, and bifurcation are hypothesized 
to be essential features of cortical networks which we explore in this approach. 
Explicit modeling of known excitatory and inhibitory neurons, and use of only 
known long range connections is also a basic requirement to have a biologically 
feasible network architecture. We analyse a minimal model that is intended to 
assume the least coupling that is justified by known anatomy, and use simulations 
and analytic results proved in [1, 2] to argue that an oscillatory associative memory 
function can be realized in such a system. The network is meant only as a cartoon 
of the real biology, which is designed to reveal the general mathematical principles 
and mechanisms by which the actual system might function. Such principles can 
then be observed or applied in other contexts as well. 
70 Baird 
Long range excitatory to excitatory connections are well known as associational 
connections in olfactory cortex[6], and cortico-cortico connections in neocortex. 
Since our units are neural populations, we know that some density of full cross- 
coupling exists in the system[6], and our weights are the average synaptic strengths 
of these connections. There is little problem at the population level with coupling 
symmetry in these average connection strenghts emerging from the operation of an 
outer product learning rule on initially random connections. When the network 
units are neuron pools, analog state variables arise naturally as continuous local 
pulse densities and cell voltage averages. Smooth sigmoidal population input-output 
functions, whose slope increases with arousal of the animal, have been measured in 
the olfactory system[4]. Local inhibitory interneurons are a ubiquitous feature 
of the anatomy of cortex throughout the brain[5]. It is unlikely that they make 
long range connections (> I mm) by themselves. These connections, and even the 
debated interconnections between them, are therefore left out of a minimal model. 
The resulting network is actually a fair caricature of the well studied circuitry of 
olfactory (prepyriform) cortex. This is thought to be one of the clearest cases of a 
real biological network with associative memory function [6]. Although neocortex 
is far more complicated, it may roughly be viewed as two olfactory cortices stacked 
on top of each other. We expect that analysis of this system will lend insight into 
mechanisms of associative memory there as well. In [3] we show that this model 
is capable of storing complicated multifrequency spatio-temporal trajectories, and 
argue that it may serve as a model of memory for sequences of actions in motor 
cortex. 
For an N dimensional system, the minimal coupling structure is described math- 
ematically by the matrix 
T- gI 0 ' 
where W is the N/2 x N/2 matrix of excitatory interconnections, and gI and hi are 
N/2 x N/2 identity matrices multiplied by the positive scalars g, and h. These give 
the strength of coupling around local inhibitory feedback loops. A state vector is 
composed of local average cell voltages for N/2 excitatory neuron populations  and 
N/2 inhibitory neuron populations  (hereafter notated as x, y  Rs/2). Standard 
network equations with this coupling might be, in component form, 
v/2 
ki - -rxi - ha(yi) -{- E Wija(xJ) -{- bi (1) 
Oi = --ryi + ga(xi), (2) 
where r(x) = tanh(x) or some other sigmoidal function symmetric about 0. In- 
tuitively, since the inhibitory units Yi receive no direct input and give no direct 
output, they act as hidden units that create oscillation for the amplitude patterns 
stored in the excitatory cross-connections W. This may be viewed as a simple gen- 
eralization of the analog Hopfield network architecture to store periodic instead 
of static attractors. 
Associative Memory in a Simple Model of Oscillating Cortex 71 
If we expand this network to third order in a Taylors series about the origin, we get 
a network that looks something like, 
i = -ryi q- gxi, (4) 
where at(O) = 1, and  m 
.,a (0)(< 0) is absorbed into Wijki. A sigmoid symmetric 
about zero has odd symmetry, and the even order terms of the expansion vanish, 
leaving the cubic terms as the only nonlinearity. The actual expansion of the ex- 
citatory sigmoids in (1,2) (in this coordinate system) will only give cubic terms of 
x',NI2 3 
the form z-i= l/Viixi ï¿½ The competitive (negative) cubic terms of (3) therefore con- 
stitute a more general and directly programmable nonlinearity that is independent 
of the linear terms. They serve to create multiple periodic attractors by causing 
the oscillatory modes of the linear term to compete, much as the sigmoidal non- 
linearity does for static modes in a Hopfield network. Intuitively, these terms may 
be thought of as sculpting the maxima of a saturation landscape into which the 
stored linear modes with positive eigenvalues expand, and positioning them to lie 
in the directions specified by the eigenvectors of these modes to make them stable. 
A precise definition of this landscape is given by a strict Liapunov function in a 
special polar coordinate system[1, 3]. Since we have had no success storing multiple 
oscillatory attractors in the sigmoid net (1,2) by any learning rule, we are driven 
to take this very effective higher order net seriously as a biological model. From a 
physiological point of view, (3,4) may be considered a model of a biological network 
which is operating in the linear region of the known axonal sigmoid nonlinearities[4], 
and contains instead sigma-pi units or higher order synaptic nonlinearities. 
2.1 Biological justification of th
