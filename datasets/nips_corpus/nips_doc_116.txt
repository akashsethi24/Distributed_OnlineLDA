5O2 
LINKS BETWEEN MARKOV MODELS AND 
MULTILAYER PERCEPTRONS 
H. Bourlard t,* & C.J. Wellekens t 
(t)Philips Research Laboratory 
Brussels, B-1170 Belgium. 
(*)Int. Comp. Science Institute 
Berkeley, CA 94704 USA. 
ABSTRACT 
Hidden Markov models are widely used for automatic speech recog- 
nition. They inherently incorporate the sequential character of the 
speech signal and are statistically trained. However, the a-priori 
choice of the model topology limits their flexibility. Another draw- 
back of these models is their weak discriminating power. Multilayer 
perceptrons are now promising tools in the connectionist approach 
for classification problems and have already been successfully tested 
on speech recognition problems. However, the sequential nature of 
the speech signal remains difficult to handle in that kind of ma- 
chine. In this paper, a discriminant hidden Markov model is de- 
fined and it is shown how a particular multilayer perceptron with 
contextual and extra feedback input units can be considered as a 
general form of such Markov models. 
INTRODUCTION 
Hidden Markov models (HMM) [Jelinek, 1976; Bourlard et al., 1985] are widely used 
for automatic isolated and connected speech recognition. Their main advantages 
lie in the ability to take account of the time sequential order and variability of 
speech signals. However, the a-priori choice of a model topology (number of states, 
probability distributions and transition rules) limits the flexibility of the HMM's, 
in particular speech contextual information is difficult to incorporate. Another 
drawback of these models is their weak discriminating power. This fact is clearly 
illustrated in [Bourlard & Wellekens, 1989; Waibel et al., 1988] and several solutions 
have recently been proposed in [Bahl et al., 1986; Bourlard & Wellekens, 1989; 
Brown, 1987]. 
The multilayer perceptton (MLP) is now a familiar and promising tool in con- 
nectionist approach for classification problems [Rumelhart et al., 1986; Lippmann, 
1987] and has already been widely tested on speech recognition problems [Waibel 
et al., 1988; Watrous & Shastri, 1987; Bourlard & Wellekens, 1989]. However, the 
sequential nature of the speech signal remains difficult to handle with MLP. It is 
shown here how an MLP with contextual and extra feedback input units can be 
considered as a form of discriminant HMM. 
Links Between Markov Models and Multilayer Percepttons 503 
STOCHASTIC MODELS 
TRAINING CRITERIA 
Stochastic speech recognition is based on the comparison of an utterance to be 
recognized with a set of probabilistic finite state machines known as HMM. These 
are trained such that the probability P(WIX ) that mode] Wi has produced the 
associated utterance X must be maximized, but the parameter space which this 
optimization is performed over makes the difference between independently trained 
models and discriminant ones. 
Indeed, the probability P(WilX) can be written as 
e(XlW,).P(W,) 
e(W, lX) = e(x) 
In a recognition phase, P(X) may be considered as a constant since the model 
parameters are fixed but, in a training phase, this probability depends on the pa- 
rameters of all possible models. Taking account of the fact that the models are 
mutually exclusive and if A represents the parameter set (for all possible models), 
(1) may then be rewritten as: 
p(XlWi, 
P(WlX, = e(XlW,,)e(wO + 
(2) 
Maximization of P(Wi IX, ) as given by (2) is usually simplified by restricting it 
to the subspace of the W/ parameters. This restriction leads to the Maximum 
Likelihood Estimators (MLE). The summation term in the denominator is constant 
over the parameter space of W/and thus, maximization of P(XIWi, ) implies that 
of its bilinear map (2). A language model provides the value of P(Wi) independently 
of the acoustic decoding [Jelinek, 1976]. 
On the other hand, maximization of P(Wi I X, ) with respect to the whole parameter 
space (i.e. the parameters of all models W, W2,...) leads to discriminant models 
since it implies that the contribution of P(XIWi, )P(Wi) should be enhanced while 
that of the rival models, represented by 
-P(XIW,,)P(W), 
should be reduced. This maximization with respect to the whole parameter space 
has been shown equivalent to the maximization of Mutual Information (MMI) be- 
tween a model and a vector sequence [Bahl et al., 1986; Brown, 1987]. 
STANDARD HIDDEN MARKOV MODELS 
In the regular discrete HMM, the acoustic vectors (e.g. corresponding to 10 ms 
speech frames) are generally quantized in a front-end processor where each one is 
replaced by the closest (e.g. according to an Euclidean norm) prototype vector 
504 Bourlard and Wellekens 
Yi selected in a predetermined finite set y of cardinality I. Let Q be a set of K 
different states q(k), with k = 1,..., K. Markov models are then constituted by the 
association (according to a predefined topology) of some of these states. If HMM are 
trained along the MLE criterion, the parameters of the models (defined hereunder) 
must be optimized for maximizing P(XIW ) where X is a training sequence of 
quantized acoustic vectors x  y, with n = 1,...,N and W is its associated 
Markov model made up of L states qt  Q with � = 1,..., L. Of course, the same 
state may occur several times with different indices �, so that L  K. Let us denote 
by q the presence on state qt at a given time n  [1, N]. Since events qn 
 are 
mutually exclusive, probability ?(XIW) can be written for any arbitrary n: 
L 
p(xlw) = p(q, xlw), 
�=1 
where P(q, XIW ) denotes thus the probability that X is produced by W while 
associating xn with state q. Maximization of (3) can be worked out by the classical 
forward-backward recurrences of the Baom-Welch algorithm [Jelinek 1976, Bourlard 
et al., 1985] 
Maximization of P(XIW) is also usually approximated by the Viterbi criterion. It 
can be viewed as a simplified version of the MLE criterion where, instead of taking 
account of all possible state sequences in W capable of producing X, one merely 
considers the most probable one. To make all possible paths apparent, (3) can also 
be rewritten as 
L L 
P(XIW ) = ...  P(q,',qN,,xIW), 
�=1 
and the explicit formulation of the Viterbi criterion is obtained by replacing all 
summations by a max operator. Probability (3) is then approximated by: 
(XIW ) = max P(q,,...,qNN,xIw) ' (4) 
and can be calculated by the classical dynamic time warping (DTW) algorithm 
[Bourlard et al., 1985]. In that case, each training vector is then uniquely associated 
with only one particular transition. 
In both cases (MLE and Viterbi), it can be shown that, according to classical 
hypotheses, P(XIW) and P(XIW) are estimated from the set of local parameters 
p[q(g),uilq(-)(k), w], for i = 1,...,I and k,� = 1,...,K. Notations q(-)(k) and 
q(�) denote states  Q observed at two consecutive instants. In the particular case 
of the Viterbi criterion, these parameters are estimated by: 
nit Vi  [1, I], Vk,�  [1, K] (5) 
/5[q(�), uilq(-)(k)] -- K , , 
where ni} denotes the number of times each prototype vector  has been associ- 
ated with a particular transition from q(k) to q(�) during the training. However, if 
Links Between Markov Models and Multilayer Percepttons 505 
the models are trained along this formulation of the Viterbi algorithm, no discrimi- 
nation is taken into account. For instance, it is interesting to observe that the local 
probability (5) is not the suitable measure for the labeling of a prototype vector 
Yi, i.e. to find the most probable state given a current input vector and a specified 
previous state. Indeed, the decision should ideally be based on the Bayes rule. In 
that cae, the most probable state q(�ort) is defined by 
tort = argnax p[q(�)[yi,q(-)(k)], (6) 
and not on the basis of (5). 
It can easily be proved that the estimate of the Bayes probabilities in (6) are: 
IS[q(�)lyi,q(-)(k)] = K nikt 
Em=l )ikra 
(7) 
In the last section, it is shown that these values can be generated at the output of 
a particular MLP. 
DISCRIMINANT HMM 
For quantized acoustic vectors and Viterbi criterion, an alternative HMM using 
discriminant local probabilities can also be described. Indeed, as the correct crite- 
rion should be based on (1), comparing with (4), the Viterbi formulation of this 
probability is 
(WIX ) = max P(q,...,q,,W[X). (8) 
Expression (8) clearly puts the best path into evidence. The right hand side factor- 
izes into 
IX).P(wIx, I N 
p(q, N WlX)- P(q,, ,qtv qt,, ,qtv) 
, � ' ', qtv, ....... 
and suggests two separate steps for the recognition. The first factor represents the 
acoustic decoding in which the acoustic vector sequence is converted into a sequence 
of states. Then, the second factor represents a phonological and lexical step: once 
the sequence of states is known, the model W associated with X can be found from 
the state sequence without an explicit dependence on X so that 
N N 
P(WIX, q], ,qtv)= P(Wlq, , � 
.... qtv) 
For example, if the states represent phonemes, this probability must be estimated 
from phonological knowledge of the vocabulary once for all in a separate process 
without any reference to the input vector sequence. 
On the contrary, P(q], ..., qtNNI X) is immediately related to the discriminant local 
probabilities and may be factorized in 
..,qNlX) p(q,lX).p(qlX, .P(qtNlX, N-1 
� = ' (9) 
506 Bourlard snd Wellekens 
Now, each factor of (9) may be simplified by relaxing the conditional constraints. 
More specifically, the factors of (9) are assumed dependent on the previous state 
only and on a signal window of length 2p + 1 centered around the current acoustic 
vector. The current expression of these local contributions becomes 
i ql i-1 
p(q,lX,  .,q._) = p(q. ri+io i-. 
' .... i-p'qt,_) ' 
(10) 
where input contextual information is now taken into account, X, denoting the 
vector sequence z,,, z,,+, ..., z,. If input contextual information is neg
