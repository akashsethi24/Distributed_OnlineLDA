Remote Sensing Image Analysis via a Texture 
Classification Neural Network 
Hayit K. Greenspan and Rodney Goodman 
Department of Electrical Engineering 
California Institute of Technology, 116-81 
Pasadena, CA 91125 
hayit@electra.micro. calt ech.edu 
Abstract 
In this work we apply a texture classification network to remote sensing im- 
age analysis. The goal is to extract the characteristics of the area depicted 
in the input image, thus achieving a segmented map of the region. We have 
recently proposed a combined neural network and rule-based framework 
for texture recognition. The framework uses unsupervised and supervised 
learning, and provides probability estimates for the output classes. We 
describe the texture classification network and extend it to demonstrate 
its application to the Landsat and Aerial image analysis domain. 
I INTRODUCTION 
In this work we apply a texture classification network to remote sensing image 
analysis. The goal is to segment the input image into homogeneous textured regions 
and identify each region as one of a prelearned library of textures, e.g. tree area and 
urban area distinction. Classification o f remote sensing imagery is of importance in 
many applications, such as navigation, surveillance and exploration. It has become 
a very complex task spanning a growing number of sensors and application domains. 
The applications include: landcover identification (with systems such as the AVIRIS 
and SPOT), atmospheric analysis via cloud-coverage mapping (using the AVHRR 
sensor), oceanographic exploration for sea/ice type classification (SAR input) and 
more. 
Much attention has been given to the use of the spectral signature for the identifica- 
425 
426 Greenspan and Goodman 
tion of region types (Wharton, 1987; Lee and Philpot, 1991). Only recently has the 
idea of adding on spatial information been presented (Ton et al, 1991). In this work 
we investigate the possibility of gaining information from textural analysis. We 
have recently developed a texture recognition system (Greenspan et al, 1992) which 
achieves state-of-the-art results on natural textures. In this paper we apply the 
system to remote sensing imagery and check the system's robustness in this noisy 
environment. Texture can play a major role in segmenting the images into homoge- 
neous areas and enhancing other sensors capabilities, such as multispectra analysis, 
by indicating areas of interest in which further analysis can be pursued. Fusion of 
the spatial information with the spectral signature will enhance the classification 
and the overall automated analysis capabilities. 
Most of the work in the literature focuses on human expert-based rules with specific 
sensor data calibration. Some of the existing problems with this classic approach 
are the following (Ton et al, 1991): 
- Experienced photointerpreters are required to spend a considerable amount of 
time generating rules. 
- The rules need to be updated for different geographical regions. 
- No spatial rules exist for the complex Landsat imagery. 
An interesting question is if one can automate the rule generation. In this paper we 
present a learning framework in which spatial rules are learned by the system from 
a given database of examples. 
The learning framework and its contribution in a texture-recognition system is the 
topic of section 2. Experimental results of the system's application to remote sensing 
imagery are presented in section 3. 
2 The texture-classification network 
We have previously presented a texture classification network which combines a 
neural network and rule-based framework (Greenspan et al, 1992) and enables both 
unsupervised and supervised learning. The system consists of three major stages, 
as shown in Fig. 1. The first stage performs feature extraction and transforms the 
image space into an array of 15-dimensional feature vectors, each vector correspond- 
ing to a local window in the original image. There is much evidence in animal visual 
systems supporting the use of multi-channel orientation selective band-pass filters 
in the feature-extraction phase. An open issue is the decision regarding the appro- 
priate number of frequencies and orientations required for the representation of the 
input domain. We define an initial set of 15 filters and achieve a computationally 
efficient filtering scheme via the multi-resolution pyramidal approach. 
The learning mechanism shown next derives a minimal subset of the above filters 
which conveys sufficient information about the visual input for its differentiation 
and labeling. In an unsupervised stage a machine-learning clustering algorithm is 
used to quantize the continuous input features. A supervised learning stage follows 
in which labeling of the input domain is achieved using a rule-based network. Here 
an information theoretic measure is utilized to find the most informative correlations 
between the attributes and the pattern class specification, while providing proba- 
bility estimates for the output classes. Ultimately, a minimal representation for a 
library of patterns is learned in a training mode, following which the classification 
Remote Sensing Image Analysis via a Texture Classification Neural Network 427 
BPF SUPERVISED 
UNSUPR VISED 
/' Window Continuous Ouantized 
� of Input Image Feature- Vector Feature- Vector 
TEXTURE 
CLASSES 
FEATURE-EXTRACTION LEARNING 
PHASE PHASE 
Figure 1: System block diagram 
of new patterns is achieved. 
2.1 The system in more detail 
The initial stage for a classification system is the feature extraction phase. In the 
texture-analysis task there is both biological and computational evidence support- 
ing the use of Gabor-like filters for the feature-extraction. In this work, we use 
the Log Gabor pyramid, or the Gabor wavelet decomposition to define an initial 
finite set of filters. A computational efficient, scheme involves using a pyramidal 
representation of the image which is convolved with fixed spatial support oriented 
Gabor filters (Greenspan at al, 1993). Three scales are used with 4 orientations per 
scale (0,90,45,135 degrees), together with a non-oriented component, to produce a 
15-dimensional feature vector as the output of the feature extraction stage. Using 
the pyramid representation is computationally efficient as the image is subsampled 
in the filtering process. Two such size reduction stages take place in the three scale 
pyramid. The feature values thus generated correspond to the average power of the 
response, to specific orientation and frequency ranges, in an 8 � 8 window of the 
input image. Each such window gets mapped to a 15-dimensional attribute vector 
as the output of the feature extraction stage. 
The goal of the learning system is to use the feature representation described above 
to discriminate between the input patterns, or textures. Both unsupervised and 
supervised learning stages are utilized. A minimal set of features are extracted fi'om 
the 15-dimensional attribute vector, which convey sufficient information about the 
visual input for its differentiation and labeling. 
The unsupervised learning stage can be viewed as a preprocessing stage for achiev- 
ing a more compact representation of the filtered input. The goal is to quantize the 
continuous valued features which are the result of the initial filtering, thus shifting 
to a more symbolic representation of the input donmin. This clustering stage was 
found experimentally to be of importance as an initial learning phase in a classi- 
fication system. The need for discretization becomes evident when trying to learn 
associations between attributes in a symbolic representation, such as rules. 
428 Greenspan and Goodman 
The output of the filtering stage consists of N (-15), continuous valued feature 
maps; each representing a filtered version of the original input. Thus, each local 
area of the input image is represented via an N-dimensional feature vector. An 
array of such N-dimensional vectors, viewed across the input image, is the input 
to the learning stage. We wish to detect characteristic behavior across the N- 
dimensional feature space, for the family of textures to be learned. In this work, each 
dimension, out of the 15-dimensional attribute vector, is individually clustered. All 
training samples are thus projected onto each axis of the space and one-dimensional 
clusters are found using the K-means clustering algorithm (Duda and Hart, 1973). 
This statistical clustering technique consists of an iterative procedure of finding 
K means in the training sample space, following which each new input sample is 
associated with the closest mean in Euclidean distance. The means, labeled 0 thru K 
minus 1 arbitrarily, correspond to discrete codewords. Each continuous-valued input 
sample gets mapped to the discrete codeword representing its associated mean. The 
output of this preprocessing stage is a 15-dimensional quantized vector of attributes 
which is the result of concatenating the discrete-valued codewords of the individual 
dimensions. 
In the final, supervised stage, we utilize the existing information in the feature 
maps for higher level analysis, such as input labeling and classification. A rule - 
based information theoretic approach is used which is an extension of a first order 
Bayesian classifier, because of its ability to output probability estimates for the out- 
put classes (Goodman et al, 1992). The classifier defines correlations between input 
features and output classes as probabilistic rules. A data driven supervised learning 
approach utilizes an information theoretic measure to learn the most informative 
links or rules between features and class labels. The classifier then uses these links 
to provide an estimate of the probability of a given output class being true. When 
presented with a new input evidence vector, a set of rules R can be considered to 
fire. The classifier e
