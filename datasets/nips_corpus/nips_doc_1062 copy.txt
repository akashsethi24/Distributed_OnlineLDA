Generalisation of A Class of Continuous 
Neural Networks 
John Shawe-Taylor 
Dept of Computer Science, 
Royal Holloway, University of London, 
Egham, Surrey TW20 0EX, UK 
Emai]: j ohndcs. rhbnc. ac. uk 
Jieyu Zhao* 
IDSIA, Corso Elvezia 36, 
6900-Lugano, Switzerland 
Email: j ieyu$�arota. idsia. �h 
Abstract 
We propose a way of using boolean circuits to perform real valued 
computation in a way that naturally extends their boolean func- 
tionahty. The functionahty of multiple fan in threshold gates in 
this model is shown to mimic that of a hardware implementation 
of continuous Neural Networks. A Vapnik-Chervonenkis dimension 
and sample size analysis for the systems is performed giving best 
known sample sizes for a real valued Neural Network. Experimen- 
tal results confirm the conclusion that the sample sizes required for 
the networks are significantly smaller than for sigmoidal networks. 
1 Introduction 
Recent developments in complexity theory have addressed the question of com- 
plexity of computation over the real numbers. More recently attempts have been 
made to introduce some computational cost related to the accuracy of the compu- 
tations [5]. The model proposed in this paper weakens the computational power 
still further by relying on classical boolean circuits to perform the computation us- 
ing a simple encoding of the real values. Using this encoding we also show that 
TO0 circuits interpreted in the model correspond to a Neural Network design re- 
ferred to as Bit Stream Neural Networks, which have been developed for hardware 
implementation [8]. 
With the perspective afforded by the general approach considered here, we are also 
able to analyse the Bit Stream Neural Networks (or indeed any other adaptive sys- 
tem based on the technique), giving VC dimension and sample size bounds for PAC 
learning. The sample sizes obtained are very similar to those for threshold networks, 
*Work performed while at Royal Holloway, University of London 
268 J. SHAWE-TAYLOR, J. ZHAO 
despite their being derived by very different techniques. They give the best bounds 
for neural networks involving smooth activation functions, being significantly lower 
than the bounds obtained recently for sigmoidal networks [4, 7]. 
We subsequently present simulation results showing that Bit Stream Neural Net- 
works based on the technique can be used to solve a standard benchmark problem. 
The results of the simulations support the theoretical finding that for the same 
sample size generalisation will be better for the Bit Stream Neural Networks than 
for classical sigmoidal networks. It should also be stressed that the approach is 
very general - being applicable to any boolean circuit - and by its definition em- 
ploys compact digital hardware. This fact motivates the introduction of the model, 
though it will not play an important part in this paper. 
2 Definitions and Basic Results 
A boolean circuit is a directed acyclic graph whose nodes are referred to as gates, 
with a single output node of out-degree zero. The nodes with in-degree zero are 
termed input nodes. The nodes that are not input nodes are computational nodes. 
There is a boolean function associated with each computational node of arity equal 
to its in-degree. The function computed by a boolean network is determined by 
assigning (input) values to its input nodes and performing the function at each 
computational node once its input values are determined. The result is the value 
at the output node. The class TCo is defined to be those functions that can be 
computed by a family of polynomially sized Boolean circuits with unrestricted fan- 
in and constant depth, where the gates are either NOT or THRESHOLD. 
In order to use the boolean circuits to compute with real numbers we use the method 
of stochastic computing to encode real numbers as bit streams. The encoding we 
will use is to consider the stream of binary bits, for which the 1's are generated 
independently at random with probabihty p, as representing the number p. This 
is referred to as a Bernoulli sequence of probability p. In this representation, the 
multiphcation of two independently generated streams can be achieved by a simple 
AND gate, since the probability of a 1 on the output stream is equal to plp2, where 
pl is the probability of a i on the first input stream and p2 is the probabihty of 
a i on the second input stream. Hence, in this representation the boolean circuit 
consisting of a single AND gate can compute the product of its two inputs. 
More background information about stochastic computing can be found in the work 
of Gaines [1]. The analysis we provide is made by treating the calculations as exact 
real valued computations. In a practical (hardware) implementation real bit streams 
would have to be generated [3] and the question of the accuracy of a delivered result 
arises. 
In the applications considered here the output values are used to determine a binary 
value by comparing with a threshold of 0.5. Unless the actual output is exactly i or 
0 (which can happen), then however many bits are collected at the output there is a 
slight probabihty that an incorrect classification will be made. Hence, the number 
of bits required is a function of the difference between the actual output and 0.5 
and the level of confidence required in the correctness of the classification. 
Definition I The real function computed by a boolean circuit C, which computes 
the boolean function 
fc: {0, 1} ' {0, 1}, 
is the function 
gc: [0, 1] ' ) [0, 1], 
Generalisation of a Class of Continuous Neural Networks 269 
obtained by coding each input independently as a Bernoulli sequence and interpreting 
the output as a similar sequence. 
Hence, by the discussion above we have for the circuit C consisting of a single AND 
gate, the function gc is given by gc(xx, x9.) = xlx9.. 
We now give a proposition showing that the definition of real computation given 
above is well-defined and generalises the Boolean computation performed by the 
circuit. 
Proposition 2 The bit stream on the output of a boolean circuit computing a real 
function is a Bernoulli sequence. The real function gc computed by an n input 
boolean circuit C can be expressed in terms of the corresponding boolean function 
fc as follows: 
where 
P(a) - H x?'(1 - xi) (1-'). 
In particular, 
=fc. 
Proof: The output bit stream is a Bernoulli sequence, since the behaviour at each 
time step is independent of the behaviour at previous time sequences, assuming the 
input sequences are independent. Let the probability of a i in the output sequence 
be p. Hence, gc(x): p. At any given time the input to the circuit must be one 
of the 2 n possible binary vectors c. Pz(c) gives the probability of the vector c 
occurring. Hence, the expected value of the output of the circuit is given in the 
proposition statement, but by the properties of a Bernoulli sequence this value is 
also p. The final claim holds since P.(a) = 1, while P.(a') = 0 for a y a'.. 
Hence, the function computed by a circuit can be denoted by a polynomial of degree 
n, though the representation given above may involve exponentially many terms. 
This representation will therefore only be used for theoretical analysis. 
3 Bit Stream Neural Networks 
In this section we describe a neural network model based on stochastic computing 
and show that it corresponds to taking TCo circuits in the framework considered 
in Section 2. 
A Stochastic Bit Stream Neuron is a processing unit which carries out very simple 
operations on its input bit streams. All input bit streams are combined with their 
corresponding weight bit streams and then the weighted bits are summed up. The 
final total is compared to a threshold value. If the sum is larger than the threshold 
the neuron gives an output 1, otherwise 0. 
There are two different versions of the Stochastic Bit Stream Neuron corresponding 
to the different data representations. The definitions are given as follows. 
Definition 3 (AND-SBSN): A n-input AND version Stochastic Bit Stream Neu- 
ron has n weights in the range [-1,1] and n inputs in the range [0,1], which are all 
unipolar representations of Bernoulli sequences. An extra sign bit is attached to 
each weight Bernoulli sequence. The threshold 0 is an integer lying between -n to n 
which is randomly generated according to the threshold probability density function 
eft(O). The computations performed during each operational cycle are 
2 70 J. SHAWE-TAYLOR, J. ZHAO 
(1) combining respectively the n bits from n input Bernoulli sequences with the 
corresponding n bits from n weight Bernoulli sequences using the AND operation. 
(2) assigning n weight sign bits to the corresponding output bits of the AND gate, 
summing up all the n signed output bits and then comparing the total with the 
randomly generated threshold value. If the total is not less than the threshold value, 
the AND-SBSN outputs 1, otherwise it outputs O. 
We can now present the main result characterising the functionality of a Stochastic 
Bit Stream Neural Network as the real function of an TCo circuit. 
Theorem 4 The functionality of a family of feedforward networks of Bit Stream 
Neurons with constant depth organised into layers with interconnections only be- 
tween adjacent layers corresponds to the function gc for an TCo circuit C of depth 
twice that of the network. The number of input streams is equal to the number 
of network inputs while the number of parameters is at most twice the number of 
weights. 
Proof: Consider first an individual neuron. We construct a circuit whose real 
functionality matches that of the neuron. The circuit has two layers. The first 
consists of a series of AND gates. Each gate links one input line of the neuron 
with its corresponding weight input. The outputs of these gates are linked into a 
threshold gate with fixed threshold 2d for the AND-SBSN, where d is the number 
of input l
