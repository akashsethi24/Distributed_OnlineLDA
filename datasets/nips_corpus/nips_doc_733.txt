How to Describe Neuronal Activity: 
Spikes, Rates, or Assemblies? 
Wulfram Getstrier and J. Leo van Hemmen 
Physik-Department der TU Miinchen 
D-85748 Garching bei Miinchen, Germany 
Abstract 
What is the 'correct' theoretical description of neuronal activity? 
The analysis of the dynamics of a globally connected network of 
spiking neurons (the Spike Response Model) shows that a descrip- 
tion by mean firing rates is possible only if active neurons fire in- 
coherently. If firing occurs coherently or with spatio-temporal cor- 
relations, the spike structure of the neural code becomes relevant. 
Alternatively, neurons can be gathered into local or distributed en- 
sembles or 'assemblies'. A description based on the mean ensemble 
activity is, in principle, possible but the interaction between differ- 
ent assemblies becomes highly nonlinear. A description with spikes 
should therefore be preferred. 
1 INTRODUCTION 
Neurons communicate by sequences of short pulses, the so-called action potentials 
or spikes. One of the most important problems in theoretical neuroscience concerns 
the question of how information on the environment is encoded in such spike trains: 
Is the exact timing of spikes with relation to earlier spikes relevant (spike or interval 
code (MacKay and McCulloch 1952) or does the mean firing rate averaged over sev- 
eral spikes contain all important information (rate code; see, e.g., Stein 1967)7 Are 
spikes of single neurons important or do we have to consider ensembles of equivalent 
neurons (ensemble code)7 If so, can we find local ensembles (e.g., columns; Hubel 
and Wiesel 1962) or do neurons form 'assemblies' (Hebb 1949) distributed all over 
the network7 
463 
464 Gerstner and van Hemmen 
2 SPIKE RESPONSE MODEL 
We consider a globally connected network of N neurons with 1 _< i < N. A neuron i 
fires, if its membrane potential passes a threshold 0. A spike at time t[ is described 
by a &pulse; thus Si(t) F 
---- Ef=i ((t -- t/f) is the spike train of neuron i. Spikes are 
labelled such that t is the most recent spike and t/F is the Ftn spike going back in 
time. 
In the Spike Response Model, short SRM, (Gerstner 1990, Gerstner and van Hem- 
men 1992) a neuron is characterized by two different response functions, e and l ref. 
Spikes which neuron i receives from other neurons evoke a synaptic potential 
N o 
j--1 
(1) 
where the response kernel 
: s-a' exp( 
T s Ts 
for s < Atr 
for s > Atr (2) 
describes a typical excitatory or inhibitory postsynaptic potential; see Fig. 1. The 
weight Zij is the synaptic efficacy of a connection from j to i, Atr is the axonal (and 
synaptic) transmission time, and rs is a time constant of the postsynaptic neuron. 
The origin s = 0 in (2) denotes the firing time of a presynaptic spike. In simulations 
we usually assume rs = 2 ms and for Atr a value between 1 and 4 ms 
Similarly, spike emission induces refractoriness immediately after spiking. This is 
modelled by a refractory potential 
h? (t) = (s)S 1 (t - s)d 
(3) 
with a refractory function 
{-cx for S < 7 re 
rf(s) = r/o/(S-7 ) for s  7 r'. 
(4) 
For 0 _ s _< 7 ! the neuron is in the absolute refractory period and cannot spike at 
all whereas for s > 7 ! spiking is possible but difficult (relative refractory period). 
To put it differently, 0 - r/ (s) describes an increased threshold immediately after 
spiking; cf. Fig. 1. In simulations, 7 ! is taken to be 4 ms. Note that, for the sake 
of simplicity, we assume that only the most recent spike $/ induces refractoriness 
whereas all past spikes $ contribute to the synaptic potential; cf., Eqs. (1) and (3). 
How to Describe Neuronal Activity: Spikes, Rates, or Assemblies? 465 
1,0 
0.0 
0.0 5.0 
10.0 15.0 20.0 
s[ms] 
Fig I Response functions. 
Immediately after firing at s = 
0 the effective threshold is in- 
creased to 0-r/f(s)(dashed). 
The form of an excitatory post- 
synaptic potential (EPSP) is 
described by the response func- 
tion e(s) (sohd). It is delayed by 
a time A tr. The arrow denotes 
the period Toc of coherent os- 
cillations; cf. Section 5. 
The total membrane potential is the sum of both parts, i.e. 
h,(t) = ? (t) + 
(5) 
Noise is included by introduction of a firing probability 
PF(h; St) = r-l (h ) St. (6) 
where 5t is an infinitesimal time interval and r(h) is a time constant which depends 
on the momentary value of the membrane potential in relation to the threshold 0. 
In analogy to the chemical reaction constant we assume 
r(h) = r0 exp[-/3(h - 0)], (7) 
where r0 is the response time at threshold. The parameter/3 determines the amount 
of noise in the system. For/3 - oo we recover the noise-free behavior, i.e., a neuron 
fires immediately, if h > 0 (r - 0), but it cannot fire, if h < 0 (r - oo). Eqs. (1), 
(3), (5), and (6) define the spiking dynamics in a network of SRM-neurons. 
3 FIRING STATISTICS 
We start our considerations with a large ensemble of identical neurons driven by the 
same arbitrary synaptic potential hSU(t). We assume that all neurons have fired a 
first spike at t = tl . Thus the total membrane potential is h(t) = hY(t) + rl rf (t- 
tl). If h(t) slowly approaches 0, some of the neurons will fire again. We now ask 
for the probability that a neuron which has fired at time t{ will fire again at a later 
time t. The conditional probability P?)(tlt{) that the next spike of a given neuron 
occurs at time t > t{ is 
P(F2)(tltl ) = r-l[h(t)]exp - r-[h(s')]ds ' . (8) 
The exponential factor is the portion of neurons that have survived from time t{ to 
time t without firing again and the prefactor r-l[h(t)] is the instantaneous firing 
probability (6) at time t. Since the refractory potential is reset after each spike, 
the spiking statistics does not depend on earlier spikes, in other words, it is fully 
described by P?)(tlt). This will be used below; cf. Eq. (14). 
466 Gerstner and van Hemmen 
As a special case, we may consider constant synaptic input h y -- h �. In this case, 
(8) yields the distribution of inter-spike intervals in a spike train of a neuron driven 
by constant input h �. The mean firing rate at an input level h � is defined as the 
inverse of the mean inter-spike interval. Integration by parts yields 
f[h �] -- dt(t-t)P?)(tltl ) = ds exp { 7'-l[hOLvref(st)ld8 t } 
(9) 
Thus both firing rate and interval distribution can be calculated for arbitrary inputs. 
4 
ASSEMBLY FORMATION AND NETWORK 
DYNAMICS 
We now turn to a large, but structured network. Structure is induced by the 
formation of different assemblies in the system. Each neuronal assembly cu (Hebb 
1949) consists of neurons which have the tendency to be active at the same time. 
Following the traditional interpretation, active means an elevated mean firing rate 
during some reasonable period of time. Later, in Section 5.3, we will deal with a 
different interpretation where active means a spike within a time window of a few 
ms. In any case, the notion of simultaneous activity allows to define an activity 
pattern {, 1 _< i <_ N} with  = i if i G cu and  = 0 otherwise. Each neuron 
may belong to different assemblies 1 _< tt <_ q. The vector i = (/,...,[) is the 
'identity card' of neuron i, e.g., i = (1, 0, 0, 1, 0) says that neuron i belongs to 
assembly i and 4 but not to assembly 2,3, and 5. 
Note that, in general, there are many neurons with the same identity card. This 
can be used to define ensembles (or sublattices) L(x) of equivalent neurons, i.e., 
L(x) = {ili = x} (van Hemmen and Kiihn 1991). In general, the number of 
neurons IL(x)l in an ensemble L(x) goes to infinity if N - cx:, and we write 
IL(x)l = p(x)N. The mean activity of an ensemble L(x) can be defined by 
et+At 
A(x,t)= lim lim IL(x)l- x J, Sii(t)dt. (10) 
At--*0 
i ) 
In the following we assume that the synaptic efficacies have been adjusted according 
to some Hebbian learning rule in a way that allows to stabilize the different activity 
patterns or assemblies a u. To be specific, we assume 
J0 q q 
Jij -- - Y Y Qupost()pre() (11) 
/=1 ':1 
where post(x) and pre(x) are some arbitrary functions characterizing the pre- and 
postsynaptic part of synaptic learning. Note that for Qu = u and post(x) and 
pre(x) linear, Eq. (11) can be reduced to the usual Hebb rule. 
With the above definitions we can write the synaptic potential of a neuron i  L(x) 
in the following form 
q q oo 
h*Yx,t) = Jo Y. Y] Qupost(x ) y.pre(z ) fo (s')p(z)A(z,t - s')ds'. (12) 
/=1 ,=1 
How to Describe Neuronal Activity: Spikes, Rates, or Assemblies? 467 
We note that the index i and j has disappeared and there remains a dependence 
upon x and z only. The activity of a typical ensemble is given by (Gerstner and 
van Hemmen 1993, 1994) 
A(x, t): P?)(tlt- s)A(x,t- s)ds (13) 
where 
p?)(tlt_s)=r-l[hY(x,t)+rf*/(s)]exp- ' 
(14) 
is the conditional probability (8) that a neuron i  L(x) which has fired at time 
t-s fires again at time t. Equations (12) - (14) define the ensemble dynamics of the 
network. 
5 DISCUSSION 
5.1 ENSEMBLE CODE 
Equations. (12) - (14) show that in a large network a description by mean ensemble 
activities is, in principle, possible. A couple of things, however, should be noted. 
First, the interaction between the activity of different ensembles is highly nonlinear. 
It involves three integrations over the past and one exponentiation; cf. (12) - (14). 
If we had started theoretical modeling with an approach based on mean activities, 
it would have been hard to find the correct interaction term. 
Second, L(x) defines an ensemble of equivalent neurons which is a subset of a given 
assembly cu. A reduction of (12) to pure assembly activities is, in general, not 
possible. Finally, equivalent neurons that form an ensemble L(x) are not necessarily 
situated next to each other. In fact, they may be distributed all over the network; 
cf. Fig. 2. In this case a local ensemble average yields meaningless results
