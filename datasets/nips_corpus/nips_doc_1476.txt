Coordinate Transformation Learning of 
Hand Position Feedback Controller by 
Using Change of Position Error Norm 
Eimei Oyama* 
Mechanical Eng. Lab. 
Namiki 1-2, Tsukuba Science City 
Ibaraki 305-8564 Japan 
Susurnu Tachi 
The University of Tokyo 
Hongo 7-3-1, Bunkyo-ku 
Tokyo 113-0033 Japan 
Abstract 
In order to grasp an object, we need to solve the inverse kine- 
matics problem, i.e., the coordinate transformation from the visual 
coordinates to the joint angle vector coordinates of the arm. Al- 
though several models of coordinate transformation learning have 
been proposed, they suffer from a number of drawbacks. In human 
motion control, the learning of the hand position error feedback 
controller in the inverse kinematics solver is important. This paper 
proposes a novel model of the coordinate transformation learning 
of the human visual feedback controller that uses the change of 
the joint angle vector and the corresponding change of the square 
of the hand position error norm. The feasibility of the proposed 
model is illustrated using numerical simulations. 
1 INTRODUCTION 
The task of calculating every joint angle that would result in a specific hand position 
is called the inverse kinematics problem. An important topic in neuroscience is the 
study of the learning mechanisms involved in the human inverse kinematics solver. 
We questioned five pediatricians about the motor function of infants suffering from 
serious upper limb disabilities. The doctors stated that the infants still were able 
to touch and stroke an object without hindrance. In one case, an infant without 
a thumb had a major kinematically influential surgical operation, transplanting an 
index finger as a thumb. After the operation, the child was able to learn how to 
use the index finger like a thumb [1]. In order to explain the human motor learning 
*Phone:+81-298-58-7298, Fax:+81-298-58-7201, e-mail:eimei@mel.go.jp 
Coordinate Transformation Learning of Feedback Controller 1039 
capability, we believe that the coordinate transformation learning of the feedback 
controller is a necessary component. 
Although a number of learning models of the inverse kinematics solver have been 
proposed, a definitive learning model has not yet been obtained. This is from the 
point of view of the structural complexity of the learning model and the biolog- 
ical plausibility of employed hypothesis. The Direct Inverse Modeling employed 
by many researchers [2] requires the complex switching of the input signal of the 
inverse model. When the hand position control is performed, the input of the in- 
verse model is the desired hand position, velocity, or acceleration. When the inverse 
model learning is performed, the input is the observed hand position, velocity, or 
acceleration. Although the desired signal and the observed signal could coincide, 
the characteristics of the two signals are very different. Currently, no research has 
succeesfully modeled the switching system. Furthermore, that learning model is not 
goal-directed; i.e., there is no direct way to find an action that corresponds to a 
particular desired result. The Forward and Inverse Modeling proposed by Jordan 
[3] requires the back-propagation signal, a technique does not have a biological ba- 
sis. That model also requires the complex switching of the desired output signal 
for the forward model. When the forward model learning is performed, the desired 
output is the observed hand position. When the inverse kinematics solver learn- 
ing is performed, the desired output is the desired hand position. The Feedback 
Error Learning proposed by Kawato [4] requires a pre-existing accurate feedback 
controller. 
It is necessary to obtain a learning model that possesses a number of characteristics: 
(1) it can explain the human learning function; (2) it has a simple structure; and 
(3) it is biologically plausible. This paper presents a learning model of coordinate 
transformation function of the hand position feedback controller. This model uses 
the joint angle vector change and the corresponding change of square of the hand 
position error norm. 
2 BACKGROUND 
2.1 Discrete Time First Order Model of Hand Position Controller 
Let 0  R m be the joint angle vector and x  R be the hand position/orientation 
vector given by the vision system. The relationship between x and 0 is expressed 
as x - f(O) where f is a C  class function. The Jacobian of the hand position 
vector is expressed as J(O) = Of(O)/00. Let Xd be the desired hand position and 
e -- Xd -- x = Xd -- f(O) be the hand position error vector. In this paper, an 
inverse kinematics problem is assumed to be a least squares minimization problem 
that calculates 0 in order to minimize the square of the hand position error norm 
$(zd, 0) -lel2/2 -Izd- j(0)12/2. 
First, the feed-forward controller in the human inverse kinematics solver is disre- 
garded and the following first order control system, consisting of a learning feedback 
controller, is considered: 
0(k+ 1) = O(k) +AO(k) (1) 
Disturbance Joint Angle 
Position [Feedback ' Noise d(k) Vector 
Error + z__ 
 e(k) Controller  
Desired 
Hand [ ' �  
Position  T 
Hand 
Position 
x(? 
Figure 1: Configuration of 1-st Order Model of Hand Position Controller 
1040 E. Oyama and S. Tachi 
zx0(k) = fb(0(k),e()) + a() (2) 
e() = xd- f(0()) (a) 
where d(k) is assumed to be a disturbance noise from all components except the 
hand position control system. Figure 1 shows the configuration of the control sys- 
tem. In this figure, z -x is the operator that indicates a delay in the discrete time 
signal by a sampling interval of At. Although the human hand position control sys- 
tem includes higher order complex dynamics terms which are ignored in Equation 
(2), McRuer's experimental model of human compensation control suggests that the 
term that converts the hand position error to the hand velocity is a major term in 
the human control system [5]. We consider Equation (2) to be a good approximate 
model for the analysis of human coordinates transformation learning. 
The learner fb(0, e)  R , which provides the hand position error feedback, is 
modeled using the artificial neural network. In this paper, the hand position error 
feedback controller learning by observing output x(k) is considered without any 
prior knowledge of the function f(O). 
2.2 Learning Model of the Neural Network 
Let Ib(O,e ) be the desired output of the learner Ifb(O,e). Ib(O,e ) functions as 
a teacher for I'fb(O, e). Let fb(O, e) be the updated output of I'ib(O, e) by the 
learning. Let E[t(O, e)[O, e] be the expected value of a scalar, a vector, or a matrix 
function t(O, e) when the input vector (0, e) is given. We assume that I'ib(O, e) is 
an ideal learner which is capable of realizing the mean of the desired output signal, 
completely. 'I'+ib(O, e) can be expressed as follows: 
� I'b(O,e )  E[I,(O,e)lO, e ] = I'.fb(O,e) + E[AI'.fb(O,e)lO, e ] (4) 
Ab(0, ) = (0, ) - (0, e) (5) 
When the expected value of Alb(0, e) is expressed as: 
E[,x,f(o,)lO,]  - a(0, ), () 
Ri b  R  x  is a positive definite matrix, d the inequality 
0(0, ) 0( -(n - )(0, )) 
10e) I = I 0fb(0, e) I < 1 (7) 
is satisfied, the fin learning result c be expressed : 
� f,(O,e) m RGive (8) 
by the iteration of the update of f, (0, e) expressed in Equation (4). 
3 USE OF CHANGE OF POSITION ERROR NORM 
3.1 A Novel Learning Model of Feedback Controller 
The change of the square of the hand position error norm S = S(xd, 0 + 0) -- 
S(xd, O) reflects whether or not the change of the joint angle vector A0 is in proper 
direction. The propose novel leaning model can be expressed  follows: 
where a is a small positive re number. We now consider a lge number of tris 
of Equation (2) with a large variety of initial status 0(0) with learnings conducted 
at the point of the input space of the feedback controller (0, e) = (O(k - 1), e(k - 1)) 
at time k. S d 0 can be cculated as follows. 
S = S(k) - S(k- 1) = ([e(k)l  -le(k- 1)1 ) (10) 
0 = 0(- 1) (xx) 
Coordinate Transformation Learning of Feedback Controller 1041 
Change of Square of 
[ S_.quat..of [ Hand Position Error Norm 
Hand 
Position 
Error 
e(k) 
Error Signal for '  1 
Feedback lnpul for  ] lnpm for 
Learning ', ] Control 
 AO(10 
Change of 
JointAngle 
Vector 
(15) 
where � is a 2-operand operator that indicates the Croneker's product. H(xd, O)  
R TM is the Hessian of S(xd, 0). O(AO 3) is the sum of third nd higher order 
terms of A0 in each equation. When A0 is small enough, the following approximate 
equations axe obtained: 
Therefore, AS can be approximated as follows: 
AS  -erJ(O)AO + 1 
10J(O) 
2 O0 
-- � A0)A0 (16) 
(17) 
determined as: 
1 
AS(xa, O) - OS(xa, O) AO+ AoTH(xa, O)AO +O(AO 3) 
oo 
10J(O)  
= --eT(j(O) + 20 � AO)AO + AOTjT(O)J(O)AO + O(AO a) 
Distutbalme 
Con.oiler d( k ) 
o(k- l ) o(k ) 
Figure 2: Configuration of Learning Model of Feedback Controller 
Figure 2 shows the conceptual diagram of the proposed learning model. 
Let p(q[O, e) be the probability density function of a vector q at at the point (0, e) 
in the input space of Ib(0, e). In order to simplify the analysis of the proposed 
learning model, d(k) is assumed to satisfy the following equation: 
p(dlO, e) = p(-dlO, e) (12) 
When A0 is small enough, the result of the learning using Equation (9) can be 
expressed as: 
� I, ib(O,e )  a(RoJr(O)J(O) + I)-XRoJr(O)e (13) 
Ro = E[AoAoTIO, e] (14) 
where Jr(O)e is a vector in the steepest descent direction of S(xa, 0). When d(k) is 
a non-zero vector, Ro is a positive definite symmetric matrix and (RoJrJ + I) -1 
is a positive definite matrix. When a is appropriate, l,(0, e) as expressed in 
Equation (13) can provide appropriate output error feedback control. The deriva- 
tion of the above result will be illustrated in Section 3.2. A partially modified 
steepest descent direct
