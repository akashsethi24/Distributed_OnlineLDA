419 
COMPUTER MODELING OF ASSOCIATIVE LEARNING 
DANIEL L. ALKON 1 FRANCIS QUEK 2a THOMAS P. VOGL 2b 
1. Laboratory for Cellular and Molecular 
Neurobiology, NINCDS, NIH, Bethesda, MD 20892 
Environmental Research Institute of Michigan 
a) P.O. Box 8618, Ann Arbor, MI 48107 
b) 1501 Wilson Blvd., Suite 1105, Arlington, 
VA 22209 
ABSTRACT
INTRODUCTION 
Most of the current neural networks use models which have 
only tenuous connections to the biological neural systems 
on which they purport to be based, and negligible input 
from the neuroscience/biophysics communities. This paper 
describes an ongoing effort which approaches neural net 
research in a program of close collaboration of neuros- 
cientists and engineers. The effort is designed to 
elucidate associative learning in the marine snail 
Hermissenda crassicornis, in which Pavlovian conditioning 
has been observed. Learning has been isolated in the four 
neuron network at the convergence of the visual and 
vestibular pathways in this animal, and biophysical 
changes, specific to learning, have been observed in the 
membrane of the photoreceptor B cell. A basic charging 
capacitance model of a neuron is used and enhanced with 
biologically plausible mechanisms that are necessary to 
replicate the effect of learning at the cellular level. 
These mechanisms are non-linear and are, primarily, 
instances of second order control systems (e.g., fatigue, 
modulation of membrane resistance, time dependent 
rebound), but also include shunting and random background 
firing. The output of the model of the four-neuron 
network displays changes in the temporal variation of 
membrane potential similar to those observed in electro- 
physiological measurements. 
420 Alkon, Quek and Vogl 
NEUROPHYSIOLOGICAL BACKGROUND 
Alkon  showed that Hermissenda crassicornis, a marine 
snail, is capable of associating two stimuli in a fashion 
which exhibits all the characteristics of classical 
Pavlovian conditioning (acquisition, retention, extinc- 
tion, and savings) 2. In these experiments, Hermissenda 
were trained to associate a visual with a vestibular 
stimulus. In its normal environment, Hermissenda moves 
toward light; in turbulence, the animal increases the area 
of contact of its foot with the surface on which it is 
moving, reducing its forward velocity. Alkon showed that 
the snail can be condi-tioned to associate these stimuli 
through repeated exposures to ordered pairs (light 
followed by turbulence). 
When the snails are exposed to light (the unconditioned 
stimulus) followed by turbulence (the conditioned 
stimulus) after varying time intervals, the snails 
transfer to the light their unconditioned response to 
turbulence (increased area of foot contact); i.e., when 
presented with light alone, they respond with an increased 
area of foot contact. The effect of such training lasts 
for several weeks. It was further shown that the learning 
was maximized when rotation followed light by a fixed 
interval of about one second, and that such learning 
exhibits all the characteristics of classical conditioning 
observed in higher animals. 
The relevant neural interconnections of Hermissenda have 
been mapped by Alkon, and learning has been isolated in 
the four neuron sub-network (Figure 1) at the con-vergence 
of the visual and vestibular pathways of this animal. 
Light generates signals in the B cells while turbulence is 
transduced into signals by the statocyst's hair cells, the 
animal's vestibular organs. The optic ganglion cell 
mediates the interconnections between the two sensory 
pathways. 
The effects of learning also ve been observed at the 
cellular level. Alkon eta have shown that bio- 
physical changes associated with learning occur in the 
photo-receptor B cell of Hermissenda. The signals in 
the neurons take the form of voltage dependent ion 
Computer Nio&eling of Associative Learning 
421 
A B c 
$ooC�s 
ton networ t the convergence of 
u Iqerm ssend craS- 
-  four ne _-+avs of ermiS 
. 1. = � r ''  � ate ,- 
9ur vestbua P----s ndc .... .naOSes. 
. vsUal and 'lled enu,,j,  xcitatory . 
t . _ All _ ',n ind,Cq___ om the 
sc�rnl o en ,d,.-. ' h% ' 'i he oP 
' all P .... -+c n _ ,,nto t 
he type B 
recept nto t � drect 
� 1. . ck o . . 
lon cgl c feedp_ � at&on, .,_ � ell 
gang � - s napt exct hair c 
b) pgstve irect ?P%. es the ?Ph tnc. nhibitS 
 eotor: 1, an toq ect no thus ds 
that nh'- 
he. hecada hir cell '. lhe cephlic 
t pe B.ce,f_ ,tersensory ;,' nhibitOrY' ' 
 In%r-. au_;;' s are mutually ' 
d Crassicorn s' 
422 Alkon, Quek and Vogl 
currents, and learning is reflected in biophysical changes 
in the membrane of the B cell. The effects of ion 
currents can be observed in the form of time variations in 
membrane potential recorded by means of microelectrodes. 
It is the variation in membrane potential resulting from 
associative learning that is the focus of this research. 
Our goal is to model those properties of biological 
neurons sufficient (and necessary) to demonstrate associa- 
tive learning at the neural network level. In order to 
understand the effect and necessity of each component of 
the model, a minimalist approach was adopted. Nothing was 
added to the model which was not necessary to produce a 
required effect, and then only when neurophysiologists, 
biophysicists, electrical engineers, and computer scien- 
tists agreed that the addition was reasonable from the 
perspective of their disciplines. 
METHOD 
Following Kuffler and Nicholas 4, the model is described 
in terms of circuit elements. It must be emphasized 
however, that this is simply a recognition of the fact 
that the chemical and physical processes occurring in the 
neuron can be described by (partial) differential equa- 
tions, as can electronic circuits. The equivalent circuit 
of the charging and discharging of the neuron 
membrane is shown in Figure 2. The model was constructed 
using the P3 network simulation shell developed by Zipser 
and Rabin s. The P3 strip-chart capability was 
particularly useful in facilitating interdisciplinary 
interactions. Figure 3 shows the response of the basic 
model of the neuron as the frequency of input pulses is 
varied. 
Our aim, however, is not to model an individual neuron. 
Rather, we consistently focus on properties of the neural 
network that are necessary and sufficient to demonstrate 
associative learning. Examination of the behavior of 
biological neurons reveals additional common properties 
that express themselves differently depending on the 
function of the individual neuron. These properties 
include background firing, second order controls, and 
shunting. Their inclusion in the model is necessary for 
the simulation of associative learning, and their im- 
plementation is described below. 
Computer Modeling of Associative Learning 423 
INPUT CIRCUITRY 
R S 
0 C R 
o 
,, 
0 Rk NN Sk/ 
* ' Sdecay / C 
membrane 
potential 
S. S k 
� closes when there are input EPSPs to the 
the cell, otherwise , open. 
' 'S(ecay ' closes when there is no input ESPSs to the 
the cell, otherwise, open. 
Figure 2. Circuit model of the basic neuron. The lines 
from the left are the inputs to the neuron from its 
R_, s ar 
dendritic connections 'to presynaptic n.eurons. ' e 
the resistances that determine the magn;tude of th,'effect 
(voltage) of the pulses from presynaptic neurons. The gap 
indicated by open circles is a high impedance coupler. R 
through R, together with C, determine the rise time for 
the kth ;nput of the potential across the capacitor C, 
which represents the membrane. Rdeca controls the dis- 
charge time constant of the capacitor C When the 
membrane potential (across C) exceeds threshold potential, 
the neuron fires a pulse into its axon (to all output 
connections) and the charge on C is reduced by the 
discharge quantum (see text). 
BACKGROUND FIRING IN ALL NEURONS 
Background firing, i.e., spontaneous firing by neurons 
without any input pulses from other neurons, has been 
observed in all neurons v. The fundamental importance of 
background firing is exemplified by the fact that in the 
four neuron network under study, the optic ganglion does 
424 Alkon, Quek and Vogl 
Figure 3. Response of the basic model of a single neuron 
to a variety of inputs. The four horizontal strips, from 
top to bottom, show: 1) the input stream; 2) the resulting 
membrane potential; 3) the resulting stream of output 
pulses; and 4) the composite output of pulses superimposed 
on the membrane potential, emulating the corresponding 
electrophysiological measurement. The four vertical 
sections, from left to right, indicate: a) an extended 
input, simulating exposure of the B cell to light; b) a 
presynaptic neuron firing at maximum frequency; c) a 
presynaptic neuron firing at an intermediate frequency; d) 
a presynaptic neuron firing at a frequency insufficient to 
cause the neuron to fire.but sufficient to maintain the 
neuron at a membrane potential just below firing 
threshold. 
BACKGROUND FIRING IN ALL NEURONS (Continued) 
not have any synapses that excite it (all its inputs are 
inhibitory). However, the optic ganglion provides the 
only two excitatory synapses in the entire network (one on 
the photoreceptor B cell and the other on the cephalad 
statocyst hair cell). Hence, without back-ground firing, 
i.e., when there is no external stimuli of the neurons, 
all activity in the network would cease. 
Further, without background firing, any stimulus to either 
the vestibular or the visual receptors will completely 
swamp the response of the network. 
Computer Modeling of Associative Learning 425 
Background firing is incorporated in our model by applying 
random pulses to a 'virtual' excitatory synapse. By 
altering the mean frequency of the random pulses, various 
levels of 'internal' homeostatic neuronal activity can be 
simulat
