215 
Consonant Recognition by Modular Construction of 
Large Phonemic Time-Delay Neural Networks 
Alex Waibel 
Carnegie-Mellon University 
Pittsburgh, PA 15213, 
ATR Interpreting Telephony Research Laboratories 
Osaka, Japan 
Abstract 
In this paper 1 we show that neural networks for speech recognition can be constructed in 
a modular fashion by exploiting the hidden structure of previously trained phonetic 
subcategory networks. The performance of resulting larger phonetic nets was found to be 
as good as the performance of the subcomponent nets by themselves. This approach 
avoids the excessive learning times that would be necessary to Ixain larger networks and 
allows for incremental learning. Large time-delay neural networks constructed 
incrementally by applying these modular training techniques achieved a recognition 
performance of 96.0% for all consonants. 
1. Introduction 
Recently we have demonstrated that connectionist architectures capable of capturing 
some critical aspects of the dynamic nature of speech, can achieve superior recognition 
performance for difficult but small phonemic discrimination tasks such as discrimination 
of the voiced consonants B,D and G [Waibel 89, Waibel 88a]. Encouraged by these 
results we wanted to explore the question, how we might expand on these models to 
make them useful for the design of speech recognition systems. A problem that emerges 
as we attempt to apply neural network models to the full speech recognition problem is 
the problem of scaling. Simply extending neural networks to ever larger structures and 
retraining them as one monolithic net quickly exceeds the capabilities of the fastest and 
largest supercomputers. The search complexity of finding a good solutions in a huge 
space of possible network configurations also soon assumes unmanageable proportions. 
Moreover, having to decide on all possible classes for recognition ahead of time as well 
as collecting sufficient data to Ixain such a large monolithic network is impractical to say 
the least. In an effort to extend our models from small recognition tasks to large scale 
speech recognition systems, we must therefore explore modularity and incremental 
learning as design strategies to break up a large learning task into smaller subtasks. 
Breaking up a large task into subtasks to be tackled by individual black boxes 
interconnected in ad hoc arrangements, on the other hand, would mean to abandon one of 
the most atlxactive aspects of connectionism: the ability to perform complex constraint 
satisfaction in a massively parallel and interconnected fashion, in view of an overall 
optimal performance goal. In this paper we demonstrate based on a set of experiments 
aimed at phoneme recognition that it is indeed possible to construct large neural networks 
incrementally by exploiting the hidden structure of smaller pretrained subcomponent 
1An extended version of this paper will also appear in the Proceedings of the 1989 Intemational Conference 
on Acoustics, Speech and Signal Processing. Copyright: IEEE. Reprinted with permission. 
9.16 Wabl 
networks. 
2. Small Phonemic Classes by Time-Delay Neural Networks 
In our previous work, we have proposed a Time-Delay Neural Network architecture (as 
shown on the left of Fig. 1 for B,D,G) as an approach to phoneme discrimination that 
achieves very high recognition scores [Waibel 89, Waibel 88a]. Its multilayer 
architecture, its shift-invariance and the time delayed connections of its units all 
contributed to its performance by allowing the net to develop complex, non-linear 
decision surfaces and insensitivity to misalignments and by incorporating contextual 
information into decision making (see [Waibel 89, Waibel 88a] for detailed analysis and 
discussion). It is trained by the back-propagation procedure [Rumelhart 86] using shared 
weights for different time shifted positions of the net [Waibel 89, Waibel 88a]. In spirit it 
has similarities to other models recently proposed [Watrous 88, Tank 87]. This network, 
however, had only been trained for the voiced stops B,D,G and we began our extensions 
by training similar networks for the other phonemic classes in our database. 
], maim 
:ffZlllm .liBIll 
-n; ï¿½ [1111111 
15 frames 
10 msec frame rate 
H,delen L,lye' 2 
Hdelen Layer 1 
Figui'e 1. The TDNN architecture: BDG-net (left), BDGPTK-net (righ0 
All phoneme tokens in our experiments were extracted using phonetic handlabels from a 
large vocabulary database of 5240 common Japanese words. Each word in the database 
was spoken in isolation by one male native Japanese speaker. All utterances were 
recorded in a sound proof booth and digitized at a 12 kHz sampling rate. The database 
was then split into a training set and a testing set of 2620 utterances each. A 150 msec 
range around a phoneme boundary was excised for each phoneme token and 16 mel scale 
filterbank coefficients computed every 10 msec [waibel 89, Waibel 88a]. The 
Consonant Recognition by Modular Construction 217 
preprocessed training and testing data was then used to train or to evaluate our TDNNs' 
performance for various phoneme classes. For each class, TDNNs with an architecture 
similar to the BDG-net in Fig. 1 were trained. A total of seven nets aimed at the major 
coarse phonetic classes in Japanese were trained, including voiced stops B, D, G, 
voiceless stops P,T,K, the nasals M, N and syllabic nasals, fricatives S, SH, H and Z, 
affficates CH, TS, liquids and glides R, W, Y and finally the set of vowels A, I, U, E and 
O. Each of these nets was given between two and five phoneroes to distinguish and the 
pertinent input data was presented for learning. Note, that each net was trained only 
within each respective coarse class and has no notion of phonemes from other classes yet. 
Evaluation of each net on test data within each of these subcategories revealed that an 
average rate of 98.8% can be achieved (see [Waibel 88b] for a more detailed tabulation of 
results). 
3. Scaling TDNNs to Larger Phonemic Classes 
We have seen that TDNNs achieve superior recognition performance on difficult but 
small recognition tasks. To train these networks substantial computational resources 
were needed. This raises the question of how our networks could be extended to 
encompass all phonemes or handle speech recognition in general. To shed light on this 
question of scaling, we consider first the problem of extending our networks from the 
task of voiced stop consonant recognition (hence the BDG-task) to the task of 
distinguishing among all stop consonants (the BDGPTK-task). 
For a network aimed at the discrimination of the voiced stops (a BDG-net), 
approximately 6000 connections had to be trained over about 800 training tokens. An 
identical net (also with approximately 6000 connections 2) can achieve discrimination 
among the voiceless stops CP, T and K). To extend our networks to the recognition 
of all stops, i.e., the voiced and the unvoiced stops (B,D,G,P,T,K), a larger net is 
required. We have trained such a network for experimental purposes. To allow for the 
necessary number of features to develop we have given this net 20 units in the first 
hidden layer, 6 units in hidden layer 2 and 6 output units. On the fight of Fig. 1 we show 
this net in actual operation with a G presented at its input. Eventually a high 
performance network was obtained that achieves 98.3% correct recognition over a 1613- 
token BDGPTK-test database, but it took inordinate amounts of learning to arrive at the 
trained net (18 days on a 4 processor Aliiant!). Although going from voiced stops to all 
stops is only a modest increase in task size, about 18,000 connections had to be trained. 
To make matters worse, not only the number of connections should be increased with 
task size, but in general the amount of training data required for good generalization of a 
larger net has to be increased as well. Naturally, there are practical limits to the size of a 
training database, and more training data translates into even more learning time. 
Learning is further complicated by the increased complexity of the higher dimensional 
weightspace in large nets as well as the limited precision of our simulators. Despite 
progress towards faster learning algorithms [Haffner 88, Fahlman 88], it is clear that we 
cannot hope for one single monolithic network to be trained within reasonable time as we 
2Note, that these am connections over which a back-propagation pass is performed during each iteration. 
Since many of them sham the same weights, only a small fraction (about 500) of them am actually free 
parameters. 
218 Wankel 
increase size to handle larger and larger tasks. Moreover, requiring that all classes be 
considered and samples of each class be presented during training, is undesirable for 
practical reasons as we contemplate the design of large neural systems. Alternative ways 
to modularly construct and incrementally train such large neural systems must therefore 
be explored. 
3.1. Experiments with Modularity 
Four experiments were performed to explore methodologies for constructing phonetic 
neural nets from smaller component subnets. As a task we used again stop consonant 
recognition (BDGPTK) although other tasks have recently been explored with similar 
success (BDG and MNsN) [Waibel 88c]. As in the previous section we used a large 
database of 5240 common Japanese words spoken in isolation from which the testing an 
training tokens for the voiced stops (the BDG-set) and for the voiceless stops (the PTK- 
set) was extracted. 
Two separate TDNNs have been trained. On testing data the BDG-net used here 
performed 98.3% correct for the BDG-set and the PTK-net achieved 98.7% correct 
recognition for the PTK-set. As a first naive attempt we have now simply run a speech 
token from either set (i.e., B,D,G,P,T or K) through both a BDG-net and a PTK-net and 
selected the class with the highest acti
