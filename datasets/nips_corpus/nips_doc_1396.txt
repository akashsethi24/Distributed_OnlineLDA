Neural Basis of ObjectsCentered 
Representations 
Sophie Deneve and Alexandre Pouget 
Georgetown Institute for Computational and Cognitive Sciences 
Georgetown University 
Washington, DC 20007-2197 
sophie, alex@giccs.georgetown.edu 
Abstract 
We present a neural model that can perform eye movements to a 
particular side of an object regardless of the position and orienta- 
tion of the object in space, a generalization of a task which has 
been recently used by Olson and Gettner [4] to investigate the neu- 
ral structure of object-centered representations. Our model uses an 
intermediate representation in which units have oculocentric recep- 
tive fields- just like collicular neurons-- whose gain is modulated by 
the side of the object to which the movement is directed, as well as 
the orientation of the object. We show that these gain modulations 
are consistent with Olson and Gettner's single cell recordings in the 
supplementary eye field. This demonstrates that it is possible to 
perform an object-centered task without a representation involv- 
ing an object-centered map, viz., without neurons whose receptive 
fields are defined in object-centered coordinates. We also show that 
the same approach can account for object-centered neglect, a situ- 
ation in which patients with a right parietal lesion neglect the left 
side of objects regardless of the orientation of the objects. 
Several authors have argued that tasks such as object recognition [3] and manipula- 
tion [4] are easier to perform if the object is represented in object-centered coordi- 
nates, a representation in which the subparts of the object are encoded with respect 
to a frame of reference centered on the object. Compelling evidence for the existence 
of such representations in the cortex comes from experiments on hemineglect-- a 
neurological syndrome resulting from unilateral lesions of the parietal cortex such 
that a right lesion, for example, leads patients to ignore stimuli located on the left 
side of their egocentric space. Recently, Driver et al. (1994) showed that the deficit 
can also be object-centered. Hence, hemineglect patients can detect a gap in the 
upper edge of a triangle when this gap is associated with the right side of the object 
Neural BaMs of Object- Centered Representations 25 
A. B. 
I 
Object-centered 
cueing 
Spatial ,  
cueing 
2 
Three possible locations: 
Time 
Left of the object Right of the object 
Figure 1: A- Driver et al. (1994) experiment demonstrating objectscentered neglect. 
Subjects were asked to detect a gap in the upper part of the middle triangle, while 
fixating at the cross, when the overall figure is tilted clockwise (top) or counterclock- 
wise (bottom). Patients perform worse for the clockwise condition, when the gap 
is perceived to be on the left of the overall figure. B- Sequence of screens presented 
on each trial in Olson and Gettner experiment (1995). 1- Fixation, 2- apparition of 
a cue indicating where the saccade should go, either in object-centered coordinates 
(object-centered cueing), or in screen coordinates (spatial cueing), 3- delay period, 
4- apparition of the bar in one of three possible locations (dotted lines), and 5- sac- 
cade to the cued location. C- Schematic response of an SEF neuron for 4 different 
conditions. Adapted from [4]. 
but not when it belongs to the left side (figure l-A). 
What could be the neural basis of these object-centered representations? The sim- 
plest scheme would involve neurons with receptive fields defined in object-centered 
coordinates, i.e., the cells respond to a particular side of an object regardless of 
the position and orientation of the object. A recent experiment by Olson and Get- 
tner (1995) supports this possibility. They recorded the activity of neurons in the 
supplementary eye field (SEF) while the monkey was performing object-directed 
saccades. The task consisted of making a saccade to the right or left side of a 
bar, independently of the position of the bar on the screen and according to the 
instruction provided by a visual cue. For instance, the cue corresponding to the 
instruction 'Go to the right side of the bar' was provided by highlighting the right 
side of a small bar briefly flashed at the beginning of the trial (step 2 in figure l-B). 
By changing the position of the object on the screen, it is possible to compare 
the activity of a neuron for movements involving different saccade directions but 
directed to the same side of the object, and vice-versa, for movements involving 
the same saccade direction but directed to opposite sides of the object. Olson and 
Gettner found that many neurons responded more prior to saccades directed to 
a particular side of the bar, independently of the direction of the saccades. For 
example, some neurons responded more for an upward right saccade directed to the 
left side of the bar but not at all for the same upward right saccade directed to the 
right side of the bar (column I and 3, figure 1-C). This would suggest that these 
neurons have bar-centered receptive 1 fields, i.e., their receptive fields are centered 
use the term receptive field in a general sense, meaning either receptive or motor 
26 S. Deneve and A. Pouget 
Figure 2: Schematic structure of the network with activity patterns in response 
to the horizontal bar shown in the V1 map and the command 'Go to the right'. 
Only one SEF map is active in this case, the one selective to the right edge of the 
bar (where right is defined in retinal coordinates), object orientation of 0 � and the 
command 'Go to the right'. The letter a, b, c and d indicate which map would be 
active for the same command but for various orientations of the object, respectively, 
0 �, 90 �, 180 �, 270 �. The dotted lines on the maps indicate the outline of the bar. 
Only a few representative connections are shown. 
on the bar and not on the retina. This would correspond to what we will call an 
explicit object-centered representation. 
We argue in this paper that these data are compatible with a different type of 
representation which is more suitable for the task performed by the monkey. We 
describe a neural network which can perform a saccade to the right, or left, boundary 
of an object, regardless of its orientation, position or size-- a generalization of the 
task used by Olson and Gettner. This network uses units with receptive fields 
defined in oculocentric coordinates, i.e., they are selective for the direction and 
amplitude of saccades with respect to the fixation point, just like collicular neurons. 
These tuning curves, however, are also modulated by two types of signals, the 
orientation of the object, and the command indicating the side of the object to 
which the saccade should be directed. We show that these response properties are 
compatible with the Olson and Gettner data and provide predictions for future 
experiments. We also show that a simulated lesion leads to object-centered neglect 
as observed by Driver et al. {1994). 
1 Network Architecture 
The network performs a mapping from the image of the bar and the command 
(indicating the side of the object to which the saccade must be directed) to the 
appropriate motor command in oculocentric coordinates (the kind of command 
observed in the frontal eye field, FEF). We use a bar whose left and right sides are 
defined with respect to a a triangle appearing on the top of the bar (see figure 2). 
The network is composed of four parts. The first two parts of the network models the 
field. 
Neural Basis of Object- Centered Representations 27 
lower areas in visual cortex, where visual features are segmented within retinotopic 
maps. In the first layer, the image is projected on a very simple Vl-like map (10 
by 10 neurons with activity equal to one if a visual feature appears within their 
receptive field, and zero otherwise). The second part on the network contains 4 
different V2 retinotopic maps, responding respectively to the right, left, top and 
bottom boundary of the bar. 
This model of V2 is intended to reproduce the response properties of a subset of 
cells recently discovered by Zhou et al. (1996). These cells respond to oriented 
edges, like V1 cells, but when the edge belongs to a closed figure, they also show 
a selectivity for the side on which the figure appears with respect to the edge. For 
example, a cell might respond to a vertical edge only if this edge is on the right 
side of the figure but not on the left (where right and left are defined with respect 
to the viewer, not the object itself). This was observed for any orientation of the 
edge, but we limit ourselves in this model to horizontal and vertical ones. 
The third part of the network models the SEF and is divided into 4 groups of 4 
maps, each group receiving connections from the corresponding map in V2 (figure 2). 
Within each group of maps, visual activity is modulated by signals related to the 
orientation of the object (assumed to be computed in temporal cortex) such that 
each of the 4 maps respond best for one particular orientation (respectively 0 �, 90 �, 
180 � and 270�). For example, a neuron in the second map of the top group responds 
maximally if: 1- there is an edge in its receptive field and the figure is below, and 
2- the object has an orientation of 90 � counterclockwise. Note that this situation 
arises only if the left side of the object appears in the cell's receptive field; it will 
never occur for the right side. However, the cell is only partially selective to the 
left side of the object, e.g., it does not respond when the left side is in the retinal 
receptive field and the orientation of the object is 270 � counterclockwise. 
These collection of responses can be used to generate an object-centered saccade by 
selecting the maps which are partially selective for the side of the object specified 
by the command. This is implemented in our network by modulating the S
