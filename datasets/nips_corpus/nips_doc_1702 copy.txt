Learning Statistically Neutral Tasks 
without Expert Guidance 
Ton Weijters 
Information Technology, 
Eindhoven University, 
The Netherlands 
Antal van den Bosch 
ILK, 
Tilburg University, 
The Netherlands 
Eric Postma 
Computer Science, 
Universiteit Maastricht, 
The Netherlands 
Abstract 
In this paper, we question the necessity of levels of expert-guided 
abstraction in learning hard, statistically neutral classification 
tasks. We focus on two tasks, date calculation and parity-12, that 
are claimed to require intermediate levels of abstraction that must 
be defined by a human expert. We challenge this claim by demon- 
strating empirically that a single hidden-layer BP-SOM network can 
learn both tasks without guidance. Moreover, we analyze the net- 
work's solution for the parity-12 task and show that its solution 
makes use of an elegant intermediary checksum computation. 
i Introduction 
Breaking up a complex task into many smaller and simpler subtasks facilitates 
its solution. Such task decomposition has proved to be a successful technique in 
developing algorithms and in building theories of cognition. In their study and 
modeling of the human problem-solving process, Newell and Simon [1] employed 
protocol analysis to determine the subtasks human subjects employ in solving a 
complex task. Even nowadays, many cognitive scientists take task decomposition, 
i.e., the necessity of explicit levels of abstraction, as a fundamental property of 
human problem solving. Dennis Norris' [2] modeling study on the problem-solving 
capacity of autistic savants is a case in point. In the study, Norris focuses on the 
date-calculation task (i.e., to calculate the day of the week a given date fell on), 
which some autistic savants have been reported to perform flawlessly [3]. In an 
attempt to train a multi-layer neural network on the task, Norris failed to get a 
satisfactory level of generalization performance. Only by decomposing the task into 
three sub-tasks, and training the separate networks on each of the sub-tasks, the 
date-calculation task could be learned. Norris concluded that the date-calculation 
task is solvable (learnable) only when it is decomposed into intermediary steps using 
human assistance [2]. 
The date-calculation task is a very hard task for inductive learning algorithms, 
because it is a statistically neutral task: all conditional output probabilities on 
any input feature have chance values. Solving the task implies decomposing it, 
if possible, into subtasks that are not statistically neutral. The only suggested 
decomposition of the date-calculation task known to date involves explicit assistance 
74 T. Weijters, A. v. d. Bosch and E. Postma 
MFN 
SOM 
- class A elements 
- class B elements 
- unlabelled element 
Figure 1' An example BP-SOM network. 
from a human supervisor [2]. This paper challenges the decomposition assumption 
by showing that the date-calculation task can be learned in a single step with a 
appropriately constrained single hidden-layer neural network. In addition, another 
statistically neutral task, called the parity-n task (given an n-length bit string of 
1's and O's, calculate whether the number of 1's is even or odd) is investigated. 
In an experimental study by Dehaene, Bossini, and Giraux [4], it is claimed that 
humans decompose the parity-n task by first counting over the input string, and 
then perform the even/odd decision. In our study, parity-12 is shown to be learnable 
by a network with a single hidden layer. 
2 BP-SOM 
Below we give a brief characterization of the functioning of BP-SOM. For details we 
refer to [5]. The aim of the BP-SOM learning algorithm is to establish a coopera- 
tion between BP learning and SOM learning in order to find adequately constrained 
hidden-layer representations for learning classification tasks. To achieve this aim, 
the traditional MFN architecture [6] is combined with SOMs [7]: each hidden layer of 
the MFN is associated with one SOM (See Figure 1). During training of the weights in 
the MEN, the corresponding SOM is trained on the hidden-unit activation patterns. 
After a number of training cycles of BP-SOM learning, each SOM develops a two- 
dimensional representation, that is translated into classification information, i.e., 
each SOM element is provided with a class label (one of the output classes of the 
task). For example, let the BP-SOM network displayed in Figure I be trained on 
a classification task which maps instances to either output class A or B. Three 
types of elements can be distinguished in the SOM: elements labelled with class A, 
elements labelled with class B, and unlabelled elements (no winning class could be 
found). The two-dimensional representation of the SOM is used as an addition to 
the standard BP learning rule [6]. Classification and reliability information from the 
SOMs is included when updating the connection weights of the MFN. The error of 
a hidden-layer vector is an accumulation of the error computed by the BP learning 
rule, and a SOM-error. The SOM-error is the difference between the hidden-unit 
activation vector and the vector of its best-matching element associated with the 
same class on the SOM. 
An important effect of including SOM information in the error signals is that clusters 
of hidden-unit activation vectors of instances associated with the same class tend 
to become increasingly similar to each other. On top of this effect, individual 
hidden-unit activations tend to become more streamlined, and often end up having 
activations near one of a limited number of discrete values. 
Learning Statistically Neutral Tasks without Expert Guidance 75 
3 The date-calculation task 
The first statistically neutral calculation task we consider is the date-calculation 
task: determining the day of the week on which a given date fell. (For instance, 
October 2, 1997 fell on a Friday.) Solving the task requires an algorithmic approach 
that is typically hard for human calculators and requires one or more intermediate 
steps. It is generally assumed that the identity of these intermediate steps follows 
from the algorithmic solution, although variations exist in the steps as reportedly 
used by human experts [2]. We will show that such explicit abstraction is not 
needed, after reviewing the case for the necessity of human assistance in learning 
the task. 
3.1 Date calculation with expert-based abstraction 
Norris [2] attempted to model autistic savant date calculators using a multi-layer 
feedforward network (MFN) and the back-propagation learning rule [6]. He intended 
to build a model mimicking the behavior of the autistic savant without the need 
either to develop arithmetical skills or to encode explicit knowledge about reg- 
ularities in the structure of dates. A standard multilayer network trained with 
backpropagation [6] was not able to solve the date-calculation task. Although the 
network was able to learn the examples used for training, it did not manage to 
generalize to novel date-day combinations. In a second attempt Norris split up the 
date-calculation task in three simpler subtasks and networks. 
Using the three-stage learning strategy Norris obtained a nearly perfect performance 
on the training material and a performance of over 90% on the test material (errors 
are almost exclusively made on dates falling in January or February in leap years). 
He concludes with the observation that The only reason that the network was able 
to learn so well was because it had some human assistance. [2, p.285]. In addition, 
Norris claims that even if the [backpropagation] net did have the right number of 
layers there would be no way for the net to distribute its learning throughout the 
net such that each layer learned the appropriate step in computation. [2, p. 290]. 
3.2 Date calculation without expert-based abstraction 
We demonstrate that with the BP-SOM learning rule, a single hidden-layer feedfor- 
ward network can become a successful date calculator. Our experiment compares 
three types of learning: standard backpropagation learning (BP, [6]), backpropa- 
gation learning with weight decay (BPWD, [8]), and BP-SOM learning. Norris used 
BP learning in his experiment which leads to overfitting [2] (a considerably lower 
generalization accuracy on new material as compared to reproduction accuracy on 
training material); BPWD learning was included to avoid overfitting. 
The parameter values for BP (including the number of hidden units for each task) 
were optimized by performing pilot experiments with BP. The optimal learning-rate 
and momentum values were 0.15 and 0.4, respectively. BP, BPWD, and BP-SOM were 
trained for a fixed number of cycles rrt = 2000. Early stopping, a common method 
to prevent overfitting, was used in all experiments with BP, BPWD, and BP-SOM [9]. 
In our experiments with BP-SOM, we used the same interval of dates as used by 
Norris, i.e., training and test dates ranged from January 1, 1950 to December $1, 
1999. We generated two training sets, each consisting of 3,653 randomly selected 
instances, i.e., one-fifth of all dates. We also generated two corresponding test sets 
and two validation sets (with 1,000 instances each) of new dates within the same 
50-year period. In all our experiments, the training set, test set, and validation set 
76 T. Weij'ters, A. v. d. Bosch and E. Postma 
Table 1: Average generalization performances (plus standard deviation, after '+'; 
averaged over ten experiments) in terms of incorrectly-processed training and test 
instances, of BP, BPWD, and BP-SOM, trained on the date-calculation task and the 
parity-12 task. 
BP:  incorrect BPWD: % incorrect BP-SOM: % incorrect 
Task Train I Test Train I Test Train I Test 
date calc. 20.8 +5.4 28.8 +7.8 1.5 + 0.3 8.8 +1.4 2.9 +2.0 3.3 +1.9 
parity-12 14.1 +18.8 27.4 +16.4 21.6 +24.2 22.4 +18.3 5.9 +10.2 6.2 +10.7 
had empty intersections. We partitioned the input int
