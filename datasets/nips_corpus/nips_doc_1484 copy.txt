A Principle for Unsupervised 
Hierarchical Decomposition of Visual Scenes 
Michael C. Mozer 
Dept. of Computer Science 
University of Colorado 
Boulder, CO 80309-0430 
ABSTRACT 
Structure in a visual scene can be described at many levels of granular- 
ity. At a coarse level, the scene is composed of objects; at a finer level, 
each object is made up of parts, and the parts of subparts. In this work, I 
propose a simple principle by which such hierarchical structure can be 
extracted from visual scenes: Regularity in the relations among different 
parts of an object is weaker than in the internal structure of a part. This 
principle can be applied recursively to define part-whole relationships 
among elements in a scene. The principle does not make use of object 
models, categories, or other sorts of higher-level knowledge; rather, 
part-whole relationships can be established based on the statistics of a 
set of sample visual scenes. I illustrate with a model that performs unsu- 
pervised decomposition of simple scenes. The model can account for 
the results from a human learning experiment on the ontogeny of part- 
whole relationships. 
1 INTRODUCTION 
The structure in a visual scene can be described at many levels of granularity. Con- 
sider the scene in Figure 1 a. At a coarse level, the scene might be said to consist of stick 
man and stick dog. However, stick man and stick dog themselves can be decomposed fur- 
ther. One might describe stick man as having two components, a head and a body. The 
head in turn can be described in terms of its parts: the eyes, nose, and mouth. This sort of 
scene decomposition can continue recursively down to the level of the primitive visual fea- 
tures. Figure 1 b shows a partial decomposition of the scene in Figure 1 a. 
A scene decomposition establishes part-whole relationships among objects. For 
example, the mouth (a whole) consists of two parts, the teeth and the lips. If we assume 
that any part can belong to only one whole, the decomposition imposes a hierarchical 
structure over the elements in the scene. 
Where does this structure come from? What makes an object an object, a part a part? 
I propose a simple principle by which such hierarchical structure can be extracted from 
visual scenes and incorporate the principle in a simulation model. The principle is based 
on the statistics of the visual environment, not on object models or other sorts of higher- 
level knowledge, or on a teacher to classify objects or their parts. 
Hierarchical Decomposition of Visual Scenes 53 
2 WHAT MAKES A PART A PART? 
Parts combine to form objects. Parts are combined in different ways to form different 
objects and different instances of an object. Consequently, the structural relations among 
different parts of an object are less regular than is the internal structure of a part. To illus- 
trate, consider Figure 2, which depicts four instances of a box shell and lid. The compo- 
nents of the lid--the top and the handle--appear in a regular configuration, as do the 
components of the shell--the sides and base--but the relation of the lid to the shell is vari- 
able. Thus, configural regularity is an indication that components should be grouped 
together to form a unit. I call this the regularity principle. Other variants of the regularity 
principle have been suggested by Becker (1995) and Tenenbaum (1994). 
The regularity depicted in Figure 2 is quite rigid: one component of a part always 
occurs in a fixed spatial position relative to another. The regularity principle can also be 
cast in terms of abstract relationships such as containment and encirclement. The only dif- 
ference is the featural representation that subserves the regularity discovery process. In 
this paper, however, I address primarily regularities that are based on physical features and 
fixed spatial relationships. Another generalization of the regularity principle is that it can 
be applied recursively to suggest not only parts of wholes, but subparts of parts. 
According to the regularity principle, information is implicit in the environment that 
can be used to establish part-whole relationships. This information comes in the form of 
statistical regularities among features in a visual scene. The regularity principle does not 
depend on explicit labeling of parts or objects. 
In contrast, Schyns and Murphy (1992, 1993) have suggested a theory of part ontog- 
eny that presupposes explicit categorization of objects. They propose a homogeneity prin- 
ciple which states that if a fragment of a stimulus plays a consistent role in 
categorization, the perceptual parts composing the fragment are instantiated as a single 
unit in the stimulus representation in memory. Their empirical studies with human sub- 
jects find support for the homogeneity principle. 
Superficially, the homogeneity and regularity principles seem quite different: while 
the homogeneity principle applies to supervised category learning (i.e., with a teacher to 
classify instances), the regularity principle applies to unsupervised discovery. But it is pos- 
sible to transform one learning paradigm into the other. For example, in a category learn- 
ing task, if only one category is to be learned and if the training examples are all positive 
instances of the category, then inducing the defining characteristics of the category is 
equivalent to extracting regularities in the stimulus environment. Thus, category learning 
in a diverse stimulus environment can be conceptualized as unsupervised regularity 
extraction in multiple, narrow stimulus environments (each environment being formed by 
taking all positive instances of a given class). 
(a) [ (b) 
scene 
stick man stick dog 
head body 
eyes nose mouth arm torso leg 
lips teeth 
FIGURE 1. (a) A graphical depiction of stick man and his faithful companion, stick dog; (b) a 
partial decomposition of the scene into its parts. 
FIGURE 2. Four different instances of a box with a lid 
54 M. C. Mozer 
There are several other differences between the regularity principle proposed here 
and the homogeneity principle of Schyns and Murphy, but they are minor. Schyns and 
Murphy seem to interpret fragment more narrowly as spatially contiguous perceptual 
features. They also don't address the hierarchical nature of part-whole relationships. 
Nonetheless, the two principles share the notion of using the statistical structure of the 
visual environment to establish part-whole relations. 
3 A FLAT REPRESENTATION OF STRUCTURE 
I have incorporated the regularity principle into a neural net that discovers part- 
whole relations in its environment. Neural nets, having powerful learning paradigms for 
unsupervised discovery, are well suited for this task. However, they have a fundamental 
difficulty representing complex, articulated data structures of the sort necessary to encode 
hierarchies (but see Pollack, 1988, and Smolensky, 1990, for promising advances). I thus 
begin by describing a novel representation scheme for hierarchical structures that can 
readily be integrated into a neural net. 
The tree structure in Figure 1 b depicts one representation of a hierarchical decompo- 
sition. The complete tree has as its leaf nodes the primitive visual features of the scene. 
The tree specifies the relationships among the visual features. There is another way of cap- 
turing these relationships, more connectionist in spirit than the tree structure. The idea is 
to assign to each primitive feature a tag--a scalar in [0, 1]--such that features within a 
subtree have similar values. For the features of stick man, possible tags might be: eyes .1, 
nose .2, lips .28, teeth .32, arm .6, torso .7, leg .8. 
Denoting the set of all features having tags in [or, [] by S(ot, [), one can specify any 
subtree of the stick man representation. For example, S(0,1) includes all features of stick 
man; S(0,.5) includes all features in the subtree whose root is stick man's head, S(.5,1) his 
body; S(.25,.35) indicates the parts of the mouth. By a simple algorithm, tags can be 
assigned to the leaf nodes of any tree such that any subtree can be selected by specifying 
an appropriate tag range. The only requirement for this algorithm is knowledge of the 
maximum branching factor. There is no fixed limit to the depth of the tree that can be thus 
represented; however, the deeper the tree, the finer the tag resolution that will be needed. 
The tags provide a flat way of representing hierarchical structure. Although the 
tree is implicit in the representation, the tags convey all information in the tree, and thus 
can capture complex, articulated structures. The tags in fact convey additional informa- 
tion. For example in the above feature list, note that lips is closer to nose than teeth is to 
nose. This information can easily be ignored, but it is still worth observing that the tags 
carry extra baggage not present in the symbolic tree structure. 
It is convenient to represent the tags on a range [0, 2) rather than [0,1 ]. This allows 
the tag to be identified with a directional or angular--value. Viewed as part of a cyclic 
continuum, the directional tags are homogeneous, in contrast to the linear tags where tags 
near 0 and 1 have special status by virtue of being at endpoints of the continuum. Homo- 
geneity results in a more elegant model, as described below. 
The directional tags also permit a neurophysiological interpretation, albeit specula- 
tive. It has been suggested that synchronized oscillatory activities in the nervous system 
can be used to convey information above and beyond that contained in the average firing 
rate of individual neurons (e.g., Eckhorn et al., 1988; Gray et al., 1989; von der Malsburg, 
1981). These oscillations vary in their phase, the relative offset of the bursts. The direc- 
tional tags could map directly to phases of oscillations, providing a means of implement- 
ing the tagging in neocortex. 
4
