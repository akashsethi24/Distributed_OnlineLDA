Learning to Segment Images 
Using Dynamic Feature Binding 
Michael C. Moser 
Dept. of Comp. Science & 
Inst. of Cognitive Science 
University of Colorado 
Boulder, CO 80309-0430 
Richard S. Zeme] 
Dept. of Comp. Science 
University of Toronto 
Toronto, Ontario 
Canada M5S 1A4 
Marlene Behrmann 
Dept. of Psychology & 
Faculty of Medicine 
University of Toronto 
Toronto, Ontario 
Canada M5S 1A1 
Abstract 
Despite the fact that complex visual scenes contain multiple, overlapping 
objects, people perform object recognition with ease and accuracy. One 
operation that facilitates recognition is an early segmentation process in 
which features of objects are grouped and labeled according to which ob- 
ject they belong. Current computational systems that perform this oper- 
ation are based on predefined grouping heuristics. We describe a system 
called MAOI� that learns how to group features based on a set of pre- 
segmented examples. In many cases, MAOI� discovers grouping heuristics 
similar to those previously proposed, but it also has the capability of find- 
ing nonintuitive structural regularities in images. Grouping is performed 
by a relaxation network that attempts to dynamically bind related fea- 
tures. Features transmit a complex-valued signal (amplitude and phase) 
to one another; binding can thus be represented by phase locking related 
features. MAGI�'S training procedure is a generalization of recurrent back 
propagation to complex-valued units. 
When a visual image contains multiple, overlapping objects, recognition is difficult 
because features in the image are not grouped according to which object they belong. 
Without the capability to form such groupings, it would be necessary to undergo a 
massive search through all subsets of image features. For this reason, most machine 
vision recognition systems include a component that performs feature grouping or 
image segmentation (e.g., Gu.man, 1968; Lowe, 1985; Mart, 1982). 
436 
Learning to Segment Images Using Dynamic Feature Binding 437 
A multitude of heuristics have been proposed for segmenting images. Gestalt psy- 
chologists have explored how people group elements of a display and have suggested 
a range of grouping principles that govern human perception (Rock & Palmer, 1990). 
Computer vision researchers have studied the problem from a more computation- 
al perspective. They have investigated methods of grouping elements of an image 
based on nonaccidental regularitiet--feature combinations that are unlikely to occur 
by chance when several objects are juxtaposed, and are thus indicative of a single 
object (Kanade, 1981; Lowe & Binford, 1982). 
In these earlier approaches, the researchers have hypothesized a set of grouping 
heuristics and then tested their psychological validity or computational utility. In 
our work, we have taken an adaptive approach to the problem of image segmenta- 
tion in which a system learns how to group features based on a set of examples. 
We call the system MA(IC, an acronym for multiple-object _adaptive grouping of 
image components. In many cases MA(IC discovers grouping heuristic similar to 
those proposed in earlier work, but it also has the capability of finding nonintuitive 
structural regularities in images. 
MAGIC is trained on a set of presegmented images containing multiple objects. By 
presegmented, we mean that each image feature is labeled as to which object it 
belongs. MA(I� learns to detect configurations of the image features that have a 
consistent labeling in relation to one another across the training examples. Identify- 
ing these configurations allows MAGIC to then label features in novel, unsegmented 
images in a manner consistent with the training examples. 
1 REPRESENTING FEATURE LABELINGS 
Before describing MAGIC, we must first discuss a representation that allows for 
the labeling of features. Von der Malsburg (1981), yon der Malsburg & Schneider 
(1986), Gray et al. (1989), and Eckhorn et al. (1988), among others, have suggested 
a biologically plausible mechanism of labeling through temporal correlations among 
neural signals, either the relative timing of neuronal spikes or the synchronization of 
oscillatory activities in the nervous system. The key idea here is that each processing 
unit conveys not just an activation valuc average firing frequency in neural terms m 
but also a second, independent value which represents the relative phase of firing. 
The dynamic grouping or binding of a set of features is accomplished by aligning 
the phases of the features. Recent work (Goebel, 1991; Hummel & Biederman, in 
press) has used this notion of dynamic binding for grouping image features, but has 
been based on relatively simple, predetermined grouping heuristics. 
2 THE DOMAIN 
Our initial work has been conducted in the domain of two-dimensional geometric 
contours, including rectangles, diamonds, crosses, triangles, hexagons, and octa- 
gons. The contours are constructed from four primitive feature types--oriented 
line segments at 0 �, 45 �, 90 �, and 135�mand are laid out on a 15 x 20 grid. At 
each location on the grid are units, called feature units, that detect each of the four 
primitive feature types. In our present experiments, images contain two contours. 
Contours are not permitted to overlap in their activation of the same feature unit. 
438 
Mozer, Zcm�l, and Bchrmann 
Figure 1: The architecture of MAGIC. The lower layer contains the feature units; the 
upper layer contains the hidden units. Each layer is arranged in a spatiotopic array 
with a number of different feature types at each position in the array. Each plane in 
the feature layer corresponds to a different feature type. The grayed hidden units 
are reciprocally connected to all features in the corresponding grayed region of the 
feature layer. The lines between layers represent projections in both directions. 
THE ARCHITECTURE 
The input to MAaIO is a pattern of activity over the feature units indicating which 
features are present in an image. The initial phases of the units are random. MAaIC's 
task is to assign appropriate phase values to the units. Thus, the network performs 
a type of pattern completion. 
The network architecture consists of two layers of units, as shown in Figure 1. The 
lower (input) layer contains the feature units, arranged in spatiotopic arrays with 
one array per feature type. The upper layer contains hidden units that help to align 
the phases of the feature units; their response properties are determined by training. 
Each hidden unit is reciprocally connected to the units in a local spatial region of 
all feature arrays. We refer to this region as a patch; in our current simulations, the 
patch has dimensions 4 x 4. For each patch there is a corresponding fLxed-size pool 
of hidden units. To achieve uniformity of response across the image, the pools are 
arranged in a spatiotopic array in which neighboring pools respond to neighboring 
patches and the weights of all pools are constrained to be the same. 
The feature units activate the hidden units, which in turn feed back to the feature 
units. Through a relaxation process, the system settles on an assignment of phases 
to the features. 
Learning to Segment Images Using Dynamic Feature Binding 439 
4 NETWORK DYNAMICS 
Formally, the response of each feature unit i, zi, is a complex value in polar form, 
(o4,pi), where o4 is the amplitude or activation and pi is the phase. Similarly, the 
response of each hidden unit j, p, has components (b, q). The weight connecting 
unit i to unit j, wi, is also complex valued, having components (pi,0ji). The 
activation rule we propose is a generalization of the dot product to the complex 
domain: 
netj = x. wj 
---- iiji 
where net i N the net Nput to Mdden ut j. The net Nput N psed through 
a squhNg nonearity that maps the mpHtude of the response from the range 
0   to 0  1 but leaves the phe unaffected: 
netj 
The flow of activation from the hidden layer to the feature layer follows the same 
dynamics, although in the current implementation the amplitudes of the features 
are clamped, hence the top-down flow affects only the phases. One could imagine a 
more general architecture in which the relaxation process determined not only the 
phase values, but cleaned up noise in the feature amplitudes as well. 
The intuition underlying the activation rule is as follows. The activity of a hidden 
unit, bi, should be monotonically related to how well the feature response pattern 
matches the hidden unit weight vector, just as in the standard real-valued activation 
rule. Indeed, one can readily see that if the feature and weight phases are equal 
(Pi = 8il), the rule for b i reduces to the real-valued case. Even if the feature 
and weight phases differ by a constant (p = 8i + c), b i is unaffected. Thi, is 
a critical property of the activation rule: Because absolute phase values have no 
intrinsic meaning, the response of a unit should depend only on the relative phases. 
The activation rule achieves this by essentially ignoring the average difference in 
phase between the feature units and the weights. The hidden phase, qi, reflects this 
average difference. 
5 LEARNING ALGORITHM 
During training, we would like the hidden units to learn to detect configurations 
of features that reliably indicate phase relationships among the features. We have 
experimented with a variety of training algorithms. The one with which we have 
had greatest success involves running the network for a fixed number of iterations 
and, after each iteration, attempting to adjust the weights so that the feature phase 
pattern will match a target phase pattern. Each training trial proceeds as follows: 
440 Mozer, Zcm�l, and Bchrmann 
1. A training example is generated at random. This involves selecting two con- 
tours and instantiating them in an image. The features of one contour have 
tar9et phase 0 � an
