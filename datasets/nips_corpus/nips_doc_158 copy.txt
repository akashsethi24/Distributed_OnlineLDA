81 
WHAT SIZE NET GIVES VALID 
G EN ERALIZ ATIO N? * 
Eric B. Baum 
Department of Physics 
Princeton University 
Princeton NJ 08540 
David Haussler 
Computer and Information Science 
University of California 
Santa Cruz, CA 95064 
ABSTRACT 
We address the question of when a network can be expected to 
generalize from m random training examples chosen from some ar- 
bitrary probability distribution, assuming that future test examples 
are drawn from the same distribution. Among our results are the 
following bounds on appropriate sample rs. network size. Assume 
0 < e < 1/8. We show that if m > O( w v 
_ _ .7-1og.T) random exam- 
ples can be loaded on a feedforward network of linear threshold 
functions with N nodes and W weights, so that at least a fraction 
1 -  of the examples are correctly classified, then one has confi- 
dence approaching certainty that the network will correctly classify 
a fraction i - e of future test examples drawn from the same dis- 
tribution. Conversely, for fully-connected feedforward nets with 
one hidden layer, any learning algorithm using fewer than f(---) 
random training examples will, for some distributions of examples 
consistent with an appropriate weight choice, fail at least some 
fixed fraction of the time to find a weight choice that will correctly 
classify more than a 1 - e fraction of the future test examples. 
INTRODUCTION 
In the last few years, many diverse real-world problems have been attacked by back 
propagation. For example expert systems have been produced for mapping text 
to phoneroes [sr87], for determining the secondary structure of proteins [qs88], and 
for playing backgammon [ts88]. 
In such problems, one starts with a training database, chooses (by making an ed- 
ucated guess) a network, and then uses back propagation to load as many of the 
training examples as possible onto the network. The hope is that the network so de- 
signed will generalize to predict correctly on future examples of the same problem. 
This hope is not always realized. 
* This paper will appear in the January 1989 issue of Neural Computation. For 
completeness, we reprint this full version here, with the kind permission of MIT 
Press. � 1989, MIT Press 
82 Baum and Haussler 
We address the question of when valid generalization can be expected. Given a 
training database of rn examples, what size net should we attempt to load these 
on? We will assume that the examples are drawn from some fixed but arbitrary 
probability distribution, that the learner is given some accuracy parameter e, and 
that his goal is to produce with high probability a feedforward neural network that 
predicts correctly at least a fraction I - e of future examples drawn from the same 
distribution. These reasonable assumptions are suggested by the protocol proposed 
by Valiant for learning from examples [val84]. However, here we do not assume the 
existence of any target function; indeed the underlying process generating the 
examples may classify them in a stochastic manner, as in e.g. [dh73]. 
Our treatment of the problem of valid generalization will be quite general in that 
the results we give will hold for arbitrary learning algorithms and not just for 
backpropagation. The results are based on the notion of capacity introduced by 
Cover [cov65] and developed by Vapnik and Chervonenkis [vc71], [vap82]. Recent 
overviews of this theory are given in [dev88], [behw87b] and [po184], from the various 
perspectives of pattern recognition, Valiant's computational learning theory, and 
pure probability theory, respectively. This theory generalizes the simpler counting 
arguments based on cardinality and entropy used in [behw87a] and [dswshhj87], in 
the latter case specifically to study the question of generalization in feedforward 
nets (see [yap82] or [behw87b]). 
The particular measures of capacity we use here are the maximum number of di- 
chotomies that can be induced on rn inputs, and the Vapnik-Chervonenkis 
Dimension, defined below. We give upper and lower bounds on these measures for 
classes of networks obtained by varying the weights in a fixed feedforward architec- 
ture. These results show that the VC dimension is closely related to the number of 
weights in the architecture, in analogy with the number of coefficients or degrees 
of freedom in regression models. One particular result, of some interest indepen- 
dent of its implications for learning, is a construction of a near minimal si.e net 
architecture capable of implementing all dichotomies on a randomly chosen set of 
points on the n-hypercube with high probability. 
Applying these results, we address the question of when a network can be expected 
to generalize from rn random training examples chosen from some arbitrary prob- 
ability distribution, assuming that future test examples are drawn from the same 
distribution. Assume 0 < e _< 1/8. We show that if m > O(-log) random ex- 
amples can be loaded on a feedforward network of linear threshold functions with 
N nodes and W weights, so that at least a fraction 1 -  of the examples are cor- 
rectly classified, then one has confidence approaching certainty that the network 
will correctly classify a fraction 1 - e of future test examples drawn from the same 
distribution. Conversely, for fully-connected feedforward nets with one hidden layer, 
any learning algorithm using fewer than l'(--) random training examples will, for 
some distributions of examples consistent with an appropriate weight choice, fil 
at least some fixed fraction of the time to find a weight choice that will correctly 
classify more than a 1 - e fraction of the future test examples. 
What Size Net Gives Valid Generalization? 83 
Ignoring the constant and logarithmic factors, these results suggest that the appro- 
priate number of training examples is approximately the number of weights times 
the inverse x of the accuracy parameter e. Thus, for example, if we desire an accu- 
racy level of 90%, corresponding to e = 0.1, we might guess that we would need 
about 10 times as many training examples as we have weights in the network. This 
is in fact the rule of thumb suggested by Widrow [wid87], and appears to work firly 
well in practice. At the end of Section 3, we briefly discuss why learning algorithms 
that try to minimize the number of non-zero weights in the network [rum87] [hin87] 
may need fewer training examples. 
DEFINITIONS 
We use In to denote the natural logarithm and log to denote the logarithm base 
2. We define an ezample as a pr (,a),  ,a  (-1,+1). We define a 
random sample as a sequence of examples drawn independently at random from 
some distribution D on ' x {-1, +1}. Let f be a function om  into {-1, 
We define the eor of f, with respect to D,  the probabity a  f(5) for (5, a) 
a random exple. 
Let F be a class of{-1, +1}-valued functions on ' and let S be a set of m points 
in '. A dichotomy of S induced by f 6 F is a partition of S into two disjoint 
subsets S + and S- such that f(5) = +1 for $ 6 S + and f(5) = -1 for $ 6 S-. 
By AF(S) we denote the number of distinct dichotomies of S induced by functions 
f F, and by zXF(n) we denote the maximum of At(S) over all S C ' of 
cardinality m. We say S is shattered by F if At(S) = 21sl, i.e. all dichotomies of 
S can be induced by functions in F. The Vapnik-Chervonenkis (VC) dimension of 
F, denoted �Cdin(F), is the cardinality of the largest S C ' that is shattered 
by F, i.e. the largest rn such that At(m) = 2 'a. 
A feedforward net with input from ' is a directed acyclic graph G with an ordered 
sequence of n source nodes (called inputs) and one sink (called the output). Nodes 
of G that are not source nodes axe called computation nodes, nodes that are neither 
source nor sink nodes are called hidden nodes. With each computation node nl 
there is associated a function fi: i,deg, ee(,,) __ {--1, +1}, where indeg'ee(ni) is 
the number of incoming edges for node hi. With the net itself there is associated 
a function f: ' -- {-1, +1} defined by composing the ffs in the obvious way, 
assuming that component i of the input $ is placed at the i th input node. 
A feedforward architecture is a class of feedforwaxd nets all of which share the 
same underlying graph. Given a graph G we define a feedforward axchitecture by 
associating to each computation node ni a class of functions Fi from 
It should be noted that our bounds differ significantly from those given in [dev88] in 
that the latter exhibit a dependence on the inverse of e '. This is because we derive 
our results from Vapnik's theorem on the uniform relative deviation of frequencies 
from their probabilities ([vap82], see Appendix A3 of [behw87b]), giving sharper 
bounds as e approaches 0. 
84 Baurn and Haussler 
to (-1, -{-1. The resulting architecture consists of all feedforward nets obtained by 
choosing a particular function ft from Ft for each computation node nt. We will 
identify an architecture with the class of functions computed by the individual nets 
withi the architecture when no confusion will arise. 
CONDITIONS SUFFICIENT FOR VALID 
GENERALIZATION 
Theorem 1: Let F be a feedforward architecture generated by an underlying 
graph G with N _ 2 computation nodes and Ft be the class of functions associated 
with computation node nt of G, 1 _ i _ N. Let d -- i=x VCdim(Ft). Then 
a(.) < HV=x a,(,) < (re,Vd) d for . _> d, where e is the base of the natural 
logarithm. 
Proof: Assume G has n input nodes and that the computation nodes of G are 
ordered so that node nt receives inputs only from input nodes and from computation 
nodes nj, 1 _ j _ i- 1. Let S be a set ofrn points in '. The dichotomy 
induced on S by the function in node nx can be chosen in at most Az,, (m) ways. 
This choice determines the input to node n. for each of the rn points in S. The 
dichotomy induced on these m inputs by the function in node n. can
