Universal Approximation and Learning 
of Trajectories Using Oscillators 
Pierre Baldi* 
Division of Biology 
California Institute of Technology 
Pasadena, CA 91125 
pJbaldi @juliet. caltech. edu 
Kurt Hornik 
Technische Universit&it Wien 
Wiedner Hauptstrage 8-10/1071 
A-1040 Wien, Austria 
Kurt. Hornik @tuwien. ac. at 
Abstract 
Natural and artificial neural circuits must be capable of travers- 
ing specific state space trajectories. A natural approach to this 
problem is to learn the relevant trajectories from examples. Un- 
fortunately, gradient descent learning of complex trajectories in 
amorphous networks is unsuccessful. We suggest a possible ap- 
proach where trajectories are realized by combining simple oscil- 
lators, in various modular ways. We contrast two regimes of fast 
and slow oscillations. In all cases, we show that banks of oscillators 
with bounded frequencies have universal approximation properties. 
Open questions are also discussed briefly. 
I INTRODUCTION: TRAJECTORY LEARNING 
The design of artificial neural systems, in robotics applications and others, often 
leads to the problem of constructing a recurrent neural network capable of producing 
a particular trajectory, in the state space of its visible units. Throughout evolution, 
biological neural systems, such as central pattern generators, have also been faced 
with similar challenges. A natural approach to tackle this problem is to try to 
learn the desired trajectory, for instance through a process of trial and error 
and subsequent optimization. Unfortunately, gradient descent learning of complex 
trajectories in amorphous networks is unsuccessful. Here, we suggest a possible 
approach where trajectories are realized, in a modular and hierarchical fashion, by 
combining simple oscillators. In particular, we show that banks of oscillators have 
universal approximation properties. 
*Also with the Jet Propulsion Laboratory, California Institute of Technology. 
452 P. BALDI, K. HORNIK 
To begin with, we can restrict ourselves to the simple case of a network with one  
visible linear unit and consider the problem of adjusting the network parameters 
in a way that the output unit activity u(t) is equal to a target function f(t), over 
an interval of time [0, T]. The hidden units of the network may be non-linear and 
satisfy, for instance, one of the usual neural network charging equations such as 
dui ui 
= -- + -,jwijfjuj(t- rij), (1) 
dt 
where ri is the time constant of the unit, the rij represent interaction delays, and 
the functions fj are non-linear input/output functions, sigmoidal or other. In the 
next section, we briefly review three possible approaches for solving this problem, 
and some of their limitations. In particular, we suggest that complex trajectories 
can be synthesized by proper combination of simple oscillatory components. 
2 
THREE DIFFERENT APPROACHES TO TRAJECTO- 
RY LEARNING 
2.1 GRADIENT DESCENT APPROACHES 
One obvious approach is to use a form of gradient descent for recurrent networks 
(see [2] for a review), such as back-propagation through time, in order to mod- 
ify any adjustable parameters of the networks (time constants, delays, synaptic 
weights and/or gains) to reduce a certain error measure, constructed by comparing 
the output u(t) with its target f(t). While conceptually simple, gradient descent 
applied to amorphous networks is not a successful approach, except on the most 
simple trajectories. Although intuitively clear, the exact reasons for this are not 
entirely understood, and overlap in part with the problems that can be encountered 
with gradient descent in simple feed-forward networks on regression or classification 
tasks. 
There is an additional set of difficulties with gradient descent learning of fixed points 
or trajectories, that is specific to recurrent networks, and that has to do with the 
bifurcations of the system being considered. In the case of a recurrent 2 network, as 
the parameters are varied, the system may or may not undergo a series of bifurca- 
tions, i.e., of abrupt changes in the structure of its trajectories and, in particular, of 
its attractors (fixed points, limit cycles, ... ). This in turn may translate into abrupt 
discontinuities, oscillations or non-convergence in the corresponding learning curve. 
At each bifurcation, the error function is usually discontinuous, and therefore the 
gradient is not defined. Learning can be disrupted in two ways: when unwanted 
abrupt changes occur in the flow of the dynamical system, or when desirable bifur- 
cations are prevented from occurring. A classical example of the second type is the 
case of a neural network with very small initial weights being trained to oscillate, 
in a symmetric and stable fashion, around the origin. With small initial weights, 
the network in general converges to its unique fixed point at the origin, with a large 
error. If we slightly perturb the weights, remaining away from any bifurcation, the 
network continues to converge to its unique fixed point which now may be slightly 
displaced from the origin, and yield an even greater error, so that learning by gradi- 
ent descent becomes impossible (the starting configuration of zero weights is a local 
minimum of the error function). 
All the results to be derived can be extended immediately to the case of higher- 
dimensional trajectories. 
2In a feed-forward network, where the transfer functions of the units are continuous, the 
output is a continuous function of the parameters and therefore there are no bifurcations. 
Universal Approximation and Learning of Trajectories Using Oscillators 453 
Figure 1: A schematic representation of a 3 layer oscillator network for double figure 
eight. Oscillators with period T in a given layer gate the corresponding oscillators, 
with period T/2, in the previous layer. 
2.2 DYNAMICAL SYSTEM APPROACH 
In the dynamical system approach, the function f(t) is approximated in time, over 
[0, T] by a sequence of points y0, yl, .... These points are associated with the iterates 
of a dynamical system, i.e., Yn+l --' F(yn) -- Fn(yo), for some function F. Thus 
the network implementation requires mainly a feed-forward circuit that computes 
the function F. It has a simple overall recursive structure where, at time n, the 
output F(y) is calculated, and fed back into the input for the next iteration. 
While this approach is entirely general, it leaves open the problem of constructing 
the function F. Of course, F can be learned from examples in a usual feed-forward 
connectionist network. But, as usual, the complexity and architecture of such a 
network are difficult to determine in general. Another interesting issue in trajectory 
learning is how time is represented in the network, and whether some sort of clock is 
needed. Although occasionally in the literature certain authors have advocated the 
introduction of an input unit whose output is the time t, this explicit representation 
is clearly not a suitable representation, since the problem of trajectory learning 
reduces then entirely to a regression problem. The dynamical system approach 
relies on one basic clock to calculate F and recycle it to the input layer. In the 
next approach, an implicit representation of time is provided by the periods of the 
oscillators. 
2.3 OSCILLATOR APPROACH 
A different approach was suggested in [1] where, loosely speaking, complex tra- 
jectories are realized using weakly pre-structured networks, consisting of shallow 
hierarchical combinations of simple oscillatory modules. The oscillatory modules 
can consist, for instance, of simple oscillator rings of units satisfying Eq. 1, with 
two or three high-gain neurons, and an odd number of inhibitory connections ([3]). 
To fix the ideas, consider the typical test problem of constructing a network capable 
of producing a trajectory associated with a double figure eight curve (i.e., a set 
of four loops joined at one point), see Fig. 1. In this example, the first level of 
the hierarchy could contain four oscillator rings, one for each loop of the target 
trajectory. The parameters in each one of these four modules can be adjusted, for 
instance by gradient descent, to match each of the loops in the target trajectory. 
454 P. BALDI, K. HORNIK 
The second level of the pyramid should contain two control modules. Each of these 
modules controls a distinct pair of oscillator networks from the first level, so that 
each control network in the second level ends up producing a simple figure eight. 
Again, the control networks in level two can be oscillator rings and their parameters 
can be adjusted. In particular, after the learning process is completed, they should 
be operating in their high-gain regimes and have a period equal to the sum of the 
periods of the circuits each one controls. 
Finally, the third layer consists of another oscillatory and adjustable module which 
controls the two modules in the second level, so as to produce a double figure 
eight. The third layer module must also end up operating in its high-gain regime 
with a period equal to four times the period of the oscillators in the first layer. 
In general, the final output trajectory is also a limit cycle because it is obtained 
by superposition of limit cycles in the various modules. If the various oscillators 
relax to their limit cycles independently of one another, it is essential to provide 
for adjustable delays between the various modules in order to get the proper phase 
adjustments. In this way, a sparse network with 20 units or so can be constructed 
that can successfully execute a double figure eight. 
There are actually different possible neural network realizations depending on how 
the action of the control modules is implemented. For instance, if the control units 
are gating the connections between corresponding layers, this amounts to using 
higher order units in the network. If one high-
