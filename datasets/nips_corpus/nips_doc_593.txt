$ynaptic Weight Noise During MLP 
Learning Enhances Fault-Tolerance, 
Generalisation and Learning Trajectory 
Alan F. Murray 
Dept. of Electrical Engineering 
Edinburgh University 
Scotland 
Peter J. Edwards 
Dept. of Electrical Engineering 
Edinburgh University 
Scotland 
Abstract 
We analyse the effects of analog noise on the synaptic arithmetic 
during MultiLayer Perceptron training, by expanding the cost func- 
tion to include noise-mediated penalty terms. Predictions are made 
in the light of these calculations which suggest that fault tolerance, 
generalisation ability and learning trajectory should be improved 
by such noise-injection. Extensive simulation experiments on two 
distinct classification problems substantiate the claims. The re- 
sults appear to be perfectly general for all training schemes where 
weights are adjusted incrementally, and have wide-ranging implica- 
tions for all applications, particularly those involving inaccurate 
analog neural VLSI. 
1 Introduction 
This paper demonstrates both by consideration of the cost function and the learn- 
ing equations, and by simulation experiments, that injection of random noise on 
to MLP weights during learning enhances fault-tolerance without additional super- 
vision. We also show that the nature of the hidden node states and the learning 
trajectory is altered fundamentally, in a manner that improves training times and 
learning quality. The enhancement uses the mediating influence of noise to dis- 
tribute information optimally across the existing weights. 
491 
492 Murray and Edwards 
Taylor[Taylor, 72] has studied noisy synapses, largely in a biological context, and 
infers that the noise might assist learning. We have already demonstrated that noise 
injection both reduces the learning time and improves the network's generalisation 
ability[Murray, 91],[Murray, 92]. It is established[Matsuoka, 92],[Bishop, 90] that 
adding noise to the training data in neural (MLP) learning improves the quality 
of learning, as measured by the trained network's ability to generalise. Here we 
infer (synaptic) noise-mediated terms that sculpt the error function to favour faster 
learning, and that generate more robust internal representations, giving rise to 
better generalisation and immunity to small variations in the characteristics of the 
test data. Much closer to the spirit of this paper is the work of Hanson[Hanson, 90]. 
His stochastic version of the delta rule effectively adapts weight means and standard 
deviations. Also Sequin and Clay[Sequin, 91] use stuck-at faults during training 
which imbues the trained network with an ability to withstand such faults. They 
also note, but do not pursue, an increased generalisation ability. 
This paper presents an outline of the mathematical predictions and verification 
simulations. A full description of the work is given in [Murray, 93]. 
2 Mathematics 
Let us analyse an MLP with I input, J hidden and K output nodes, with a set of 
P training input vectors op = {oip}, looking at the effect of noise injection into the 
error function itself. We are thus able to infer, from the additional terms introduced 
by noise, the characteristics of solutions that tend to reduce the error, and those 
which tend to increase it. The former will clearly be favoured, or at least stabilised, 
by the additional terms, while the latter will be de-stabilised. 
Let each weight Tab be augmented by a random noise source, such that Tab 
Ta + AaTa, for all weights {Ta}. Neuron thresholds are treated in precisely 
the same way. Note in passing, but importantly, that this synaptlc noise is not 
the same as noise on the input data. Input noise is correlated across the synapses 
leaving an input node, while the synaptic noise that forms the basis of this study 
is not. The effect is thus quite distinct. 
Considering, therefore, an error function of the form :- 
K-1 K-1 
1 . 1 
= 
k=O k=O 
Where 5p is the target output. We can now perform a Taylor expansion of the out- 
put Okp to second order, around the noise-free weight set, {TN), and thus augment 
the error function :- 
+ + +o(> 3) 
ab ab,cd 
If we ignore terms of order 3 nd above, and taking the time verge over the 
learning phase, we cn infer tlmt two terms re dded to the error function :- 
Synaptic Weight Noise During MLP Learning 493 
Consider also the perceptron rule update on the hidden-output layer along with the 
expanded error function :- 
020kp 
p P ab 
(4) 
averaged over several training epochs (which is acceptable for small values of r the 
adaption rate parameter). 
3 Simulations 
The simulations detailed below are based on the virtual targets algorithm 
[Murray, 92], a variant on backpropagation, with broadly similar performance. The 
targets algorithm was chosen for its faster convergence properties. Two contrast- 
ing classification tasks were selected to verify the predictions made in the following 
section by simulation. The first, a feature location task, uses real world normalised 
greyscale image data. The task was to locate eyes in facial images - to classify 
sections of these as either eye or not-eye. The network was trained on 16 x 16 
preclassified sections of the images, classified as eyes and not-eyes. The not-eyes 
were random sections of facial images, avoiding the eyes (see Fig. 1). The second, 
(16xl 6 section 
eye 
not-eye 
Figure 1: The eye/not-eye classifier. 
more artificial task, was the ubiquitous character encoder (Fig. 2) where a 25- 
1  26 
ï¿½ 
Figure 2: The character encoder task. 
dimensional binary input vector describing the 26 alphabetic characters (each 5 x 5 
pixels) was used to train the network with a one-out-of-26 output code. 
During the simulations noise was added to the weights at a level proportional to the 
weight size and at a probability distribution of uniform density (i.e. -Amax  A  
A,ax). Levels of up to 40% were probed in detail - although it is clear that the 
expansion above is not quantitatively valid at this level. Above these percentages 
further improvements were seen in the network performance, although the dynamics 
of the training algorithm became chaotic. The injected noise level was reduced 
494 Murray and Edwards 
smoothly to a minimum value of 1% as the network approached convergence (as 
evidenced by the highest output, bit error). As in all neural network simulations, the 
results depended upon the training parameters, network sizes and the random start 
position of the network. To overcome these factors and to achieve a meaningful 
result 35 weight sets were produced for each noise level. All other characteristics 
of the training process were held constant. The results are therefore not simply 
pathological freaks. 
4 Prediction/Verification 
4.1 Fault Tolerance 
Consider the first derivative penalty term in the expanded cost function (3), aver- 
aged over all patterns, output nodes and weights :- 
, CTab 
The implications of this term are straightforward. 
(5) 
For large values of the (weight- 
ed) average magnitude of the derivative, the overall error is increased. This term 
therefore causes solutions to be favoured where the dependence of outputs on in- 
dividual weights is evenly distributed across the entire weight set. Furthermore, 
weight saliency should not only have a lower average value, but a smaller scatter 
across the weight set as the training process attempts to reconcile the competing 
pressures to reduce both (1) and (5). This more distributed representation should 
be manifest in an improved tolerance to faulty weights. 
lOO 
 o 
 60 
_ o 
g 2o 
o-- 
o 
noise = 1070 
noise = 20% 
noise = 30% 
noise = 4lYYo - - - 
5 10 15 20 25 
Synapses Removed (%) 
Figure 3' Fault tolerance in the character encoder problem. 
Simulations were carried out on 35 weight sets produced for each of the two problems 
at each of 5 levels of noise injected during training. Weights were then random- 
ly removed and the networks tested on the training data. The resulting graphs 
(Fig. 3, 4) show graceful degradation with an increased tolerance to faults with 
injected noise during training. The networks were highly constrained for these sim- 
ulations to remove some of the natural redundancy of the MLP structure. Although 
the eye/not-eye problem contains a high proportion of redundant information, the 
Synaptic Weight Noise During MLP Learning 495 
 70 
50 
noise = 0% 
0 25 
noie = 10% 
noie = 20% 
5 10 15 20 
Synapses Removed (%) 
Figure 4: Fault tolerance enhancement in the eye/not-eye classifier. 
improvement in the networks ability to withstand damage, with injected noise, is 
clear. 
4.2 Generalisation Ability 
Considering the derivative in equation 5, and looking at the input-hidden weights. 
The term that is added to the error function, again averaged over all patterns, 
output nodes and weights is :- 
KxA2 [5r)i2 , 2 2 ,  ] 
O:p T Ojp Oip 2 (6) 
If an output neuron has a non-zero connection from a particular hidden node (Tkj  
0), and provided the input oip is non-zero and is connected to the hidden node (Tji y 
0), there is also a term o}p that will tend to favour solutions with the hidden 
nodes also turned firmly ON or OFF (i.e. ojp - 0 or 1). Remembering, of 
course, that all these terms are noise-mediated, and that during the early stages 
of training, the actual error ekp, in (1), will dominate, this term will de-stabilise 
final solutions that balance the hidden nodes on the slope of the sigmoid. Naturally, 
hidden nodes oj that are firmly ON or OFF are less likely to change state as a 
result of small variations in the input data {oi}. This should become evident in an 
increased tolerance to input perturbations and therefore an increased generalisation 
ability. 
Simulations were again carried out on the two problems using 35 weight sets for 
each level of injected synaptic noise during training. For the character encoder 
problem generalisation
