99 
Connectionist Learning of Expert Preferences by 
Comparison Training 
Gerald Tesauro 
IBM Thomas J. Watson Research Center 
PO Box 704, Yorktown lteights, NY 10598 USA 
Abstract 
A new training paradigm, called the coznparison paradigm, is introduced 
for tasks in which a network must learn to choose a preferred pattern from a 
set of n, alternatives, based on examples of human expert preferences. In this 
paradigm, the input to the network consists of two of the n alternatives, and 
the trained outtrot is the expert's judgement of which i)attcrn is better. This 
paradigm is applied to the learning of backgammon, a difflcult board game in 
which the expert selects a move from a set of legal moves. With comparison 
training, much higher levels of performance can be achieved, wi{h networks 
that are much smaller, and with coding schemes that arc much simpler and 
easier to understand. Furthermore, it is possible to set up the network so 
that it always produces consistent rank-orderings. 
1. Introduction 
There is now widespread interest in the use of cmuectimist netw,rks f,r real- 
world practical problem solving. The principal areas of application which 
have been stndied so far involve relatively low-level signal processing and 
pattern recognition tasks. Howewe. r, connectionist networks night also be 
nscfil in higher-level tasks which are currently tackled by expert systens 
and knowledge engineering aptmaches [2]. In ibis paper, we consider problem 
domains in which the expert is given a set of n alternatives as input (n may be 
either small or large), and must select the m,t (lcsirahle r most preferable 
alternative. This type of task occurs repeatedly throughout the {loznains 
of politics, bnsiness, economics, medicine, and many others. Whether it is 
choosing a foreign-policy option, a weap(ms contractor, a c(mrse of treatment 
for a disease, or simply what to have for dinner, prblezns requiring choice 
are constantly being fa(:ed and solved by huznan experts. 
How might a learning system such as a, connectionist network be set up to 
learn to make such choices from human expert examples? The imnediately 
obvious approach is to train the network to produce a numerical output 
100 esauro 
score for ea.ch input alternative. To make a choice, then, one would haxe 
the network score ea.ch alternative, and select the alternative with the high- 
est score. Since the learning system learns from examples, it seems logical to 
train the network on a da. ta base of examples in which a human expert has 
entered a numerical score for each possible choice. However, there are two 
major problems with such an approach. First, in many domains in which n 
is la. rge, it would be tremendously time-consuming for the expert to create 
a da. ta base in which each individual alternative has been painstaking evalu- 
ated, even the vast number of obviously bad alternatives which are not even 
worth considering. (It is important for the network to see examples of bad 
alterna. tives, otherwise it would tend to produce high scores for everything.) 
More importantly, in ma.ny domains human experts do not think in terms of 
absolute scoring functions, ami it would thus be extremely difficult to create 
training data containing absolute scores, because such scoring is alien to the 
expert's way of thinking about the problem. Instead, the most natural way 
to make training data is simply to record the expert in action, i.e., for each 
problem situation, record each of the alternatives he had to choose from, and 
record which one he actually selected. 
For these reasons, we advocate teaching the network to compare pairs of 
alterna.tives, rather than scoring individual alternatives. In other words, the 
input should be two of the set of n alternatives, and the output should be a 
I or 0 depending on which of the two alternatives is better. From a set of 
recorded human expert preferences, one can then teach the network that the 
expcrt's choice is better than all other alternatives. 
One potential concern raised by this approach is that, in performance mode 
after the network is trained, it might be necessary to make n? comparisons to 
select the best alterna.tive, whereas mly n individual scores 3re needed in the 
other approa.ch. However, the network can select the best alterna. tive with 
only n comparisons by going through the list f Mterntiw;s in order, and 
comparing the current alternative with the best alternative seen so far. If 
the current alternative is better, it becomes the new best Mternativc, and if 
it is worse, it is rejected. Another potential concern is that a network which 
only knows how to compare might m,t produce a consistent rank-ordering, 
i.e., it might say that alternative a is better than b, b is better than c, and 
c is better than a, and then one does not know which Mterna.tivc to select. 
However, we shall see la.tcr that it is p,ssiblc t guarantee cmsistency with a 
constrained architecture which forces the network to (:,rate uI) with absolute 
numerical scores for individual alternatives. 
In the following, we shall examine the aI)plicatim of the c(anparison train- 
ing paradigm to the game of backgammon, as considerable experience has 
already been obtained in this domain. In previous papers [7,6], a network 
was described which learned to play backgammon froln an expert da, ta base, 
using the so-called back-propagation learning rule [5]. In that system, the 
network was trained to score individual moves. In other words, the input 
Connectionist Learning of Expert Preferences ! O1 
consists of a move (defined by the initial i)osition before the move and the 
final position after the move), and the tiesired output is a real number indi- 
cating the strength of the move. Henceforth we shall refer to this training 
paradigm as the relative score paradigm. While this approach produced 
considerable s,ccess, it had a number of serious limitations. We shall see 
that the comparison para.dign solves one of the m,,st important limitations 
of the previous approach, with the result that the overall perfornance of 
the network is much better, the number of c,nnecti,ms required is greatly 
reduced, and the network's input c,,ding scheme is much simpler and easier 
to understand. 
2. Previous backgammon networks 
In [7], a netwt,rk was described which learned t,, play fairly good backgam- 
mon by back-propagation learning {,f a large expert training set, using the 
rela, tive score paradigm described previously. After training, the network 
was tested both by measuring its perf,rmance on a test set of p,,sitions not 
used in training, and by actual game play against humans and conventlena.1 
conputer prograins. The best netw,,rk was able to defeat Snn Microsys- 
tems' Gammontool, the best available connercial pr(,gram, by a substa,ntial 
ma. rgin, but it was still far from human expert-level performance. 
The ba.sic conclusion of [7] was that it was possible to achieve decent levels 
of performance by this network learning procedure, but it, was not an easy 
matter, and required substantial human intervenlim. The choice of a coding 
scheme for the input inft,rma. tion, f,,r example, was found t,, be an extremely 
intportant issue. The best coding schemes contained a. great deal of domain- 
specific informa.tion. The best cnc,,ding (f the raw board infornation was 
in terms of concepts tha, t human experts use to describe local transitions, such 
as slotting, stripping, etc.. Als(,, a few pro-computed features were 
required in addition to the raw b{mrd informati(m. Thus it was necessary 
to be a. domain expert in order to design a suitable netw(,rk coding schene, 
and it seemed tha. t the only way to discover the best (:,,ting scheme was 
by pa.instaking trial and err,r. This was somewhat disapp,finting, as it was 
hoped that the network learning pr,,(:edure w(mhl aut,mati(:ally produce an 
expert backgamnon network with little {r no huntan eff,,r. 
3. Coxnparison paradigm netsvork set-up 
In the standard t)ractice of ba.(:k-i)rt)t)agation , a c,)mparis,)n paradigm net- 
work would have an input layer, one (,r more layers of hid(len units, and a.n 
output layer, with full connectivity between ad. jat'ent layers. The input layer 
would represent, two final board p,sitions a and b, and the (utt)ut layer would 
have just a. single unit to represent which b,m.rd psition was better. The 
10 Tesauro 
teacher signal for the output unit would be a 1 if board position a was better 
than b, and a 0 if b was better than a. 
The proposed comparison paradigm network would overcome the limitation 
of only being a.ble to consider individual moves in isolation, without knowl- 
edge of witat other alternatives are available. In a.dditi(n, the sophisticated 
coding scheme that was developed to encode transition infofinn tion would not 
be needed, since comparisons could be based solely on the final board states. 
The comparison a,pproach offers greater sensitivity in distinguishing between 
close alternatives, a,nd as stated previously, it corresp,nds more closely to 
the actual form of human expert knowledge. 
These advantages are formidable, but there are some important problems 
with the approach as currently described. One technical problem is that the 
learning is significantly slower. This is because 2n c(mtparisons per training 
position are presented to the network, where n ,- 20, whereas in the relative 
score approach, only about 3-4 ntovcs per position w(mld bc presented. It 
was therefore necessary to develop a. number of technical tricks to increase 
the speed of the simulator (:ode for this specific application (to be described 
in a future publication). 
A more fundamental problown with the approach, however, is the issue of con- 
sistency of network comparisons. Two properties are required fi)r complete 
consistency: (1) The comparison between any
