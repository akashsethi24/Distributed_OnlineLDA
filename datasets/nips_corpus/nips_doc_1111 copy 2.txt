Adaptive Back-Propagation in On-Line 
Learning of Multilayer Networks 
Ansgar H. L. West ,2 and David Saad 2 
Department of Physics, University of Edinburgh 
Edinburgh EH9 3JZ, U.K. 
aNeural Computing Research Group, University of Aston 
Birmingham B4 7ET, U.K. 
Abstract 
An adaptive back-propagation algorithm is studied and compared 
with gradient descent (standard back-propagation) for on-line 
learning in two-layer neural networks with an arbitrary number 
of hidden units. Within a statistical mechanics framework, both 
numerical studies and a rigorous analysis show that the adaptive 
back-propagation method results in faster training by breaking the 
symmetry between hidden units more efficiently and by providing 
faster convergence to optimal generalization than gradient descent. 
1 INTRODUCTION 
Multilayer feedforward perceptrons (MLPs) are widely used in classification and 
regression applications due to their ability to learn a range of complicated maps [1] 
from examples. When learning a map fo from N-dimensional inputs  to scalars ( 
the parameters {W} of the student network are adjusted according to some training 
algorithm so that the map defined by these parameters fw approximates the teacher 
fo as close as possible. The resulting performance is measured by the generalization 
error eg, the average of a suitable error measure  over all possible inputs % = {}. 
This error measure is normally defined as the squared distance between the output 
of the network and the desired output, i.e., 
e = l[fv()- fo()] a. 
(1) 
One distinguishes between two learning schemes: batch learning, where training 
algorithms are generally based on minimizing the above error on the whole set of 
given examples, and on-line learning, where single examples are presented serially 
and the training algorithm adjusts the parameters after the presentation of each 
324 A.H.L. WEST, D. SAAD 
example. We measure the efficiency of these training algorithms by how fast (or 
whether at all) they converge to an acceptable generalization error. 
This research has been motivated by recent work [2] investigating an on-line learn- 
ing scenario of a general two-layer student network trained by gradient descent on a 
task defined by a teacher network of similar architecture. It has been found that in 
the early stages of training the student is drawn into a suboptimal symmetric phase, 
characterized by each student node imitating all teacher nodes with the same degree 
of success. Although the symmetry between the student nodes is eventually broken 
and the student converges to the minimal achievable generalization error, the ma- 
jority of the training time may be spent with the system trapped in the symmetric 
regime, as one can see in Fig. 1. To investigate possible improvements we introduce 
an adaptive back-propagation algorithm, which improves the ability of the student 
to distinguish between hidden nodes of the teacher. We compare its efficiency with 
that of gradient descent in training two-layer networks following the framework 
of [2]. In this paper we present numerical studies and a rigorous analysis of both 
the breaking of the symmetric phase and the convergence to optimal performance. 
We find that adaptive back-propagation can significantly reduce training time in 
both regimes by breaking the symmetry between hidden units more efficiently and 
by providing faster exponential convergence to zero generalization error. 
2 DERIVATION OF THE DYNAMICAL EQUATIONS 
The student network we consider is a soft committee machine [3], consisting of 
K hidden units which are connected to N-dimensional inputs  by their weight 
vectors W- {W} (i = 1,...,K). All hidden units are connected to the linear 
output unit by couplings of unit strength and the implemented mapping is there- 
fore fw() = i= g(xi), where xi - W/. is the activation of hidden unit i and g(.) 
is a sigmoidal transfer function. The map f0 to be learned is defined by a teacher 
network of the same architecture except for a possible difference in the number of 
hidden units M and is defined by the weight vectors B = {B} (n = 1,..., M). 
Training examples are of the form (,), where the components of the input 
vectors  are drawn independently from a zero mean unit variance Gaussian dis- 
tribution; the outputs are  M 
= y,= g(y), where y = B . is the activation of 
teacher hidden unit n. 
An on-line training algorithm A is defined by the update of each weight in re- 
sponse to the presentation of an example (, ), which can take the general form 
W/+ - W/ + .Ai({/}, W,,), where {/} defines parameters adjustable by 
the user. In the case of standard back-propagation, i.e., gradient descent on the 
error function defined in Eq. (1)' A/gd(r/, W,, ) = (rl/N)5 ' with 
 = 6g'(z) = [ - fw()]gt(zf), 
where the only user adjustable parameter is the learning rate r/ scaled by 1/N. 
One can readily see that the only term that breaks the symmetry between different 
hidden units is  ' 
g (x i ), i.e., the derivative of the transfer function g(.). The fact that 
a prolonged symmetric phase can exist indicates that this term is not significantly 
different over the hidden units for a typical input in the symmetric phase. 
The rationale of the adaptive back-propagation algorithm defined below is therefore 
to alter the f-term, in order to magnify small differences in the activation between 
hidden units. This can be easily achieved by altering f(xi) to f(xi), where  
plays the role of an inverse temperature. Varying  changes the range of hidden 
unit activations relevant for training, e.g., for  > i learning is more confined to 
Adaptive Back-Propagation in On-line Learning of Multilayer Networks 325 
small activations, when compared to gradient descent (/ = 1). The whole adaptive 
back-propagation training algorithm is therefore: 
.A abpf  5g'(lxf)  rl 
i [r/,fi, W , ,() = - (3) 
-i 
with 5  in Eq. (2). To compare the adaptive back-propagation algorithm with 
normal gradient descent, we follow the statistical mechanics calculation in [2]. Here 
we will only outline the main ideas and present the results of the calculation. 
As we are interested in the typical behaviour of our training algorithm we average 
over all possible instances of the examples . We rewrite the update equations (3) 
in  as equations in the order parameters describing the overlaps between student 
nodes Oij = -, student and teacher nodes Rin = 'n and teacher nodes 
Tnm = Bn .Bin. The generalization error eg, measuring the typical performance, can 
be expressed in these variables only [2]. The order parameters Qij and in are the 
new dynamical variables, which are self-averaging with respect to the randomness 
in the training data in the thermodynamic limit (N  ). If we interpret the 
normalized example number a = /N  a continuous time variable, the update 
equations for the order parameters become first order coupled differential equations 
d lin 
do 
dQij 
do 
(4) 
All the integrals in Eqs. (4) and the generalization error can be calculated explicitly 
if we choose g(x) - erf(x/v) as the sigmoidal activation function [2]. The exact 
form of the resulting dynamical equations for adaptive back-propagation is similar to 
the equations in [2] and will be presented elsewhere [4]. They can easily be integrated 
numerically for any number of K student and M teacher hidden units. For the 
remainder of the paper, we will however focus on the realizable case (K -- M) and 
uncorrelated isotropic teachers of unit length T,m - 
The dynamical evolution of the overlaps Qij and Ri follows from integrating the 
equations of motion (4) from initial conditions determined by the random initial- 
ization of the student weights W. Whereas the resulting norms Qii of the student 
vector will be order O(1), the overlaps Qij between student vectors, and student- 
teacher vectors/i will be only order O(1/x/). The random initialization of the 
weights is therefore simulated by initializing the norms Qii and the overlaps Qij and 
/i from uniform distributions in the [0, 0.5] and [0, 10 -x] interval respectively. 
In Fig. i we show the difference of a typical evolution of the overlaps and the 
generalization error for fi - 12 and/ - i (gradient descent) for K - 3 and /- 0.01. 
In both cases, the student is drawn quickly into a suboptimal symmetric phase, 
characterized by a finite generalization error (Fig. le) and no differentiation between 
the hidden units of the student: the student norms Qii and overlaps Qij are similar 
(Figs. lb,ld) and the overlaps of each student node with all teacher nodes Rin are 
nearly identical (Figs. la, lc). The student trained by gradient descent (Figs. lc,ld) 
is trapped in this unstable suboptimal solution for most of the training time, whereas 
adaptive back-propagation (Figs. la,lb) breaks the symmetry significantly earlier. 
The convergence phase is characterized by a specialization of the different student 
nodes and the evolution of the overlap matrices Q and R to their optimal value T, 
except for the permutational symmetry due to the arbitrary labeling of the student 
nodes. Clearly, the choice/ - 12 is suboptimal in this regime. The student trained 
with / - i converges faster to zero generalization error (Fig. le). In order to 
optimize/ seperately for both the symmetric and the convergence phase, we will 
examine the equations of motions analytically in the following section. 
326 A.H.L. WEST, D. SAAD 
1.0 
0,8- 
0.6- 
0.2- 
0.0 
1.0 
0.8- 
0.6- 
0.2- 
0.0 
(a) 
'-'--- R11 
ï¿½ R12 
R13 
I R2 
 R 
R23 
L R 
R32 
R33 ...... 
.2-' 
' ' ' I ' ' ' I ' ' ' I ' ' ' I 
0 20000 40000  60000 80000 0 
(b)  1 __ 
0 
/ 
! ......... 
I 0 
0.2 .2 
,,, ,,, ,, ,-, , ,  0.0 
0 20000 40000 ( 60000 80000 0 
.04 
Figure 1: Dynamical evolution of the 
student-teacher overlaps Rin (a,c), the 
student-student overla
