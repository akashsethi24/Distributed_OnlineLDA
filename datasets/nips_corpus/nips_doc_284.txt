A Neural Network for Feature Extraction 719 
A Neural Network for Feature Extraction 
Nathan Intrator 
Div. of Applied Mathematics, and 
Center for Neural Science 
Brown University 
Providence, RI 02912 
ABSTRACT 
The paper suggests a statistical framework for the parameter esti- 
mation problem associated with unsupervised learning in a neural 
network, leading to an exploratory projection pursuit network that 
performs feature extraction, or dimensionality reduction. 
1 INTRODUCTION 
The search for a possible presence of some unspecified structure in a high dimen- 
sional space can be difficult due to the curse of dimensionalitt problem, namely 
the inherent sparsity of high dimensional spaces. Due to this problem, uniformly 
accurate estimations for all smooth functions are not possible in high dimensions 
with practical sample sizes (Cox, 1984, Barron, 1988). 
Recently, exploratory projection pursuit (PP) has been considered (Jones, 1983) as a 
potential method for overcoming the curse of dimensionality problem (Huber, 1985), 
and new algorithms were suggested by Friedman (1987), and by Hall (1988, 1989). 
The idea is to find low dimensional projections that provide the most revealing 
views of the full-dimensional data emphasizing the discovery of nonlinear effects 
such as clustering. 
Many of the methods of classical multivariate analysis turn out to be special cases 
of PP methods. Examples are principal component analysis, factor analysis, and 
discriminant analysis. The various PP methods differ by the projection index opti- 
mized. 
720 Intrator 
Neural networks seem promising for feature extraction, or dimensionality reduction, 
mainly because of their powerful parallel computation. Feature detecting functions 
of neurons have been studied in the past two decades (von der Malsburg, 1973, Nass 
et al., 1973, Cooper et al., 1979, Takeuchi and Amari, 1979). It has also been shown 
that a simplified neuron model can serve as a principal component analyzer (Oja, 
1982). 
This paper suggests a statistical framework for the parameter estimation problem 
associated with unsupervised learning in a neural network, leading to an exploratory 
PP network that performs feature extraction, or dimensionality reduction, of the 
training data set. The formulation, which is similar in nature to PP, is based on 
a minimization of a cost function over a set of parameters, yielding an optimal 
decision rule under some norm. First, the formulation of a single and a multiple 
feature extraction are presented. Then a new projection index (cost function) that 
favors directions possessing multimodality, where the multimodality is measured 
in terms of the separability property of the data, is presented. This leads to the 
synaptic modification equations governing learning in Bienenstock, Cooper, and 
Munro (BCM) neurons (1982). A network is presented based on the multiple feature 
extraction formulation, and both, the linear and nonlinear neurons are analysed. 
2 SINGLE FEATURE EXTRACTION 
We associate a feature with each projection direction. With the addition of a 
threshold function we can say that an input posses a feature associated with that 
direction if its projection onto that direction is larger than the threshold. In these 
terms, a one dimensional projection would be a single feature extraction. 
The approach proceeds as follows: Given a compact set of parameters, define a 
family of loss functions, where the loss function corresponds to a decision made by 
the neuron whether to fire or not for a given input. Let the risk be the averaged 
loss over all inputs. Minimize the risk over all possible decision rules, and then 
minimize the risk over the parameter set. In case the risk does not yield a meaningful 
minimization problem, or when the parameter set over which the minimization takes 
place can be restricted by some a-priori knowledge, a penalty, i.e. a measure on the 
parameter set, may be added to the risk. 
Define the decision problem (f,-r, P, L,.A), where f: (aO),..., a(')), a:(i) C R v, 
is a fixed set of input vectors, (f, -c, P) the corresponding probability space, .A = 
{0, 1} the decision space, and {Lo}oEBM, Lo : f x .A  R is the family of loss 
functions. B M is a compact set in R M. Let Z) be the space of all decision rules. 
The risk Ro: Z) - R, is given by: 
i=1 
For a fixed 8, the optimal decision 50 is chosen so that: 
A Neural Network for Feature Extraction 721 
Since the minimization takes place over a finite set, the minimizer exists. In par- 
ticulax, for a given a(i) the decision $0(a:(i)) is chosen so that Lo(e(O,$o(e(O)) < 
1 - 
Now we find an optimal  that minimizes the risk, namely,  will be such that: 
R(6) = min {Ro(6o)}. (2.3) 
8BM 
The minimum with respect to 8 exits since B M is compact. 
Ro(o) becomes a function that depends only on 8, and when 8 represents a vector 
in R r, Ro can be viewed as a projection index. 
3 MULTI-DIMENSIONAL FEATURE EXTRACTION 
In this case we have a single layer network of interconnected units, each performing 
a single feature extraction. All units receive the same input and the interaction be- 
tween the units is via lateral inhibition. The formulation is similar to single feature 
extraction, with the addition of interaction between the single feature extractors. 
Let Q be the number of features to be extracted from the data. The multiple de- 
cision rule 0 = (?),..., 0 (?)) takes values in .A: {0, 1} <?. The risk of node k 
is given by: R?)(): ii P(e(i))L?)(e(O,()(e(O)), and the total risk of the 
network is Ro(5) - =l R?)(). Proceeding as before, we can minimize over the 
decision rules  to get 0, and then minimize over 8 to get , as in equation (2.3). 
The coupling of the equations via the inhibition, and the relation between the 
different features extracted is exhibited in the loss function for each node and will 
become clear through the next example. 
4 
FINDING THE OPTIMAL 0 FOR A SPECIFIC LOSS 
FUNCTION 
4.1 A SINGLE BCM NEURON - ONE FEATURE EXTRACTION 
In this section, we present an exploratory PP method with a specific loss function. 
The differential equations performing the optimization turn out to be a good ap- 
proximation of the low governing synaptic weight modification in the BCM theory 
for learning and memory in neurons. The formal presentation of the theory, and 
some theoretical analysis is given in (Bienenstock, 1980, Bienenstock et al., 1982), 
mean field theory for a network based on these neurons is presented in (Scofield 
and Cooper, 1985, Cooper and Scofield, 1988), more recent analysis based on the 
statistical viewpoint is in (Intrator 1990), computer simulations and the biological 
relevance are discussed in (Saul et al., 1986, Bear et al., 1987, Cooper et al., 1988). 
We start with a short review of the notations and definitions of BCM theory. 
Consider a neuron with input vector a: : (a,...,a:r), synaptic weights vector 
m = (m,..., mr), both in R r, and activity (in the linear region) c = a � rn. 
722 Intrator 
Define Om: E[(a-rn) ] �(c, Ore) -- c   
- 5cO,, b(c, O,) = c  4cO, The input 
a, which is a stochastic process, is assumed to be of Type II ;o mixing, bounded, and 
piecewise constant. The ;o mixing property specifies the dependency of the future 
of the process on its past. These assumptions are needed for the approximation of 
the resulting deterministic equation by a stochastic one and are discussed in detail 
in (Intrator, 1990). Note that c represents the linear projection of a onto m, and 
we seek an optimal projection in some sense. 
The BCM synaptic modification equations are given by: rh = it(t)ck(e.m, 0,), 
rn(0) = rn0, where it(t) is a global modulator which is assumed to take into account 
all the global factors affecting the cell, e.g., the beginning or end of the critical 
period, state of arousal, etc. 
Rewriting the modification equation as  = it(t)(a � m)(a .m - :40,)a, we see 
that unlike a classical ttebb-Stent rule, the threshold 0,, is dynamic. This gives 
the modification equation the desired stability, with no extra conditions such as 
saturation of the activity, or normalization of 11 m [[, and also yields a statistically 
meaningful optimization. 
Returning to the statistical formulation, we let 0 = m be the parameter to be 
estimated according to the above formulation and define an appropriate loss function 
depending on the cell's decision whether to fire or not. The loss function represents 
the intuitive idea that the neuron will fire when its activity is greater than some 
threshold, and will not otherwise. We denote the firing of the neuron by a = 1. 
f{o.,, c3(s, O,)ds. Consider the following loss function: 
Define K = 
Lo(,a) = Lm(,a): 
-. 
n -. 
- fo( 
( � ') 
(-m) 
(-m) 
>Ore, a--1 
<Ore, a=l 
<Orn, a=0 
>Ore, a:0 
It follows from the definition of Lo and from the definition of 50 in (2.2) that 
Lm(e, 5m) : --it �(S, Ore)ds -- ---{(a. m) a -- E[(a. m)2](a � m) 2} (4.2) 
The above definition of the loss function suggests that the decision of a neuron 
whether to fire or not is based on a dynamic threshold (a: � m) > 0,,. It turns out 
that the synaptic modification equations remain the same if the decision is based 
on a fixed threshold. This is demonstrated by the following loss function, which 
leads to the same risk as in equation (4.3): K = -it fo. (s, O.)ds, 
Lo(z,a) = Lm(e,a): K - it f( c)(s, Om)ds, 
(x.,) ^ 
-it  (8, on 
(a-m)_>0, a= 1 
(.m)<0, a= 1 
(a.m) <_0, a--O 
(;r .m)> 0, a--0 
(4.1 ) 
A Neural Network for Feature Extraction 723 
The risk is given by: 
Ro(6o) = --{E[(a- m) a] - E2[(a � m)2]}. (4.3) 
The following graph represents the b function and the associated loss function 
L.(x, 6.) of the activity c. 
THE q FUNCTION THE LOSS FUNCTION 
Fig. 1: The Function ;b and the Loss Functions for a Fixed m and �,. 
From the graph of the loss function it follows tha
