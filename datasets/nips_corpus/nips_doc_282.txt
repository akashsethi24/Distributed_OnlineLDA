274 Weinshall, Edelman and Biilthoff 
A self- 
organizing multiple-view 
of 3D objects 
representation 
Daphna Weinshall 
Center for Biological 
Information Processing 
MIT E25-201 
Cambridge, MA 02139 
Shlmon Edelman 
Center for Biological 
Information Processing 
MIT E25-201 
Cambridge, MA 02139 
Heinrich H. Bfdthoff 
Dept. of Cognitive and 
Linguistic Sciences 
Brown University 
Providence, RI 02912 
ABSTRACT 
We demonstrate the ability of a two-layer network of thresholded 
summation units to support representation of 3D objects in which 
several distinct 2D views are stored for each object. Using unsu- 
pervised Hebbian relaxation, the network learned to recognize ten 
objects from different viewpoints. The training process led to the 
emergence of compact representations of the specific input views. 
When tested on novel views of the same objects, the network ex- 
hibited a substantial generalization capability. In simulated psy- 
chophysical experiments, the network's behavior was qualitatively 
similar to that of human subjects. 
! Background 
Model-based object recognition involves, by definition, a comparison between the 
input image and models of different objects that are internal to the recognition 
system. The form in which these models are best stored depends on the kind of 
information available in the input, and on the trade-off between the amount of 
memory allocated for the storage and the degree of sophistication required of the 
recognition process. 
In computer vision, a distinction can be made between representation schemes that 
use 3D object-centered coordinate systems and schemes that store viewpoint-specific 
information such as 2D views of objects. In principle, storing enough 2D views would 
A Self-Organizing Multiple-View Representation of 3D Objects 275 
allow the system to use simple recognition techniques such as template matching. 
If only a few views of each object are remembered, the system must have the capa- 
bility to normalize the appearance of an input object, by carrying out appropriate 
geometrical transformations, before it can be directly compared to the stored rep- 
resentations. 
What representation strategy is employed by the human visual system? The notion 
that objects are represented in viewpoint-dependent fashion is supported by the 
finding that commonplace objects are more readily recognized from certain so-called 
canonical vantage points than from other, random viewpoints (Palmer et al. 1981). 
Namely, canonical views are identified more quickly (and more accurately) than 
others, with response times decreasing monotonically with increasing subjective 
goodness.t 
The monotonic increase in the recognition latency with misorientation of the object 
relative to a canonical view prompts the interpretation of the recognition process in 
terms of a mechanism related to mental rotation. In the classical mental rotation 
task (see Shepard & Cooper 1982), the subject is required to decide whether two 
simultaneously presented images are two views of the same 3D object. The average 
latency of correct response in this task is linearly dependent on the difference in 
the 3D attitude of the object in the two images. This dependence is commonly 
accounted for by postulating a process that attempts to rotate the 3D shapes per- 
ceived in the two images into congruence before making the identity decision. The 
rotation process is sometimes claimed to be analog, in the sense that the represen- 
tation of the object appears to pass through intermediate orientation stages as the 
rotation progresses (Shepard & Cooper 1982). 
Psychological findings seem to support the involvement of some kind of mental 
rotation in recognition by demonstrating the dependence of recognition latency for 
an unfamiliar view of an object on the distance to its closest familiar view. There 
is, however, an important qualification. Practice with specific objects appears to 
cause this strategy to be abandoned in favor of a more memory-intensive, less time- 
consuming direct comparison strategy. Under direct comparison, many views of the 
objects are stored and recognition proceeds in essentially constant time, provided 
that the presented views are sufficiently close to one of the stored views (Tart & 
Pinker 1989, Edelman et al. 1989). 
From the preceding outline, it appears that a faithful model of object representa- 
tion in the human visual system should provide both for the ability to rotate 
3D objects and for the fast direct-comparison strategy that supersedes mental ro- 
tation for highly familiar objects. Surprisingly, it turns out that mental rotation 
in recognition can be replicated by a self-organizing memory-intensive model based 
on direct comparison. The rest of the present paper describes such a model, called 
CLF (conjunctions of localized features; see Edelman & Weinshall 1989). 
x Canonical views of objects can be reliably identified in subjective judgement as well as in 
recognition tasks. For example, when asked to form a mental image of an object, people usually 
imagine it a, seen from a canonical perspective. 
276 Weinshall, Edelman and Bfilthoff 
INPUT (feature) LAYER 
l/ 
REPRESENTATION LAYER I 
FOOTPRINT of object O1 
Figure 1: The network consists of two layers, F (input, or feature, layer) and 
R (representation layer). Only a small part of the projections from F to R are 
shown. The network encodes input patterns by making units in the R-layer respond 
selectively to conjunctions of features localized in the F-layer. The curve connecting 
the representations of the different views of the same object in R-layer symbolizes 
the association that builds up between these views as a result of practice. 
2 The model 
The structure of the model appears in Figure. 1 (see Edelman & Weinshall 1989 for 
details). The first (input, or feature) layer of the network is a feature map. In our 
experiments, vertices of wire-frame objects served as the input features. Every unit 
in the (feature) F-layer is connected to all units in the second (representation) R- 
layer. The initial strength of a vertical (V) connection between an F-unit and an 
R-unit decreases monotonically with the horizontal distance between the units, 
according to an inverse square law (which may be considered the first approximation 
to a Gaussian distribution). In our simulations the size of the F-layer was 64 x 64 
units and the size of the R-layer - 16 x 16 units. Let (z, /) be the coordinates of an 
F-unit and (i, j) - the coordinates of an R-unit. The initial weight between these 
two units is wijl,=o = ([1 + (z - 4i) 2 + (y - 4j)2]) -t, where  = 50 and (4i, 4j) 
is the point in the F-layer that is directly above the R-unit (i, j). 
The R-units in the representation layer are connected among themselves by lateral 
(L) connections, whose initial strength is zero. Whereas the V-connections form the 
representations of individual views of an object, the L-connections form associations 
among different views of the same object. 
2.1 Operation 
During training, the input to the model is a sequence of appearances of an object, 
encoded by the 2D locations of concrete sensory features (vertices) rather than a list 
A Self-Organizing Multiple-View Representation of 3D Objects 277 
of abstract features. At the first presentation of a stimulus several representation 
units are active, all with different strengths (due to the initial distribution of vertical 
connection strengths). 
2.1.1 Winner Take All 
We employ a simple winner-take-all (WTA) mechanism to identify for each view 
of the input object a few most active R-units, which subsequently are recruited to 
represent that view. The WTA mechanism works as follows. The net activities 
of the R-units are uniformly thresholded. Initially, the threshold is high enough to 
ensure that all activity in the R-layer is suppressed. The threshold is then gradually 
decreased, by a fixed (multiplicative) amount, until some activity appears in the 
R-layer. If the decrease rate of the threshold is slow enough, only a few units will 
remain active at the end of the WTA process. In our implementation, the decrease 
rate was 0.95. In most cases, only one winner emerged. 
Note that although the WTA can be obtained by a simple computation, we prefer 
the stepwise algorithm above because it has a natural interpretation in biological 
terms. Such an interpretation requires postulating two mechanisms that operate in 
parallel. The first mechanism, which looks at the activity of the R-layer, may be 
thought as a high fan-in OR gate. The second mechanism, which performs uniform 
adjustable thresholding on all the R-units, is similar to a global bias. Together, they 
resemble feedback-regulated global arousal networks that are thought to be present, 
e.g., in the medulla and in the limbic system of the brain (Kandel  Schwartz 1985). ' 
2.1.2 Adjustment of weights and thresholds 
In the next stage, two changes of weights and thresholds occur that make the 
currently active R-units (the winners of the WTA stage) selectively responsive to 
the present view of the input object. First, there is an enhancement of the V- 
connections from the active (input) F-units to the active R-units (the winners). 
At the same time, the thresholds of the active R-units are raised, so that at the 
presentation of a different input these units will be less likely to respond and to be 
recruited anew. We employ Hebbian relaxation to enhance the V-connections from 
the input layer to the active R-unit (or units). The connection strength v, from 
F-unit a to R-unit b = (i, j) changes by 
(1) 
where Aij is the activation of the R-unit (i, j) after WTA, v e is an upper bound 
on a connection strength and c is a parameter controlling the rate of convergence. 
The threshold of a winner R-unit is increased by 
2 The relationship of this approach to other WTA algorithms is discussed in Edelman &
