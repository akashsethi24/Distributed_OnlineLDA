630 Morgan and Bourlard 
Generalization and Parameter Estimation 
in Feedforward Nets: 
Some Experiments 
I' Mï¿½rgant 
nternational Computer Science Institute 
Berkeley, CA 94704, USA 
H. Bourlard : 
Philips Research Laboratory Brussels 
B-1170 Brussels, Belgium 
ABSTRACT 
We have done an empirical study of the relation of the number of 
parameters (weights) in a feedforward net to generalization perfor- 
mance. Two experiments are reported. In one, we use simulated data 
sets with well-controlled parameters, such as the signal-to-noise ratio 
of continuous-valued data. In the second, we train the network on 
vector-quantized mel cepstm from real speech samples. In each case, 
we use back-propagation to train the feedforward net to discriminate in 
a multiple class pattern classification problem. We report the results of 
these studies, and show the application of cross-validation techniques 
to prevent overfitting. 
I INTRODUCTION 
It is well known that system models which have too many parameters (with respect 
to the number of measurements) do not generalize well to new measurements. For 
instance, an autoregressive (AR) model can be derived which will represent the training 
data with no error by using as many parameters as there are data points. This would 
Generalization and Parameter Estimation in Feedforward Nets 631 
generally be of no value, as it would only represent the training data. Criteria such as the 
Akaike Information Criterion (AIC) [Akaike, 1974, 1986] can be used to penalize both 
the complexity of AR models and their training error variance. In feedforward nets, we 
do not currently have such a measure. In fact, given the aim of building systems which 
are biologically plausible, there is a temptation to assume the usefulness of indefinitely 
large adaptive networks. In contrast to our best guess at Nature's tricks, man-made sys- 
tems for pattern recognition seem to require nasty amounts of data for training. In short, 
the design of massively parallel systems is limited by the number of parameters that can 
be learned with available training data. It is likely that the only way truly massive sys- 
tems can be built is with the help of prior information, e.g., connection topology and 
weights that need not be learned [Feldman et al, 1988]. 
Learning theory [Valiant, V.N., 1984; Pearl, J., 1978] has begun to establish what 
is possible for trained systems. Order-of-magnitude lower bounds have been established 
for the number of required measurements to train a desired size feedforward net 
[Baum&Haussler, 1988]. Rules of thumb suggesting the number of samples required for 
specific distributions could be useful for practical problems. Widrow has suggested hav- 
ing a training sample size that is 10 times the number of weights in a network (Uncle 
Bernie's Rule)[Widrow, 1987]. We have begun an empirical study of the relation of the 
number of parameters in a feedforward net (e.g. hidden units, connections, feature 
dimension) to generalization performance for data sets with known discrimination com- 
plexity and signal-to-noise ratio. In the experiment reported here, we are using simulated 
data sets with controlled parameters, such as the number of clusters of continuous-valued 
data. In a related practical example, we have trained a feedforward network on vector- 
quantized reel cepstra from real speech samples. In each case, we are using the back- 
propagation algorithm [Rumelhart et al, 1986] to train the feedforward net to discriminate 
in a multiple class pattern classification problem. Our results confirm that estimating 
more parameters than there are training samples can degrade generalization. However, 
the peak in generalization performance (for the difficult pattern recognition problems 
tested here) can be quite broad if the networks are not trained too long, suggesting that 
previous guidelines for network size may have been conservative. Furthermore, cross- 
validation techniques, which have also proved quite useful for autoregressive model 
order determination, appear to improve generalization when used as a stopping criterion 
for iteration, and thus preventing overtraining. 
2 RANDOM VECTOR PROBLEM 
2.1 METHODS 
Studies based on synthesized data sets will generally show behavior that is dif- 
ferent from that seen with a real data set. Nonetheless, such studies are useful because of 
the ease with which variables of interest may be altered. In this case, the object was to 
manufacture a difficult pattern recognition problem with statistically regular variability 
between the training and test sets. This is actually no easy trick; if the problem is too 
easy, then even very small nets will be sufficient, and we would not be modeling the 
632 Morgan and Bourlard 
problem of doing hard pattern classification with small amounts of training data. If the 
problem is too hard, then variations in performance will be lost in the statistical varia- 
tions inherent to methods like back-propagation, which use random initial weight values. 
Random points in a 4-dimensional hyperrectangle (drawn from a uniform probabil- 
ity distribution) are classified arbitrarily into one of 16 classes. This group of points will 
be referred to as a cluster. This process is repeated for 1-4 nonoverlapping hyperrectan- 
gles. A total of 64 points are chosen, 4 for each class. All points are then randomly per- 
turbed with noise of uniform density and range specified by a desired signal-to-noise 
ratio (SNR). The noise is added twice to create 2 data sets, one to be used for training, 
and the other for test. Intuitively, one might expect that 16454 hidden units would be 
required to transform the training space for classification by the output layer. However, 
the variation between training and test and the relatively small amount of data (256 
numbers) suggest that for large numbers of parameters (over 256) there should be a 
significant degrading of generalization. Another issue was how performance in such a 
situation would vary over large numbers of iterations. 
Simulations were run on this data using multi-layer perceptrons(MLP) (i.e., layered 
feedforward networks) with 4 continuous-valued inputs, 16 outputs, and a hidden layer of 
sizes ranging from 4 to 128. Nets were run for signal-to-noise ratios of 1.0 and 2.0, where 
the SNR is defined as the ratio of the range of the original cluster points to the range of 
the added random values. Error back-propagation without momentum was used, with an 
adaptation constant of .25 . For each case, the 64 training patterns were used 10,000 
times, and the resulting network was tested on the second data set every 100 iterations so 
that generalization could be observed during the learning. Blocks of ten scores were 
averaged to stabilize the generalization estimate. After this smoothing, the standard devi- 
ation of error (using the normal approximation to the binomial distribution) was roughly 
1%. Therefore, differences of 3% in generalization performance are significant at a level 
of .001. All computation was performed on Sun4-110's using code written in C at ICSI. 
Roughly a trillion floating point operations were required for the study. 
2.2 RESULTS 
Table I shows the test performance for a single cluster and a signal-to-noise ratio 
of 1.0 . The chart shows the variation over a range of iterations and network size 
(specified both as//hidden units, and as ratio of//weights to//measurements, or weight 
ratio). Note that the percentages can have finer gradation than 1/64, due to the averag- 
ing, and that the performance on the training set is given in parentheses. Test perfor- 
mance is best for this case for 8 hidden units (24.7%), or a weight ratio of .62 (after 2000 
iterations), and for 16 units (21.9%), or a weight ratio of 1.25 (after 10000 iterations). For 
larger networks, the performance degrades, presumably because of the added noise. At 
2000 iterations, the degradation is statistically significant, even in going from 8 to 16 hid- 
den units. There is further degradation out to the 128-unit case. The surprising thing is 
that, while this degradation is quite noticeable, it is quite graceful considering the order- 
of magnitude range in net sizes. An even stronger effect is the loss of generalization 
power when the larger nets are more fully mined. All of the nets generalized better when 
Generalization and Parameter Estimation in Feedforward Nets 633 
they were trained to a relatively poor degree, especially the larger ones. 
Table I -- Test (and training) scores: 1 cluster, SNR = 1.0 
#hidden #weights 
units #inputs 
%Test (Train) Correct after N Iterations 
1000 2000 5000 10000 
4 .31 9.2(4.4) 21.7(15.6) 12.0(25.9) 15.6(34.4) 
8 .62 11.4(5.2) 24.7(17.0) 20.6(29.8) 21.4(63.9) 
16 1.25 13.6(6.9) 21.1(18.4) 18.3(37.2) 21.9(73.4) 
32 2.50 12.8(6.4) 18.4(18.3) 17.8(41.7) 13.0(80.8) 
64 5.0 13.6(7.7) 18.3(20.8) 19.7(34.4) 18.0(79.2) 
128 10.0 11.6(6.7) 17.7(19.1) 12.2(34.7) 15.6(75.6) 
Table II shows the results for the same 1-cluster problem, but with higher SNR 
data (2.0). In this case, a higher level of test performance was reached, and it was 
reached for a larger net with more iterations (40.8% for 64 hidden units after 5000 itera- 
tions). At this point in the iterations, no real degradation was seen for up to 10 times the 
number of weights as data samples. However, some signs of performance loss for the 
largest nets was evident after 10000 iterations. Note that after 5000 iterations, the net- 
works were only half-trained (roughly 50% error on the training set). When they were 
80-90% trained, the larger nets lost considerable ground. For instance, the 10 x net (128 
hidden units) lost performance from 40.5% to 28.1% during these iterations. It appears 
that the higher signal-to-noise of this example permitted performance gains for even 
higher overparametrization factors, but that the result was even more sensitive to tra
