Dynamics of Supervised Learning with 
Restricted Training Sets 
A.C.C. Coolen 
Dept of Mathematics 
King's College London 
Strand, London WC2R 2LS, UK 
tcoolen @mth.kcl.ac.uk 
D. Saad 
Neural Computing Research Group 
Aston University 
Birmingham B4 7ET, UK 
saadd@aston.ac.uk 
Abstract 
We study the dynamics of supervised learning in layered neural net- 
works, in the regime where the size p of the training set is proportional 
to the number N of inputs. Here the local fields are no longer described 
by Gaussian distributions. We use dynamical replica theory to predict 
the evolution of macroscopic observables, including the relevant error 
measures, incorporating the old formalism in the limit pin  oz. 
1 INTRODUCTION 
Much progress has been made in solving the dynamics of supervised learning in layered 
neural networks, using the strategy of statistical mechanics: by deriving closed laws for the 
evolution of suitably chosen macroscopic observables (order parameters) in the limit of an 
infinite system size [1, 2, 3, 4]. For a recent review and guide to references see e.g. [5]. 
The main successful procedure developed so far is built on the following cornerstones: 
� The task to be learned is defined by a 'teacher', which is itselfa neural network. This in- 
duces a natural set of order parameters (mutual weight vector overlaps between the teacher 
and the trained, 'student', network). 
� The number of network inputs is infinitely large. This ensures that fluctuations in the 
order parameters will vanish, and enables usage of the central limit theorem. 
� The number of 'hidden' neurons is finite, in both teacher and student, ensuring a finite 
number of order parameters and an insignificant cumulative impact of the fluctuations. 
� The size of the training set is much larger than the number of updates. Each example 
presented is now different from the previous ones, so that the local fields will have Gaussian 
distributions, leading to closure of the dynamic equations. 
In this paper we study the dynamics of learning in layered networks with restricted training 
sets, where the number p of examples scales linearly with the number N of inputs. Indi- 
vidual examples will now re-appear during the learning process as soon as the number of 
weight updates made is of the order of p. Correlations will develop between the weights 
198 A. C. C. Coolen and D. Saad 
40 I 
o 
Y oo- 
a0.5 
t=50 
a=0.5 
t=50 
40 
20 
Y 00 
-4000 -t000 -2 0 -IflO0 00 IflO0 2000 IflO0 4O0 -10 - 0 -10 
00 10 20 10 40 
Figure 1' Student and teacher fields (z, y) (see text) observed during numerical simulations 
of on-line learning (learning rate r/= 1) in a perceptron of size N = 10,000 at t = 50, using 
1 
examples from a training set of size p = N. Left: Hebbian learning. Right: AdaTron 
learning [5]. Both distributions are clearly non-Gaussian. 
and the training set examples and the student's local fields (activations) will be described by 
non-Gaussian distributions (see e.g. Figure 1). This leads to a breakdown of the standard 
formalism: the field distributions are no longer characterized by a few moments, and the 
macroscopic laws must now be averaged over realizations of the training set. The first rig- 
orous study of the dynamics of learning with restricted training sets in non-linear networks, 
via generating functionals [6], was carried out for networks with binary weights. Here we 
use dynamical replica theory (see e.g. [7]) to predict the evolution of macroscopic observ- 
ables for finite c, incorporating the old formalism as a special case (c = pin - oc). For 
simplicity we restrict ourselves to single-layer systems and noise-free teachers. 
2 FROM MICROSCOPIC TO MACROSCOPIC LAWS 
A 'student' perceptron operates a rule which is parametrised by the weight vector J  Rv: 
S() = sgn[J-] = sgn[x] (1) 
It tries to emulate a teacherNPerceptron which operates a similar rule, characterized by a 
(fixed) weight vector B  R . The student modifies its weight vector J iteratively, using 
examples of input vectors  which are drawn at random from a fixed (randomly composed) 
training set/) = {1 P} C D = {-1, 1} N, of size p aN with a > 0, and the 
corresponding values of the teacher outputs T() = sgn[B- ] = sgn[y]. Averages 
over the training set/5 and over the full set D will be denoted as (())b and (())D, 
respectively. We will analyze the following two classes of learning rules: 
on-line- J(m+l) = J(m) + 3 (rn) 6[J(rn).(rn),B.(rn)] 
(2) 
batch' J(m+ 1)= J(m) + 3 (  [d(m).,B.])5 
In on-line learning one draws at each step m a question (rn) at random from the training 
set, the dynamics is a stochastic process; in batch learning one iterates a deterministic map. 
Our key dynamical observables are the training- and generalization errors, defined as 
Et(a) = 
Eg(J) = (O[--(J.)(B.)])D (3) 
Only if the training set/5 is sufficiently large, and if there are no correlations between J and 
the training set examples, will these two errors be identical. We now turn to macroscopic 
observables fl[J] = (ft[J],...,ftt[J]). For N  oc (with finite times t = m/N 
Dynamics of Supervised Learning with Restricted Training Sets 199 
and with finite k), and if our observables are of a so-called mean-field type, their associated 
macroscopic distribution Pt (f) is found to obey a Fokker-Planck type equation, with flow- 
and diffusion terms that depend on whether on-line or batch learning is used. We now 
choose a specific set of observables F[J], taylored to the present problem: 
Q[j] = j2, R[J] = J.B, P[x,y;J] = (5[x-J.] 5[y-B.])b (4) 
This choice is motivated as follows: (i) in order to incorporate the old formalism we need 
Q [J] and R[J], (ii) the training error involves field statistics calculated over the training set, 
as given by P[x, y; J], and (iii) for a < oc one cannot expect closed equations for a finite 
number of order parameters, the present choice effectively represents an infinite number. 
We will assume the number of arguments (x, y) for which P[x, y; J] is evaluated to go to 
infinity after the limit N  oc has been taken. This eliminates technical subtleties and 
allows us to show that in the Fokker-Planck equation all diffusion terms vanish as N --> c. 
The latter thereby reduces to a Liouville equation, describing deterministic evolution of our 
macroscopic observables. For on-line learning one arrives at 
d-Q=2rl dxdyP[x,y]x6[x;y]+rl 2 dxdyP[x,y]62[x;y] (5) 
=. faay yl y y] (6) 
dt 
0 l [/dx'P[x' y]5[x-x'-.[x',y]]-P[x,y]] 
 r[, y] =  , 
-0 dx'dy' 6[x',y'] A[x,y;x',y'] 
1 2 f , 2 , 02 
Expansion of these equations in powers of . and retaining only the tes linear in , gives 
the cogesponding equations describing batch learning. The complexity of the problem is 
fully concentrated in a Green's function Mix, y; x', y'], which is defined as 
[x, y; x', y'] =  (( ([ 1-5 , ]5[x-a.] 5[y-.] (.() 5['-X(lS[y '-.(])  ) 
It involves a sub-shell average, in which Pt (J) is the weight probability density at time t: 
f dJ K[J] pt(J)5[2-2[J]]5[R-R[J]] 1-Ixy 5[?[x,y]-?[x,y: J]] 
(K[J])c:t : fdJ pt(J)5[Q-Q[J]]5[R-R[J]]i-[x 5[P[x,y]-P[x,y;J]] 
where the sub-shells are defined with respect to the order parameters. The solution of 
(5,6,7) can be used to generate the errors of (3): 
E t : laxly [x, ylo[-]  = I arccos[R/V/-] (8) 
3 CLOSURE VIA DYNAMICAL REPLICA THEORY 
So far our analysis is still exact. We now close the macroscopic laws (5,6,7) by making, for 
N  oc, the two key assumptions underlying dynamical replica theory [7]: 
(i) Our macroscopic observables {Q, R, P} obey closed dynamic equations. 
(ii) These equations are self-averaging with respect to the realisation of/). 
(i) implies that probability variations within the {Q, R, P} subshells are either absent or 
irrelevant to the evolution of {Q, R, P}. We may thus make the simplest choice for Pt (J): 
Pt(J)  p(J),,5[Q-Q[J]]5[R-R[J]] HS[P[x, yl-P[x,y;J]] (9) 
xy 
200 A. C. C. Coolen and D. Saad 
p(J) depends on time implicitly, via the order parameters {Q, R, P}. The procedure (9) 
leads to exact laws if our observables {Q, R, P} indeed obey closed equations for N  oc. 
It gives an approximation if they don't. (ii) allows us to average the macroscopic laws over 
all training sets; it is observed in numerical simulations, and can probably be proven using 
the formalism of [6]. Our assumptions result in the closure of (5,6,7), since now .A[...] is 
expressed fully in terms of {Q, R, P}. The final ingredient of dynamical replica theory is 
the realization that averaging fractions is simplified with the replica identity [8] 
fdJ W[J, zlO[J,z ] = lira d J1 'dJn (O[j1 zl H w[Ja,zl>z 
What remains is to perform integrations. One finds that P[w, y]  P[wly]P[y] with P[y] = 
  y2   y2 
(2) 2 e 2 . Upon introducing the short-hands Dy = (2) 2e dy and {f(, y)) = 
fDydx P[y]f(, y) we can write the resulting macroscopic laws as follows: 
d 
 = 2u + vz  = vm 
dt 
 I fdx'P[x'y] {Stx-x'-Grx',y]]-Stx-x']} 
P[xly] =  
o 
-. { V[xly] [v(- y)+ my + IV- m-(Q- )v][x, y]] } 
with 
(10) 
0 2 
+ ,2 z  r[xly] 
(ll) 
U = ([x,y]G[x,y]), V: (xG[x,y]), W- (yG[x,y]), Z = (62[x,y]) 
As before the batch equations follow upon expanding in r/and retaining only the linear 
terms. Finding the function [x, y] (in replica symmetric ansatz) requires solving a saddle- 
point problem for a scalar observable q and a function M[xly]. Upon introducing 
B - V/qQ - R2 
Q(1-q) (f[x,y,z]). = fdx M[xlY]eBXZf[x,y,z] 
fdx 3[xly], 
(with fdx M[xly ] = 1 for all y) the saddle-point equations acquire the form 
for all X,y' ?[Xly]: fOz 
1 
((x-Ry) 2) + (qQ-R2)[1-5] = [Q(1 +q)-2R2](xff2[x,y]) 
The solution M[xly ] of the functional saddle-point equation, given a value for q in the 
physical range q � [R 2/Q, 1], is unique [9]. The function [x, y] is then given by 
� [X,y]: (v/qQ-j2p[XIy]} -1 /Dz z([X-x]). (12) 
4 THE LIMIT 
For consistency we show 
