Computational structure of coordinate 
transformations: A generalization study 
Zoubin Ghahramani 
zoubin@psyche.mit.edu 
Daniel M. Wolpert 
wolpert@psyche.mit.edu 
Michael I. Jordan 
jordan@psyche.mit.edu 
Department of Brain & Cognitive Sciences 
Massachusetts Institute of Technology 
Cambridge, MA 02139 
Abstract 
One of the fundamental properties that both neural networks and 
the central nervous system share is the ability to learn and gener- 
alize from examples. While this property has been studied exten- 
sively in the neural network literature it has not been thoroughly 
explored in human perceptual and motor learning. We have chosen 
a coordinate transformation system--the visuomotor map which 
transforms visual coordinates into motor coordinates--to study the 
generalization effects of learning new input-output pairs. Using a 
paradigm of computer controlled altered visual feedback, we have 
studied the generalization of the visuomotor map subsequent to 
both local and context-dependent remappings. A local remapping 
of one or two input-output pairs induced a significant global, yet 
decaying, change in the visuomotor map, suggesting a representa- 
tion for the map composed of units with large functional receptive 
fields. Our study of context-dependent remappings indicated that 
a single point in visual space can be mapped to two different fin- 
ger locations depending on a context variable--the starting point 
of the movement. Furthermore, as the context is varied there is 
a gradual shift between the two remappings, consistent with two 
visuomotor modules being learned and gated smoothly with the 
context. 
I Introduction 
The human central nervous system (CNS) receives sensory inputs from a multi- 
tude of modalities, each tuned to extract different forms of information from the 
1126 Zoubin Ghahramani, Daniel M. Wolpert, Michael I. Jordan 
environment. These sensory signals are initially represented in disparate coordi- 
nate systems, for example visual information is represented retinotopically whereas 
auditory information is represented tonotopically. The ability to transform infor- 
mation between coordinate systems is necessary for both perception and action. 
When we reach to a visually perceived object in space, for example, the location 
of the object in visual coordinates must be converted into a representation appro- 
priate for movement, such as the configuration of the arm required to reach the 
object. The computational structure of this coordinate transformation, known as 
the visuomotor map, is the focus of this paper. 
By examining the change in visuomotor coordination under prismatically induced 
displacement and rotation, Helmholtz (1867/1925) and Stratton (1897a,1897b) pi- 
oneered the systematic study of the representation and plasticity of the visuomotor 
map. Their studies demonstrate both the fine balance between the visual and mo- 
tor coordinate systems, which is disrupted by such perturbations, and the ability 
of the visuomotor map to adapt to the displacements induced by the prisms. Sub- 
sequently, many studies have further demonstrated the remarkable plasticity of the 
map in response to a wide variety of alterations in the relationship between the vi- 
sual and motor system (for reviews see Howard, 1982 and Welch, 1986)--the single 
prerequisite for adaptation seems to be that the remapping be stable (Welch, 1986). 
Much less is known, however, about the topological properties of this map. 
A coordinate transformation such as the visuomotor map can be regarded as a func- 
tion relating one set of variables (inputs) to another (outputs). For the visuomotor 
map the inputs are visual coordinates of a desired target and the outputs are the 
corresponding motor coordinates representing the arm's configuration (e.g. joint 
angles). The problem of learning a sensorimotor remapping can then be regarded 
as a function approximation problem. Using the theory of function approximation 
one can make explicit the correspondence between the representation used and the 
patterns of generalization that will emerge. Function approximators can predict 
patterns of generalization ranging from local (look-up tables), through intermedi- 
ate (CMACs, Albus, 1975; and radial basis functions, Moody and Darken, 1989 ) 
to global (parametric models). 
In this paper we examine the representational structure of the visuomotor map 
through the study of its spatial and contextual generalization properties. In the 
spatial generalization study we address the question of how pointing changes over 
the reaching workspace after exposure to a highly localized remapping. Previous 
work on spatial generalization, in a study restricted to one dimension, has led to the 
conclusion that the visuomotor map is constrained to generalize linearly (Bedford, 
1989). We test this conclusion by mapping out the pattern of generalization induced 
by one and two remapped points in two dimensions. 
In the contextual generalization study we examine the question of whether a single 
point in visual space can be mapped into two different finger locations depending on 
the context of a movement--the start point. If this context-dependent remapping 
occurs, the question arises as to how the mapping will generalize as the context is 
varied. Studies of contextual remapping have previously shown that variables such 
as eye position (Kohler, 1950; Hay and Pick, 1966; Shelhamer et al., 1991), the feel of 
prisms (Kravitz, 1972; Welch, 1971) or an auditory tone (Kravitz and Yaffe, 1972), 
can induce context-dependent aftereffects. The question of how these context- 
Computational Structure of Coordinate Transformations 112 7 
dependent maps generalize--which has not been previously explored--reflects on 
the possible representation of multiple visuomotor maps and their mixing with a 
context variable. 
Spatial Generalization 
To examine the spatial generalization of the visuomotor map we measured the 
change in pointing behavior subsequent to one- and two-point remappings. In order 
to measure pointing behavior and to confine subjects to learn limited input-output 
pairs we used a virtual visual feedback setup consisting of a digitizing tablet to 
record the finger position on-line and a projection/mirror system to generate a 
cursor spot image representing the finger position (Figure la). By controlling the 
presence of the cursor spot and its relationship to the finger position, we could both 
restrict visual feedback of finger position to localized regions of space and introduce 
perturbations of this feedback. 
a) Perturbed 
Finger Position 
VGA Screen 
Projector 
Finger feedback 
mae F 
\ 
\ 
Rear projection screen 
imageSemi-silvered mirror 
Digitizing Tablet Actual 
Finger Position 
b) c) � � � 
Pemeived o o AcfiJal 
Fger Position  Position 
e) 
Figure 1. a) Experimental setup. The subjects view the reflected image of the 
rear projection screen by looking down at the mirror. By matching the screen- 
mirror distance to the mirror-tablet distance all projected images appeared to be in 
the plane of the finger (when viewed in the mirror) independent of head position. 
b) The position of the grid of targets relative to the subject. Also shown, for the 
z-shift condition, is the perceived and actual finger position when pointing to the 
central training target. The visually perceived finger position is indicated by a cursor 
spot which is displaced from the actual finger position. c) A schematic showing the 
perturbation for the z-shift group. To see the cursor spot on the central target the 
subjects had to place their finger at the position indicated by the tip of the arrow. 
d) & e) Schematics similar to c) showing the perturbation for the y-shift and two 
point groups, respectively. 
In the tradition of adaptation studies (e.g. Welch, 1986), each experimental session 
consisted of three phases: pre-exposure, exposure, and post-exposure. During the 
pre- and post-exposure phases, designed to assess the visuomotor map, the subject 
pointed repeatedly, without visual feedback of his finger position, to a grid of tar- 
gets over the workspace. As no visual input of finger location was given, no learning 
of the visuomotor map could occur. During the exposure phase subjects pointed 
repeatedly to one or two visual target locations, at which we introduced a discrep- 
1128 Zoubin Ghahramani, Daniel M. Wolpert, Michael I. Jordan 
ancy between the actual and visually displayed finger location. No visual feedback 
of finger position was given except when within 0.5 cm of the target, thereby confin- 
ing any learning to the chosen input-output pairs. Three local perturbations of the 
visuomotor map were examined: a 10 cm rightward displacement (x-shift group, 
Figure lc), 10 cm displacement towards the body (y-shift group, Figure ld), and a 
displacement at two points, one 10 cm away from, and one 10 cm towards the body 
(two point group, Figure le). For example, for the x-shift displacement the subject 
had to place his finger 10 cm to the right of the target to visually perceive his finger 
as being on target (Figure lb). Separate control subjects, in which the relationship 
between the actual and visually displayed finger position was left unaltered, were 
run for both the one- and two-point displacements, resulting in a total of 5 groups 
with 8 subjects each. 
50 
45 
40 
30 
25 
2O 
45- 
41) 
30 
25 
20 
-10 -5 0 5 10 15 20 
X (cm) 
50' 
45. 
40- 
30' 
25' 
20. 
Q 45 
40 
' 35 
; 30 
20 
55' 
50' 
45- 
40- 
35' 
.o- 
25' 
-10 -5 0 5 10 15 20 
X (cm) 
55' 
50- 
45. 
40' 
35- 
25. 
20' 
-15 -10 -5 0 
20' 
15 
-10 -5 0 5 10 15 20 
X (cm) 
50 
>' 3oi 
2(] 
- 10 0 10 20 
X (cm) 
 30 
25 
- 10 0 10 20 
X (cm) 
5O 
30 
20 
5 10 15 20 25 -15-10 -5 0 5 10 15 20 25 -10 0 10 
X (cm) X (crn) X (cm) 
Figure 2. Results of the spatial generalization study. The first column shows the 
mean change in pointing, along with 95% co
