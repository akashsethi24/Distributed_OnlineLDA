Multi-Task Learning for Stock Selection 
Joumana Ghosn 
Dept. Informatique et 
Recherche Oprationnelle 
Universit de Montreal 
Montreal, Qc H3C-3J7 
ghosniro. umontreal. ca 
Yoshua Bengio * 
Dept. Informatique et 
Recherche Oprationnelle 
Universit de Montreal 
Montreal, Qc H3C-3J7 
bengioyï¿½iro. umontreal. ca 
Abstract 
Artificial Neural Networks can be used to predict future returns 
of stocks in order to take financial decisions. Should one build a 
separate network for each stock or share the same network for all 
the stocks? In this paper we also explore other alternatives, in 
which some layers are shared and others are not shared. When 
the prediction of future returns for different stocks are viewed as 
different tasks, sharing some parameters across stocks is a form 
of multi-task learning. In a series of experiments with Canadian 
stocks, we obtain yearly returns that are more than 14% above 
various benchmarks. 
I Introduction 
Previous applications of ANNs to financial time-series suggest that several of these 
prediction and decision-taking tasks present sufficient non-linearities to justify the 
use of ANNs (Refenes, 1994; Moody, Levin and Rehfuss, 1993). These models can 
incorporate various types of explanatory variables: so-called technical variables (de- 
pending on the past price sequence), micro-economic stock-specific variables (such 
as measures of company profitability), and macro-economic variables (which give 
information about the business cycle). 
One question addressed in this paper is whether the way to treat these different vari- 
ables should be different for different stocks, i.e., should one use the same network 
for all the stocks or a different network for each stock? To explore this question 
*also, AT&T Labs, Holmdel, NJ 07733 
Multi-Task Learning for Stock Selection 947 
we performed a series of experiments in which different subsets of parameters are 
shared across the different stock models. When the prediction of future returns for 
different stocks are viewed as different tasks (which may nonetheless have some- 
thing in common), sharing some parameters across stocks is a form of multi-task 
learning. 
These experiments were performed on 9 years of data concerning 35 large capital- 
ization companies of the Toronto Stock Exchange (TSE). Following the results of 
previous experiments (Bengio, 1996), the networks were not trained to predict the 
future return of stocks, but instead to directly optimize a financial criterion. This 
has been found to yield returns that are significantly superior to training the ANNs 
to minimize the mean squared prediction error. 
In section 2, we review previous work on multi-task. In section 3, we describe the 
financial task that we have considered, and the experimental setup. In section 4, 
we present the results of these experiments. In section 5, we propose an extension 
of this work in which the models are re-parameterized so as to automatically learn 
what must be shared and what need not be shared. 
2 Parameter Sharing and Multi-Task Learning 
Most research on ANNs has been concerned with tabula rasa learning. The learner 
is given a set of examples (x,y), (x2,y2), ..., (xN,YN) chosen according to some 
unknown probability distribution. Each pair (x, y) represents an input x, and a 
desired value y. One defines a training criterion C to be minimized in function 
of the desired outputs and of the outputs of the learner f(x). The function f is 
parameterized by the parameters of the network and belongs to a set of hypotheses 
H, that is the set of all functions that can be realized for different values of the 
parameters. The part of generalization error due to variance (due to the specific 
choice of training examples) can be controlled by making strong assumptions on 
the model, i.e., by choosing a small hypotheses space H . But using an incorrect 
model also worsens performance. 
Over the last few years, methods for automatically choosing H based on similar 
tasks have been studied. They consider that a learner is embedded in a world 
where it faces many related tasks and that the knowledge acquired when learn- 
ing a task can be used to learn better and/or faster a new task. Some methods 
consider that the related tasks are not always all available at the same time (Pratt, 
1993; Silver and Mercer, 1995): knowledge acquired when learning a previous task 
is transferred to a new task. Instead, all tasks may be learned in parallel (Baxter, 
1995; Caruana, 1995), and this is the approach followed here. Our objective is not 
to use multi-task learning to improve the speed of learning the training data (Pratt, 
1993; Silver and Mercer, 1995), but instead to improve generalization performance. 
For example, in (Baxter, 1995), several neural networks (one for each task) are 
trained simultaneouly. The networks share their first hidden layers, while all the 
remaining layers are specific to each network. The shared layers use the knowledge 
provided from the training examples of all the tasks to build an internal represen- 
tation suitable for all these tasks. The remaining layers of each network use the 
internal representation to learn a specific task. 
In the multitask learning method used by Caruana (Caruana, 1995), all the hidden 
948 J. Ghosn and Y. Bengio 
layers are shared. They serve as mutual sources of inductive bias. It was also 
suggested that besides the relevant tasks that are used for learning, it may be 
possible to use other related tasks that we do not want to learn but that may 
help to further bias the learner (Caruana, Baluja and Mitchell, 1996; Intrator and 
Edelman, 1996). 
In the family discovery method (Omohundro, 1996), a parameterized family of 
models is built. Several learners are trained separately on different but related 
tasks and their parameters are used to construct a manifold of parameters. When 
a new task has to be learned, the parameters are chosen so as to maximize the data 
likelihood on the one hand, and to maximize a family prior on the other hand 
which restricts the chosen parameters to lie on the manifold. 
In all these methods, the values of some or all the parameters are constrained. 
Such models restrict the size of the hypotheses space sufficiently to ensure good 
generalization performance from a small number of examples. 
3 Application to Stock Selection 
We apply the ideas of multi-task learning to a problem of stock selection and port- 
folio management. We consider a universe of 36 assets, including 35 risky assets 
and one risk-free asset. The risky assets are 35 Canadian large-capitalization stocks 
from the Toronto Stock Exchange. The risk-free asset is represented by 90-days 
Canadian treasury bills. The data is monthly and spans 8 years, from February 
1986 to January 1994 (96 months). Each month, one can buy or sell some of these 
assets in such a way as to distribute the current worth between these assets. We do 
not allow borrowing or short selling, so the weights of the resulting portfolio are all 
non-negative (and they sum to 1). 
We have selected 5 explanatory variables, 2 of which represent macro-economic 
variables which are known to influence the business cycle, and 3 of which are micro- 
economic variables representing the profitability of the company and previous price 
changes of the stock. The macro-economic variables were derived from yields of 
long-term bonds and from the Consumer Price Index. The micro-economic variables 
were derived from the series of dividend yields and from the series of ratios of stock 
price to book value of the company. Spline extrapolation (not interpolation) was 
used to obtain monthly data from the quarterly or annual company statements or 
macro-economic variables. For these variables, we used the dates at which their 
value was made public, not the dates to which they theoretically refer. 
To take into account the non-stationarity of the financial and economic time-series, 
and estimate performance over a variety of economic situations, multiple training 
experiments were performed on different training windows, each time testing on 
the following 12 months. For each architecture, 5 such trainings took place, with 
training sets of size 3, 4, 5, 6, and 7 years respectively. Furthermore, multiple such 
experiments with different initial weights were performed to verify that we did not 
obtain lucky results due to particular initial weights. The 5 concatenated test 
periods make an overall 5-year test period from February 1989 to January 1994. 
The training algorithm is described in (Bengio, 1996) and is based on the optimiza- 
tion of the neural network parameters with respect to a financial criterion (here 
maximizing the overall profit). The outputs of the neural network feed a trading 
Multi-Task Learning for Stock Selection 949 
module. The trading module has as input at each time step the output of the net- 
work, as well as, the weights giving the current distribution of worth between the 
assets. These weights depend on the previous portfolio weights and on the relative 
change in value of each asset (due to different price changes). The outputs of the 
trading module are the current portfolio weights for each of the assets. Based on 
the difference between these desired weights and the current distribution of worth, 
transactions are performed. Transaction costs of 1% (of the absolute value of each 
buy or sell transaction) are taken into account. Because of transaction costs, the ac- 
tions of the trading module at time t influence the profitability of its future actions. 
The financial criterion depends in a non-additive way on the performance of the 
network over the whole sequence. To obtain gradients of this criterion with respect 
to the network output we have to backpropagate gradients backward through time, 
through the trading module, which computes a differentiable function of its inputs. 
Therefore, a
