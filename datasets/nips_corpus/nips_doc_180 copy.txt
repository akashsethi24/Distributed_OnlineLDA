149 
FIXED POINT ANALYSIS FOR RECURRENT 
NETWORKS 
Mary B. Ottaway 
Patrice Y. Simard 
Dept. of Computer Science 
University of Rochester 
Rochester NY 14627 
Dana H. Ballard 
ABSTRACT 
This paper provides a systematic analysis of the recurrent backpropaga- 
tion (RBP) algorithm, introducing a number of new results. The main 
limitation of the RBP algorithm is that it assumes the convergence of 
the network to a stable fixed point in order to backpropagate the error 
signals. We show by experiment and eigenvalue analysis that this condi- 
tion can be violated and that chaotic behavior can be avoided. Next we 
examine the advantages of RBP over the standard backpropagation al- 
gorithm. RBP is sitown to build stable fixed points corresponding to the 
input patterns. This makes it an appropriate tool for content address- 
able memories, one-to-many function learning, and inverse problems. 
INTRODUCTION 
In the last few years tilere has been a great resurgence of interest in neural network 
learning algorithms. One of the most successful of these is the Backpropagation learning 
algorithm of [Rumelhart 86], which has shown its usefulness in a number of applications. 
This algorithm is representative of others that exploit internal units to represent very 
nonlinear decision surfaces [Lipproart 87] and thus overcomes the limits of the classical 
perceptton [Rosenblatt 62]. 
WitIt its enormous advantages, the backpropagation algorithm has a number of dis- 
advantages. Two of these are the inability to fill in patterns and the inability to solve 
one-to-many inverse problems [Jordan 88]. These limitations follow from the fact that 
the algorithm is only defined for a feedforward network. Thus if part of the pattern is 
missing or corrupted in the input, this error will be propagated through to the output and 
the original pattern ;viii not be restored. In one-to-many problems, several solutions are 
possible for a given input. On a feedforward net, the competing targets for a given input 
introduce contradictory error signals and learning in unsuccessful. 
Very recently, these limitations have been removed with the specification of a recurrent 
backpropagation algorithm [Pineda 87]. This algorithm effectively extends the backpropa- 
gation idea to networks of arbitrary connection topologies. This advantage, however, does 
not come without some risk. Since the connections in the network are not symmetric, the 
stability of the network is not guaranteed. For some choices of weights, the state of the 
units nay oscillate indefinitely. 
This paper provides a systematic analysis of the recurrent backpropagation (RBP) 
algorithn, introducing a number of new results. The main limitation of the RBP algorithm 
is that it assrunes the convergence of the network to a stable fixed point in order to 
150 Sirnard, Ottaway and Ballard 
backpropagate the error signals. We show by experiment and eigenvalue analysis that this 
condition can be violated and that chaotic behavior can be avoided. 
Next we examine the advantage in convergence speed of RBP over the standard back- 
propagation algorithm. RBP is shown to build stable fixed points corresponding to the 
input patterns. This makes it an appropriate tool for content addressable memories, many- 
to-one function learning and inverse problem. 
MODEL DESCRIPTION 
The simulations have been done on a recurrent backpropagation network with first order 
units. Using the same formalism as [Pineda 87], the vector state a: is updated according 
to the equation: 
dxi/dt = -x, + #,(u) + I, (1) 
i = 1,2,...,N (2) 
where 
Ui -'  WijXj for 
The activation function is the logistic function 
1 
#(() = 1 + e- (3) 
The networks we will consider are organized in modules (or sets) of units that perform 
similar functions. For example, we talk about fully connected module if each unit in the 
module is connected to each of the others. An input module is a set of units where each 
tinit has non-zero input function Ii. Note that a single unit can belong to more than 
one module at a time. The performance of the network is measured through the energy 
function: 
vhere 
N 
i--1 
(4) 
s, = - x?) and x? = (5) 
An output module is a set of units i such that Ji  O. Units that do not belong to any 
input or output modules are called hidden units. A unit (resp module) can be clamped 
and tinclamped. When the unit (resp module) is unclamped, Ii = Ji -' 0 for the unit 
(resp the module). If the unit is clamped, it behave according to the pattern presented to 
the network. Unclamping a unit results in making it hidden. Clamping and unclamping 
actions are handy concepts for the study of content addressable memory or generalization. 
The goal for the network is to minimize the energy function by changing the weights 
accordingly. One way is to perform a gradient descent in E using the delta rule: 
OE 
dwo/dt = -- Owij (6) 
where  is a learning rate constant. The weight variation  a function of the error is given 
by the formul [Pineda 87, Alineida 87] 
dwid/dt=nyFx F (7) 
Fixed Point Analysis for Recurrent Networks 151 
witere y? is a solution of the dynamical system 
dyi/dt = -Yi + gi(ui ) wikyk + Ji (8) 
The above discussion, assumes that the input function I and the target T are constant 
over time. In our simulation however, we have a set of patterns Pa presented to the 
network. A pattern is a tuple in ([0, 1] t (U)) r, where N is the total number of units 
and U stands for unclamped. The ita vMue of the tuple is the value signed to Ii and 
when the pattern is presented to the network (if the value is U, the unit is unclamped for 
the time of presentation of the pattern). This definition of a pattern does not allow 
and Ti to have different values. This is not an important restriction however since we 
can can always simulate such an (inconsistent) unit with two units. The energy function 
to be minimized over all the patterns is defined by the equation: 
(9) 
The gradient of Etot,t is simply the sum of the gradients of E(a), and hence the updating 
equation has the form: 
dwij/dt = r Z y?(o)x?(c) (10) 
When a pattern P, is presented to the network, an approximation of x�(e) is first 
computed by doing a few iterations using equation I (propagation). Then, an approx- 
imation of y�(e) is evaluated by iterating equation 8 (backpropagation). The weights 
are finally updated using equation 10. If we assume the number of iterations to evaluate 
xj��(e) and y�(cr) to be constant, the total number of operations required to update the 
weights is O(N ). The validity of this assumption will be discussed in a later section. 
CONVERGENCE OF THE NETWORK 
The learning algorithm for our network assumes a correct approximation of x �. This value 
is computed by recursively propagating the activation signals according to equation 1. The 
effect of varying the number of propagations can be illustrated with a simple experiment. 
Consider a fully connected network of eight units (it's a directed anti-reflexive graph). 
Four of them are auto-associative units which are presented various patterns of zeroes and 
ones. An auto-associative unit is best viewed as two visible units, one having all of the 
inctuning connections and one having all of the outgoing connections. When the auto- 
associative unit is not clamped, it is viewed as a hidden unit. The four remMning units 
arc hidden. The error is measured by the differences between the activations (from the 
incoming connections) of the auto-associative nnits and the corresponding target value 
/] for each pattern. In running the experiment, eight patterns were presented to the 
network perfo[213zrming I to 5 propagations of the activations using Equation 1, 20 back- 
propagations of the error signals according to Equation 8, and one update (Equation 10) 
of the weights per presentation. We define an epoch to be a sweep through the eight 
patterns using the above formula of execution on each. The corresponding results using 
a learning rate of 0.2 are shown in figure 1. It can easily be seen that using one or two 
propagations does not suffice to set the hidden units to their correct values. However, 
the network does learn correctly how to reproduce the eight patterns when 3 or more 
152 Simard, Ottaway and Ballard 
Error 2 -- 
0 
5OO 
 p. ropagations 
1000 1500 2000 
Error 2 -- 
I 1 , 4 back-propagations 
0 500 1000 1500 2000 
Figure 1' Learning curves for a recurrent network with different numbers of propa- 
gations of the activation and back-propagation of the error signals. 
Fixed Point Analysis for Recurrent Networks 153 
propagations are done after each presentation of a new pattern. This is not surprising 
since the rate of convergence to a fixed point is geometric (if the fixed point is stable), 
thus making only a few propagations necessary. We suspect that larger networks with a 
fully connected topology will still only require a few iterations of forward propagation if 
the fixed points are fairly stable. In the next section, we will study a problem, where this 
assumption is not true. In such a situation, we use an algorithm where the number of 
forward propagations varies dynamically. 
For some specialized networks such as a feed-forward one, the number of propagations 
must be at least equal to the number of layers, so that the output units receive the 
activation corresponding to the input before the error signal is sent. 
Similarly, yO is computed recursively by iterative steps. We used the same experiment 
as described above with 1 to 4 back-propagations of the error signals to evaluate the time 
yt takes to converge. The rest of this experiment remained the same as above, except 
that the number of propagations for a: t was set to 20. The learning curves are shown in 
figure 1. It is interesting to note that with only one propagation of the error signal, the 
system was able to complete the learning, for the isolated curve ten
