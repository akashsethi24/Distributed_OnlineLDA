Discontinuous Recall Transitions Induced By 
Competition Between Short- and Long-Range 
Interactions in Recurrent Networks 
N.S. Skantzos, C.F. Beckmann and A.C.C. Coolen 
Dept of Mathematics, King's College London, Strand, London WC2R 2LS, UK 
E-mail: skantzos@mth.kcl.ac.uk tcoolen@mth.kcl.ac.uk 
Abstract 
We present exact analytical equilibrium solutions for a class of recur- 
rent neural network models, with both sequential and parallel neuronal 
dynamics, in which there is a tunable competition between nearest- 
neighbour and long-range synaptic interactions. This competition is 
found to induce novel coexistence phenomena as well as discontinuous 
transitions between pattern recall states, 2-cycles and non-recall states. 
1 INTRODUCTION 
Analytically solvable models of large recurrent neural networks are bound to be simplified 
representations of biological reality. In early analytical studies such as [ 1, 2] neurons were, 
for instance, only allowed to interact with a strength which was independent of their spatial 
distance (these are the so-called mean field models). At present both the statics of infinitely 
large mean-field models of recurrent networks, as well as their dynamics away from satura- 
tion are well understood, and have obtained the status of textbook or review paper material 
[3, 4]. The focus in theoretical research of recurrent networks has consequently turned to 
new areas such as solving the dynamics of large networks close to saturation [5], the anal- 
ysis of finite size phenomenology [6], solving biologically more realistic (e.g. spike-based) 
models [7] or analysing systems with spatial structure. In this laper we analyse mod- 
els of recurrent networks with spatial structure, in which there are two types of synapses: 
long-range ones (operating between any pair of neurons), and short-range ones (operating 
between nearest neighbours only): In contrast to early papers on spatially structured net- 
works [8], one here finds that, due to the nearest neighbour interactions, exact solutions 
based on simple mean-field approaches are ruled out. Instead, the present models can be 
solved exactly by a combination of mean-field techniques and the so-called transfer ma- 
trix method (see [9]). In parameter regimes where the two synapse types compete (where 
one has long-range excitation with short-range inhibition, or long-range Hebbian synapses 
with short-range anti-Hebbian synapses) we find interesting and potentially useful novel 
phenomena, such as coexistence of states and discontinuous transitions between them. 
338 N. S. Skantzos, C. F. Beckmann and A. C. C. Coolen 
2 MODEL DEFINITIONS 
We study models with N binary neuron variables ai = 4-1, which evolve in time stochas- 
tically on the basis of post-synaptic potentials hi (), following 
I [1 :k: tanh[/hi((t))]] hi(W) = E Jijaj + Oi (1) 
Prob[ai(t + 1)= +1] =  
The variables Jq and Oi represent synaptic interactions and firing thresholds, respectively. 
The (non-negative) parameter/ controls the amount of noise, with/ = 0 and/ = oo corre- 
sponding to purely random and purely deterministic response, respectively. If the synaptic 
matrix is symmetric, both a random sequential execution and a fully parallel execution of 
the stochastic dynamics (1) will evolve to a unique equilibrium state. The corresponding 
microscopic state probabilities can then both formally be written in the Boltzmann form 
Po() ~ exp[-BH()], with [10] 
Zseq() ---- -- E �'iZij�'J-E OiO'i 
i<j  
1 
Hpar() = - E log cosh[/hi()]- E Oiai 
i i 
(2) 
For large systems the macroscopic observables of interest can be obtained by differentiation 
of the free energy per neuron f = - limv- (/N) - log Ye exp[-/H()], which acts 
as a generating function. For the synaptic interactions JO and the thresholds Oi we now 
make the following choice: 
model I: Ji =  ij + Js(Sid+! + 5i,j-! ) ij Oi = Oi (3) 
(which corresponds to the result of having stored a binary pattern '  {-1, 1} v through 
Hebbian-type learning), with Jr, J,, 0   and i + N -- i. The neurons can be thought of as 
being arranged on a periodic one-dimensional array, with uniform interactions of strength 
Jti IN, in combination with nearest neighbour interactions of strength J,ij. Note that 
model I behaves in exactly the same way as the following 
model II: jq _ Jt 
-  + J(5,j+ + 5i,j_) 0 = 0 (4) 
since a simple transformation ai ---> aii maps one model into the other. Taking derivatives 
of f with respect to the parameters 0 and J, for model II produces our order parameters, 
expressed as equilibrium expectation values. For sequential dynamics we have 
Of _ lim 1 E(rri+rri ) (5) 
Of_ lim 1 
m = O0 N-o 
For parallel dynamics the corresponding expressions turn out to be 
1Of_ lim I 1 Of _ lim 1 E(ai+x tanh[/3hi(ff)]) 
m-- 200 N-oN 
(6) 
We have simplified (6) with the identities (ai+ tanh[/3hi()]} = (ai- tanh[/hi()]} and 
(tanh[/hi ()]} = (ai}, which follow from (1) and from invariance under the transforma- 
tion i --> N + 1 - i (for all i). For sequential dynamics a describes the average equilibrium 
state covariances of neighbouring neurons. For parallel dynamics a gives the average equi- 
librium state covariances of neurons at a given time t, and their neighhours at time t + 1 (the 
difference between the two meanings of a will be important in the presence of 2-cycles). 
In model II m is the average activity in equilibrium, whereas for model I one finds 
m = lim 1 
i 
This is the familiar overlap order parameter of associative memory models [1, 2], which 
measures the quality of pattern recall in equilibrium. The observable a transforms similarly. 
Competition between Short- and Long-Range Interactions 339 
3 SOLUTION VIA TRANSFER MATRICES 
From this stage onwards our analysis will refer to model II, i.e eqn (4); the results can im- 
mediately be translated into the language of model I (3) via the transformation cr i -- crii. 
In calculating f it is advantageous to separate terms induced by the long-range synapses 
from those induced by the short-range ones, via insertion of 1 = fdm 6[rn -  Y]i cri]' 
Upon using the integral representation of the 6-function, we then arrive at 
f = - lim 1 
with v- - log dmdrh e -v(''r) 
I 2 1 
qseq(m,r) = -im -mO - Jtm /3N lOgRseq() (7) 
1 
qSpar (m, rh) =-im& - m0 -/30 log Rpar(m, rh) (8) 
The quantities R contain all complexities due to the short-range interactions in the model 
(they describe a periodic one-dimensional system with neighbout interactions only): 
aseq() = W' E, 
{-,} 
Rpar(m, ) - E �-i/3Vn 'i rl �'ilogcosh/3[Jtrn+O+Jo(ri+x+a,_x)] 
e{-,}  
They can be calculated using the transfer-matrix technique [9], which exploits an interpre- 
tation of the summations over the N neuron states ai as matrix multiplications, giving 
: [Tseq] Tseq: e_/jo e/Jo+i/ 
= [ror] ror = coh[o] 
where wo =Jtm +  and w+ = wo 4- 2J. The identity Tr [T v] = A v A v 
+ + _,in which 
A+ are the eigenvalues of the 2 x 2 matrix T, enables us to take the limit N   in our 
equations. The integral over (m, h) is for N   evaluated by gradient descent, and is 
dominated by the saddle points of the exponent b. We thus arrive at the transparent result 
lseq 
f = extr (m,h) 4�r(m, h) = -imh- mO-  logA r (9) 
where seq and lpar 
.,+ .,+ are the largest eigenvalues of Tseq and Tpar. For simplicity, we will 
restrict ourselves to the case where 0 = 0; generalisation of what follows to the case of 
arbitrary 0, by using the full form of (9), is not significantly more difficult. The expressions 
defining the value(s) of the order parameter rn can now be obtained from the saddle point 
equations Oraq(m, ) -- Oq(m, ) -- 0. Straightforward differentiation shows that 
sequential: rh = imJt, rn = G(rn; Jr, Js) 
parallel: rh = irnJt, rn = G (rn; Jr, J ) for Jt > 0 (10) 
 = -imJt, rn = G(rn;-Jt,-Js) for Jt < 0 
with 
G(ra; Jt, J ) = sinh[/Jtm] (11) 
sinh:[/Jtrn] + e-4/3Jo 
Note that equations (10,11) allow us to derive the physical properties of the parallel dy- 
namics model from those of the sequential dynamics model via simple transformations. 
340 N. S. Skantzos, C. F. Beckmann and.4. C. C. Coolen 
4 PHASE TRANSITIONS 
Our main order parameter m is to be determined by solving an equation of the form m - 
G(m), in which G(m) = G(m; Jr, Js) for both sequential and parallel dynamics with 
Jt >_ 0, whereas G(m) = G(m;-Jt,-Js) for parallel dynamics with Jt < 0. Note that, 
due to (7(0; Jr, J,) - 0, the trivial solution m = 0 always exists. In order to obtain a phase 
diagram we have to perform a bifurcation analysis of the equations (10,11), and determine 
the combinations of parameter values for which specific non-zero solutions are created or 
annihilated (the transition lines). Bifurcations of non-zero solutions occur when 
m = (7(m) and 1 = (7'(m) (12) 
The first equation in (12) states that m must be a solution of the saddle-point problem, the 
second one states that this solution is in the process of being created/annihilated. Nonzero 
solutions of m = G(m) can come into existence in two qualitatively different ways: as con- 
tinuous bifurcations away from the trivial solution m - 0, and as discontinuous bifurcations 
away from the trivial solution. These two types will have to be treated differently. 
4.1 Continuous Transitions 
An analytical expression for the lines in the (/J,,/Jt) plane where continuous transitions 
occur between recall states (where m  0) and non-recall states (where rn = 0) is obtained 
by solving the coupled equations (12) for m = 0. This gives: 
cont. trans.: sequential: Jt = e -23 
parallel: /3Jr = e -2a' and /3Jr = -e a' (13) 
If along the transition lines (13) we inspect the behaviour of (7(m) close to m = 0 we 
can anticipate the possible existence of discontinuous ones, using the properties of G(m) 
for m -> +o0, in combination with G(-m) = -G(m). 
