Can Simple Cells Learn Curves? A Hebbian Model in a Structured Environment 125 
Can Simple Cells Learn Curves? A 
Hebbian Model in a Structured 
Environment 
William R. $oftky 
Divisions of Biology and Physics 
103-33 Caltech 
Pasadena, CA 91125 
bill@aurel.caltech.edu 
Daniel M. Kammen 
Divisions of Biology and Engineering 
216-76 Caltech 
Pasadena, CA 91125 
kammen@aurel.cns.caltech.ed u 
ABSTRACT 
In the mammalian visual cortex, orientation-selective 'simple cells' 
which detect straight lines may be adapted to detect curved lines 
instead. We test a biologically plausible, Hebbian, single-neuron 
model, which learns oriented receptive fields upon exposure to un- 
structured (noise) input and maintains orientation selectivity upon 
exposure to edges or bars of all orientations and positions. This 
model can also learn arc-shaped receptive fields upon exposure 
to an environment of only circular rings. Thus, new experiments 
which try to induce an abnormal (curved) receptive field may pro- 
vide insight into the plasticity of simple cells. The model suggests 
that exposing cells to only a single spatial frequency may induce 
more striking spatial frequency and orientation dependent effects 
than heretofore observed. 
I Introduction 
Although most mathematical theories of cortical function assume plasticity of indi- 
vidual cells, there is a strong debate in the biological community between instruc- 
tional (plastic) and selectional (hard-wired) models of orientation-selective cells 
126 Softky and Kammen 
(which we will call simple cells) in striate visual cortex. Thus, a theory of simple 
cell learning which can make experimental predictions is desirable. 
1.1 Overview of Plasticity Experiments 
The most illuminating experiments addressing the plasticity of visual cortex are 
collectively called stripe-rearing. Such experiments artificially restrict the visual 
environment of animals (usually kittens) to a few straight, dark, parallel lines (e.g. 3 
vertical stripes.) In the many cases studied, examination of the visual cortex reveals 
that animals which viewed such limited visual environments posses more simple cells 
tuned to the exposed orientation than tuned to other orientations. (For comparison, 
the simple cells of animals with normal visual experience are equally distributed 
among all orientations.) But the observed changes in cell populations can be equally 
well explained by instructional and selectional hypotheses (Stryker et a/.1978). 
Although many variations on stripe-rearing have been tried (different orientations 
for each eye, one eye closed, etc.), only environments spanning a very restricted 
subset (straight lines) of the natural environment have been studied (Hirsch et al. 
1983, Blakemore et al. 1978, and see references therein). Conclusions regarding 
plasticity have been based on changes in populations of simple cells, rather than on 
changes in individual cells. Statistical arguments based on changes in large groups 
of cells are questionable, since the well-documented lateral interactions between 
cortical neurons may constrain population ratios, e.g. limit the fraction of neurons 
responding to a single orientation. 
1.2 New Experimental Approach 
We propose several experiments to alter the receptive field (RF) of a single cell (see 
also Fregnac et al. 1988). How might that be done? The RF of a simple cell has only 
one characteristic spatial frequency (Jones & Palmer 1987 and ref's therein). To try 
altering the shape of that RF, it is necessary to present a pattern which is different 
from a simple bar or edge, but is still sufficiently similar in spatial frequency to 
activate the same population of retinal cells that detect the bar. An arc-shaped RF 
satisfies this condition; to generate an arc-shaped RF, an environment of circular 
rings (rather than bent bars) is necesary, since complete circles lack sharp end-effects 
which could overexcite spatial opponent cells and thus disturb learning. 
This paper proposes a very simple Hebbian model of a neuron, and examines the 
resulting plasticity upon exposure to edge, bar, and arc-shaped stimuli. 
2 Mathematical Model 
The model applies a simple Hebbian learning rule to an array of about 400 synapses. 
There are several important features of this model. One is that the stimulus is a 
visual environment of structured input (bars, edges, or circles) rather than only 
stochastic (noise) input, as was used in the previous Hebb-learning models of Linsker 
(1986) and Kammen &: Yuille (1988). (For a review of Hebbian learning and neural 
development see Kammen and Yuille 1990). Second, the input is Laplace filtered 
Can Simple Cells Learn Curves? A Hebbian Model in a Structured Environment 127 
to simulate the retinal processing stage; and third, all connections are rectified to 
be excitatory, like direct afferent input to simple cells. 
2.1 Overview 
We model the neuron as an array of non-negative synapses, distributed within a 
circular region. To let the neuron see a single pattern in the visual environment 
(see Figure 1, end of text), the array is overlaid on a much larger positive array (the 
filtered image), which represents the environment. Each synapse value is multiplied 
by its corresponding input pixel, and the sum of these products forms the neuron's 
output. If the output is above a threshold value, each synapse is changed slightly 
to make it more like its corresponding pixel (the synapse is increased for a positive 
pixel, and decreased for a zero pixel.) If the output is low, nothing is changed. This 
process implements the correlation-based (Hebbian) learning rule for synapse 
modification. To ensure maturation, we presented roughly one million training 
images to each neuron. Because there are many filtered images, only one is chosen 
at random for each iteration, and the neuron is overlapped at some random spatial 
offset. 
2.2 Input Filtering Process 
The visual environment is a collection of N black-on-white pictures of a single shape 
(such as straight lines), at fixed contrast. The environment seen by the neuron is 
a set of N filtered images, whose non-negative elements are produced from the 
pictures by a rectified, Laplace-like, center-surround process similar to that of the 
mammalian retina (Van Essen & Anderson 1988). To determine the RF of a mature 
array of synapses, the combined efficacy of all synapses is calculated for each pixel, 
and displayed as a grey scale (white = excitatory, black - inhibitory). See Figure 
2, at end of text, for several examples of mature RF's. 
2.3 Plasticity Under Visual Stimulation 
The neuron's input synapses cover a circle much smaller than the filtered image. A 
single exposure to the environment overlaps the synapse array at a random position 
on the input image (chosen randomly from the training set). This overlap pairs 
each synapse with an input from a filter whose center has like polarity (on or off), 
so that each synapse represents a definite polarity of retinal cell. 
A typical run involves perhaps 10 6 exposures. There is no time variable, so that 
motion and temporal correlations between images are entirely absent. During each 
exposure a Hebb rule (section 2.4) changes synaptic weights based on current cell 
output and input values. When the neuron is exposed to filtered stochastic input 
(noise-rearing), synapses are intitialized randomly. When the neuron is exposed 
to structured environments, synapses are initialized with the orderly synapse arrays 
which result from noise-rearing. (As in animals, synapses may evolve in response to 
filtered random input before they are exposed to the external environment.) 
128 Softky and Kammen 
2.4 A Choice of Hebb Rules for Learning Plasticity 
Hebb postulated (1949) that neurons modify their synapses according to the fol- 
lowing rule: the synapse will increase in efficacy if the post-synaptic and presy- 
naptic excitations are coincident. There are many different formulae which satisfy 
Hebb's criterion; this model explores some simple representative ones. During each 
exposure to input, the synapses are adjusted according to the following type of 
hard-limited Hebb rule: 
out -- E syni x ini (1) 
i 
And if (out- thresh) > 0 ï¿½ 
Asyni = (out--thresh)nx ini x growth (2) 
if ini > 0 and syni < 10 
-- -(out- thresh) n x decay 
if ini '- 0 and syni  0.5 
-- 0 otherwise 
(3) 
(4) 
The constants growth and decay are positive, and the exponent n is at least one. 
Both types of threshold depend on the neuron's recent output history: either the 
average of the previous 200 outputs, or one half the maximum previous output 
(decaying by .9995 each exposure until a new - exceeds it). This Hebb Rule 
assumes that the cell can detect the current input value before its modification by 
a synapse. 
2.5 Choice of Parameters 
The constants growth and decay are not sensitive parameters. We found that only 
three parameter regimes exist: all synapses saturate at maximum, all saturate at 
minimum, or some at maximum and some at minimum. Only the latter regime is 
of interest, because only it contains structured RF's. 
Most simulations used n = 1,2,3 with both thresholds. The threshold based on 
maximum output enhances learning selectivity, while the averaged output version 
can be derived from a principle of excess information (See Appendix). Because 
simple cell RF's have approximately Gaussian envelopes (Jones & Palmer 1987), 
some simulations were done with Gaussian envelopes modulating the maximum 
synapse values. That modification made no difference in the results observed. 
3 Results and Discussion 
The production of oriented RFs during exposure to unstructured input confirms 
previous results by Linsker (1986) and Yuille et al. (1989), but with some im- 
portant differences. Like those models, the neurons simulated here learn oriented 
stripe-patterns as a kind of lowest-energy configuration under exposur
