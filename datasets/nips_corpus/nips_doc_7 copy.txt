474 
OPTIMIZATION WITH ARTIFICIAL NEURAL NETWORK SYSTEMS: 
A MAPPING PRINCIPLE 
AND 
A COMPARISON TO GRADIENT BASED METHODS * 
Harrison MonFook Leong 
Research Institute for Advanced Computer Science 
NASA Ames Research Center 230-5 
Moffett Field, CA, 94035 
ABSTRACT 
General formulae for mapping optimization problems into systems of ordinary differential 
equations associated with artificial neural networks are presented. A comparison is made to optim- 
ization using gradient-search methods. The performance measure is the settling time from an initial 
state to a target state. A simple analytical example illustrates a situation where dynamical systems 
representing artificial neural network methods would settle faster than those representing gradient- 
search. Settling time was investigated for a more complicated optimization problem using com- 
puter simulations. The problem was a simplified version of a problem in medical imaging: deter- 
mining loci of cerebral activity from electromagnetic measurements at the scalp. The simulations 
showed that gradient based systems typically setfled 50 to 100 times faster than systems based on 
current neural network optimization methods. 
INTRODUCTION 
Solving optimization problems with systems of equations based on neurobiological principles 
has recently received a great deal of attention. Much of this interest began when an artificial 
neural network was devised to find near-optimal solutions to an np-complete problem t3. Since 
then, a number of problems have been mapped into the same acdficial neural network and varia- 
tions of it to.3.,.7.8.9.2L23.2, In this paper, a unifying principle underlying these mappings is 
derived for systems of first to n th-order ordinary differential equations. This mapping principle 
bears similarity to the mathematical tools used to generate optimization methods based on the gra- 
dient. In view of this, it seemed important to compare the optimization efficiency of dynamical 
systems constructed by the neural network mapping principle with dynamical systems constructed 
from the gradient. 
THE PRINCIPLE 
This paper concerns itself with networks of computational units having a state variable v, a 
function f that describes how a unit is driven by inputs, a linear ordinary differential operator with 
constant coefficients D (v) that describes the dynamical response of each unit, and a function g that 
describes how the output of a computational unit is determined from its state v. In particular, the 
paper explores how outputs of the computational units evolve with time in terms of a scalar func- 
tion E, a single state variable for the whole network. Fig. 1 summarizes the relationships between 
variables, functions, and operators associated with each computational unit. Eq. (1) summarizes the 
equations of motion for a network composed of such units: 
tY()(v ) = j'(g (vO ..... gN(vN ) ) 
where the i th element of/(t) is D(t)(v;) ' superscript (M) denotes that operator D is M tn order, 
the i tn element of f is fi(gt(vt) ..... gv(vv)), and the network is comprised of N computa- 
tional units. The network of Hopfield t2 has M=I, functions f are weighted linear sums, and func- 
tions  (where the i  element of  is gi(vi) ) are all the same sigmoJd function. We will exam- 
ine two ways of defining functions  given a function F. Along with these definitions will be 
Work supported by NASA Cooperative Agreement No. NCC 2408 
American Institute of Physics 1988 
475 
deftned corresponding functions E that will be used to describe the dynamics of Eq. (1). 
The first method corresponds to optimization methods introduced by artificial neural network 
research. It will be referred to as method V (dell g): 
�-- 
with associated E function 
Here, 
dr,, (s) 
dt (2b) 
denotes the gradient of H, where partials are taken with respect to variables of 2?, and 
Ee denotes the E function associated with gradient operator Ve. With appropriate operator D and 
functions f and , EF is simply the energy function of Hopfield 2. Note that F_,q. (2a) makes 
explicit that we will only be concerned with f' that can be derived from scalar potential functions. 
For example, this restriction excludes artificial neural networks that have connections between exci- 
tatory and inhibitory units such as that of Freeman 8. The second method corresponds to optimiza- 
tion methods based on the gradient. It will be referred to as method V v, (dell v): 
f = V-,F (3a) 
with associated E function 
t N 
= F() - ,. 9(U)(v:(s)) 
to that for Eqs. (2). 
dvi(s) ] dvi(s) 
dt J dt ds 
(3b) 
 computational unit i: 
transform that determines unit i's 
g;(, output from state variable vi 
/t D (v:)  differential operator specifying the 
\ - v(] function governing how inputs to 
 //'- unit i are combined to drive it 
Figure 1: Schematic of a computational unit i from which net- 
where notation is analogous 
The critical result 
that allows us to map 
optimization problems into 
networks described by Eq. 
(1) is that conditions on the 
constituents of the equation 
can be chosen so that along 
any solution trajectory, the 
E function corresponding 
to the system will be a 
monotonic function of time. 
For method Vxv, here are 
the conditions: all func- 
tions  axe 1) differentiable 
and 2) monotonic in the 
same sense. Only the first 
works considered in this paper are constructed. Trianes suggest 
condition is needed to 
make a similar assertion for connections between computational units. 
method V�. When these conditions are met and when solutions of Eq. (1) exist, the dynamical sys- 
tems can he used for optimization. The appendix contains proofs for the monotonicity of function 
E along solution trajectories and references necessary existence theorems. In conclusion, mapping 
optimization problems onto dynamical systems summarized by Eq. (1) can he reduced to a matter 
of differentiation if a scalar function representation of the problem can be found and the integrals 
of Eqs. (2b) and (3b) are ignorable. This last assumption is certainly upheld for the case where 
operator D has no derivatives less than M t order. In simulations below, it will be observed to 
hold for the case M=I with a nonzero 0 t order derivative in D. (Also see Lapedes and Farber 9.) 
PERSPECTIVES OF RECENT WORK 
476 
The formulations above can be used to classify the neural network optimization techniques 
used in several recent studies. In these studies, the functions  were all identical. For the most 
part, following Hopfield's formulation, researchers o.3.1,.7,23. z have used method Vi to derive 
forms of Eq. (1) that exhibit the ability to find extrema of Ei with Ei quadratic in functions  and 
all functions  describable by sigrnoid functions such as tanh (x). However, several researchers 
have written about artificial neural networks associated with non-quadratic E functions. Method 
Vi has been used to derive systems capable of finding extrema of non-quadratic Ei 19. Method 
V� has been used to derive systems capable of optimizing E- e where E- e were not necessarily qua- 
dratic in variables  2. A sort of hybrid of the two methods was used by leffery and Rosner a to 
find extrema of functions that were not quadratic. The important distinction is that their functions f 
were derived from a given function F using Eq. (3a) where, in addition, a sign definite diagonal 
matrix was introduced; the left side of Eq. (3a) was left multiplied by this matrix. A perspective 
on the relationship between all three methods to construct dynamical systems for optimization is 
summarized by Eq. (4) which describes the relationship between methods Vi and VN 
[as(v,) ]-, 
vf, = a,g [. (4) 
where diag [ xl ] is a diagonal matrix with xi as the diagonal element of row i. (A similar equation 
has been derived for quadratic F .) The relationship between the method of Jeffery and Rosner 
and V is simply F.q. (4) with the time dependent diagonal matrix replaced by a constant diagonal 
matrix of free parameters. It is noted that Jeffery and Rosner presented timing results that compared 
simulated annealing, conjugate-gradient, and artificial neural network methods for optimization. 
Their results axe not comparable to the results reported below since they used computation time as 
a performance measure, not settling times of analog systems. The perspective provided by F.q. (4) 
will be useful for anticipating the relative performance of methods Vi and V in the analytical 
example below and will aid in understanding the results of computer simulations. 
COMPARISON OF METHODS V AND 
When M=I and operator D has no 0 th order derivatives, method V is the basis of gradient- 
search methods of optimization. Given the long history of of such methods, it is important to know 
what possible benefits could be achieved by the relatively new optimization scheme, method Vi. 
In the following, the optimization efficiency of methods Vi,, ad V v, is compared by comparing set- 
tling times, the time required for dynamical systems described by Eq. (1) to traverse a continuous 
path to local optima. To qualify this performance measure, this study anticipates application to the 
creation of analog devices that would instantlate F.q. (1); hence, we are not interested in estimating 
the number of discrete steps that would be required to find local optima, an appropriate perfor- 
mance measure if the point was to develop new numerical methods. An analytical example will 
serve to illustrate the possibility of improvements in settling time by using method Vi instead of 
method V,. Computer simulations will be reported for more complicated problems following this 
example. 
For the analytical example, we will examine the case where all functions  are identical and 
g (v) = tanhG (v - Th ) (5) 
where G > 0 is the gain and Th is the threshold. Transforms similar to this are widely used in 
ar
