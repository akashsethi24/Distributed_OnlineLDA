Task and Spatial Frequency Effects on Face 
Specialization 
Matthew N. Dailey Garrison W. Cottrell 
Department of Computer Science and Engineering 
U.C. San Diego 
La Jolla, CA 92093-0114 
{mdailey, ary}cs. ucsd. edu 
Abstract 
There is strong evidence that face processing is localized in the brain. 
The double dissociation between prosopagnosia, a face recognition 
deficit occurring after brain damage, and visual object agnosia, difficulty 
recognizing other kinds of complex objects, indicates that face and non- 
face object recognition may be served by partially independent mecha- 
nisms in the brain. Is neural specialization innate or learned? We sug- 
gest that this specialization could be the result of a competitive learn- 
ing mechanism that, during development, devotes neural resources to the 
tasks they are best at performing. Further, we suggest that the specializa- 
tion arises as an interaction between task requirements and developmen- 
tal constraints. In this paper, we present a feed-forward computational 
model of visual processing, in which two modules compete to classify 
input stimuli. When one module receives low spatial frequency infor- 
mation and the other receives high spatial frequency information, and 
the task is to identify the faces while simply classifying the objects, the 
low frequency network shows a strong specialization for faces. No other 
combination of tasks and inputs shows this strong specialization. We 
take these results as support for the idea that an innately-specified face 
processing module is unnecessary. 
1 Background 
Studies of the preserved and impaired abilities in brain damaged patients provide important 
clues on how the brain is organized. Cases ofprosopagnosia, a face recognition deficit often 
sparing recognition of non-face objects, and visual object agnosia, an object recognition 
deficit that can occur without appreciable impairment of face recognition, provide evidence 
that face recognition is served by a special mechanism. (For a recent review of this 
18 M. N. Dailey and G. W. Cottrell 
evidence, see Moscovitch, Winocur, and Behrmann (1997)). In this study, we begin to 
provide a computational account of the double dissociation. 
Evidence indicates that face recognition is based primarily on holistic, configural informa- 
tion, whereas non-face object recognition relies more heavily on local features and analysis 
of the parts of an object (Farah, 1991; Tanaka and Sengco, 1997). For instance, the distance 
between the tip of the nose and an eye in a face is an important factor in face recognition, 
but such subtle measurements are rarely as critical for distinguishing, say, two buildings. 
There is also evidence that configural information is highly relevant when a human be- 
comes an expert at identifying individuals within other visually homogeneous object 
classes (Gauthier and Tarr, 1997). 
What role might configural information play in the development of a specialization for face 
recognition? de Schonen and Mancini (1995) have proposed that several factors, including 
different rates of maturation in different areas of cortex, an infant's tendency to track the 
faces in its environment, and the gradual increase in visual acuity as an infant develops, 
all combine to force an early specialization for face recognition. If this scenario is correct, 
the infant begins to form configural face representations very soon after birth, based pri- 
marily on the low spatial frequency information present in face stimuli. Indeed, Costen, 
Parker, and Craw (1996) showed that although both high-pass and low-pass image filter- 
ing decrease face recognition accuracy, high-pass filtering degrades identification accuracy 
more quickly than low-pass filtering. Furthermore, Schyns and Oliva (1997) have shown 
that when asked to recognize the identity of the face in a briefly-presented hybrid image 
containing a low-pass filtered image of one individual's face and a high-pass filtered image 
of another individual's face, subjects consistently use the low-frequency component of the 
image for the task. This work indicates that low spatial frequency information may be more 
important for face identification than high spatial frequency information. 
Jacobs and Kosslyn (1994) showed how differential availability of large and small receptive 
field sizes in a mixture of experts network (Jacobs, Jordan, Nowlan, and Hinton, 1991) 
can lead to experts that specialize for what and where tasks. In previous work, we 
proposed that a neural mechanism allocating resources according to their ability to perform 
a given task could explain the apparent specialization for face recognition evidenced by 
prosopagnosia (Dailey, Cottrell, and Padgett, 1997). We showed that a model based on 
the mixture of experts architecture, in which a gating network implements competitive 
learning between two simple homogeneous modules, could develop a specialization such 
that damage to one module disproportionately impaired face recognition compared to non- 
face object recognition. 
In the current study, we consider how the availability of spatial frequency information af- 
fects face recognition specialization given this hypothesis of neural resource allocation by 
competitive learning. We find that when high and low frequency information is split 
between the two modules in our system, and the task is to identify the faces while simply 
classifying the objects, the low-frequency module consistently specializes for face recog- 
nition. After describing the study, we discuss its results and their implications. 
2 Experimental Methods 
We presented a modular feed-forward neural network preprocessed images of 12 differ- 
ent faces, 12 different books, 12 different cups, and 12 different soda cans. We gave the 
network two types of tasks: 
Learning to recognize the superordinate classes of all four object types (hereafter 
referred to as classification). 
2. Learning to distinguish the individual members of one class (hereafter referred to 
Task and Spatial Frequency Effects on Face Specialization 19 
as identification) while simply classifying objects of the other three types. 
For each task, we investigated the effects of high and low spatial frequency information on 
identification and classification in a visual processing system with two competing modules. 
We observed how splitting the range of spatial frequency information between the two 
modules affected the specializations developed by the network. 
2.1 Image Data 
We acquired face images from the Cottrell and Metcalfe facial expression database (1991) 
and captured multiple images of several books, cups, and soda cans with a CCD camera 
and video frame grabber. For the face images, we chose five grayscale images of each of 12 
individuals. The images were photographed under controlled lighting and pose conditions; 
the subjects portrayed a different facial expression in each image. For each of the non-face 
object classes, we captured five different grayscale images of each of 12 books, 12 cups, 
and 12 cans. These images were also captured under controlled lighting conditions, with 
small variations in position and orientation between photos. The entire image set contained 
240 images, each of which we cropped and scaled to a size of 64x64 pixels. 
2.2 Image Preprocessing 
To convert the raw grayscale images to a biologically plausible representation more suitable 
for network learning and generalization, and to experiment with the effect of high and 
low spatial frequency information available in a stimulus, we extracted Gabor jet features 
from the images at multiple spatial frequency scales then performed a separate principal 
components analysis on the data from each filter scale separately to reduce input pattern 
dimensionality. 
2.2.1 Gabor jet features 
The basic two-dimensional Gabor wavelet resembles a sinusoid grating restricted by a two- 
dimensional Gaussian, and may be tuned to a particular orientation and sinusoidal fre- 
quency scale. The wavelet can be used to model simple cell receptive fields in cat primary 
visual cortex (Jones and Palmer, 1987). Buhmann, Lades, and yon der Malsburg (1990) 
describe the Gabor jet, a vector consisting of filter responses at multiple orientations and 
scales. 
We convolved each of the 240 images in the input data set with two-dimensional Gabor 
(a ' ' s  5 s 7,)and subsampled an 
filters at five scales in eight orientations ,v, , 7, , :Y, --, 7, s 
8x8 grid of the responses to each filter. The process resulted in 2560 complex numbers 
describing each image. 
2.2.2 Principal components analysis 
To reduce the dimensionality of the Gabor jet representation while maintaining a segrega- 
tion of the responses from each filter scale, we performed a separate PCA on each spatial 
frequency component of the pattern vector described above. For each of the 5 filter scales 
in the jet, we extracted the subvectors corresponding to that scale from each pattern in the 
training set, computed the eigenvectors of their covariance matrix, projected the subvectors 
from each of the patterns onto these eigenvectors, and retained the eight most significant 
coefficients. Reassembling the pattern set resulted in 240 40-dimensional vectors. 
20 M. N. Dailey and G. W. Cottrell 
Inputs 
Module 1 
Gate 
Ioo.-.l 
Figure 1: Modular network architecture. The gating network units mix the outputs of the 
hidden layers multiplicatively. 
2.3 The Model 
The model is a simple modular feed-forward network inspired by the mixture of experts 
architecture (Jordan and Jacobs, 1995); however, it contains hidden layers and is trained by 
backpropagation of error rather than maximum likelihood estimation or expectation maxi- 
mization. The connections to the output units come from two separate input/hidden layer 
pairs; these connections are gated multiplicatively by a simple linear network with so
