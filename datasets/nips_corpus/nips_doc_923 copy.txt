An experimental comparison 
of recurrent neural networks 
Bill G. Horne and C. Lee Giles* 
NEC Research Institute 
4 Independence Way 
Princeton, NJ 08540 
{horne, giles }research. nj. nec. com 
Abstract 
Many different discrete-time recurrent neural network architec- 
tures have been proposed. However, there has been virtually no 
effort to compare these arch:_tectures experimentally. In this paper 
we review and categorize many of these architectures and compare 
how they perform on various classes of simple problems including 
grammatical inference and nonlinear system identification. 
I Introduction 
In the past few years several recurrent neural network architectures have emerged. 
In this paper we categorize various discrete-time recurrent neural network architec- 
tures, and perform a quantitative comparison of these architectures on two prob- 
lems: grammatical inference and nonlinear system identification. 
2 RNN Architectures 
We broadly divide these networks into two groups depending on whether or not the 
states of the network are guaranteed to be observable. A network with observable 
states has the property that the states of the system can always be determined from 
observations of the input and output alone. The archetypical model in this class 
*Also with UMIACS, University of Maryland, College Park, MD 20742 
698 Bill G. Home, C. Lee Giles 
Table 1: Terms that are weighted in various single layer network architectures. ui 
represents the ith input at the current time step, zi represents the value of the jth 
node at the previous time step. 
Architecture bias ui zi uiuj ziuj zi z.i 
First order x x x 
High order x 
Bilinear x x x 
Quadratic x x x x x x 
was proposed by Narendra and Parthasarathy [9]. In their most general model, the 
output of the network is computed by a multilayer perceptron (MLP) whose inputs 
are a window of past inputs and outputs, as shown in Figure la. A special case of 
this network is the Time Delay Neural Network (TDNN), which is simply a tapped 
delay line (TDL) followed by an MLP [7]. This network is not recurrent since there 
is no feedback; however, the TDL does provide a simple form of dynamics that 
gives the network the ability model a limited class of nonlinear dynamic systems. 
A variation on the TDNN, called the Gamma network, has been proposed in which 
the TDL is replaced by a set of cascaded filters [2]. Specifically, if the output of 
one of the filters is denoted xj(k), and the output of filter i connects to the input 
of filter j, the output of filter j is given by, 
xs(k + 1) = #xi(k) + (1 - #)xs(k ). 
In this paper we only consider the case where # is fixed, although better results can 
be obtained if it is adaptive. 
Networks that have hidden dynamics have states which are not directly accessible 
to observation. In fact, it may be impossible to determine the states of a system 
from observations of it's inputs and outputs alone. We divide networks with hid- 
den dynamics into three classes: single layer networks, multilayer networks, and 
networks with local feedback. 
Single layer networks are perhaps the most popular of the recurrent neural network 
models. In a single layer network, every node depends on the previous output of 
all of the other nodes. The function performed by each node distinguishes the 
types of recurrent networks in this class. In each of the networks, nodes can be 
characterized as a nonlinear function of a weighted sum of inputs, previous node 
outputs, or products of these values. A bias term may also be included. In this 
paper we consider first-order networks, high-order networks [5], bilinear networks, 
and Quadratic networks[12]. The terms that are weighted in each of these networks 
are summarized in Table 1. 
Multilayer networks consist of a feedforward network coupled with a finite set of 
delays as shown in Figure lb. One network in this class is an architecture proposed 
by Robinson and Fallside [11], in which the feedforward network is an MLP. Another 
popular networks that fits into this class is Elman's Simple Recurrent Network 
(SRN) [3]. An Elman network can be thought of as a single layer network with an 
extra layer of nodes that compute the output function, as shown in Figure lc. 
In locally recurrent networks the feedback is provided locally within each individual 
An Experimental Comparison of Recurrent Neural Networks 699 
MLP 
(b) (c) 
Figure 1: Network architectures: (a) Narendra and Parthasarathy's Recurrent Neu- 
ral Network, (b) Multilayer network and (c) an Elman network. 
node, but the nodes are connected together in a feed forward architecture. Specifi- 
cally, we consider nodes that have local output feedback in which each node weights 
a window of its own past outputs and windows of node outputs from previous layers. 
Networks with local recurrence have been proposed in [1, 4, 10]. 
3 Experimental Results 
3.1 Experimental methodology 
In order to make the comparison as fair as possible we have adopted the following 
methodology. 
� Resources. We shall perform two fundamental comparisons. One in which the 
number of weights is roughly the same for all networks, another in which the 
number of states is equivalent. In either case, we shall make these numbers large 
enough that most of the networks can achieve interesting performance levels. 
Number of weights. For static networks it is well known that the generalization 
performance is related to the number of weights in the network. Although this 
theory has never been extended to recurrent neural networks, it seems reasonable 
that a similar result might apply. Therefore, in some experiments we shall try 
to keep the number of weights approximately equal across all networks. 
Number of states. It can be argued that for dynamic problems the size of the 
state space is a more relevant measure for comparison than the number of 
weights. Therefore, in some experiments we shall keep the number of states 
equal across all networks. 
� Vanilla learning. Several heuristics have been proposed to help speed learning 
and improve generalization of gradient descent learning algorithms. However, 
such heuristics may favor certain architectures. In order to avoid these issues, 
we have chosen simple gradient descent learning algorithms. 
� Number of simulations. Due to random initial conditions, the recurrent 
neural network solutions can vary widely. Thus, to try to achieve a statistically 
significant estimation of the generalization of these networks, a large number of 
experiments were run. 
700 Bill G. Home, C. Lee Giles 
Figure 2: A randomly generated six state finite state machine. 
3.2 Finite state machines 
We chose two finite state machine (FSM) problems for a comparison of the ability of 
the various recurrent networks to perform grammatical inference. The first problem 
is to learn the minimal, randomly generated six state machine shown in Figure 2. 
The second problem is to infer a sixty-four state finite memory machine [6] described 
by the logic function 
y() = ( - )() + (- )y( - 3) + ()(- )( - ) 
where u(k) and y(k) represent the input and output respectively at time k and g' 
represents the complement of x. 
Two experiments were run. In the first experiment all of the networks were designed 
such that the number of weights was less than, but as close to 60 as possible. In the 
second experiment, each network was restricted to six state variables, and if possible, 
the networks were designed to have approximately 75 weights. Several alternative 
architectures were tried when it was possible to configure the architecture differently 
and yield the same number of weights, but those used gave the best results. 
A complete set of 254 strings consisting of all strings of length one through seven is 
sufficient to uniquely identify both of these FSMs. For each simulation, we randomly 
partitioned the data into a training and testing set consisting of 127 strings each. 
The strings were ordered lexographically in the training set. 
For each architecture 100 runs were performed on each problem. The on-line Back 
Propagation Through Time (BPTT) algorithm was used to train the networks. 
Vanilla learning was used with a learning rate of 0.5. Training was stopped at 1000 
epochs. The weights of all networks were initialized to random values uniformly 
distributed in the range [-0.1, 0.1]. All states were initialize to zeros at the begin- 
ning of each string except for the High Order net in which one state was arbitrarily 
initialized to a value of 1. 
Table 2 summarizes the statistics for each experiment. From these results we draw 
the following conclusions. 
� The bilinear and high-order networks do best on the small randomly generated 
machine, but poorly on the finite memory machine. Thus, it would appear that 
there is benefit to having second order terms in the network, at least for small 
finite state machine problems. 
� Narendra and Parthasarathy's model and the network with local recurrence do 
far better than the other networks on the problem of inferring the finite memory 
An Experimental Comparison of Recurrent Neural Networks 701 
Table 2: Percentage classification error on the FSM experiment for (a) networks with 
approximately the same number of weights, (b) networks with the same number of 
state variables. %P = The percentage of trials in which the training set was learned 
perfectly, W -- the number of weights, and NS = the number of states. 
training error testing error 
FSM Architecture t mean (std) mean (std) % P N W NS 
N  r 2.8 (4.4) 16.9 (8.6) 22 56 8 
TDNN 12.5 (2.1) 33.8 (4.1) 0 56 8 
Gamma 19.6 (2.4) 24.8 (3.2) 0 56 8 
First Order 12.9 (6.9) 26.5 (9.0) 0 48 6 
B. ND High Order 0.8 (1.5) 6.2 (6.1) 60 50 5 
Bilinear 1.3 (2.7) 5.7 (6.1) 46 55 5 
Quadratic 12.9 (13.4) 17.7 (14.1) 12 45 3 
Multilayer 19.4 (13.6) 23.4 (13.5) 6 54 4 
Elman 3.5 (5.5) 12.7 (9.1) 27 55 6 
Local 2.s (1.5) 26.7 (7.6) 4 60 20 
N 
