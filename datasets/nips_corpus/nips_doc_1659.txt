Maximum entropy discrimination 
Tommi Jaakkola 
MIT AI Lab 
545 Technology Sq. 
Cambridge, MA 02139 
tommiai. mir. edu 
Marina Meila 
MIT AI Lab 
545 Technology Sq. 
Cambridge, MA 02139 
mmp ai. mir. edu 
Tony Jebara 
MIT Media Lab 
20 Ames St. 
Cambridge, MA 02139 
jebaramedia. mir. edu 
Abstract 
We present a general framework for discriminative estimation based 
on the maximum entropy principle and its extensions. All calcula- 
tions involve distributions over structures and/or parameters rather 
than specific settings and reduce to relative entropy projections. 
This holds even when the data is not separable within the chosen 
parametric class, in the context of anomaly detection rather than 
classification, or when the labels in the training set are uncertain or 
incomplete. Support vector machines are naturally subsumed un- 
der this class and we provide several extensions. We are also able 
to estimate exactly and efficiently discriminative distributions over 
tree structures of class-conditional models within this flamework. 
Preliminary experimental results are indicative of the potential in 
these techniques. 
I Introduction 
Effective discrimination is essential in many application areas. Employing gener- 
ative probability models such as mixture models in this context is attractive but 
the criterion (e.g., maximum likelihood) used for parameter/structure estimation 
is suboptimal. Support vector machines (SVMs) are, for example, more robust 
techniques as they are specifically designed for discrimination [9]. 
Our approach towards general discriminative training is based on the well known 
maximum entropy principle (e.g., [3]). This enables an appropriate training of both 
ordinary and structural parameters of the model (cf. [5, 7]). The approach is not 
limited to probability models and extends, e.g., SVMs. 
2 Maximum entropy classification 
Consider a two-class classification problem  where labels y � {-1, 1} are assigned 
The extension to a multi-class is straightforward[4]. The formulation also admits an 
easy extension to regression problems, analogously to SVMs. 
Maximum Entropy Discrimination 471 
to examples X  X. Given two generative probability distributions P(XlOv) with 
parameters Or, one for each class, the corresponding decision rule follows the sign 
of the discriminant function: 
v(xlo) 
c(xlo) = log + b 
(1) 
where 0 = {O,O_,b} and b is a bias term, usually expressed as a log-ratio b = 
log p/(1 -p). The class-conditional distributions may come from different families 
of distributions or the parametric discriminant function could be specified directly 
without any reference to models. The parameters 0v may also include the model 
structure (see later sections). 
The parameters 0 = {0, 0_, b} should be chosen to maximize classification accu- 
racy. We consider here the more general problem of finding a distribution P(O) 
over parameters and using a convex combination of discriminant functions, i.e., 
f P(O)�(XlO)dO in the decision rule. The search for the optimal P(O) can be for- 
malized as a maximum entropy (ME) estimation problem. Given a set of training 
examples {X,... ,XT} and corresponding labels {y,... ,yT} we find a distribu- 
tion P(O) that maximizes the entropy H(P) subject to the classification constraints 
f P(O) [Yt �(XtlO)] dO _> 7 for all t. Here 7 > 0 specifies a desired classification 
margin. The solution is unique (if it exists) since H(P) is concave and the linear 
constraints specify a convex region. Note that the preference towards high entropy 
distributions (fewer assumptions) applies only within the admissible set of distribu- 
tions 7v consistent with the constraints. See [2] for related work. 
We will extend this basic idea in a number of ways. The ME formulation assumes, 
for example, that the training examples can be separated with the specified mar- 
gin. We may also have a reason to prefer some parameter values over others and 
would therefore like to incorporate a prior distribution P0(O). Other extensions 
and generalizations will be discussed later in the paper. 
A more complete formulation is based on the following minimum relative entropy 
principle: 
Definition 1 Let {Xt, Yt} be the training examples and labels, �(X]O) a parametric 
discriminant function, and 7 = [7,...,fit] a set of margin variables. Assuming a 
prior distribution P0(O,7), we find the discriminative minimum relative entropy 
(MRE) distribution P(O, 7) by minimizing D(PIIPo ) subject to 
f r(o, 7) [Yt �(XtlO) - ?t] dOd7 _ 0 
(2) 
for all t. Here  = sign ( f P(O) �(XlO ) dO ) specifies the decision rule for any 
new example X. 
The margin constraints and the preference towards large margin solutions are encod- 
ed in the prior P0 (7). Allowing negative margin values with non-zero probabilities 
also guarantees that the admissible set 7 > consisting of distributions P(�, 7) con- 
sistent with the constraints, is never empty. Even when the examples cannot be 
separated by any discriminant function in the parametric class (e.g., linear), we 
get a valid solution. The miss-classification penalties follow from P0(7) as well. 
472 T. Jaakkola, M. Meila and T. debara 
a) , c) 
.----'  j Po 
 D(P,P 0 ) 
/ 
o 05 
Figure 1: a) Minimum relative entropy (MRE) projection from the prior distribution 
to the admissible set. b) The margin prior Po(%). c) The potential terms in the 
MRE formulation (solid line) and in SVMs (dashed line). c = 5 in this case. 
Suppose P0(O, 7) = P0(O)P0(7) and Po(7) = 1-It Po(7t), where 
Po(7t) = ce -c0-v) for 7t _< 1, 
(3) 
This is shown in Figure lb. The penalty for margins smaller than 1 - 1/c (the prior 
mean of 7t) is given by the relative entropy distance between P(7) and P0(7). This 
is similar but not identical to the use of slack variables in support vector machines. 
Other choices of the prior are discussed in [4]. 
The MRE solution can be viewed as a relative entropy projection from the prior 
distribution P0(O,7) to the admissible set P. Figure la illustrates this view. From 
the point of view of regularization theory, the prior probability P0 specifies the 
entropic regularization used in this approach. 
Theorem 1 The solution to the MRE problem has the following general form [1] 
__1 P0(O, 7) e -], [ y,c(XlO)-v (4) 
P(o, 7) = 
where is the noalization constant (paition function) and  = (,..., T) 
defines a set of non-negative Lagrange multipliers, one for each classification con- 
straint.  are set by finding the unique maximum of the following jointly concave 
objective function: J() = -logZ() 
The solution is sparse, i.e., only a few Lagrange multipliers will be non-zero. This 
arises because many of the classification constraints become irrelevant once the 
constraints are enforced for a small subset of examples. Sparsity leads to immediate 
but weak generalization guarantees expressed in terms of the number of non-zero 
Lagrange multipliers [4]. Practical leave-one-out cross-validation estimates can be 
also derived. 
2.1 Practical realization of the MRE solution 
We now turn to finding the MRE solution. To begin with, we note that any disjoint 
factorization of the prior P0(O,7), where the corresponding parameters appear in 
distinct additive components in ytl(Xt, O) -7t, leads to a disjoint factorization of 
the MRE solution P(O, 7). For example, {O \ b, b, 7} provides such a factorization. 
As a result of this factorization, the bias term could be eliminated by imposing 
additional constraints on the Lagrange multipliers [4]. This is analogous to the 
handling of the bias term in support vector machines [9]. 
We consider now a few specific realizations such as support vector machines and a 
class of graphical models. 
Maximum Entropy Discrimination 473 
2.1.1 Support vector machines 
It is well known that the log-likelihood ratio of two Gaussian distributions with equal 
covariance matrices yields a linear decision rule. With a few additional assumptions, 
the MRE formulation gives support vector machines: 
Theorem 2 Assuming �(X, O) = oTx -- b and P0(O, 7) = Po(O)Po(b)Po(7) where 
Po(O) is N(O,I), Po(b) approaches a non-informative prior, and Po(7) is given by 
eq. (3) then the Lagrange multipliers .k are obtained by maximizing J(.k) subject to 
0 <_ At <_ c and Y';.t ,ktYt ---- O, where 
I (xtTxt,) 
J(A) = E[ St + log(1 - At/c)] -  E AtAt, ytyt, 
t t,t' 
(5) 
The only difference between our J(A) and the (dual) optimization problem for 
SVMs is the additional potential term log(1 -At/c). This highlights the effect 
of the different miss-classification penalties, which in our case come from the MRE 
projection. Figure lb shows, however, that the additional potential term does not 
always carry a huge effect (for c = 5). Moreover, in the separable case, letting 
c -+ c, the two methods coincide. The decision rules are formally identical. 
We now consider the case where the discriminant function �(X, )) corresponds to 
the log-likelihood ratio of two Gaussians with different (and adjustable) covariance 
matrices. The parameters ) in this case are both the means and the covariances. 
The prior P0()) must be the conjugate Normal-Wishart to obtain closed form 
integrals 2 for the partition function, Z. Here, P()i, 
a density over means and covariances. 
The prior distribution has the form P0 ()x) = Af(mx; m0, V/k) ZW(V; kVo, k) with 
parameters (k, m0, V0) that can be specified manually or one may let k -+ 0 to get 
a non-informative prior. Integrating over the parameters and the margin, we get 
Z = Z v x Z1 x Z-l, where 
a N? d/2 ISxl d F( (N, + 1- j)/2) 
1-I j= 1 
(6) 
N1 _A Zt Wt, .'1 __A__ Zt 't' xt, Sl -- Zt wtXtX? - NiX1X1 T. Here, wt is a scalar 
weight given by wt = u(yt)+Ytt. For Z_, the weights are set to wt = u(-yt)-Yt,kt; 
u(.) is the step function. Given Z, updating  is done by maximizing J(). The 
resulting marginal MRE distribution over the parameters (normalized by Z x Z_i) 
