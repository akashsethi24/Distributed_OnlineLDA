6O2 
GENERALIZATION OF BACKPROPAGATION 
TO 
RECURRENT AND HIGHER ORDER NEURAL NETWORKS 
Fernando J. Pineda 
Applied Physics Laboratory, Johns Hopkins University 
Johns Hopkins Rd., Laurel MD 20707 
Abstract 
A general method for deriving backpropagation algorithms for networks 
with recurrent and higher order networks is introduced. The propagation of activation 
in these networks is determined by dissipative differential equations. The error signal 
is backpropagated by integrating an associated differential equation. The method is 
introduced by applying it to the recurrent generalization of the feedforward 
backpropagation network. The method is extended to the case of higher order 
networks and to a constrained dynamical system for training a content addressable 
memory. The essential feature of the adaptive algorithms is that adaptive equation has 
a simple outer product form. 
Preliminary experiments suggest that learning can occur very rapidly in 
networks with recurrent connections. The continuous formalism makes the new 
approach more suitable for implementation in VLSI. 
Introduction 
One interesting class of neural networks, typified by the Hopfield neural 
networks (1,2) or the networks studied by Amari (3,4) are dynamical systems with three 
salient properties. First, they posses very many degrees of freedom, second their 
dynamics are nonlinear and third, their dynamics are dissipative. Systems with these 
properties can have complicated attractor structures and can exhibit computational 
abilities. 
The identification of attractors with computational objects, e.g. memories at d 
rules, is one of the foundations of the neural network paradigm. In this paradigm, 
programming becomes an excercise in manipulating attractors. A learning algorithm is 
a rule or dynamical equation which changes the locations of fixed points to encode 
information. One way of doing this is to minimize, by gradient descent, some 
function of the system parameters. This general approach is reviewed by Amari (4) 
and forms the basis of many learning algorithms. The formalism described here is a 
specific case of this general approach. 
The purpose of this paper is to introduce a formalism for obtaining adaptive 
dynamical systems which are based on backpropagation(5,6,?). These dynamical 
systems are expressed as systems of coupled first order differential equations. The 
formalism will be illustrated by deriving adaptive equations for a recurrent network 
with first order neurons, a recurrent network with higher order neurons and finally a 
recurrent first order associative memory. 
Example 1: Recurrent backpropagation with first order units 
Consider a dynamical system whose state vector x evolves according to the 
following set of coupled differential equations 
American Institute of Physics 1988 
603 
dxi/dt =-x i + gi(.wijxj) + I i (1) 
J 
where i=l,...,N. The functions gi are assumed to be differentiable and may have 
different forms for various populations of neurons. In this paper we shall make no 
other requirements on gi' In the neural network literature it is common to take these 
functions to be sigmoid shaped functions. A commonly used form is the logistic 
function, 
g() = (1 + e-)- 1. (2) 
This form is biologically motivated since it attempts to account for the refractory phase 
of real neurons. However, it is important to stress that there is nothing in the 
mathematical content of this paper which requires this form -- any differentiable 
function will suffice in the formalism presented in this paper. For example, a choice 
which may be of use in signal processing is sin(). 
A necessary condition for the learning algorithms discussed here to exist is that the 
system posesses stable isolated attractors, i.e. fixed points. The attractor structure of 
(1) is the same as the more commonly used equation 
dui/dt =-u i + .wijg(uj) + K i. (3) 
J 
Because (1) and (3) are related by a simple linear transformation. Therefore results 
concerning the stability of (3) are applicable to (1). Amari � studied the dynamics of 
equation (3) in networks with random conections. He found that collective variables 
corresponding to the mean activation and its second moment must exhibit either stable 
or bistable behaviour. More recently, Hopfield (2) has shown how to construct content 
addressable memories from symmetrically connected networks with this same 
dynamical equation. The symmetric connections in the network gaurantee global 
stability. The solution of equation (1) is also globally asymptotically stable if w can be 
transformed into a lower triangular matrix by row and column exchange operations. 
This is because in such a case the network is a simply a feedforward network and the 
output can be expressed as an explicit function of the input. No Liapunov function 
exists for arbitrary weights as can be demonstrated by constructing a set of weights 
which leads to oscillation. In practice, it is found that oscillations are not a problem 
and that the system converges to fixed points unless special weights are chosen. 
Therefore it shall be assumed, for the purposes of deriving the backpropagation 
equations, that the system ultimately settles down to a fixed point. 
Consider a system of N neurons, or units, whose dynamics is determined by 
equation (1). Of all the units in the network we will arbitrarily define some subset of 
them (A) as input units and some other subset of them (f2) as output units. Units 
which are neither members of A nor f2 are denoted hidden units. A unit may be 
simultaneously an input unit and an output unit. The external environment influences 
the system through the source term, I. If a unit is an input unit, the corresponding 
component of I is nonzero. To make this more precise it is useful to introduce a 
notational convention. Suppose that � represent some subset of units in the network 
then the function �i is defined by 
1 if i-th unit is a member of � 
�i = { (4) 
0 otherwise 
In terms of this function, the components of the I vector are given by 
I i = i�iA , (5) 
6O4 
where i is determined by the external environment. 
Ouroal will be to find a local algorithm which adjusts the weight matrix w so that 
a given initial state x � = X(to), and a given input I result in a fixed point, x ��= x(too), 
whose components have a desired set of values Ti along the output units. This will be 
accomplished by minimizing a function E which eneasures the distance between the 
desired fixed point and the actual fixed point i.e., 
N 
E = 1 I; Ji 2 (6) 
2 i=l 
where 
Ji = (Ti- x�� i ) Oil I . (7) 
E depends on the weight matrix w through the fixed point x��(w). A learning 
algorithm drives the fixed points towards the manifolds which satisfy xi �� = T i on the 
output units. One way of accomplishing this with dynamics is to let the system evolve 
in the weight space along trajectories which are antiparallel to the gradient of E. In 
other words, 
OE 
dwij/dt = - q i)w.. (8) 
where q is a numerical constant which def'mes the (slow) time scale on which w 
changes. q must be small so that x is always essentially at steady state, i.e. 
x(t) _= x ��. It is important to stress that the choice of gradient descent for the learning 
dynamics is by no means unique, nor is it necessarily the best choice. Other learning 
dynami,cs, which employ second order time derivatives (e.g. the momentum 
m  
ethod ) or which employ second order space derivatives (e.g. second order 
backpropagation(8)) may be more useful in particular applications. However, equation 
(8) does have the virtue of being the simplest dynamics which minimizes E. 
On performing the differentiations in equation (8), one immediately obtains 
)Xk 
dwrs/dt = q I; Jk � (9) 
k )w 
rs 
The derivative of x�� k with respect to w_ is obtained by f'u'st noting that the fixed 
pmnts of equauon (1J-sansfy the nonlinear algebrmc equanon 
x�� i = gi(Z. wijx��j) + I i , (10) 
J 
differentiating both sides of this equation with respect to Wrs and finally solving for 
aX��k/aWrs. The result is 
aX��k - (L- 1)kr gr'(Ur)X�� s (11) 
Wr s 
where gr' is the derivative of gr and where the matrix L is given by 
Lij = �ij - gi'(ui)wij � (12) 
�:: is the Kroneker � function ( �:: = 1 if i=j, otherwise �ij = 0). On substituting (11) 
iro (9) one obtains the remarkably simple form 
6O5 
dwrs/dt = q yrX�� s 
where 
Yr = gr (Ur) (L- 1)kr 
Equations (13) and (14) specify a formal learning rule. 
(13) 
(14) 
Unfortunately, equation 
(14) requires a matrix inversion to calculate the error signals Yk. Direct matrix 
inversions are necessarily nonlocal calculations and therefore ttiis leaming algorithm is 
not suitable for implementation as a neural network. Fortunately, a local method for 
calculating Yr can be obtained by the introduction of an associated dynamical system. 
To obtain this dynamical system first rewrite equation (14) as 
ZLrk(Yr / gr'(Ur )} = Jk (15) 
r 
Then multiply both sides by fk'(Uk), substitute the explicit form for L and finally sum 
over r. The result is 
0=-Yk + gk'(Uk){ ZWrkYr + Jk ] (16) 
r 
One now makes the observation that the solutions of this linear equation are the fixed 
points of the dynamical system given by 
dYk/dt = - Yk +gk'(Uk ){ ZWrkYr + Jk ) (17) 
r 
This last step is not unique, equation (16) could be transformed in various ways 
leading to related differential equations, cf. Pineda (9). It is not difficult to show that 
the fu'st order finite difference approximation (with a time step At = 1) of equations 
(1), (13) and (17) has the same form as the conventional backpropagation algorithm. 
Equations (1), (13) and (17) completely specify the dynamics for an adaptive 
neural network, provided that (1) and (17) converge to stable fixed points and 
provided that both quantities on the fight hand side of equation (13) are the steady 
state solutions of (1) and (17). 
It was pointed out by Almeida (10) that the local stabili
