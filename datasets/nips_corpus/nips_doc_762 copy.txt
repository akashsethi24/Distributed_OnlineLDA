Illumination-Invariant Face Recognition with a 
Contrast Sensitive Silicon Retina 
Joachim M. Buhmann 
Rheinische Friedrich-Wilhelms-Universitfit 
Institut ftir Informatik II, R6merstrage 164 
D-53117 Bonn, Germany 
Martin Lades 
Ruhr-Universitfit Bochum 
Institut ftir Neuroinformatik 
D-44780 Bochum, Germany 
Frank Eeckman 
Lawrence Livermore National Laboratory 
ISCR, P.O.Box 808, L-426 
Livermore, CA 94551 
Abstract 
Changes in lighting conditions strongly effect the performance and reli- 
ability of computer vision systems. We report face recognition results 
under drastically changing lighting conditions for a computer vision sys- 
tem which concurrently uses a contrast sensitive silicon retina and a con- 
ventional, gain controlled CCD camera. For both input devices the face 
recognition system employs an elastic matching algorithm with wavelet 
based features to classify unknown faces. To assess the effect of analog 
on-chip preprocessing by the silicon retina the CCD images have been 
digitally preprocessed with a bandpass filter to adjust the power spec- 
trum. The silicon retina with its ability to adjust sensitivity increases 
the recognition rate up to 50 percent. These comparative experiments 
demonstrate that preprocessing with an analog VLSI silicon retina gen- 
erates image data enriched with object-constant features. 
1 Introduction 
Neural computation as an information processing paradigm promises to enhance artificial 
pattern recognition systems with the learning capabilities of the cerebral cortex and with the 
769 
770 Buhmann, Lades, and Eeckman 
adaptivity of biological sensors. Rebuilding sensory organs in silicon seems to be particu- 
larly promising since their neurophysiology and neuroanatomy, including the connections 
to cortex, are known in great detail. This knowledge might serve as a blueprint for the design 
of artificial sensors which mimic biological perception. Analog VLSI retinas and cochleas, 
as designed by Carver Mead (Mead, 1989; Mahowald, Mead, 1991) and his collaborators 
in a seminal research program, will ultimately be integrated in vision and communication 
systems for autonomous robots and other intelligent information processing systems. 
The study reported here explores the influence of analog retinal preprocessing on the 
recognition performance of a face recognition system. Face recognition is a challenging 
classification task where object inherent distortions, like facial expressions and perspective 
changes, have to be separated from other image variations like changing lighting conditions. 
Preprocessing with a silicon retina is expected to yield an increased recognition rate since the 
first layers of the retina adjust their local contrast sensitivity and thereby achieve invariance 
to variations in lighting conditions. 
Our face recognizer is equipped with a silicon retina as an adaptive camera. For comparison 
purposes all images are registered simultaneously by a conventional CCD camera with 
automatic gain control. Galleries with images of 109 different test persons each are taken 
under three different lighting conditions and two different viewing directions (see Fig. 1). 
These different galleries provide separate statistics to measure the sensitivity of the system 
to variations in light levels or contrast and image changes due to perspective distortions. 
Naturally, the performance of an object recognition system depends critically on the classifi- 
cation strategy pursued to identify unknown objects in an image with the models stored in a 
database. The matching algorithm selected to measure the performance enhancing effect of 
retinal preprocessing deforms prototype faces in an elastic fashion (Buhmann et al., 1989; 
Buhmann et al., 1990; Lades et al., 1993). Elastic matching has been shown to perform 
well on the face classification task recognizing up to 80 different faces reliably (Lades et al., 
1993) and in a translation, size and rotation invariant fashion (Buhmann et al., 1990). The 
face recognition algorithm was initially suggested as a simplified version of the Dynamic 
Link Architecture (von der Malsburg, 1981), an innovative neural classification strategy with 
fast changes in the neural connectivity during recognition stage. Our recognition results 
and conclusions are expected to be qualitatively typical for a whole range of face/object 
recognition systems (Turk, Pentland, 1991; Yuille, 1991; Brunelli, Poggio, 1993), since any 
image preprocessing with emphasis on object constant features facilitates the search for the 
correct prototype. 
2 The Silicon Retina 
The silicon retina used in the recognition experiments models the interactions between 
receptors and horizontal cells taking place in the outer plexiform layer of the vertebrate 
retina. All cells and their interconnections are explicitly represented in the chip so that 
the following description simultaneously refers to both biological wetware and silicon 
hardware. Receptors and horizontal cells are electrically coupled to their neighbors. The 
weak electrical coupling between the receptors smoothes the image and reduces the in- 
fluence of voltage offsets between adjacent receptors. The horizontal cells have a strong 
lateral electrical coupling and compute a local background average. There are reciprocal 
excitatory-inhibitory synapses between the receptors and the horizontal cells. The horizon- 
tal cells use shunting inhibition to adjust the membrane conductance of the receptors and 
Illumination-Invariant Face Recognition with a Contrast Sensitive Silicon Retina 771 
thereby adjust their sensitivity locally. This feedback interaction produces an antagonistic 
center/surround organization of receptive fields at the output. The center is represented 
by the weakly coupled excitatory receptors and the surround by the more strongly coupled 
inhibitory horizontal cells. The center/surround organization removes the average intensity 
and expands the dynamic range without response compression. Furthermore, it enhances 
edges. 
In contrast to this architecture, a conventional CCD camera can be viewed as a very primitive 
retina with only one layer of non-interacting detectors. There is no DC background removal, 
causing potential over- and underexposure in parts of the image which reduces the useful 
dynamic range. A mechanical iris has to be provided to adjust the mean luminance level 
to the appropriate setting. Since cameras are designed for faithful image registration rather 
than vision, on-chip pixel processing, if provided at all, is used to improve the camera 
resolution and signal-to-noise ratio. 
Three adjustable parameters allow us to fine tune the retina chip for an object recognition 
experiment: (i) the diffusivity of the cones (ii) the diffusivity of the horizontal cells (iii) the 
leak in the horizontal cell membrane. Changes in the diffusivities affect the shape of the 
receptive fields, e.g., a large diffusivity between cones smoothes out edges and produces a 
blurred image. The other extreme of large diffusivity between horizontal cells pronounces 
edges and enhances the contrast gain. The retina chip has a resolution of 90 x 92 pixels, 
it was designed by (Boahen, Andreou, 1992) and fabricated in 2/tm n-well technology by 
MOSIS. 
3 Elastic Matching Algorithm for Face Recognition 
Elastic matching is a pattern classification strategy which explicitly accounts for local 
distortions. A prototype template is elastically deformed to measure local deviations from a 
new, unknown pattern. The amount of deformation and the similarity of local image features 
provide us with a decision criterion for pattern classification. The rubbersheet-like behavior 
of the prototype transformation makes elastic matching a particularly attractive method for 
face recognition where ubiquitous local distortions are caused for example by perspective 
changes and different facial expressions. Originally, the technique was developed for 
handwritten character recognition (Burr, 1981). The version of elastic matching employed 
for our face recognition experiments is based on attributed graph matching. A detailed 
description with a plausible interpretation in neural networks terms is published in (Lades 
et al., 1993). Each prototype face is encoded as a planar graph with feature vectors attached 
to the vertices of the graph and metric information attached to the edges. The feature vectors 
extract local image information at pixel :i in a multiscale fashion, i.e., they are functions 
of wavelet coefficients. Each feature vector establishes a correspondence between a vertex 
i of a prototype graph and a pixel gi in the image. The components of a feature vector are 
defined as the magnitudes of the convolution of an image with a set of two-dimensional, 
DC free Gaussian kernels centered at pixel gi. The kernels with the form 
( 
p; ( =  exp 
2rr 2 
[exp (ig)- exp (-cr2/2)] 
(1) 
are parameterized by the wave vector/ defining their orientations and their sizes. To 
construct a self-similar set of filter functions we select eight different orientations and five 
772 Burmann, Lades, and Eeckman 
different scales according to 
7r 2_/2 (cos(-/t), ' 7r 
(v,/t) =  7r s,n(/t)) (2) 
with v E {0,...,4};/t E {0,..., 7}. The multi-resolution data format represents local 
distortions in a robust way, i.e., only feature vectors in the vicinity : of an image distortion 
are altered by the changes. The edge labels encode metric information, in particular we 
choose the difference vectors Agij ---- gi - gj as edge labels. 
To generate a new prototype graph for the database, the center of a new face is determined 
by matching a generic face template to it. A 7 x 10 rectangular grid with 10 pixel spacing 
between vertices and edges between adjacent vertices is then centered at that point. The 
saliency of image points is taken into account by deforming that generic grid so that each 
