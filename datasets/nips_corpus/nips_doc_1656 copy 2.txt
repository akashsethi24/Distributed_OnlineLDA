Low Power Wireless Communication via 
Reinforcement Learning 
Timothy X Brown 
Electrical and Computer Engineering 
University of Colorado 
Boulder, CO 80309-0530 
timxb@colorado. edu 
Abstract 
This paper examines the application of reinforcement learning to a wire- 
less communication problem. The problem requires that channel util- 
ity be maximized while simultaneously minimizing battery usage. We 
present a solution to this multi-criteria problem that is able to signifi- 
cantly reduce power consumption. The solution uses a variable discount 
factor to capture the effects of battery usage. 
1 Introduction 
Reinforcement learning (RL) has been applied to resource allocation problems in telecom- 
munications, e.g., channel allocation in wireless systems, network routing, and admission 
control in telecommunication networks [1, 2, 8, 10]. These have demonstrated reinforce- 
ment learning can find good policies that significantly increase the application reward 
within the dynamics of the telecommunication problems. However, a key issue is how 
to treat the commonly occurring multiple reward and constraint criteria in a consistent way. 
This paper will focus on power management for wireless packet communication channels. 
These channels are unlike wireline channels in that channel quality is poor and varies over 
time, and often one side of the wireless link is a battery operated device such as a laptop 
computer. In this environment, power management decides when to transmit and receive 
so as to simultaneously maximize channel utility and battery life. 
A number of power management strategies have been developed for different aspects of 
battery operated computer systems such as the hard disk and CPU [4, 5]. Managing the 
channel is different in that some control actions such as shutting off the wireless transmitter 
make the state of the channel and the other side of the communication unobservable. 
In this paper, we consider the problem of finding a power management policy that simul- 
taneously maximizes the radio communication's earned revenue while minimizing battery 
usage. The problem is recast as a stochastic shortest path problem which in turn is mapped 
to a discounted infinite horizon with a variable discount factor. Results show significant 
reductions in power usage. 
894 T. X. Brown 
l Mobile 
Application [-[ 
Radio Channel Radio 
Application 
Figure 1: The five components of the radio communication system. 
2 Problem Description 
The problem is comprised of five components as shown in Figure 1: mobile application, 
mobile radio, wireless channel, base station radio, and base station application. The ap- 
plications on each end generate packets that are sent via a radio across the channel to the 
radio and then application on the other side. The application also defines the utility of a 
given end-to-end performance. The radios implement a simple acknowledgment/retransmit 
protocol for reliable transmission. The base station is fixed and has a reliable power supply 
and therefore is not power constrained. The mobile power is limited by a battery and it 
can choose to turn its radio off for periods of time to reduce power usage. Note that even 
with the radio off, the mobile system continues to draw power for other uses. The channel 
adds errors to the packets. The rate of errors depends on many factors such as location 
of mobile and base station, intervening distance, and levels of interference. The problem 
requires models for each of these components. To be concrete, the specific models used in 
this paper are described in the following sections. It should be emphasized that in order to 
focus on the machine learning issues, simple models have been chosen. More sophisticated 
models can readily be included. 
2.1 The Channel 
The channel carries fixed-size packets in synchronous time slots. All packet rates are nor- 
malized by the channel rate so that the channel carries one packet per unit time in each 
direction. The forward and reverse channels are orthogonal and do not interfere. 
Wireless data channels typically have low error rates. Occasionally, due to interference or 
signal fading, the channel introduces many errors. This variation is possible even when the 
mobile and base station are stationary. The channel is modeled by a two state Gilbert-Elliot 
model [3]. In this model, the channel is in either a good or a bad state with a packet 
error probabilities pg and pb where pg < pb. The channel is symmetric with the same loss 
rate in both directions. The channel stays in each state with a geometrically distributed 
holding time with mean holding times ha and hb time slots. 
2.2 Mobile and Base Station Application 
The traffic generated by the source is a bursty ON/OFF model that alternates between gen- 
erating no packets and generating packets at rate tON. The holding times are geometrically 
distributed with mean holding times hON and ]tOF F. The traffic in each direction is inde- 
pendent and identically distributed. 
2.3 The Radios 
The radios can transmit data from the application and send it on the channel and simul- 
taneously receive data from the other radio and pass it on to its application. The radios 
implement a simple packet protocol to ensure reliability. Packets from the sources are 
queued in the radio and sent one by one. Packets consist of a header and data. The header 
carries acknowledgements (ACK's) with the most recent packet received without error. The 
header contains a checksum so that errors in the payload can be detected. Errored packets 
Low Power I4qreless Communication via Reinforcement Learning 895 
Parameter Name Symbol Value 
Channel Error Rate, Good pg 0.01 
Channel Error Rate, Bad Pb 0.20 
Channel Holding Time, Good hg 100 
Channel Holding Time, Bad hb 10 
Source On Rate tON 1.0 
Source Holding Time, On ]tON 1 
Source Holding Time, Off hoF F 10 
Power, Radio Off POFF 7 W 
Power, Radio On PON 8.5 W 
Power, Radio Transmitting PTX 10 W 
Real Time Max Delay d,ax 3 
Web Browsing Time Scale do 3 
Table 1: Application parameters. 
cause the receiving radio to send a packet with a negative acknowledgment (NACK) to the 
other radio instructing it to retransmit the packet sequence starting from the errored packet. 
The NACK is sent immediately even if no data is waiting and the radio must send an empty 
packet. Only unerrored packets are sent on to the application. The header is assumed to 
always be received without error  . 
Since the mobile is constrained by power, the mobile is considered the master and the base 
station the slave. The base station is always on and ready to transmit or receive. The mobile 
can turn its radio off to conserve power. Every ON-OFF and OFF-ON transition generates 
a packet with a message in the header indicating the change of state to the base station. 
These message packets carry no data. The mobile expends power at three levels--PoFF, 
PON, and Ptx corresponding to the radio off, receiver on but no packet transmitted, and 
receiver on packet transmitted. 
2.4 Reward Criteria 
Reward is earned for packets passed in each direction. The amount depends on the ap- 
plication. In this paper we consider three types of applications, an e-mail application, a 
real-time application, and a web browsing application. In the e-mail application, a unit 
reward is given for every packet received by the application. In the real time application a 
unit reward is given for every packet received by the application with delay less than d,a. 
The reward is zero otherwise. In the web browsing application, time is important but not 
critical. The value of a packet with delay d is (1 - I/d0) a, where do is the desired time 
scale of the arrivals. 
The specific parameters used in this experiment are given in Table 1. These were gathered 
as typical values from [7, 9]. It should be emphasized that this model is the simplest 
model that captures the essential characteristics of the problem. More realistic channels, 
protocols, applications, and rewards can readily be incorporated but for this paper are left 
out for clarity. 
A packet error rate of 20% implies a bit error rate of less than 1%. Error correcting codes in the 
header can easily reduce this error rate to a low value. The main intent is to simplify the protocol for 
this paper so that time-outs and other mechanisms do not need to be considered. 
896 T. X. Brown 
Component States 
Channel {good,bad} 
Application { ON,OFF} 
Mobile {ON,OFF} 
Mobile {List of waiting and unacknowledged packets and their current delay} 
Base Station {List of waiting and unacknowledged packets and their current delay} 
Table 2: Components to System State. 
3 Markov Decision Processes 
At any given time slot, t, the system is in a particular configuration, z, defined by the state 
of each of the components in Table 2. The system state is s = (z, t) where we include 
the time in order to facilitate accounting for the battery. The mobile can choose to toggle 
its radio between the ON and OFF state and rewards are generated by successfully received 
packets. The task of the learner is to determine a radio ON/OFF policy that maximizes the 
total reward for packets received before batteries run out. 
The battery life is not a fixed time. First, it depends on usage. Second, for a given drain, 
the capacity depends on how long the battery was charged, how long it has sat since being 
charged, the age of the battery, etc. In short, the battery runs out at a random time. The 
system can be modeled as a stochastic shortest path problem whereby there exists a terminal 
state, so, that corresponds to the battery empty in which no more reward is possible and the 
system remains permanently at no cost. 
3.1 Multi-criteria Objective 
Formally, the goal is to learn a policy for each possible system state so as to maximize 
J(s) = E c(t) s, , 
t=0 
where E{.Is, is the expectation over possible trajectories starting f
