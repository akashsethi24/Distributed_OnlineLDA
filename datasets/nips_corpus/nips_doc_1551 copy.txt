An Integrated Vision Sensor for the 
Computation of Optical Flow Singular Points 
Charles M. Higgins and Christof Koch 
Division of Biology, 139-74 
California Institute of Technology 
Pasadena, CA 91125 
[chuck, koch] Oklab. caltech. edu 
Abstract 
A robust, integrative algorithm is presented for computing the position of 
the focus of expansion or axis of rotation (the singular point) in optical 
flow fields such as those generated by self-motion. Measurements are 
shown of a fully parallel CMOS analog VLSI motion sensor array which 
computes the direction of local motion (sign of optical flow) at each pixel 
and can directly implement this algorithm. The flow field singular point 
is computed in real time with a power consumption of less than 2 roW. 
Computation of the singular point for more general flow fields requires 
measures of field expansion and rotation, which it is shown can also be 
computed in real-time hardware, again using only the sign of the optical 
flow field. These measures, along with the location of the singular point, 
provide robust real-time self-motion information for the visual guidance 
of a moving platform such as a robot. 
1 INTRODUCTION 
Visually guided navigation of autonomous vehicles requires robust measures of self-motion 
in the environment. The heading direction, which corresponds to the focus of expansion 
in the visual scene for a fixed viewing angle, is one of the primary sources of guidance 
information. Psychophysical experiments [WH88] show that humans can determine their 
heading direction very precisely. In general, the location of the singular point in the visual 
field provides important self-motion information. 
Optical flow, representing the motion seen in each local area of the visual field, is partic- 
700 C. M. Higgins and C. Koch 
ularly compute-intensive to process in real time. We have previously shown [DHK97] a 
fully parallel, low power, CMOS analog VLSI vision processor for computing the local 
direction of motion. With onboard photoreceptors, each pixel computes in continuous time 
a vector corresponding to the sign of the local normal flow. In this article, we show how 
these motion vectors can be integrated in hardware to compute the singular point of the 
optical flow field. While each individual pixel suffers from transistor mismatch and spatial 
variability with respect to its neighbors, the integration of many pixels serves to average out 
these irregularities and results in a highly robust computation. This compact, low power 
self-motion processor is well suited for autonomous vehicle applications. 
Extraction of self-motion information has been a topic of research in the machine vision 
community for decades, and has generated volumes of research; see [FA97] for a good 
review. While many algorithms exist for determining flow field singular points in complex 
self-motion situations, few are suitable for real-time implementation. Integrated hardware 
attempts at self-motion processing have only begun recently, with the work of Indiveri et 
al [IKK96]. The zero crossing in a 1D array of CMOS velocity sensors was used to detect 
one component of the focus of expansion. In a separate chip, the sum of a radial array 
of velocity sensors was used to compute the rate of flow field expansion, from which the 
time-to-contact can be calculated. McQuirk [McQ96] built a CCD-based image processor 
which used an iterative algorithm to locate consistent stable points in the image, and thus 
the focus of expansion. More recently, Deutschmann et al. [DW98] have extended Indiveri 
et al.'s work to 2D by summing rows and columns in a 2D CMOS motion sensor array and 
using software to detect zero crossings and find the flow field singular point. 
2 SINGULAR POINT ALGORITHM 
In order to compute the flow field singular point, we compute the sum of the sign of optical 
flow over the entire field of view. Let the field of view be centered at (0, 0) and bounded 
by 4-L in both spatial dimensions; then (vector quantities are indicated in boldface) 
L L 
S=/_ /_ U(x,y)dxdy (1) 
L L 
where U(x,y) : (Ux(x,y),Uy(x,y)) = sgn(V(x,y)) and V(x,y) is the optical flow 
field. Consider a purely expanding flow field with the focus of expansion (FOE) at the 
center of the visual field. Intuitively, the vector sum of the sign of optical flow will be zero, 
because each component is balanced by a spatially symmetric component with opposite 
sign. As the FOE moves away from the center of the visual field, the sum will increase or 
decrease depending on the FOE position. 
An expanding flow field may be expressed as 
Ve(x, y): A(x,y). ((x - X,), ( - �,)) (2) 
where A(x, y) denotes the local rate of expansion and (Xe, �e) is the focus of expansion. 
The integral (1) applied to this flow field yields 
S = -4L. (X, �) 
as long as A is positive. Note that, due to the use of optical flow sign only, this quantity is 
independent of the speed of the flow field components. We will discuss in Section 5 how 
the positivity requirement of A can be relaxed somewhat. 
Integrated Computation of Optical Flow Singular Points 701 
Similarly, a clockwise rotating flow field may be expressed as 
Vr(x, y): 3(x,y). ((y - �r),-(x - Xr)) (3) 
where B(x, y) denotes the local rate of rotation and (X., Y.) is the axis of rotation (AOR). 
The integral (1) applied to this flow field yields 
S= -4L. (Y.,-X,.) 
as long as B is positive. 
Let us now consider the case of a combination of these expanding and rotating fields (2) 
and (3): 
V(x,y) = OV + (1 - O)Vr (4) 
This flow field is spiral in shape; the parameter 0 defines the mix of the two field types. The 
sum in this case is more complex to evaluate, but for 0 small (rotation dominating), 
S = -4L. (CXe + Y, CYe - X) (5) 
and for 8 large (expansion dominating), 
S = -4L. (Xe + (1/C)5,�e - (1/C)X.) (6) 
where C = 0.4 Since it is mathematically impossible to recover both the FOE and AOR 
1 -OB � 
with only two equations,  let us equate the FOE and AOR and concentrate on recovering the 
unique singular point of this spiral flow field. In order to do this, we need a measurement 
of the quantity C, which reflects the relative mix and strength of the expanding and rotating 
flow fields. 
2.1 COEFFICIENTS OF EXPANSION AND ROTATION 
Consider a contour integral around the periphery of the visual field of the sign of optical 
flow components normal to the contour of integration. If we let this contour be a square of 
size 2L centered at (0, 0), we can express this integral as 
8LCexp = (Uy(x,L) - Uy(x,-L))dx + (Ux(L,y) - Ux(-L,y))dy (7) 
L L 
This integral can be considered as a 'template' for expanding flow fields. The quantity 
Cexp reaches unity for a purely expanding flow field with FOE within the visual field, and 
reaches zero for a purely rotating flow field. A similar quantity for rotation may be defined 
by an integral of the sign of optical flow components parallel to the contour of integration: 
8LCo : - + - (8) 
L L 
It can be shown that for  small (rotation dominating), Cp  C. As 0 increases, Cexp 
saturates at unity. Similarly, for  large (expansion dominating), Cot  (1/C). As 0 
decreases, Cot saturates at unity. This suggests the following approximation to equations 
(5) and (6), letting X = Xe = X and '} = Y: Y 
S = -4L. (CpX + CotY, CpY - CotX) (9) 
from which equation the singular point (X, Y) may be uniquely calculated. Note that this 
generalized expression also covers contracting and counterclockwise rotating fields (for 
which the quantities Cexp and Cot would be negative). 
 In fact, if A and B are constant, there exists no unique solution for the FOE and AOR. 
702 C. M. Higgins and C. Koch 
3 HARDWARE IMPLEMENTATION 
The real-time hardware implementation of the above algorithm utilizes a fully parallel 
14x 13 CMOS analog VLSI motion sensor array. The elementary motion detectors are 
briefly described below. Each pixel in the array creates a local motion vector when crossed 
by a spatial edge; this vector is represented by two currents encoding the :r and /compo- 
nents. These currents persist for an adjustable period of time after stimulation. By using 
the serial pixel scanners at the periphery of the chip (normally used to address each pixel 
individually), it is possible to connect all of these currents to the same output wire, thus im- 
plementing the sum required by the algorithm. In this mode, the current outputs of the chip 
directly represent the sum $ in equation (1), and power consumption is less than 2 roW. 
A similar sum combining sensor row and column outputs around the periphery of the chip 
could be used to implement the quantities Cexjo and C,.ot in equations (7) and (8). Due 
to the sign changes necessary, this sum cannot be directly implemented with the present 
implementation. However, it is possible to emulate this sum by scanning off the vector 
field and performing the sum in real-time software. 
3.1 ELEMENTARY MOTION DETECTOR 
The 1D elementary motion detector used in this processor is the ITI (Inhibit, Trigger, and 
Inhibit) sensor. Its basic operation is described in Figure 1; see [DHK97] for details. The 
sensor is edge sensitive, approximately invariant to stimulus contrast above 20% and func- 
tions over a stimulus velocity range from 10-800 pixels/sec. 
 PIXELA  PIXELB 
J 
 PIXEL C ,4 intensity 
i 
TED i B intensity 
C intensity 
Direction voltage 
Vright 
Direction voltage 
V le'l 
Output current 
I out 
time 
Figure 1: ITI sensor: a spatial edge crossing the sensor from left to right triggers direc- 
tion voltages for both directions V,.i9/t and �e.ft in pixel B. The same edge subsequently 
crossing pixel C inhibits the null direction voltage �<ft. The output current is continu- 
ously computed as the difference between V,.ig/t and �.ft; the resulting positive output 
current lout indicates rightward motion. Pixels B and A interact similarly to detect left- 
ward motio
