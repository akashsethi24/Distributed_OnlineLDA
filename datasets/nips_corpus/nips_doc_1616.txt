A Winner-Take-All Circuit with 
Controllable Soft Max Property 
Shih-Chii Liu 
Institute for Neuroinformatics, ETH/UNIZ 
Winterthurstrasse 190, CH-8057 Zurich 
Switzerland 
shih@ini.phys.ethz.ch 
Abstract 
I describe a silicon network consisting of a group of excitatory neu- 
rons and a global inhibitory neuron. The output of the inhibitory 
neuron is normalized with respect to the input strengths. This out- 
put models the normalization property of the wide-field direction- 
selective cells in the fly visual system. This normalizing property is 
also useful in any system where we wish the output signal to code 
only the strength of the inputs, and not be dependent on the num- 
ber of inputs. The circuitry in each neuron is equivalent to that in 
Lazzaro's winner-take-all (WTA) circuit with one additional tran- 
sistor and a voltage reference. Just as in Lazzaro's circuit, the 
outputs of the excitatory neurons code the neuron with the largest 
input. The difference here is that multiple winners can be chosen. 
By varying the voltage reference of the neuron, the network can 
transition between a soft-max behavior and a hard WTA behav- 
ior. I show results from a fabricated chip of 20 neurons in a 1.2pm 
CMOS technology. 
1 Introduction 
Lazzaro and colleagues (Lazzaro, 1988) were the first to implement a hardware 
model of a winner-take-all (WTA) network. This network consists of N excitatory 
cells that are inhibited by a global signal. Improvements of this network with ad- 
dition of positive feedback and lateral connections have been described (Morris, 
1998; Indiveri, 1998). The dynamics and stability properties of networks of cou- 
pled excitatory and inhibitory neurons have been analyzed by many (Amari, 1982; 
Grossberg, 1988). Grossberg described conditions under which these networks will 
exhibit WTA behavior. Lazzaro's network computes a single winner as reflected by 
the outputs of the excitatory cells. Several winners can be chosen by using more 
localized inhibition. 
In this work, I describe two variants of a similar architecture where the outputs of 
the excitatory neurons code the relative input strengths as in a soft-max compu- 
tation. The relative values of the outputs depend on the number of inputs, their 
relative strengths and two parameter settings in the network. The global inhibitory 
718 S.-C. Liu 
ei_ 1 ei ei+ 1 
Yi-1 
wi. 
Yi+l 
Wi+l 
Figure 1: Network model of recurrent inhibitory network. 
signal can also be used as an output. This output saturates with increasing num- 
ber of active inputs, and the saturation level depends on the input strengths and 
parameter settings. This normalization property is similar to the normalization be- 
havior of the wide-field direction-selective cells in the fly visual system. These cells 
code the temporal frequency of the visual inputs and are largely independent of the 
stimulation size. The circuitry in each neuron in the silicon network is equivalent 
to that in Lazzaro et. al.'s hard WTA network with an additional transistor and 
a voltage reference. By varying the voltage reference, the network can transition 
between a soft-max computation and a hard WTA computation. In the two vari- 
ants, the outputs of the excitatory neurons either code the strength of the inputs 
or are normalized with respect to a constant bias current. Results from a fabri- 
cated network of 20 neurons in a 1.2/zm AMI CMOS show the different regimes of 
operation. 
2 Network with Global Inhibition 
The generic architecture of a recurrent network with excitatory neurons and a single 
inhibitory neuron is shown in Figure 1. The excitatory neurons receive an external 
input, and they synapse onto a global inhibitory neuron. The inhibitory neuron, in 
turn, inhibits the excitatory neurons. The dynamics of the network is described as 
follows: 
N 
dyi 
dt = -Yi + ei - g(E wjyj) (1) 
j=l 
where wj is the weight of the synapse between the jth excitatory neuron and the 
inhibitory neuron, and yj is the state of the jth neuron. Under steady-state condi- 
N 
tions, Yi = ei -- YT, where YT = g(j= wjyj). 
Assume a linear relationship between YT and yj, and letting wj - w, 
N -V= 1 ej 
YT = w E YJ -- w 
l+wN 
j=l 
As N increases, YT -- --1 e 
N . If all inputs have the same level, e, then YT -- e. 
A Yrinner-Take-All Circuit with Controllable Soft Max Property 719 
Iol 
VT 
Vr2 
Figure 2: First variant of the architecture. Here we show the circuit for two excita- 
tory neurons and the global inhibition neuron, M4. The circuit in each excitatory 
neuron consists of an input current source, I, and transistors, M to M3. The 
inhibitory transistor is a fixed current source, Ib. The inputs to the inhibitory 
transistor, Io and I;2 are normalized with respect to Ib. 
3 First Variant of Network with Fixed Current Source 
In Sections 3 and 4, I describe two variants of the architecture shown in Figure 
1. The two variants differ in the way that the inhibition signal is generated. The 
first network in Figure 2 shows the circuitry for two excitatory neurons and the 
inhibition neuron. Each excitatory neuron is a linear threshold unit and consists of 
an input current, I, and transistors, M, M2, and M3. The state of the neuron is 
represented by the current, Ir. The diode-connected transistor, M, introduces a 
rectifying nonlinearity into the system since It1 cannot be negative. The inhibition 
current, IT, is sunk by M, and is determined by the gate voltage, VT. The inhibition 
neuron consists of a current source, Ib, and VT is determined by the corresponding 
current, I and the corresponding transistor, Ms in each neuron. Notice that IT 
cannot be greater than the largest input to the network and the inputs to this 
network can only be excitatory. The input currents into the transistor, M4, are 
defined as Io and lo2 and are normalized with respect to the current source, Ib. In 
the hard WTA condition, the output current of the winning neuron is equal to the 
bias current, I,. 
This network exhibits either a soft-maximum behavior or a hard WTA behavior 
depending on the value of an external bias, Va. The inhibition current, IT, is 
derived as: 
INIi Nil 
- - (2) 
+ + N 
where N is the number of active excitatory neurons (that is, neurons whose 
Ii > IT), Ii is the same input current to each neuron, and Is - Ioe v/r. In 
deriving the above equation, we assumed that  - 1. The inhibition current, IT, is 
a linear combination of the states of the neurons because IT = Y. Ii x I/I. 
Figure 3(a) shows the response of the common-node voltage, VT, as a function of 
the number of inputs for different input values measured from a fabricated silicon 
network of 20 neurons. The input current to each neuron is provided by a pFET 
transistor that is driven by the gate voltage, V/n. All input currents are equal in 
this figure. The saturation behavior of the network as a function of the number 
720 S.-C. 
o. O.o% 
Number of inpu Number of inputs 
(a) (b) 
Figure 3: (a) Common-node voltage, VT, as a function of the number of input 
stimuli. Va = 0.8V. (b) Common-node voltage, VT, as a function of the number 
of inputs with an input voltage of 4.3V and Vb - 0.7V. The curves correspond to 
different values of Va. 
of inputs can be seen in the different traces and the saturation level increases as 
�n decreases. As seen in Equation 2, the point at which the response saturates is 
dependent on the ratio, It,/Ia. In Figure 3(b), I show how the curve saturates at 
different points for different values of Va and a fixed Ib and V/n. 
In Figure 4, I set all inputs to zero except for two inputs, n and Vin2 that are set 
to the same value. I measured Io and Io as a function of Va as shown in Figure 
4(a). The four curves correspond to four values of �n. Initially both currents Io 
and Io2 are equal as is expected in the soft-max condition. As Va increases, the 
network starts exhibiting a WTA behavior. One of the output currents finally goes 
to zero above a critical value of Va. This critical value increases for higher input 
currents because of transistor backgate effects. In Figure 4(b), I show how the 
output currents respond as a function of the differential voltage between the two 
inputs as shown in Figure 4. Here, I fixed one input at 4.3V and swept the second 
input differentially around it. The different curves correspond to different values of 
Va. For a low value of Va, the linear differential input range is about 100mV. This 
linear range decreases as Va is increased (corresponding to the WTA condition). 
4 
Second Variant with Diode-Connected Inhibition 
Transistor 
In the second variant shown in Figure 5, the current source, M4 is replaced by a 
diode-connected transistor and the output currents, Ioi, follow the magnitude of 
the input currents. The inhibition current, IT, can be expressed as follows: 
I T : (IrilIoi) X Ia 
(s) 
where Ia is defined in Section 3. We sum Equation 3 over all neurons and assuming 
equal inputs, we get IT = v/ Iri x Ia. This equation shows that the feedback 
signal has a square root dependence on the neuron states. As we will see, this 
causes the feedback signal to saturate quickly with the number of inputs. 
A I4qnner-Take-All Circuit with Controllable Soft Max Property 721 
Vin=4.3V 4 2V4 1� p 
: ? 4'�5/ l 
0.5 0.6 0.7 0.8 
Va (v) 
2.5 
10 -7 
Va---O.7V 
-0.2 
?;' - Va--O.4V 
-0.1 0 0.1 0.2 0.3 
Vin2-Vin 1 (V) 
(a) (b) 
Figure 4: (a) Output currents, Io and Io2, as a function of V*` for a subthreshold 
bias current and �n - 4.0V to 4.3V. (b) Outputs, Io and Io2, as a function of the 
differential input voltage, AV/n, with �n = 4.3V. 
Irl I 
_- 
() I2 
Ir2 
Figure 5: Second variant of network. The schematic shows two excitatory neurons 
with diode-connected inhibition transistor. 
Substituting Iri = Ii - IT in Equation 3, we solve for IT, 
IT = -I*`N + I 
N 
(I*`N) 2 + 41,, EIi (4) 
i 
From measurements from a fabricated circuit 
