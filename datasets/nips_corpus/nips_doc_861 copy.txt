The Electrotonic Transformation: 
a Tool for Relating Neuronal Form to Function 
Nicholas T. Carnevale 
Department of Psychology, 
Yale University 
New Haven, CT 06520 
Brenda J. Claiborne 
Division of Life Sciences 
University of Texas 
San Antonio, TX 79285 
Kenneth Y. Tsai 
Department of Psychology 
Yale University 
New Haven, CT 06520 
Thomas H. Brown 
Department of Psychology 
Yale University 
New Haven, CT 06520 
Abstract 
The spatial distribution and time course of electrical signals in neurons 
have important theoretical and practical consequences. Because it is 
difficult to infer how neuronal form affects electrical signaling, we 
have developed a quantitative yet intuitive approach to the analysis of 
electrotonus. This approach transforms the architecture of the cell 
from anatomical to electrotonic space, using the logarithm of voltage 
attenuation as the distance metric. We describe the theory behind this 
approach and illustrate its use. 
1 INTRODUCTION 
The fields of computational neuroscience and artificial neural nets have enjoyed a 
mutually beneficial exchange of ideas. This has been most evident at the network level, 
where concepts such as massive parallelism, lateral inhibition, and recurrent excitation 
have inspired both the analysis of brain circuits and the design of artificial neural net 
architectures. 
Less attention has been given to how properties of the individual neurons or processing 
elements contribute to network function. Biological neurons and brain circuits have 
70 Nicholas Carnevale, Kenneth Y. Tsai, Brenda J. Claiborne, Thomas H. Brown 
been simultaneously subject to eons of evolutionary pressure. This suggests an essential 
interdependence between neuronal form and function, on the one hand, and the overall 
architecture and operation of biological neural nets, on the other. Therefore reverse- 
engineering the circuits of the brain appears likely to reveal design principles that rely 
upon neuronal properties. These principles may have maximum utility in the design of 
artificial neural nets that are constructed of processing elements with greater similarity 
to biological neurons than those which are used in contemporary designs. 
Spatiotemporal extent is perhaps the most obvious difference between real neurons and 
processing elements. The processing element of most artificial neural nets is essentially 
a point in time and space. Its activation level is the instantaneous sum of its synaptic 
inputs. Of particular relevance to Hebbian learning rules, all synapses are exposed to 
the same activation level. These simplifications may insure analytical and implementa- 
tional simplicity, but they deviate sharply from biological reality. Membrane potential, 
the biological counterpart of activation level, is neither instantaneous nor spatially 
uniform. Every cell has finite membrane capacitance, and all ionic currents are finite, 
so membrane potential must lag behind synaptic inputs. Furthermore, membrane 
capacitance and cytoplasmic resistance dictate that membrane potential will almost 
never be uniform throughout a living neuron embedded in the circuitry of the brain. 
The combination of ever-changing synaptic inputs with cellular anatomical and 
biophysical properties guarantees the existence of fluctuating electrical gradients. 
Consider the task of building a massively parallel neural net from processing elements 
with such nonideal characteristics. Imagine moreover that the input surface of each 
processing element is an extensive, highly branched structure over which approximately 
10,000 synaptic inputs are distributed. It might be tempting to try to minimize or work 
around the limitations imposed by device physics. Howevei', a better strategy might be 
to exploit the computational consequences of these properties by making them part of 
the design, thereby turning these apparent weaknesses into strengths. 
To facilitate an understanding of the spatiotemporal dynamics of electrical signaling in 
neurons, we have developed a new theoretical approach to linear electrotonus and a new 
way to make practical use of this theory. We present this method and illustrate its 
application to the analysis of synaptic interactions in hippocampal pyramidal cells. 
2 THEORETICAL BACKGROUND 
Our method draws upon and extends the results of two prior approaches: cable theory 
and two-port analysis. 
2.1 CABLE THEORY 
The modern use of cable theory in neuroscience began almost four decades ago with the 
work of Rall (1977). Much of the attraction of cable theory derives from the conceptual 
simplicity of the steady-state decay of voltage with distance along an infinite cylindrical 
cable: Y(x) = Vo e-x/ where x is physical distance and 2 is the length constant. This 
exponential relationship makes it useful to define the electrotonic distance X as the 
The Electronic Transfortnation.' A Tool for Relating Neuronal Fortn to Function 71 
logarithm of the signal attenuation: X = lnFo/V(x ). In an infinite cylindrical cable, 
electrotonic distance is directly proportional to physical distance: X = x/2. 
However, cable theory is difficult to apply to real neurons since dendritic trees are 
neither infinite nor cylindrical. Because of their anatomical complexity and irregular 
variations of branch diameter and length, attenuation in neurons is not an exponential 
function of distance. Even if a cell met the criteria that would allow its dendrites to be 
reduced to a finite equivalent cylinder (Rall 1977), voltage attenuation would not bear a 
simple exponential relationship to X but instead would vary inversely with a hyperbolic 
function (Jack et al. 1983). 
2.2 TWO-PORT THEORY 
Because of the limitations and restrictions of cable theory, Carnevale and Johnston 
(1982) turned to two-port analysis. Among their conclusions, three are most relevant to 
this discussion. 
Figure 1: Attenuation is direction-dependent. 
The first is that signal attenuation depends on the direction of signal propagation. 
Suppose that i and j are two points in a cell where i is upstream from j (voltage is 
spreading from i to j), and define the voltage attenuation from i to j: A(' = Vt/V  . Next 
suppose that the direction of signal propagation is reversed, so that j is now upstream 
from i, and define the voltage attenuation A( = Vj/V,. In general these two 
Jt 
attenuations will not be equal: A   A  
tj jt 
They also showed that voltage attenuation in one direction is identical to current 
attenuation in the opposite direction (Carnevale and Johnston 1982). Suppose current I i 
enters the cell at i, and the current that is captured by a voltage clamp at j is Ij, and 
define the current attenuation A I =Ii/Ij. Because of the directional reciprocity 
between current and voltage attenuation, A.{ = Ate. Similarly, if we interchange the 
tj gt 
current entry and voltage clamp sites, the current attenuation ratio would be A { = A . 
gt tj 
Finally, they found that charge and DC current attenuation in the same direction are 
identical (Carnevale and Johnston 1982). Therefore the spread of electrical signals 
between any two points is completely characterized by the voltage attenuations in both 
directions. 
72 Nicholas Carnevale, Kenneth Y. Tsai, Brenda J. Claiborne, Thomas H. Brown 
2.3 THE ELECTROTONIC TRANSFORMATION 
The basic idea of the electrotonic transformation is to remap the cell from anatomical 
space into electrotonic space, where the distance between points reflects the 
attenuation of an electrical signal spreading between them. Because of the critical role 
of membrane potential in neuronal function, it is usually most appropriate to deal with 
voltage attenuations. 
2.3.1 The Distance Metric 
We use the logarithm of attenuation between points as the distance metric in electrotonic 
space: L = lnA/j (Brown et al. 1992, Zador et al. 1991). To appreciate the utility of 
this definition, consider voltage spreading from point i to point j, and suppose that k is 
on the direct path between i and j. The voltage attenuations are A, = V,/V, 
I/ A Vi/V j = Ai A/c:. This last equation and our definition of L 
Akj = Vk/V J , and = t/ 
establish the additive property of electrotonic distance LO.= Lik + Lkj. That is, 
electrotonic distances are additive over a path that has a consistent direction of signal 
propagation. This justifies using the logarithm of attenuation as a metric for the 
electrical separation between points in a cell. 
At this point several important facts should be noted. First, unlike the electrotonic 
distance X of classical cable theor)', our new definition of electrotonic distance L always 
bears a simple and direct logarithmic relationship to attenuation. Second, because of 
membrane capacitance, attenuation increases with frequency. Since both steady-state 
and transient signals are of interest, we evaluate attenuations at several different 
frequencies. Third, attenuation is direction-dependent and usually asymmetric. 
Therefore at ever), frequency of interest, each branch of the cell has two different 
representations in electrotonic space depending on the direction of signal flow. 
2.3.2 Representing a Neuron in Electrotonic Space 
Since attenuation depends on direction, it is necessary to construct transforms in pairs 
for each frequency of interest, one for signal spread away from a reference point (Vout) 
and the other for spread toward it (Vin). The soma is often a good choice for the 
reference point, but any point in the cell could be used, and a different vantage point 
might be more appropriate for particular analyses. 
The only difference between using one point i as the reference instead of any other point 
j is in the direction of signal propagation along the direct path between i and j (dashed 
arrows in Figure 2), where Vou t relative to i is the same as Ym relative to j and vice 
versa. The directions of signal flow and therefore the attenuations alo
