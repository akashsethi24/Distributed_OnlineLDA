An Apobayesian Relative of Winnow 
Nick Littlestone 
NEC Research Institute 
4 Independence Way 
Princeton, NJ 08540 
Chris Mesterharm 
NEC Research Institute 
4 Independence Way 
Princeton, NJ 08540 
Abstract 
We study a mistake-driven variant of an on-line Bayesian learn- 
ing algorithm (similar to one studied by Cesa-Bianchi, Helmbold, 
and Panizza [CHP96]). This variant only updates its state (learns) 
on trials in which it makes a mistake. The algorithm makes binary 
classifications using a linear-threshold classifier and runs in time lin- 
ear in the number of attributes seen by the learner. We have been 
able to show, theoretically and in simulations, that this algorithm 
performs well under assumptions quite different from those embod- 
ied in the prior of the original Bayesian algorithm. It can handle 
situations that we do not know how to handle in linear time with 
Bayesian algorithms. We expect our techniques to be useful in 
deriving and analyzing other apobayesian algorithms. 
I Introduction 
We consider two styles of on-line learning. In both cases, learning proceeds in a 
sequence of trials. In each trial, a learner observes an instance to be classified, 
makes a prediction of its classification, and then observes a label that gives the 
correct classification. One style of on-line learning that we consider is Bayesian. 
The learner uses probabilistic assumptions about the world (embodied in a prior 
over some model class) and data observed in past trials to construct a probabilistic 
model (embodied in a posterior distribution over the model class). The learner uses 
this model to make a prediction in the current trial. When the learner is told the 
correct classification of the instance, the learner uses this information to update the 
model, generating a new posterior to be used in the next trial. 
In the other style of learning that we consider, the attention is on the correctness 
of the predictions rather than on the model of the world. The internal state of the 
An Apobayesian Relative of Winnow 205 
learner is only changed when the learner makes a mistake (when the prediction fails 
to match the label). We call such an algorithm mistake-driven. (Such algorithms are 
often called conservative in the computational learning theory literature.) There is a 
simple way to derive a mistake-driven algorithm from any on-line learning algorithm 
(we restrict our attention in this paper to deterministic algorithms). The derived 
algorithm is just like the original algorithm, except that before every trial, it makes 
a record of its entire state, and after every trial in which its prediction is correct, 
it resets its state to match the recorded state, entirely forgetting the intervening 
trial. (Typically this is actually implemented not by making such a record, but by 
merely omitting the step that updates the state.) For example, if some algorithm 
keeps track of the number of trials it has seen, then the mistake-driven version of 
this algorithm will end up keeping track of the number of mistakes it has made. 
Whether the original or mistake-driven algorithm will do better depends on the task 
and on how the algorithms are evaluated. 
We will start with a Bayesian learning algorithm that we call SBSB and use this 
procedure to derive a mistake-driven variant, SASB. Note that the variant cannot 
be expected to be a Bayesian learning algorithm (at least in the ordinary sense) 
since a Bayesian algorithm would make a prediction that minimizes the Bayes risk 
based on all the available data, and the mistake-driven variant has forgotten quite 
a bit. We call such algorithms apobayesian learning algorithms. This name is 
intended to suggest that they are derived from Bayesian learning algorithms, but 
are not themselves Bayesian. Our algorithm $ASB is very close to an algorithm 
of [CHP96]. We study its application to different tasks than they do, analyzing its 
performance when it is applied to linearly separable data as described below. 
In this paper instances will be chosen from the instance space X - {0, 1} ' for some 
n. Thus instances are composed of n boolean attributes. We consider only two 
category classifications tasks, with predictions and labels chosen from Y = {0, 1}. 
We obtain a, bound on the number of mistakes SASB makes that is comparable to 
bounds for various Winnow family algorithms given in [Lit88,Lit89]. As for those 
algorithms, the bound holds under the assumption that the points labeled I are 
linearly separable from the points labeled 0, and the bound depends on the size 5 of 
the gap between the two classes. (See Section 3 for a definition of 5.) The mistake 
bound for SASB is O( log ). While this bound has an extra factor of log  not 
present in the bounds for the Winnow algorithms, SASB has the advantage of not 
needing any parameters. The Winnow family algorithms have parameters, and the 
algorithms' mistake bounds depend on setting the parameters to values that depend 
on 5. (Often, the value of 5 will not be known by the learner.) We expect the 
techniques used to obtain this bound to be useful in analyzing other apobayesian 
learning algorithms. 
A number of authors have done related research regarding worst-case on-line 
loss bounds including [Fre96,KW95,Vov90]. Simulation experiments involving a 
Bayesian algorithm and a mistake-driven variant are described in [Lit95]. That 
paper provides useful background for this paper. Note that our present analysis 
techniques do not apply to the apobayesian algorithm studied there. The closest of 
the original Winnow family algorithms to SASB appears to be the Weighted Ma- 
jbrity algorithm [LW94], which was analyzed for a case similar to that considered 
'n this paper in [Lit89]. One should get a roughly correct impression of SASB if 
206 N. Littlestone and C. Mesterharm 
one thinks of it as a version of the Weighted Majority algorithm that learns its 
parameters. 
In the next section we describe the Bayesian algorithm that we start with. In 
Section 3 we discuss its mistake-driven apobayesian variant. Section 4 mentions 
some simulation experiments using these algorithms, and Section 5 is the conclusion. 
2 A Bayesian Learning Algorithm 
To describe the Bayesian learning algorithm we must specify a family of distribu- 
tions over X x Y and a prior over this family of distributions. We parameterize 
the distributions with parameters (91,... ,gn+x) chosen from O - [0, 1] n+x. The 
parameter 9+x gives the probability that the label is 1, and the parameter 9i gives 
the probability that the ith attribute matches the label. Note that the probability 
that the ith attribute is I given that the label is I equals the probability that the 
ith attribute is 0 given that the label is 0. We speak of this linkage between the 
probabilities for the two classes as a symmetry condition. With this linkage, the 
observation of a point from either class will affect the posterior distribution for both 
classes. It is perhaps more typical to choose priors that allow the two classes to be 
treated separately, so that the posterior for each class (giving the probability of ele- 
ments of X conditioned on the label) depends only on the prior and on observations 
from that class. The symmetry condition that we impose appears to be important 
to the success of our analysis of the apobayesian variant of this algorithm. (Though 
we impose this condition to derive the algorithm, it turns out that the apobayesian 
variant can actually handle tasks where this condition is not satisfied.) 
We choose a prior on O that gives probability I to the set of all elements 
1 
 -- (1,..., n+X) E ) for which at most one of x,... ,, does not equal . 
The prior is uniform on this set. Note that for any ) in this set only a single at- 
1 of matching the label, and thus only a single 
tribute has a probability other than  
attribute is relevant. Concentrating on this set turns out to lead to an apobayesian 
algorithm that can, in fact, handle more than one relevant attribute and that per- 
forms particularly well when only a small fraction of the attributes are relevant. 
This prior is related to to the familiar Naive Bayes model, which also assumes 
that the attributes are conditionally independent given the labels. However, in the 
typical Naive Bayes model there is no restriction to a single relevant attribute and 
the symmetry condition linking the two classes is not imposed. 
Our prior leads to the following algorithm. (The name $BSB stands for Symmetric 
Bayesian Algorithm with Singly-variant prior for Bernoulli distribution.) 
Algorithm SBSB Algorithm $BSB maintains counts si of the number of times 
each attribute matches the label, a count M of the number of times the label is 1, 
and a count t of the number of trials. 
Initialization si - 0 for i = 1,..., n 
M-0 t-0 
Prediction Predict I given instance (x,...,x) if and only if 
n xi(si-l)-]-(1--xi)(--si-]-X) n 
(M+I), (st,) > (t-M+l) 
i----1 i=1 (Sti) 
Update M-M+y,t-t+l, and for each i , ifxi-ythensi-si+l 
An Apobayesian Relative of Winnow 207 
3 An Apobayesian Algorithm 
We construct an apobayesian algorithm by converting algorithm SBSB into a 
mistake-driven algorithm using the standard conversion given in the introduction. 
We call the resulting learning algorithm SASB; we have replaced Bayesian with 
Apobayesian in the acronym. 
In the previous section we made assumptions made about the generation of the 
instances and labels that led to SBSB and thence to SASB. These assumptions 
have served their purpose and we now abandon them. In analyzing the apobayesian 
algorithm we do not assume that the instances and labels are generated by some 
stochastic process. Instead we assume that the instance-label pairs in all of the 
trials are linearly-separable, that is, that there exist some Wl,... ,w,, and c such 
n 
that for every instance-label pair (x, y) we have -i=x WiXi -
