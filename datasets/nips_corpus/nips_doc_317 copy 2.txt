Learning Time-varying Concepts 
Anthony Kuh 
Dept. of Electrical Eng. 
U. of Hawaii at Manoa 
Honolulu, HI 96822 
kuh@wiliki.eng.hawaii.edu 
Thomas Petsche 
Siemens Corp. Research 
755 College Road East 
Princeton, NJ 08540 
petsche learning. siemens.com 
Ronald L. Rivest 
Lab. for Computer Sci. 
MIT 
Cambridge, MA 02139 
rivest@theory.lcs.mit.edu 
Abstract 
This work extends computational learning theory to situations in which concepts 
vary over time, e.g., system identification of a time-varying plant. We have 
extended formal definitions of concepts and learning to provide a framework 
in which an algorithm can track a concept as it evolves over time. Given 
this framework and focusing on memory-based algorithms, we have derived 
some PAC-style sample complexity results that determine, for example, when 
tracking is feasible. We have also used a similar framework and focused on 
incremental tracking algorithms for which we have derived some bounds on 
the mistake or error rates for some specific concept classes. 
1 INTRODUCTION 
The goal of our ongoing research is to extend computational learning theory to include 
concepts that can change or evolve over time. For example, face recognition is complicat- 
ed by the fact that a persons face changes slowly with age and more quickly with changes 
in make up, hairstyle, or facial hair. Speech recognition is complicated by the fact that 
a speakers voice may change over time due to fatigue, illness, stress, or background 
noise (Galletti and Abbott, 1989). 
Time varying systems often appear in adaptive control or signal processing applications. 
For example, adaptive equalizers adjust the receiver and transmitter to compensate for 
changes in the noise on a transmission channel (Lucky et al., 1968). The kinematics of 
a robot arm can change when it picks up a heavy load or when the motors and drive 
train responses change due to wear. The output of a sensor may drift over time as the 
components age or as the temperature changes. 
183 
184 Kuh, Petsche, and Rivest 
Computational learning theory as introduced by Valiant (1984) can make some useful 
statements about whether a given class of concepts can be learned and provide proba- 
bilistic bounds on the number of examples needed to learn a concept. Haussler, et al. 
(1987), and Littlestone (1989) have also shown that it is possible to bound the number of 
mistakes that a learner will make. However, while these analyses allow the concept to be 
chosen arbitrarily, that concept must remain fixed for all time. Littlestone and Warmuth 
(1989) considered concepts that may drift, but in the context of a different accuracy 
measure than we use. Our research seeks explore further modifications to existing theory 
to allow the analysis of performance when learning time-varying concept. 
In the following, we describe two approaches we are exploring. Section 3 describes 
an extension of the PAC-model to include time-varying concepts and shows how this 
new model applies to algorithms that base their hypotheses on a set of stored examples. 
Section 4 described how we can bound the mistake rate of an algorithm that updates its 
estimate based on the most recent example. In Section 2 we define some notation and 
terminology that is used in the remainder of the based. 
2 NOTATION & TERMINOLOGY 
For a dichotomy that labels each instance as a positive or negative example of a concept, 
we can formally describe the model as follows. Each instance xi is drawn randomly, 
according to an arbitrary fixed probability distribution, from an instance space X. The 
concept c to be learned is drawn randomly, according to an arbitrary fixed probability 
distribution, from a concept class C. Associated with each instance is a label ai = c(xi) 
such that ai - 1 if xi is a positive example and ai = 0 otherwise. The learner is presented 
with a sequence of examples (each example is a pair {xi, ai)) chosen randomly from X. 
The learner must form an estimate, , of c based on these examples. 
In the time-varying case, we assume that there is an adversary who can change c over 
time, so we change notation slightly. The instance xt is presented at time t. The concept 
ct is active at time t if the adversary is using ct to label instances at that time. The 
sequence of t active concepts, ct -- {cl,..., ct} is called a concept sequence of length t. 
The algorithm's task is to form an estimate -t of the actual concept sequence ct, i.e., at 
each time t, the tracker must use the sequence of randomly chosen examples to form an 
estimate t of ct. A set of length t concept sequences is denoted by C(t) and we call a 
set of infinite length concept sequences a concept sequence space and denote it by C. 
Since the adversary, if allowed to make arbitrary changes, can easily make the tracker's 
task impossible, it is usually restricted such that only small or infrequent changes are 
allowed. In other words, each C(t) is a small subset of C t. 
We consider two different types of different types of tracking (learning) algorithms, 
memory-based (or batch) and incremental (or on-line). We analyze the sample complexity 
of batch algorithms and the mistake (or error) rate of incremental algorithms. 
In t,he usual case where concepts are time-invariant, batch learning algorithms operate 
in two distinct phases. During the first phase, the algorithm collects a set of training 
examples. Given this set, it then computes a hypothesis. In the second phase, this 
hypothesis is used to classify all future instances. The hypothesis is never again updated. 
In Section 3 we consider memory-based algoritms derived from batch algorithms. 
Learning Time-varying Concepts 185 
When concepts are time-invariant, an on-line learning algorithm is one which constantly 
modifies its hypothesis. On each iteration, the leamer (1) receives an instance; (2) predicts 
a label based on the current hypothesis; (3) receives the correct label; and (4) uses the 
correct label to update the hypothesis. In Section 4, we consider incremental algorithms 
based on on-line algorithms. 
When studying learnability, it is helpful to define the Vapnik-Chervonenkis (VC) dimen- 
sion (Vapnik and Chervonenkis, 1971) of a concept class: VCdim(C) is the cardinality 
of the largest set such that every possible labeling scheme is achieved by some concept 
in C. Blumer et al. (1989) showed that a concept class is learnable if and only if the 
VC-dimension is finite and derived an upper bound (that depends on the VC dimension) 
for the number of examples need to PAC-leam a learnable concept class. 
3 MEMORY-BASED TRACKING 
In this section, we will consider memory-based trackers which base their current hypoth- 
esis on a stored set of examples. We build on the definition of PAC-leaming to define 
what it means to PAC-track a concept sequence. Our main result here is a lower bound 
on the maximum rate of change that can be PAC-tracked by a memory-based learner. 
A memory-based tracker consists of (a) a function w(e, 6); and (b) an algorithm � that 
produces the current hypothesis, t using the most recent w (e, 6) examples. The memory- 
based tracker thus maintains a sliding window on the examples that includes the most 
recent w (e, 6) examples. We do not require that � run in polynomial time. 
Following the work of Valiant (1984) we say that an algorithm .,4 PAC-tracks a concept 
sequence space � C_ � if, for any c  �, any distribution D on X, any e, 6 > 0, and 
access to examples randomly selected from X according to D and labeled at time t by 
concept ct; for all t sufficiently large, with t  chosen uniformly at random between 1 and 
t, it is true that 
Pr(d(ct,,t,) _< 6) >_ 1-6. 
The probability includes any randomization algorithm .4 may use as well as the random 
selection of t  and the random selection of examples according to the distribution D, 
and where d(c,c') = D(x � c(x)  c'(x)) is the probability that c and c' disagree on a 
randomly chosen example. 
Learnability results often focus on learners that see only positive examples. For many 
concept classes this is sufficient, but for others negative examples are also necessary. 
Natarajan (1987) showed that a concept class that is PAC-leamable can be learned using 
only positive examples if the class is closed under intersection. 
With this in mind, let's focus on a memory-based tracker that modifies its estimate 
using only positive examples. Since PAC-tracking requires that .4 be able to PAC-leam 
individual concepts, it must be true that .4 can PAC-track a sequence of concepts only if 
the concept class is closed under intersection. However, this is not sufficient. 
Observation 1. Assume C is closed under intersection. If positive examples are drawn 
from cl  C prior to time to, and from c2  C, cl C_ c2, after time to, then there exists an 
estimate of c2 that is consistent with all examples drawn from ci. 
The proof of this is straightforward once we realize that if cl _C c2, then all positive 
186 Kuh, Petsche, and Rivest 
examples drawn prior to time to from Cl are consistent with c2. The problem is therefore 
equivalent to tint choosing a set of examples from a subset of c2 and then choosing more 
examples from all of c2 -- it skews that probability distribution, but any estimate of c2 
will include all examples drawn from Cl. 
Consider the set of closed intervals on [0, 1], C = {[a, b] ] 0 _< a, b <_ 1 }. Assume that, 
for some d _> b, ct = Cl = [a,b] for all t _< to and ct = c2 = [a,d] for all t > to. All 
the examples drawn prior to to, {xt ' t < to}, are consistent with c2 and it would be nice 
to use these examples to help estimate c2. How much can these examples help? 
Theorem 1. Assume C is closed under intersection and VCdim(C) is finite; C2 C_ C; 
and .4 has PAC learned Cl  C at time to. Then,for some d such that VCdim(C2) <_ d _< 
VCdim(C ), the maximum number of examples drawn after time to required so that .4 can 
PAC 
