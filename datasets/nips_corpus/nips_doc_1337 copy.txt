Multi-modular Associative Memory 
Nir Levy David Horn 
School of Physics and Astronomy 
Tel-Aviv University Tel Aviv 69978, Israel 
Eytan Ruppin 
Departments of Computer Science & Physiology 
Tel-Aviv University Tel Aviv 69978, Israel 
Abstract 
Motivated by the findings of modular structure in the association 
cortex, we study a multi-modular model of associative memory that 
can successfully store memory patterns with different levels of ac- 
tivity. We show that the segregation of synaptic conductances into 
intra-modular linear and inter-modular nonlinear ones considerably 
enhances the network's memory retrieval performance. Compared 
with the conventional, single-module associative memory network, 
the multi-modular network has two main advantages: It is less sus- 
ceptible to damage to columnar input, and its response is consistent 
with the cognitive data pertaining to category specific impairment. 
I Introduction 
Cortical modules were observed in the somatosensory and visual cortices a few 
decades ago. These modules differ in their structure and functioning but are likely to 
be an elementary unit of processing in the mammalian cortex. Within each module 
the neurons are interconnected. Input and output fibers from and to other cortical 
modules and subcortical areas connect to these neurons. More recently, modules 
were also found in the association cortex [1] where memory processes supposedly 
take place. Ignoring the modular structure of the cortex, most theoretical models 
of associative memory have treated single module networks. This paper develops 
a novel multi-modular network that mimics the modular structure of the cortex. 
In this framework we investigate the computational rational behind cortical multi- 
modular organization, in the realm of memory processing. 
Does multi-modular structure lead to computational advantages? Naturally one 
Multi-modular Associative Memo ry 53 
may think that modules are necessary in order to accommodate memories of dif- 
ferent coding levels. We show in the next section that this is not the case, since 
one may accommodate such memories in a standard sparse coding network . In 
fact, when trying to capture the same results in a modular network we run into 
problems, as shown in the third section: If both inter and intra modular synapses 
have linear characteristics, the network can sustain memory patterns with only a 
limited range of activity levels. The solution proposed here is to distinguish be- 
tween intra-modular and inter-modular couplings, endowing the inter-modular ones 
with nonlinear characteristics. From a computational point of view, this leads to 
a modular network that has a large capacity for memories with different coding 
levels. The resulting network is particularly stable with regard to damage to mod- 
ular inputs. From a cognitive perspective it is consistent with the data concerning 
category specific impairment. 
2 Homogeneous Network 
We study an excitatory-inhibitory associative memory network [2], having N ex- 
citatory neurons. We assume that the network stores M1 memory patterns r/ of 
sparse coding level p and M2 patterns v with coding level f such that p < f << 1. 
The synaptic efficacy Zij between the jth (presynaptic) neuron and the ith (post- 
synaptic) neuron is chosen in the Hebbian manner 
1 M1 1 M 
Jij = Np Z rlrl'J + pp  v,vj , (1) 
/=1 /=1 
The updating rule for the activity state 1 of the ith binary neuron is given by 
�(t + 1) = 13 (hi(t) - O) (2) 
where 13 is the step function and 0 is the threshold. 
hi(t) = 
p 
is the local field, or membrane potential. It includes the excitatory Hebbian coupling 
of all other excitatory neurons, 
N 
(4) 
for the two memory populations as 
1 N 1 N 
mv(t) = vjw(t) ' = . (6) 
The storage capacity ct = M/N of this network has two critical capacities. Ctc 
above which the population of f v patterns is unstable and etch above which the 
population of r/ patterns is unstable. We derived equations for the overlap and 
total activity of the two populations using mean field analysis. Here we give the 
and global inhibition that is proportional to the total activity of the excitatory 
neurons 
N 
1 
Q(t) =   (t). () 
J 
The overlap re(t) between the network activity and the memory patterns is defined 
54 N. Levy, D. Horn and E. Ruppin 
fixed-point equations for the case of M1 -- M2 -- M and = 
'5- 7 Mxf  + MP . 
resulting equations are 
The 
(7) 
and 
where 
and 
(8) 
(9) 
(a) 
(b) 
001, 
0.1 
0.06 
006 0.06 
0.04  0.0 
0.04 
0.0 0.0 
f 0 0 
1 
/ ' q 
' o.4.1 � 
0 , 
0.1 0.06 0.060  
0.06 ' 
.... 0.02,,,,, 
f 0 0 
0.1 0.1 
0.06 
0.06 
0.04 
p p 
Figure 1' (a) The critical capacity ac, rs. f and p for f _> p, 0 = 0.8 and N = 1000. 
(b) (ac n- a)/a nversus f and p for the same parameters as in (a). The validity 
of these analytical results was tested and verified in simulations. 
Next, we look for the critical capacities, a nand a at which the fixed-point 
equations become marginally stable. The results are shown in Figure 1. Figure 1 (a) 
shows acnvs. the coding levels f and p (f _> p). Similar results were obtained for 
ac. As evident the critical capacities of both populations are smaller than the one 
observed in a homogeneous network in which f = p. One hence necessarily pays a 
price for the ability to store patterns with different levels of activity. 
Figure l(b) plots the relative capacity difference (ac n- ac)/acnvs. f and p. The 
function is non negative, i.e., etch >_ rtc for all f and p. Thus, low activity memories 
are more stable than high activity ones. 
Assuming that high activity codes more features [3], these results seem to be at 
odds with the view [3, 4] that memories that contain more semantic features, and 
therefore correspond to larger Hebbian cell assemblies, are more stable, such as 
concrete versus abstract words. The homogeneous network, in which the memories 
with high activity are more susceptible to damage, cannot account for these obser- 
vations. In the next section we show how a modular network can store memories 
with different activity levels and account for this cognitive phenomenon. 
Multi-modular Associative Memo ry 55 
3 Modular Network 
We study a multi modular excitatory-inhibitory associative memory network, stor- 
ing M memory patterns in L modules of N neurons each. The memories are coded 
such that in every memory a variable number f of I to L modules is active. This 
number will be denoted as modular coding. The coding level inside the modules 
is sparse and fixed, i.e., each modular Hebbian cell assembly consists of pN active 
neurons with p << 1. The synaptic efficacy Zij lk between the jth (presynaptic) 
neuron from the kth module and the ith (postsynaptic) neuron from the/th module 
is chosen in a Hebbian manner 
M 
Jijt k _ 1 
where ri'it are the stored memory patterns. The updating rule for the activity state 
�t of the ith binary neuron in the/th module is given by 
(12) 
where 0, is the threshold, and $(x) is a stochastic sigmoid function, getting the 
value 1 with probability (1 + e-) -1 and 0 otherwise. The neuron's local field, or 
membrane potential has two components, 
hit(t) = hiti,t,.,.t(t) + hit:t,.,.t(t) . (13) 
The internal field, hitinternat (t), includes the contributions from all other excitatory 
neurons that are situated in the/th module, and inhibition that is proportional to 
the total modular activity of the excitatory neurons, i.e., 
N 
j.i 
(14) 
where 
The 
N 
@t(t) = Np2Vjt(t) . (15) 
J 
external field component, hit:t,.,,t(t), includes the contributions from all 
other excitatory neurons that are situated outside the/th module, and inhibition 
that is proportional to the total network activity. 
= 6 - Ok(t) - od 
k7l j k 
(16) 
We allow here for the freedom of using more complicated behavior than the standard 
6(x) - x one. In fact, as we will see, the linear case is problematic, since only 
memory storage with limited modular coding is possible. 
The retrieval quality at each trial is measured by the overlap function, defined by 
L N 
rn ' (t) = pNfY' k=l i=1 
where f is the modular coding of 
56 N. Levy, D. Horn and E. Ruppin 
In the simulations we constructed a network of L -- 10 modules, where each module 
contains N = 500 neurons. The network stores M - 50 memory patterns randomly 
distributed over the modules. Five sets of ten memories each are defined. In each 
set the modular coding is distributed homogeneously between one to ten active 
modules. The sparse coding level within each module was set to be p = 0.05. Every 
simulation experiment is composed of many trials. In each trial we use as initial 
condition a corrupted version of a stored memory pattern with error rate of 5%, 
and check the network's retrieval after it converges to a stable state. 
1 
o.g 
o.8 
0.7 
0.6 
o.5 
0.4 
0.3 
0.2 
o.1 
o 
1 2 3 
4 5 
Modular Coding 
8 9 lO 
Figure 2: Quality of retrieval rs. memory modular coding. The dark shading repre- 
sents the mean overlap achieved by a network with linear intra-modular and inter- 
modular synaptic couplings. The light shading represents the mean overlap of a 
network with sigmoidal inter-modular connections, which is perfect for all memory 
patterns. The simulation parameters were: L - 10, N - 500, M - 50, p = 0.05, 
.k = 0.7, 0,/= 2 and O = 0.6. 
We start with the standard choice of 6(x) - x, i.e. treating similarly the intra- 
modular and inter-modular synaptic couplings. The performance of this network 
is shown in Figure 2. As evident, the network can store only a relatively narrow 
span of memories with high modular coding levels, and completely fails to retrieve 
memories with low modular coding levels (see also [5]). If, however, 6 is chosen to be 
a sigmoid function, a completely stable system is obtained, with all possible coding 
levels allowed. A sigmoid function on the external connections is hence very effective 
i
