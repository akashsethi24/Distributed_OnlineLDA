Oscillatory Model of Short Term Memory 
David Horn 
School of Physics and Astronomy 
Raymond and Beverly Sackler 
Faculty of Exact Sciences 
Tel-Aviv University 
Tel Aviv 69978, Israel 
Marius Usher* 
Dept. of Applied Mathematics 
and Computer Science 
Weizmann Institute of Science 
Rehovot 76100, Israel 
Abstract 
We investigate a model in which excitatory neurons have dynamical thresh- 
olds which display both fatigue and potentiation. The fatigue property 
leads to oscillatory behavior. It is responsible for the ability of the model 
to perform segmentation, i.e., decompose a mixed input into staggered 
oscillations of the activities of the cell-assemblies (memories) affected by 
it. Potentiation is responsible for sustaining these staggered oscillations 
after the input is turned off, i.e. the system serves as a model for short 
term lnemory. It has a limited STM capacity, reminiscent of the magical 
number 7 + 2. 
I Introduction 
The limited capacity (7 -t- 2) of the short term memory (STM) has been a subject 
of major interest in the psychological and physiological literature. It seems quite 
natural to assume that the limited capacity is due to the special dynamical nature 
of STM. Recently, Crick and Koch (1990) suggested that the working memory 
is functionally related to the binding process, and is obtained via synchronized 
oscillations of neural populations. The capacity limitation of STM may then result 
from the competition between oscillations representing items in STM. In the model 
which we investigate this is indeed the case. 
*Present address: Division of Biology, 216-76, Caltech, Pasadena CA 91125. 
125 
126 Horn and Usher 
Models of oscillating neural networks can perform various tasks: 
1. Phase-locking and synchronization in response to global coherence in the stim- 
uli, such as similarity of orientation and continuity (Kamen et al. 1989; Som- 
polinsy et al. 1990; Konig & Schillen 1991). 
2. Segmentation of incoherent stimuli in low level vision via desynchronization, 
using oscillator networks with delayed connections (Schillen & Konig 1991). 
3. Segmentation according to semantic content, i.e., separate an input of mixed in- 
formation into its components which are known memories of the system (Wang 
et al. 1990, Horn and Usher 1991). In these models the memories are repre- 
sented by competing cell assemblies. The input, which affects a subset of these 
assemblies, induces staggered oscillations of their activities. This works as long 
as the number of memories in the input is small, of the order of 5. 
4. Binding, i.e., connecting correctly different attributes of the same object which 
appear in the mixed input (Horn et al. 1991). Binding can be interpreted as 
matching the phases of oscillations representing attributes of the same object 
in two different networks which are coupled in a way which does not assume 
any relation between the attributes. 
To these we add here the important task of 
5. STM, i.e., keeping information about segmentation or binding after the input 
is turned off. 
In order to qualify as models for STM, the staggered oscillations have to prevail 
after the input stimuli disappear. Unfortunately, this does not hold for the models 
quoted above. Once the input disappears, either the network's activity dies out, 
or oscillations of assemblies not included in the original input are turned on. In 
other words, the oscillations have no inertia, and thus they do not persist after the 
disappearance of the sensory input. Our purpose is to present a model of com- 
peting neural assemblies which, upon receiving a mixed input develops oscillations 
which prevail after the stimulus disappears. In order to achieve this, the biological 
mechanism of post tetanic potentiation will be used. 
2 Dynamics of Short Term Potentiation 
It was shown that following a tetanus of electrophysiological stimulation temporary 
modifications in the synaptic strengths, mostly non Hebbian, are observed (Crick 
and Koch, 1990; Zucker, 1989). The time scale of these synaptic modifications 
ranges between 50 ms to several minutes. A detailed description of the processes 
responsible for this mechanisln was given by Zucker (1989), exhibiting a rather com- 
plex behavior. In the following we will use a simplified version of these mechanisms 
involving two processes with different time scales. We assume that following a pro- 
longed activation of a synapse, the synaptic strength exhibits depression on a short 
time scale, but recovers and becomes slightly enhanced on a longer time scale. As 
illustrated in Fig 1 of Zucker (1989), this captures most of the dynamics of Short 
Term Potentiation. The fact that these mechanisms are non Hebbian implies that 
all synapses associated with a presynaptic cell are affected, and thus the unit of 
change is the presynaptic cell (Crick & Koch 1990). 
Oscillatory Model of Short Term Memory 127 
Our previous oscillatory neural networks were based on the assumption that, in 
addition to the customary properties of the formal neuron, its threshold increases 
when the neuron keeps firing, thus exhibiting adaptation or fatigue (Horn & Usher 
1989). Motivated by the STP findings we add a new component of facilitaion, which 
takes place on a longer time scale than fatigue. We denote the dynamical threshold 
by the continuous variable r which is chosen as a sum of two components, f and p, 
representing fatigue and potentiation, 
r=alf -a2p. (1) 
Their dynamics is governed by the equations 
7df /dt = rn + (1/Cl - 1)f 7dp/dt = m q- (1/c2 - 1)p (2) 
where m describes the average neuron activity (firing rate) on a time scale which 
is large compared to the refractory period. The time constants of the fatigue and 
potentiation components, ri = �,_ are chosen so that r < r2. As a result the 
neuron displays fatigue on a short time scale, but recovers and becomes slightly 
enhanced (potentiated) on a longer time scale. This is clearly seen in Fig. 1, which 
shows the behavior when the activity m of the corresponding neuron is clamped at 
i for some time (due to sensory input) and quenched to zero afterwards. 
3 i { 
2 
-1 
/ xf 
\ 
-2 .... I .... I .... I ....  .... 
0 20 40 60 80 100 
time 
Figure 1: Behavior of the dynamic threshold r and its fatigue f and potentiation 
p components, when the neuron activity m is clamped as shown. Time scale is 
arbitrary. The parameters are c = 1.2 c2 = 1.05 a 1 -- 4 a2 = I . 
We observe here that the threshold increases during the cell's activation, being 
driven to its asymptotic value a q-1 After the release of the stimulus the dy- 
�1 
namic threshold decreases (i.e. the neuron recovers) and turns negative (signifying 
128 Horn and Usher 
potentiation). The parameters were chosen so that asymptotically the threshold 
reaches zero, i.e. no permanent effect is left. In our model we will assume a similar 
behavior for the excitatory cell-assemblies which carry the memories in our system. 
3 The Model 
Our basic model (Horn & Usher 1990) is composed of two kinds of neurons which 
are assumed to have excitatory and inhibitory synapses exclusively. Memory pat- 
terns are carried by excitatory neurons only. Furthermore, we make the simplifying 
assumption that the patterns do not overlap with one another, i.e. the model is 
composed of disjoint Hebbian cell-assemblies of excitatory neurons which affect one 
another through their interaction with a single assembly of inhibitory neurons. 
Let us denote by rat`(t) the fraction of cell-assembly number It which fires at time t, 
and by rat(t) the fraction of active inhibitory neurons. We will refer to rat` as the 
activity of the Itth memory pattern. There are P different memories in the model, 
and their activities obey the following differential equations 
drat,/dt = _rat, + Fr(Ara t, _ Bra  _ 0 t, + it,) (3) 
draI /dt = -m I q- FT(CM - Dra I - 0 I) 
where 
M = E rat` FT(X) = (1 + �-x[T)-l. (4) 
0t` and 01 are the thresholds of all excitatory and inhibitory neurons correspondingly 
and it` represents the input into cell assembly It. The four parameters A B C and 
D are all positive and represent the different couplings between the neurons. This 
system is an attractor neural network. In the absence of input and dynamical 
thresholds it is a dissipative system which flows into fixed points determined by the 
memories. 
This system is a generalization of the E-I model of Wilson and Cowan (1972) in 
which we have introduced competing memory patterns. The latter make it into an 
attractor neural network. Wilson and Cowan have shown that a pair of excitatory 
and inhibitory assemblies, when properly connected, will form an oscillator. We 
induce oscillations in a different way, keeping the option of having the network 
behave either as an attractor neural network or as an oscillating one: we turn the 
thresholds of the excitatory neurons into dynamic variables, which are defined by 
The dynamics of the new variables rt` are chosen to follow equations (1) and (2) 
where all elements, r f p and ra refer to the same cell-assembly It. To understand 
the effects of this change let us first limit ourselves to the fatigue component only, 
i.e. al = 1 and a2 = 0 in Eq. 1. Imagine a situation in which the system would flow 
into a fixed point rat` = 1. rt` will then increase until it reaches the value c/(Cl - 1). 
This means that the argument of the F- function in the equation for rat` decreases 
by g = bc/(c - 1) . If this overcomes the effect of the other terms the amplitude 
rat` decreases and the system moves out of the attractor and falls into the basin 
of a different center of attraction. This process can continue indefinitely creating 
Oscillatory Model of Short Term Memory 129 
an oscillatory network which moves from one memory to another. Envisage now 
turning on a pU component leading to an r u behavior of the type depicted in Fig. 
1. Its effect will evidently be the same as the input
